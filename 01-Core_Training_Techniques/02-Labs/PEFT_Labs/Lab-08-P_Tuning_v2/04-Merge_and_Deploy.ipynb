{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: P-Tuning v2 - Deployment Guide\n",
    "\n",
    "## 🎯 實驗目標\n",
    "\n",
    "本 Notebook 探討 **P-Tuning v2 的部署策略與優化方案**。作為深度提示調優方法,P-Tuning v2 在每個 Transformer 層都添加可訓練提示,在技術上**無法合併**到基礎模型中,但其通用性和極致的參數效率使其成為PEFT領域的重要方法。\n",
    "\n",
    "### 關鍵學習要點\n",
    "- 理解 P-Tuning v2 深度提示的部署特性\n",
    "- 掌握多層 Prompt 的優化與管理\n",
    "- 分析 P-Tuning v2 的推理開銷特性\n",
    "- 學習跨任務、跨規模的部署策略\n",
    "- 對比 P-Tuning v2 與其他 PEFT 方法的部署差異\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. P-Tuning v2 部署特性分析\n",
    "\n",
    "### 1.1 為什麼 P-Tuning v2 無法合併?\n",
    "\n",
    "**技術原因**:\n",
    "- **多層深度修改**: 在**每個** Transformer 層都添加虛擬標記,改變了整個模型的前向傳播結構\n",
    "- **動態序列拼接**: 每層都需要動態拼接提示向量,無法靜態融合到權重\n",
    "- **層級依賴性**: 不同層的提示參數相互獨立,無法簡單合併\n",
    "\n",
    "**與其他 PEFT 方法的架構對比**:\n",
    "\n",
    "| 方法 | 修改層級 | 是否可合併 | 推理開銷來源 |\n",
    "|:---|:---|:---|:---|\n",
    "| **LoRA** | 權重矩陣 | ✅ 可合併 | 無 (合併後) |\n",
    "| **IA³** | 激活值 | ✅ 可合併 | 無 (合併後) |\n",
    "| **P-Tuning v1** | 僅輸入層 | ❌ 不可合併 | 低 (MLP + 序列拼接) |\n",
    "| **P-Tuning v2** | **每個層** | ❌ **不可合併** | **中等** (每層拼接) |\n",
    "| **Prefix Tuning** | 每層 KV | ❌ 不可合併 | 中等 (KV注入) |\n",
    "| **Adapter** | 新增模組 | ❌ 不可合併 | 高 (額外層) |\n",
    "\n",
    "### 1.2 P-Tuning v2 的推理開銷分析\n",
    "\n",
    "```python\n",
    "# P-Tuning v2 的前向傳播\n",
    "for layer in transformer_layers:\n",
    "    # 1. 拼接該層的提示向量\n",
    "    layer_prompts = layer_prompt_embeddings  # 形狀: [batch, num_prompts, hidden]\n",
    "    layer_input = concat([layer_prompts, previous_output])  # ← 每層都需拼接\n",
    "    \n",
    "    # 2. 正常的Transformer計算\n",
    "    layer_output = TransformerLayer(layer_input)\n",
    "    \n",
    "    # 3. 移除提示部分,只保留真實序列\n",
    "    previous_output = layer_output[:, num_prompts:, :]\n",
    "```\n",
    "\n",
    "**開銷來源**:\n",
    "- 每層都需要拼接/截取操作\n",
    "- 序列長度增加導致注意力計算量增加\n",
    "- 需要額外的記憶體存儲每層的提示參數\n",
    "\n",
    "**對比其他方法**:\n",
    "- **vs P-Tuning v1**: 開銷更大 (每層都有拼接)\n",
    "- **vs Prefix Tuning**: 類似,但 P-Tuning v2 更簡單 (無MLP)\n",
    "- **vs Adapter**: P-Tuning v2 開銷較小 (無額外FFN層)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 環境準備與模型載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入必要的庫\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from peft import (\n",
    "    PeftModel,\n",
    "    PromptTuningConfig,\n",
    "    get_peft_model,\n",
    "    TaskType\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# 設定設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用設備: {device}\")\n",
    "\n",
    "# 設定隨機種子\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 載入訓練好的 P-Tuning v2 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型路徑設定\n",
    "base_model_name = \"bert-base-uncased\"\n",
    "adapter_path = \"./bert-ptuning-v2-cola\"  # 假設這是訓練好的 P-Tuning v2 路徑\n",
    "num_labels = 2  # CoLA 是二分類任務\n",
    "\n",
    "# 載入基礎模型和 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    num_labels=num_labels,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "print(f\"基礎模型參數量: {base_model.num_parameters():,}\")\n",
    "print(f\"基礎模型記憶體佔用: {base_model.get_memory_footprint() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 P-Tuning v2 adapter (如果存在)\n",
    "if os.path.exists(adapter_path):\n",
    "    # 找到最新的 checkpoint\n",
    "    checkpoints = [d for d in os.listdir(adapter_path) if d.startswith(\"checkpoint-\")]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(\n",
    "            [os.path.join(adapter_path, d) for d in checkpoints],\n",
    "            key=os.path.getmtime\n",
    "        )\n",
    "        peft_model = PeftModel.from_pretrained(base_model, latest_checkpoint)\n",
    "        print(f\"成功載入 P-Tuning v2 adapter: {latest_checkpoint}\")\n",
    "    else:\n",
    "        peft_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "        print(f\"成功載入 P-Tuning v2 adapter: {adapter_path}\")\n",
    "else:\n",
    "    # 如果沒有訓練好的 adapter,創建示範配置\n",
    "    print(\"未找到訓練好的 adapter,創建示範 P-Tuning v2 配置...\")\n",
    "    \n",
    "    # P-Tuning v2 使用 PromptTuningConfig,但會應用到每一層\n",
    "    ptuning_v2_config = PromptTuningConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        num_virtual_tokens=100,  # P-Tuning v2 通常用更多的虛擬標記\n",
    "        prompt_tuning_init=\"RANDOM\"\n",
    "    )\n",
    "    \n",
    "    peft_model = get_peft_model(base_model, ptuning_v2_config)\n",
    "    print(\"創建了示範 P-Tuning v2 模型\")\n",
    "\n",
    "# 顯示可訓練參數統計\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. P-Tuning v2 深度提示結構分析\n",
    "\n",
    "### 3.1 多層 Prompt 參數探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ptuning_v2_structure(model):\n",
    "    \"\"\"分析 P-Tuning v2 的多層結構和參數\"\"\"\n",
    "    ptuning_params = {}\n",
    "    total_params = 0\n",
    "    layer_count = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'prompt' in name.lower() or 'virtual' in name.lower():\n",
    "            ptuning_params[name] = {\n",
    "                'shape': param.shape,\n",
    "                'dtype': param.dtype,\n",
    "                'requires_grad': param.requires_grad,\n",
    "                'num_params': param.numel()\n",
    "            }\n",
    "            total_params += param.numel()\n",
    "            layer_count += 1\n",
    "            \n",
    "            print(f\"P-Tuning v2 參數: {name}\")\n",
    "            print(f\"  形狀: {param.shape}\")\n",
    "            print(f\"  參數量: {param.numel():,}\")\n",
    "            print()\n",
    "    \n",
    "    base_params = sum(p.numel() for p in model.base_model.parameters())\n",
    "    print(f\"=== 統計摘要 ===\")\n",
    "    print(f\"檢測到的 Prompt 層數: {layer_count}\")\n",
    "    print(f\"總 P-Tuning v2 參數量: {total_params:,}\")\n",
    "    print(f\"基礎模型參數量: {base_params:,}\")\n",
    "    print(f\"P-Tuning v2 參數佔比: {total_params / base_params * 100:.4f}%\")\n",
    "    \n",
    "    return ptuning_params, layer_count\n",
    "\n",
    "ptuning_v2_structure, num_layers = analyze_ptuning_v2_structure(peft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 深度提示的計算流程可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ptuning_v2_computation(num_virtual_tokens=100, hidden_size=768, num_layers=12):\n",
    "    \"\"\"\n",
    "    可視化 P-Tuning v2 的深度提示計算流程\n",
    "    \"\"\"\n",
    "    print(\"=== P-Tuning v2 深度提示計算流程 ===\")\n",
    "    print()\n",
    "    print(f\"配置參數:\")\n",
    "    print(f\"  虛擬標記數量: {num_virtual_tokens} tokens/layer\")\n",
    "    print(f\"  隱藏維度: {hidden_size}\")\n",
    "    print(f\"  Transformer 層數: {num_layers}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"計算流程:\")\n",
    "    print()\n",
    "    \n",
    "    seq_len = 128  # 假設的輸入序列長度\n",
    "    \n",
    "    print(f\"層 0 (Embedding 層):\")\n",
    "    print(f\"  輸入: [{seq_len}, {hidden_size}]\")\n",
    "    print(f\"  拼接虛擬標記: [{num_virtual_tokens}, {hidden_size}]\")\n",
    "    print(f\"  輸出: [{num_virtual_tokens + seq_len}, {hidden_size}]\")\n",
    "    print()\n",
    "    \n",
    "    for layer_idx in range(1, num_layers + 1):\n",
    "        if layer_idx <= 2 or layer_idx == num_layers:\n",
    "            print(f\"層 {layer_idx} (Transformer Layer {layer_idx}):\")\n",
    "            print(f\"  輸入: [{num_virtual_tokens + seq_len}, {hidden_size}]\")\n",
    "            print(f\"  Self-Attention: 包含 {num_virtual_tokens} 個虛擬標記\")\n",
    "            print(f\"  FFN 計算\")\n",
    "            print(f\"  輸出: [{num_virtual_tokens + seq_len}, {hidden_size}]\")\n",
    "            print()\n",
    "        elif layer_idx == 3:\n",
    "            print(f\"  ... (中間層省略,結構相同) ...\")\n",
    "            print()\n",
    "    \n",
    "    print(\"最終輸出:\")\n",
    "    print(f\"  移除虛擬標記部分\")\n",
    "    print(f\"  保留真實序列: [{seq_len}, {hidden_size}]\")\n",
    "    print()\n",
    "    \n",
    "    # 參數量計算\n",
    "    total_params = num_layers * num_virtual_tokens * hidden_size\n",
    "    print(\"參數統計:\")\n",
    "    print(f\"  每層參數量: {num_virtual_tokens * hidden_size:,}\")\n",
    "    print(f\"  總參數量: {total_params:,}\")\n",
    "    \n",
    "    base_params = 110 * 1e6  # BERT-base\n",
    "    print(f\"  佔基礎模型比例: {total_params / base_params * 100:.4f}%\")\n",
    "    print()\n",
    "    \n",
    "    # 計算開銷分析\n",
    "    attention_overhead = ((num_virtual_tokens + seq_len)**2 / seq_len**2 - 1) * 100\n",
    "    print(\"推理開銷分析:\")\n",
    "    print(f\"  注意力計算量增加: ~{attention_overhead:.1f}% (每層)\")\n",
    "    print(f\"  記憶體增加: ~{total_params * 2 / 1024**2:.2f} MB (FP16)\")\n",
    "    print(f\"  額外操作: {num_layers} 次拼接/截取\")\n",
    "\n",
    "visualize_ptuning_v2_computation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 推理性能基準測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference(model, tokenizer, test_texts, num_runs=10):\n",
    "    \"\"\"推理性能基準測試\"\"\"\n",
    "    model.eval()\n",
    "    total_time = 0\n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for run in range(num_runs):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            for text in test_texts:\n",
    "                inputs = tokenizer(\n",
    "                    text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=128\n",
    "                )\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                prediction = torch.argmax(outputs.logits, dim=-1).cpu().item()\n",
    "                \n",
    "                if run == 0:\n",
    "                    results.append({'text': text, 'prediction': prediction})\n",
    "            \n",
    "            end_time = time.time()\n",
    "            total_time += (end_time - start_time)\n",
    "    \n",
    "    return total_time / num_runs, results\n",
    "\n",
    "# 測試文本\n",
    "test_texts = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"She enjoys reading books.\",\n",
    "    \"Books enjoys reading she.\",  # 語法錯誤\n",
    "]\n",
    "\n",
    "print(\"=== P-Tuning v2 推理性能測試 ===\")\n",
    "ptuning_v2_time, results = benchmark_inference(peft_model, tokenizer, test_texts)\n",
    "print(f\"平均推理時間: {ptuning_v2_time:.4f} 秒\")\n",
    "print(f\"記憶體使用: {peft_model.get_memory_footprint() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n=== 與基礎模型對比 ===\")\n",
    "base_time, _ = benchmark_inference(base_model, tokenizer, test_texts)\n",
    "print(f\"基礎模型推理時間: {base_time:.4f} 秒\")\n",
    "print(f\"時間開銷: {(ptuning_v2_time - base_time) / base_time * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型保存與部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./bert-ptuning-v2-deployed\"\n",
    "\n",
    "print(f\"=== 保存 P-Tuning v2 模組到: {save_path} ===\")\n",
    "peft_model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(\"✅ 保存成功!\")\n",
    "\n",
    "# 計算模組大小\n",
    "module_size = sum(os.path.getsize(os.path.join(save_path, f)) \n",
    "                  for f in os.listdir(save_path) if os.path.isfile(os.path.join(save_path, f)))\n",
    "print(f\"模組大小: {module_size / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 部署配置與最佳實踐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = {\n",
    "    \"model_info\": {\n",
    "        \"base_model\": base_model_name,\n",
    "        \"peft_method\": \"P-Tuning v2\",\n",
    "        \"num_virtual_tokens_per_layer\": 100,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"mergeable\": False,\n",
    "        \"universal_across_tasks\": True\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"inference_overhead_percent\": (ptuning_v2_time - base_time) / base_time * 100,\n",
    "        \"parameter_efficiency\": \"0.01-0.1%\"\n",
    "    },\n",
    "    \"advantages\": [\n",
    "        \"跨任務通用性極強 (NLU + NLG)\",\n",
    "        \"規模不變性 - 大模型上效果更好\",\n",
    "        \"無需 MLP 編碼器,實現簡單\",\n",
    "        \"接近全參數微調的性能\"\n",
    "    ],\n",
    "    \"deployment_notes\": {\n",
    "        \"best_for\": \"需要跨任務、跨規模通用性的場景\",\n",
    "        \"inference_overhead\": \"中等 (~10-15%),但性能收益顯著\",\n",
    "        \"recommended_scenarios\": [\n",
    "            \"多任務學習\",\n",
    "            \"大規模模型微調\",\n",
    "            \"需要理解+生成能力\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "config_path = os.path.join(save_path, \"deployment_config.json\")\n",
    "with open(config_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(deployment_config, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"=== P-Tuning v2 部署配置 ===\")\n",
    "print(json.dumps(deployment_config, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 總結\n",
    "\n",
    "### P-Tuning v2 的核心價值\n",
    "\n",
    "**獨特優勢**:\n",
    "1. **通用性無與倫比**: 同時適用於 NLU 和 NLG 任務\n",
    "2. **規模不變性**: 模型越大,效果越接近全參數微調\n",
    "3. **實現簡單**: 無需複雜的 MLP 編碼器\n",
    "4. **性能卓越**: 僅 0.1% 參數達到 99%+ 全參數性能\n",
    "\n",
    "**部署權衡**:\n",
    "- ✅ 極致的參數效率和通用性\n",
    "- ⚠️ 存在推理開銷 (但相比性能收益是值得的)\n",
    "- ⚠️ 無法合併,需管理多層提示參數\n",
    "\n",
    "**最佳應用場景**:\n",
    "- 大規模模型的高效微調\n",
    "- 需要跨任務通用性\n",
    "- 追求最優參數效率-性能平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理資源\n",
    "print(\"=== 清理資源 ===\")\n",
    "del peft_model, base_model\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"✅ 完成\")\n",
    "\n",
    "print(\"\\n🎉 Lab 8 - P-Tuning v2 部署指南完成!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
