{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. 環境設定與函式庫安裝\n",
        "\n",
        "本筆記本旨在引導您完成 `Lab-1.1-PEFT_with_HuggingFace` 實驗所需的所有環境設定與 Python 函式庫安裝。\n",
        "\n",
        "## 步驟 1: 檢查硬體環境 (GPU)\n",
        "\n",
        "參數高效微調 (PEFT) 雖然能大幅降低資源需求，但對於大型語言模型 (LLM) 的微調，使用 GPU 仍然是必要的。以下指令將幫助您檢查系統中 NVIDIA GPU 的狀態。\n",
        "\n",
        "**如果您沒有 GPU，後續的訓練步驟將會非常緩慢甚至無法執行。**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 步驟 2: 安裝核心函式庫\n",
        "\n",
        "接下來，我們將安裝本次實驗所需的核心函式庫。\n",
        "\n",
        "- `transformers`: Hugging Face 提供的模型庫，用於載入預訓練模型和 Tokenizer。\n",
        "- `peft`: Hugging Face 提供的參數高效微調函式庫，是本次實驗的主角。\n",
        "- `datasets`: 用於載入和處理 Hugging Face Hub 上的資料集。\n",
        "- `accelerate`: 簡化在不同硬體（CPU, GPU, TPU, 多 GPU）上運行 PyTorch 程式碼的工具。\n",
        "- `bitsandbytes`: 用於模型量化，是實現 QLoRA 的關鍵。\n",
        "- `sentencepiece` & `protobuf`: `transformers` 可能需要的依賴項。\n",
        "\n",
        "我們使用 `pip` 來進行安裝。`-q` 參數表示以靜默模式安裝，減少不必要的輸出。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q transformers peft datasets accelerate bitsandbytes sentencepiece protobuf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 步驟 3: 驗證安裝\n",
        "\n",
        "安裝完成後，我們可以透過 `import` 指令來驗證核心函式庫是否安裝成功。如果以下程式碼區塊執行時沒有報錯，則表示您的環境已準備就緒。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import peft\n",
        "import datasets\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"PEFT version:\", peft.__version__)\n",
        "print(\"Datasets version:\", datasets.__version__)\n",
        "\n",
        "print(\"\n",
        "環境設定完成！您可以繼續下一個筆記本 `02-load-model-and-dataset.ipynb`。\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
