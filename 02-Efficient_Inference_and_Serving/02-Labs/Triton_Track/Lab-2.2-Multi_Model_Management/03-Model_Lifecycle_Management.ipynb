{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-2.2.3: ä¼æ¥­ç´šæ¨¡å‹ç”Ÿå‘½é€±æœŸç®¡ç†\n",
    "\n",
    "## ğŸ¯ å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "- å»ºç«‹å®Œæ•´çš„æ¨¡å‹è¨»å†Šèˆ‡è‡ªå‹•ç™¼ç¾æ©Ÿåˆ¶\n",
    "- å¯¦ç¾æ€§èƒ½ç›£æ§èˆ‡è‡ªå‹•åŒ–è©•ä¼°é«”ç³»\n",
    "- è¨­è¨ˆè‡ªå‹•æ¨¡å‹æ›´æ–°å’Œæ¼‚ç§»æª¢æ¸¬\n",
    "- æŒæ¡æ¨¡å‹é€€å½¹èˆ‡è³‡æºå›æ”¶ç­–ç•¥\n",
    "\n",
    "## ğŸ¢ ä¼æ¥­æ¡ˆä¾‹: VISA ä¿¡ç”¨è©•ä¼°æ¨¡å‹ç”Ÿå‘½é€±æœŸ\n",
    "\n",
    "VISA ç®¡ç†è‘—å…¨çƒæ•¸ç™¾å€‹ä¿¡ç”¨è©•ä¼°æ¨¡å‹ï¼š\n",
    "- **æ¨¡å‹è¨»å†Š**: è‡ªå‹•ç™¼ç¾æ–°éƒ¨ç½²çš„æ¨¡å‹\n",
    "- **æ€§èƒ½ç›£æ§**: å¯¦æ™‚è¿½è¹¤æ¨¡å‹æº–ç¢ºåº¦å’Œæ¥­å‹™æŒ‡æ¨™\n",
    "- **æ¼‚ç§»æª¢æ¸¬**: è­˜åˆ¥æ•¸æ“šåˆ†ä½ˆè®ŠåŒ–å°æ¨¡å‹çš„å½±éŸ¿\n",
    "- **è‡ªå‹•æ›´æ–°**: åŸºæ–¼æ€§èƒ½é–¾å€¼è§¸ç™¼æ¨¡å‹é‡è¨“ç·´\n",
    "- **æ™ºèƒ½é€€å½¹**: å®‰å…¨ä¸‹ç·šéæ™‚æˆ–ä½æ•ˆçš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple, Union\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import logging\n",
    "from scipy import stats\n",
    "import hashlib\n",
    "import threading\n",
    "import queue\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# è¨­å®šæ—¥èªŒ\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"ğŸš€ ä¼æ¥­ç´šæ¨¡å‹ç”Ÿå‘½é€±æœŸç®¡ç† - ç’°å¢ƒæª¢æŸ¥\")\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
    "\n",
    "# æª¢æŸ¥å¿…è¦çš„ä¾è³´\n",
    "required_packages = ['numpy', 'pandas', 'scipy']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"âœ… {package}: å·²å®‰è£\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package}: æœªå®‰è£\")\n",
    "\n",
    "print(\"\\nâœ… ç’°å¢ƒæª¢æŸ¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ æ¨¡å‹è¨»å†Šèˆ‡è‡ªå‹•ç™¼ç¾ç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelStatus(Enum):\n",
    "    \"\"\"æ¨¡å‹ç‹€æ…‹æšèˆ‰\"\"\"\n",
    "    DEVELOPING = \"developing\"\n",
    "    TESTING = \"testing\"\n",
    "    STAGING = \"staging\"\n",
    "    PRODUCTION = \"production\"\n",
    "    DEPRECATED = \"deprecated\"\n",
    "    RETIRED = \"retired\"\n",
    "    FAILED = \"failed\"\n",
    "\n",
    "class PerformanceLevel(Enum):\n",
    "    \"\"\"æ€§èƒ½ç­‰ç´šæšèˆ‰\"\"\"\n",
    "    EXCELLENT = \"excellent\"\n",
    "    GOOD = \"good\"\n",
    "    ACCEPTABLE = \"acceptable\"\n",
    "    POOR = \"poor\"\n",
    "    CRITICAL = \"critical\"\n",
    "\n",
    "@dataclass\n",
    "class ModelMetrics:\n",
    "    \"\"\"æ¨¡å‹æ€§èƒ½æŒ‡æ¨™\"\"\"\n",
    "    accuracy: float\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1_score: float\n",
    "    auc_roc: float\n",
    "    latency_p50_ms: float\n",
    "    latency_p95_ms: float\n",
    "    latency_p99_ms: float\n",
    "    throughput_rps: float\n",
    "    error_rate: float\n",
    "    memory_usage_mb: float\n",
    "    cpu_usage_percent: float\n",
    "    timestamp: datetime\n",
    "    \n",
    "    def get_performance_level(self) -> PerformanceLevel:\n",
    "        \"\"\"æ ¹æ“šæŒ‡æ¨™è¨ˆç®—æ€§èƒ½ç­‰ç´š\"\"\"\n",
    "        # ç¶œåˆè©•åˆ†ç®—æ³•\n",
    "        accuracy_score = min(self.accuracy * 100, 100)\n",
    "        latency_score = max(0, 100 - (self.latency_p99_ms / 10))  # 100ms ç‚ºæ»¿åˆ†\n",
    "        throughput_score = min(self.throughput_rps, 100)\n",
    "        error_score = max(0, 100 - (self.error_rate * 10000))  # 1% éŒ¯èª¤ç‡æ‰£100åˆ†\n",
    "        \n",
    "        overall_score = (accuracy_score * 0.4 + latency_score * 0.2 + \n",
    "                        throughput_score * 0.2 + error_score * 0.2)\n",
    "        \n",
    "        if overall_score >= 90:\n",
    "            return PerformanceLevel.EXCELLENT\n",
    "        elif overall_score >= 80:\n",
    "            return PerformanceLevel.GOOD\n",
    "        elif overall_score >= 70:\n",
    "            return PerformanceLevel.ACCEPTABLE\n",
    "        elif overall_score >= 50:\n",
    "            return PerformanceLevel.POOR\n",
    "        else:\n",
    "            return PerformanceLevel.CRITICAL\n",
    "\n",
    "@dataclass\n",
    "class ModelRegistration:\n",
    "    \"\"\"æ¨¡å‹è¨»å†Šä¿¡æ¯\"\"\"\n",
    "    model_id: str\n",
    "    name: str\n",
    "    version: str\n",
    "    description: str\n",
    "    owner_team: str\n",
    "    business_domain: str\n",
    "    model_type: str\n",
    "    framework: str\n",
    "    training_dataset: str\n",
    "    registered_at: datetime\n",
    "    last_updated: datetime\n",
    "    status: ModelStatus\n",
    "    deployment_config: Dict[str, Any]\n",
    "    performance_thresholds: Dict[str, float]\n",
    "    monitoring_config: Dict[str, Any]\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "    dependencies: List[str] = field(default_factory=list)\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        data = asdict(self)\n",
    "        data['status'] = self.status.value\n",
    "        data['registered_at'] = self.registered_at.isoformat()\n",
    "        data['last_updated'] = self.last_updated.isoformat()\n",
    "        return data\n",
    "\n",
    "class ModelRegistry:\n",
    "    \"\"\"ä¼æ¥­ç´šæ¨¡å‹è¨»å†Šä¸­å¿ƒ\"\"\"\n",
    "    \n",
    "    def __init__(self, storage_path: str = \"./model_registry\"):\n",
    "        self.storage_path = Path(storage_path)\n",
    "        self.storage_path.mkdir(exist_ok=True)\n",
    "        self.models: Dict[str, ModelRegistration] = {}\n",
    "        self.model_metrics: Dict[str, List[ModelMetrics]] = {}\n",
    "        self.auto_discovery_enabled = True\n",
    "        self._load_registry_data()\n",
    "    \n",
    "    def register_model(self, registration: ModelRegistration) -> bool:\n",
    "        \"\"\"è¨»å†Šæ–°æ¨¡å‹\"\"\"\n",
    "        try:\n",
    "            # æª¢æŸ¥æ¨¡å‹IDå”¯ä¸€æ€§\n",
    "            if registration.model_id in self.models:\n",
    "                logger.warning(f\"æ¨¡å‹ {registration.model_id} å·²å­˜åœ¨ï¼Œæ›´æ–°è¨»å†Šä¿¡æ¯\")\n",
    "            \n",
    "            # é©—è­‰å¿…è¦å­—æ®µ\n",
    "            self._validate_registration(registration)\n",
    "            \n",
    "            # è¨­ç½®é è¨­çš„æ€§èƒ½é–¾å€¼\n",
    "            if not registration.performance_thresholds:\n",
    "                registration.performance_thresholds = self._get_default_thresholds()\n",
    "            \n",
    "            # è¨­ç½®é è¨­çš„ç›£æ§é…ç½®\n",
    "            if not registration.monitoring_config:\n",
    "                registration.monitoring_config = self._get_default_monitoring_config()\n",
    "            \n",
    "            self.models[registration.model_id] = registration\n",
    "            self.model_metrics[registration.model_id] = []\n",
    "            \n",
    "            self._save_registry_data()\n",
    "            \n",
    "            logger.info(f\"âœ… æ¨¡å‹ {registration.model_id} è¨»å†ŠæˆåŠŸ\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ æ¨¡å‹è¨»å†Šå¤±æ•—: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def update_model_status(self, model_id: str, new_status: ModelStatus, reason: str = \"\") -> bool:\n",
    "        \"\"\"æ›´æ–°æ¨¡å‹ç‹€æ…‹\"\"\"\n",
    "        if model_id not in self.models:\n",
    "            logger.error(f\"æ¨¡å‹ {model_id} ä¸å­˜åœ¨\")\n",
    "            return False\n",
    "        \n",
    "        old_status = self.models[model_id].status\n",
    "        self.models[model_id].status = new_status\n",
    "        self.models[model_id].last_updated = datetime.now()\n",
    "        \n",
    "        self._save_registry_data()\n",
    "        \n",
    "        logger.info(f\"ğŸ”„ æ¨¡å‹ {model_id} ç‹€æ…‹æ›´æ–°: {old_status.value} -> {new_status.value}\")\n",
    "        if reason:\n",
    "            logger.info(f\"   åŸå› : {reason}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def record_metrics(self, model_id: str, metrics: ModelMetrics) -> bool:\n",
    "        \"\"\"è¨˜éŒ„æ¨¡å‹æ€§èƒ½æŒ‡æ¨™\"\"\"\n",
    "        if model_id not in self.models:\n",
    "            logger.error(f\"æ¨¡å‹ {model_id} ä¸å­˜åœ¨\")\n",
    "            return False\n",
    "        \n",
    "        if model_id not in self.model_metrics:\n",
    "            self.model_metrics[model_id] = []\n",
    "        \n",
    "        self.model_metrics[model_id].append(metrics)\n",
    "        \n",
    "        # åªä¿ç•™æœ€è¿‘1000æ¢è¨˜éŒ„\n",
    "        if len(self.model_metrics[model_id]) > 1000:\n",
    "            self.model_metrics[model_id] = self.model_metrics[model_id][-1000:]\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦è§¸ç™¼å‘Šè­¦\n",
    "        self._check_performance_alerts(model_id, metrics)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def discover_models(self, triton_url: str = \"http://localhost:8000\") -> List[str]:\n",
    "        \"\"\"è‡ªå‹•ç™¼ç¾ Triton æœå‹™å™¨ä¸Šçš„æ¨¡å‹\"\"\"\n",
    "        discovered_models = []\n",
    "        \n",
    "        try:\n",
    "            # æ¨¡æ“¬ Triton API èª¿ç”¨\n",
    "            # å¯¦éš›ç’°å¢ƒä¸­æœƒèª¿ç”¨: GET /v2/models\n",
    "            mock_triton_models = [\n",
    "                {\n",
    "                    'name': 'credit_scoring_v1',\n",
    "                    'version': '1.0.0',\n",
    "                    'state': 'READY',\n",
    "                    'backend': 'pytorch'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'fraud_detection_v2',\n",
    "                    'version': '2.1.0',\n",
    "                    'state': 'READY',\n",
    "                    'backend': 'onnx'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'risk_assessment_v3',\n",
    "                    'version': '3.0.0-beta',\n",
    "                    'state': 'READY',\n",
    "                    'backend': 'python'\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            for model_info in mock_triton_models:\n",
    "                model_id = f\"{model_info['name']}_{model_info['version']}\"\n",
    "                \n",
    "                # å¦‚æœæ¨¡å‹æœªè¨»å†Šï¼Œè‡ªå‹•è¨»å†Š\n",
    "                if model_id not in self.models:\n",
    "                    auto_registration = ModelRegistration(\n",
    "                        model_id=model_id,\n",
    "                        name=model_info['name'],\n",
    "                        version=model_info['version'],\n",
    "                        description=f\"è‡ªå‹•ç™¼ç¾çš„æ¨¡å‹: {model_info['name']}\",\n",
    "                        owner_team=\"auto_discovery\",\n",
    "                        business_domain=\"finance\",\n",
    "                        model_type=\"classification\",\n",
    "                        framework=model_info['backend'],\n",
    "                        training_dataset=\"unknown\",\n",
    "                        registered_at=datetime.now(),\n",
    "                        last_updated=datetime.now(),\n",
    "                        status=ModelStatus.PRODUCTION if model_info['state'] == 'READY' else ModelStatus.TESTING,\n",
    "                        deployment_config={'triton_backend': model_info['backend']},\n",
    "                        performance_thresholds={},\n",
    "                        monitoring_config={},\n",
    "                        tags=['auto_discovered']\n",
    "                    )\n",
    "                    \n",
    "                    if self.register_model(auto_registration):\n",
    "                        discovered_models.append(model_id)\n",
    "                        logger.info(f\"ğŸ” è‡ªå‹•ç™¼ç¾ä¸¦è¨»å†Šæ¨¡å‹: {model_id}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"æ¨¡å‹è‡ªå‹•ç™¼ç¾å¤±æ•—: {e}\")\n",
    "        \n",
    "        return discovered_models\n",
    "    \n",
    "    def get_models_by_status(self, status: ModelStatus) -> List[ModelRegistration]:\n",
    "        \"\"\"æŒ‰ç‹€æ…‹ç²å–æ¨¡å‹åˆ—è¡¨\"\"\"\n",
    "        return [model for model in self.models.values() if model.status == status]\n",
    "    \n",
    "    def get_models_by_domain(self, domain: str) -> List[ModelRegistration]:\n",
    "        \"\"\"æŒ‰æ¥­å‹™é ˜åŸŸç²å–æ¨¡å‹åˆ—è¡¨\"\"\"\n",
    "        return [model for model in self.models.values() if model.business_domain == domain]\n",
    "    \n",
    "    def get_model_performance_summary(self, model_id: str, days: int = 7) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"ç²å–æ¨¡å‹æ€§èƒ½æ‘˜è¦\"\"\"\n",
    "        if model_id not in self.model_metrics:\n",
    "            return None\n",
    "        \n",
    "        cutoff_time = datetime.now() - timedelta(days=days)\n",
    "        recent_metrics = [\n",
    "            m for m in self.model_metrics[model_id] \n",
    "            if m.timestamp > cutoff_time\n",
    "        ]\n",
    "        \n",
    "        if not recent_metrics:\n",
    "            return None\n",
    "        \n",
    "        # è¨ˆç®—çµ±è¨ˆæ‘˜è¦\n",
    "        accuracies = [m.accuracy for m in recent_metrics]\n",
    "        latencies = [m.latency_p99_ms for m in recent_metrics]\n",
    "        throughputs = [m.throughput_rps for m in recent_metrics]\n",
    "        error_rates = [m.error_rate for m in recent_metrics]\n",
    "        \n",
    "        return {\n",
    "            'model_id': model_id,\n",
    "            'period_days': days,\n",
    "            'total_measurements': len(recent_metrics),\n",
    "            'accuracy': {\n",
    "                'mean': np.mean(accuracies),\n",
    "                'std': np.std(accuracies),\n",
    "                'min': np.min(accuracies),\n",
    "                'max': np.max(accuracies)\n",
    "            },\n",
    "            'latency_p99_ms': {\n",
    "                'mean': np.mean(latencies),\n",
    "                'std': np.std(latencies),\n",
    "                'min': np.min(latencies),\n",
    "                'max': np.max(latencies)\n",
    "            },\n",
    "            'throughput_rps': {\n",
    "                'mean': np.mean(throughputs),\n",
    "                'std': np.std(throughputs),\n",
    "                'min': np.min(throughputs),\n",
    "                'max': np.max(throughputs)\n",
    "            },\n",
    "            'error_rate': {\n",
    "                'mean': np.mean(error_rates),\n",
    "                'std': np.std(error_rates),\n",
    "                'min': np.min(error_rates),\n",
    "                'max': np.max(error_rates)\n",
    "            },\n",
    "            'performance_level': recent_metrics[-1].get_performance_level().value,\n",
    "            'last_updated': recent_metrics[-1].timestamp.isoformat()\n",
    "        }\n",
    "    \n",
    "    def _validate_registration(self, registration: ModelRegistration):\n",
    "        \"\"\"é©—è­‰è¨»å†Šä¿¡æ¯\"\"\"\n",
    "        required_fields = ['model_id', 'name', 'version', 'owner_team', 'business_domain']\n",
    "        for field in required_fields:\n",
    "            if not getattr(registration, field):\n",
    "                raise ValueError(f\"å¿…è¦å­—æ®µ {field} ä¸èƒ½ç‚ºç©º\")\n",
    "    \n",
    "    def _get_default_thresholds(self) -> Dict[str, float]:\n",
    "        \"\"\"ç²å–é è¨­æ€§èƒ½é–¾å€¼\"\"\"\n",
    "        return {\n",
    "            'min_accuracy': 0.85,\n",
    "            'max_latency_p99_ms': 100,\n",
    "            'min_throughput_rps': 10,\n",
    "            'max_error_rate': 0.01,\n",
    "            'max_memory_usage_mb': 2048,\n",
    "            'max_cpu_usage_percent': 80\n",
    "        }\n",
    "    \n",
    "    def _get_default_monitoring_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"ç²å–é è¨­ç›£æ§é…ç½®\"\"\"\n",
    "        return {\n",
    "            'metrics_collection_interval_seconds': 300,  # 5åˆ†é˜\n",
    "            'alert_channels': ['email', 'slack'],\n",
    "            'performance_check_interval_minutes': 60,\n",
    "            'drift_detection_enabled': True,\n",
    "            'drift_check_interval_hours': 24\n",
    "        }\n",
    "    \n",
    "    def _check_performance_alerts(self, model_id: str, metrics: ModelMetrics):\n",
    "        \"\"\"æª¢æŸ¥æ€§èƒ½å‘Šè­¦\"\"\"\n",
    "        model = self.models[model_id]\n",
    "        thresholds = model.performance_thresholds\n",
    "        \n",
    "        alerts = []\n",
    "        \n",
    "        # æª¢æŸ¥å„é …æŒ‡æ¨™\n",
    "        if metrics.accuracy < thresholds.get('min_accuracy', 0.85):\n",
    "            alerts.append(f\"æº–ç¢ºåº¦éä½: {metrics.accuracy:.3f} < {thresholds['min_accuracy']}\")\n",
    "        \n",
    "        if metrics.latency_p99_ms > thresholds.get('max_latency_p99_ms', 100):\n",
    "            alerts.append(f\"å»¶é²éé«˜: {metrics.latency_p99_ms:.1f}ms > {thresholds['max_latency_p99_ms']}ms\")\n",
    "        \n",
    "        if metrics.error_rate > thresholds.get('max_error_rate', 0.01):\n",
    "            alerts.append(f\"éŒ¯èª¤ç‡éé«˜: {metrics.error_rate:.3f} > {thresholds['max_error_rate']}\")\n",
    "        \n",
    "        if alerts:\n",
    "            logger.warning(f\"âš ï¸ æ¨¡å‹ {model_id} æ€§èƒ½å‘Šè­¦:\")\n",
    "            for alert in alerts:\n",
    "                logger.warning(f\"   - {alert}\")\n",
    "    \n",
    "    def _load_registry_data(self):\n",
    "        \"\"\"è¼‰å…¥è¨»å†Šæ•¸æ“š\"\"\"\n",
    "        registry_file = self.storage_path / \"registry.json\"\n",
    "        metrics_file = self.storage_path / \"metrics.json\"\n",
    "        \n",
    "        # è¼‰å…¥æ¨¡å‹è¨»å†Šæ•¸æ“š\n",
    "        if registry_file.exists():\n",
    "            with open(registry_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                for model_id, model_data in data.items():\n",
    "                    registration = ModelRegistration(\n",
    "                        model_id=model_data['model_id'],\n",
    "                        name=model_data['name'],\n",
    "                        version=model_data['version'],\n",
    "                        description=model_data['description'],\n",
    "                        owner_team=model_data['owner_team'],\n",
    "                        business_domain=model_data['business_domain'],\n",
    "                        model_type=model_data['model_type'],\n",
    "                        framework=model_data['framework'],\n",
    "                        training_dataset=model_data['training_dataset'],\n",
    "                        registered_at=datetime.fromisoformat(model_data['registered_at']),\n",
    "                        last_updated=datetime.fromisoformat(model_data['last_updated']),\n",
    "                        status=ModelStatus(model_data['status']),\n",
    "                        deployment_config=model_data['deployment_config'],\n",
    "                        performance_thresholds=model_data['performance_thresholds'],\n",
    "                        monitoring_config=model_data['monitoring_config'],\n",
    "                        tags=model_data.get('tags', []),\n",
    "                        dependencies=model_data.get('dependencies', [])\n",
    "                    )\n",
    "                    self.models[model_id] = registration\n",
    "        \n",
    "        # è¼‰å…¥æ€§èƒ½æŒ‡æ¨™æ•¸æ“š\n",
    "        if metrics_file.exists():\n",
    "            with open(metrics_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                for model_id, metrics_list in data.items():\n",
    "                    self.model_metrics[model_id] = []\n",
    "                    for metric_data in metrics_list:\n",
    "                        metrics = ModelMetrics(\n",
    "                            accuracy=metric_data['accuracy'],\n",
    "                            precision=metric_data['precision'],\n",
    "                            recall=metric_data['recall'],\n",
    "                            f1_score=metric_data['f1_score'],\n",
    "                            auc_roc=metric_data['auc_roc'],\n",
    "                            latency_p50_ms=metric_data['latency_p50_ms'],\n",
    "                            latency_p95_ms=metric_data['latency_p95_ms'],\n",
    "                            latency_p99_ms=metric_data['latency_p99_ms'],\n",
    "                            throughput_rps=metric_data['throughput_rps'],\n",
    "                            error_rate=metric_data['error_rate'],\n",
    "                            memory_usage_mb=metric_data['memory_usage_mb'],\n",
    "                            cpu_usage_percent=metric_data['cpu_usage_percent'],\n",
    "                            timestamp=datetime.fromisoformat(metric_data['timestamp'])\n",
    "                        )\n",
    "                        self.model_metrics[model_id].append(metrics)\n",
    "    \n",
    "    def _save_registry_data(self):\n",
    "        \"\"\"ä¿å­˜è¨»å†Šæ•¸æ“š\"\"\"\n",
    "        # ä¿å­˜æ¨¡å‹è¨»å†Šæ•¸æ“š\n",
    "        registry_file = self.storage_path / \"registry.json\"\n",
    "        registry_data = {model_id: model.to_dict() for model_id, model in self.models.items()}\n",
    "        \n",
    "        with open(registry_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(registry_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # ä¿å­˜æ€§èƒ½æŒ‡æ¨™æ•¸æ“š\n",
    "        metrics_file = self.storage_path / \"metrics.json\"\n",
    "        metrics_data = {}\n",
    "        \n",
    "        for model_id, metrics_list in self.model_metrics.items():\n",
    "            metrics_data[model_id] = []\n",
    "            for metrics in metrics_list:\n",
    "                metric_dict = asdict(metrics)\n",
    "                metric_dict['timestamp'] = metrics.timestamp.isoformat()\n",
    "                metrics_data[model_id].append(metric_dict)\n",
    "        \n",
    "        with open(metrics_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metrics_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹è¨»å†Šä¸­å¿ƒ\n",
    "model_registry = ModelRegistry()\n",
    "print(\"\\nâœ… ä¼æ¥­ç´šæ¨¡å‹è¨»å†Šä¸­å¿ƒåˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ€§èƒ½ç›£æ§èˆ‡æ¼‚ç§»æª¢æ¸¬ç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DriftDetectionResult:\n",
    "    \"\"\"æ¼‚ç§»æª¢æ¸¬çµæœ\"\"\"\n",
    "    model_id: str\n",
    "    drift_type: str  # 'data_drift', 'concept_drift', 'prediction_drift'\n",
    "    severity: str    # 'low', 'medium', 'high', 'critical'\n",
    "    confidence: float\n",
    "    detected_at: datetime\n",
    "    description: str\n",
    "    affected_features: List[str]\n",
    "    statistical_tests: Dict[str, Any]\n",
    "    recommended_actions: List[str]\n",
    "\n",
    "class ModelPerformanceMonitor:\n",
    "    \"\"\"æ¨¡å‹æ€§èƒ½ç›£æ§å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, registry: ModelRegistry):\n",
    "        self.registry = registry\n",
    "        self.monitoring_active = False\n",
    "        self.monitoring_thread = None\n",
    "        self.data_buffer = {}\n",
    "        self.baseline_data = {}\n",
    "    \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"é–‹å§‹æ€§èƒ½ç›£æ§\"\"\"\n",
    "        if self.monitoring_active:\n",
    "            logger.info(\"ç›£æ§å·²åœ¨é‹è¡Œä¸­\")\n",
    "            return\n",
    "        \n",
    "        self.monitoring_active = True\n",
    "        self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)\n",
    "        self.monitoring_thread.start()\n",
    "        \n",
    "        logger.info(\"ğŸ“Š æ€§èƒ½ç›£æ§å·²å•Ÿå‹•\")\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"åœæ­¢æ€§èƒ½ç›£æ§\"\"\"\n",
    "        self.monitoring_active = False\n",
    "        if self.monitoring_thread:\n",
    "            self.monitoring_thread.join(timeout=5)\n",
    "        \n",
    "        logger.info(\"â¹ï¸ æ€§èƒ½ç›£æ§å·²åœæ­¢\")\n",
    "    \n",
    "    def collect_real_time_metrics(self, model_id: str) -> Optional[ModelMetrics]:\n",
    "        \"\"\"æ”¶é›†å¯¦æ™‚æ€§èƒ½æŒ‡æ¨™\"\"\"\n",
    "        try:\n",
    "            # æ¨¡æ“¬å¾ Triton å’Œç›£æ§ç³»çµ±æ”¶é›†æŒ‡æ¨™\n",
    "            import random\n",
    "            \n",
    "            # åŸºæ–¼æ¨¡å‹IDç”Ÿæˆä¸€è‡´çš„éš¨æ©Ÿæ•¸\n",
    "            random.seed(hash(model_id + str(int(time.time() / 300))))\n",
    "            \n",
    "            # æ¨¡æ“¬æ€§èƒ½æŒ‡æ¨™ï¼ˆå¯¦éš›ç’°å¢ƒä¸­æœƒå¾ Prometheus/Grafana ç²å–ï¼‰\n",
    "            base_accuracy = 0.85 + random.uniform(-0.05, 0.05)\n",
    "            \n",
    "            metrics = ModelMetrics(\n",
    "                accuracy=max(0.5, min(1.0, base_accuracy)),\n",
    "                precision=max(0.5, min(1.0, base_accuracy + random.uniform(-0.02, 0.02))),\n",
    "                recall=max(0.5, min(1.0, base_accuracy + random.uniform(-0.02, 0.02))),\n",
    "                f1_score=max(0.5, min(1.0, base_accuracy + random.uniform(-0.01, 0.01))),\n",
    "                auc_roc=max(0.5, min(1.0, base_accuracy + random.uniform(0.05, 0.15))),\n",
    "                latency_p50_ms=max(10, 50 + random.gauss(0, 10)),\n",
    "                latency_p95_ms=max(20, 80 + random.gauss(0, 15)),\n",
    "                latency_p99_ms=max(30, 120 + random.gauss(0, 20)),\n",
    "                throughput_rps=max(1, 25 + random.gauss(0, 5)),\n",
    "                error_rate=max(0, random.uniform(0, 0.02)),\n",
    "                memory_usage_mb=max(100, 1024 + random.gauss(0, 200)),\n",
    "                cpu_usage_percent=max(0, min(100, 45 + random.gauss(0, 15))),\n",
    "                timestamp=datetime.now()\n",
    "            )\n",
    "            \n",
    "            return metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"æ”¶é›†æ¨¡å‹ {model_id} æŒ‡æ¨™å¤±æ•—: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def detect_data_drift(self, model_id: str, new_data: np.ndarray, \n",
    "                         reference_data: np.ndarray = None) -> Optional[DriftDetectionResult]:\n",
    "        \"\"\"æª¢æ¸¬æ•¸æ“šæ¼‚ç§»\"\"\"\n",
    "        if reference_data is None:\n",
    "            reference_data = self.baseline_data.get(model_id)\n",
    "            if reference_data is None:\n",
    "                logger.warning(f\"æ¨¡å‹ {model_id} æ²’æœ‰åŸºæº–æ•¸æ“šï¼Œç„¡æ³•é€²è¡Œæ¼‚ç§»æª¢æ¸¬\")\n",
    "                return None\n",
    "        \n",
    "        try:\n",
    "            # Kolmogorov-Smirnov æª¢å®š\n",
    "            ks_statistic, ks_p_value = stats.ks_2samp(reference_data.flatten(), new_data.flatten())\n",
    "            \n",
    "            # Jensen-Shannon æ•£åº¦\n",
    "            js_divergence = self._calculate_js_divergence(reference_data, new_data)\n",
    "            \n",
    "            # Population Stability Index (PSI)\n",
    "            psi_score = self._calculate_psi(reference_data, new_data)\n",
    "            \n",
    "            # ç¶œåˆè©•ä¼°æ¼‚ç§»åš´é‡ç¨‹åº¦\n",
    "            drift_score = (ks_statistic * 0.4 + js_divergence * 0.3 + psi_score * 0.3)\n",
    "            \n",
    "            if drift_score > 0.7:\n",
    "                severity = \"critical\"\n",
    "            elif drift_score > 0.5:\n",
    "                severity = \"high\"\n",
    "            elif drift_score > 0.3:\n",
    "                severity = \"medium\"\n",
    "            else:\n",
    "                severity = \"low\"\n",
    "            \n",
    "            # ç”Ÿæˆå»ºè­°\n",
    "            recommendations = self._generate_drift_recommendations(severity, drift_score)\n",
    "            \n",
    "            return DriftDetectionResult(\n",
    "                model_id=model_id,\n",
    "                drift_type=\"data_drift\",\n",
    "                severity=severity,\n",
    "                confidence=min(1.0, drift_score),\n",
    "                detected_at=datetime.now(),\n",
    "                description=f\"æª¢æ¸¬åˆ°æ•¸æ“šåˆ†ä½ˆè®ŠåŒ–ï¼Œæ¼‚ç§»åˆ†æ•¸: {drift_score:.3f}\",\n",
    "                affected_features=[\"all\"],  # ç°¡åŒ–ç¤ºä¾‹\n",
    "                statistical_tests={\n",
    "                    \"ks_statistic\": ks_statistic,\n",
    "                    \"ks_p_value\": ks_p_value,\n",
    "                    \"js_divergence\": js_divergence,\n",
    "                    \"psi_score\": psi_score,\n",
    "                    \"overall_drift_score\": drift_score\n",
    "                },\n",
    "                recommended_actions=recommendations\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"æ¼‚ç§»æª¢æ¸¬å¤±æ•—: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def detect_concept_drift(self, model_id: str, predictions: np.ndarray, \n",
    "                           ground_truth: np.ndarray) -> Optional[DriftDetectionResult]:\n",
    "        \"\"\"æª¢æ¸¬æ¦‚å¿µæ¼‚ç§»\"\"\"\n",
    "        try:\n",
    "            # è¨ˆç®—æº–ç¢ºåº¦è¶¨å‹¢\n",
    "            window_size = min(100, len(predictions) // 4)\n",
    "            if window_size < 10:\n",
    "                return None\n",
    "            \n",
    "            accuracies = []\n",
    "            for i in range(0, len(predictions) - window_size, window_size):\n",
    "                window_pred = predictions[i:i+window_size]\n",
    "                window_truth = ground_truth[i:i+window_size]\n",
    "                accuracy = np.mean(window_pred == window_truth)\n",
    "                accuracies.append(accuracy)\n",
    "            \n",
    "            if len(accuracies) < 3:\n",
    "                return None\n",
    "            \n",
    "            # è¶¨å‹¢åˆ†æ\n",
    "            x = np.arange(len(accuracies))\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x, accuracies)\n",
    "            \n",
    "            # è®Šç•°ä¿‚æ•¸\n",
    "            cv = np.std(accuracies) / np.mean(accuracies) if np.mean(accuracies) > 0 else 0\n",
    "            \n",
    "            # è©•ä¼°æ¦‚å¿µæ¼‚ç§»\n",
    "            drift_indicators = {\n",
    "                \"negative_trend\": slope < -0.01 and p_value < 0.05,\n",
    "                \"high_variance\": cv > 0.1,\n",
    "                \"recent_drop\": len(accuracies) >= 2 and (accuracies[-1] - accuracies[0]) < -0.05\n",
    "            }\n",
    "            \n",
    "            drift_count = sum(drift_indicators.values())\n",
    "            \n",
    "            if drift_count >= 2:\n",
    "                severity = \"high\"\n",
    "            elif drift_count == 1:\n",
    "                severity = \"medium\"\n",
    "            else:\n",
    "                severity = \"low\"\n",
    "            \n",
    "            if drift_count > 0:\n",
    "                return DriftDetectionResult(\n",
    "                    model_id=model_id,\n",
    "                    drift_type=\"concept_drift\",\n",
    "                    severity=severity,\n",
    "                    confidence=drift_count / 3.0,\n",
    "                    detected_at=datetime.now(),\n",
    "                    description=f\"æª¢æ¸¬åˆ°æ¦‚å¿µæ¼‚ç§»ï¼Œæº–ç¢ºåº¦è¶¨å‹¢æ–œç‡: {slope:.4f}\",\n",
    "                    affected_features=[\"target_relationship\"],\n",
    "                    statistical_tests={\n",
    "                        \"slope\": slope,\n",
    "                        \"p_value\": p_value,\n",
    "                        \"r_squared\": r_value**2,\n",
    "                        \"coefficient_of_variation\": cv,\n",
    "                        \"drift_indicators\": drift_indicators\n",
    "                    },\n",
    "                    recommended_actions=self._generate_concept_drift_recommendations(severity)\n",
    "                )\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"æ¦‚å¿µæ¼‚ç§»æª¢æ¸¬å¤±æ•—: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _monitoring_loop(self):\n",
    "        \"\"\"ç›£æ§ä¸»å¾ªç’°\"\"\"\n",
    "        while self.monitoring_active:\n",
    "            try:\n",
    "                # ç‚ºæ‰€æœ‰ç”Ÿç”¢æ¨¡å‹æ”¶é›†æŒ‡æ¨™\n",
    "                production_models = self.registry.get_models_by_status(ModelStatus.PRODUCTION)\n",
    "                \n",
    "                for model in production_models:\n",
    "                    metrics = self.collect_real_time_metrics(model.model_id)\n",
    "                    if metrics:\n",
    "                        self.registry.record_metrics(model.model_id, metrics)\n",
    "                \n",
    "                # æª¢æŸ¥ç›£æ§é–“éš”\n",
    "                time.sleep(60)  # 1åˆ†é˜æª¢æŸ¥ä¸€æ¬¡\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"ç›£æ§å¾ªç’°éŒ¯èª¤: {e}\")\n",
    "                time.sleep(10)\n",
    "    \n",
    "    def _calculate_js_divergence(self, data1: np.ndarray, data2: np.ndarray) -> float:\n",
    "        \"\"\"è¨ˆç®— Jensen-Shannon æ•£åº¦\"\"\"\n",
    "        try:\n",
    "            # è¨ˆç®—ç›´æ–¹åœ–\n",
    "            bins = 50\n",
    "            hist1, bin_edges = np.histogram(data1, bins=bins, density=True)\n",
    "            hist2, _ = np.histogram(data2, bins=bin_edges, density=True)\n",
    "            \n",
    "            # æ­£è¦åŒ–\n",
    "            hist1 = hist1 / np.sum(hist1)\n",
    "            hist2 = hist2 / np.sum(hist2)\n",
    "            \n",
    "            # é¿å…é›¶å€¼\n",
    "            hist1 = np.where(hist1 == 0, 1e-10, hist1)\n",
    "            hist2 = np.where(hist2 == 0, 1e-10, hist2)\n",
    "            \n",
    "            # è¨ˆç®— JS æ•£åº¦\n",
    "            m = 0.5 * (hist1 + hist2)\n",
    "            js_div = 0.5 * stats.entropy(hist1, m) + 0.5 * stats.entropy(hist2, m)\n",
    "            \n",
    "            return js_div\n",
    "            \n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    def _calculate_psi(self, reference: np.ndarray, current: np.ndarray) -> float:\n",
    "        \"\"\"è¨ˆç®— Population Stability Index (PSI)\"\"\"\n",
    "        try:\n",
    "            bins = 10\n",
    "            \n",
    "            # ä½¿ç”¨åƒè€ƒæ•¸æ“šçš„åˆ†ä½æ•¸ä½œç‚ºåˆ†çµ„é‚Šç•Œ\n",
    "            bin_edges = np.percentile(reference, np.linspace(0, 100, bins + 1))\n",
    "            \n",
    "            # è¨ˆç®—å„çµ„çš„æ¯”ä¾‹\n",
    "            ref_counts, _ = np.histogram(reference, bins=bin_edges)\n",
    "            cur_counts, _ = np.histogram(current, bins=bin_edges)\n",
    "            \n",
    "            ref_props = ref_counts / len(reference)\n",
    "            cur_props = cur_counts / len(current)\n",
    "            \n",
    "            # é¿å…é›¶å€¼\n",
    "            ref_props = np.where(ref_props == 0, 1e-6, ref_props)\n",
    "            cur_props = np.where(cur_props == 0, 1e-6, cur_props)\n",
    "            \n",
    "            # è¨ˆç®— PSI\n",
    "            psi = np.sum((cur_props - ref_props) * np.log(cur_props / ref_props))\n",
    "            \n",
    "            return psi\n",
    "            \n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    def _generate_drift_recommendations(self, severity: str, drift_score: float) -> List[str]:\n",
    "        \"\"\"ç”Ÿæˆæ¼‚ç§»è™•ç†å»ºè­°\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if severity == \"critical\":\n",
    "            recommendations.extend([\n",
    "                \"ç«‹å³åœæ­¢æ¨¡å‹é æ¸¬ï¼Œåˆ‡æ›åˆ°å‚™ç”¨æ¨¡å‹\",\n",
    "                \"å•Ÿå‹•ç·Šæ€¥é‡è¨“ç·´æµç¨‹\",\n",
    "                \"é€šçŸ¥æ¨¡å‹æ“æœ‰è€…å’Œæ¥­å‹™åœ˜éšŠ\",\n",
    "                \"åˆ†ææ•¸æ“šæºè®ŠåŒ–åŸå› \"\n",
    "            ])\n",
    "        elif severity == \"high\":\n",
    "            recommendations.extend([\n",
    "                \"å¢åŠ ç›£æ§é »ç‡\",\n",
    "                \"æº–å‚™æ¨¡å‹é‡è¨“ç·´\",\n",
    "                \"æª¢æŸ¥æ•¸æ“šç®¡é“æ˜¯å¦æœ‰è®ŠåŒ–\",\n",
    "                \"è€ƒæ…®èª¿æ•´æ¨¡å‹é–¾å€¼\"\n",
    "            ])\n",
    "        elif severity == \"medium\":\n",
    "            recommendations.extend([\n",
    "                \"æŒçºŒç›£æ§æ¼‚ç§»è¶¨å‹¢\",\n",
    "                \"æª¢æŸ¥æœ€è¿‘çš„æ•¸æ“šè®ŠåŒ–\",\n",
    "                \"è©•ä¼°æ˜¯å¦éœ€è¦ç‰¹å¾µå·¥ç¨‹èª¿æ•´\"\n",
    "            ])\n",
    "        else:\n",
    "            recommendations.append(\"ç¹¼çºŒæ­£å¸¸ç›£æ§\")\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _generate_concept_drift_recommendations(self, severity: str) -> List[str]:\n",
    "        \"\"\"ç”Ÿæˆæ¦‚å¿µæ¼‚ç§»è™•ç†å»ºè­°\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if severity == \"high\":\n",
    "            recommendations.extend([\n",
    "                \"ç«‹å³å•Ÿå‹•æ¨¡å‹é‡è¨“ç·´\",\n",
    "                \"åˆ†æç›®æ¨™è®Šæ•¸é—œä¿‚è®ŠåŒ–\",\n",
    "                \"æª¢æŸ¥æ¥­å‹™ç’°å¢ƒè®ŠåŒ–\",\n",
    "                \"è€ƒæ…®åœ¨ç·šå­¸ç¿’ç­–ç•¥\"\n",
    "            ])\n",
    "        elif severity == \"medium\":\n",
    "            recommendations.extend([\n",
    "                \"å¢åŠ æ¨£æœ¬æ”¶é›†\",\n",
    "                \"è©•ä¼°é‡è¨“ç·´æ™‚æ©Ÿ\",\n",
    "                \"æª¢æŸ¥ç‰¹å¾µé‡è¦æ€§è®ŠåŒ–\"\n",
    "            ])\n",
    "        else:\n",
    "            recommendations.append(\"ç¶­æŒç¾æœ‰ç›£æ§ç­–ç•¥\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# åˆå§‹åŒ–æ€§èƒ½ç›£æ§å™¨\n",
    "performance_monitor = ModelPerformanceMonitor(model_registry)\n",
    "print(\"\\nâœ… æ¨¡å‹æ€§èƒ½ç›£æ§å™¨åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ è‡ªå‹•åŒ–æ¨¡å‹æ›´æ–°ç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class UpdateTrigger:\n",
    "    \"\"\"æ›´æ–°è§¸ç™¼å™¨\"\"\"\n",
    "    trigger_type: str  # 'performance_degradation', 'drift_detection', 'scheduled', 'manual'\n",
    "    threshold_breached: str\n",
    "    current_value: float\n",
    "    threshold_value: float\n",
    "    triggered_at: datetime\n",
    "    severity: str\n",
    "\n",
    "@dataclass\n",
    "class UpdateJob:\n",
    "    \"\"\"æ¨¡å‹æ›´æ–°ä»»å‹™\"\"\"\n",
    "    job_id: str\n",
    "    model_id: str\n",
    "    current_version: str\n",
    "    target_version: str\n",
    "    trigger: UpdateTrigger\n",
    "    status: str  # 'pending', 'training', 'validating', 'deploying', 'completed', 'failed'\n",
    "    created_at: datetime\n",
    "    started_at: Optional[datetime] = None\n",
    "    completed_at: Optional[datetime] = None\n",
    "    progress: float = 0.0\n",
    "    logs: List[str] = field(default_factory=list)\n",
    "    metrics: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "class AutoModelUpdater:\n",
    "    \"\"\"è‡ªå‹•åŒ–æ¨¡å‹æ›´æ–°ç³»çµ±\"\"\"\n",
    "    \n",
    "    def __init__(self, registry: ModelRegistry, monitor: ModelPerformanceMonitor):\n",
    "        self.registry = registry\n",
    "        self.monitor = monitor\n",
    "        self.update_jobs = {}\n",
    "        self.job_queue = queue.Queue()\n",
    "        self.worker_pool = ThreadPoolExecutor(max_workers=2)\n",
    "        self.updater_active = False\n",
    "        self.storage_path = Path(\"./model_updates\")\n",
    "        self.storage_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    def start_updater(self):\n",
    "        \"\"\"å•Ÿå‹•è‡ªå‹•æ›´æ–°ç³»çµ±\"\"\"\n",
    "        if self.updater_active:\n",
    "            logger.info(\"è‡ªå‹•æ›´æ–°å™¨å·²åœ¨é‹è¡Œä¸­\")\n",
    "            return\n",
    "        \n",
    "        self.updater_active = True\n",
    "        \n",
    "        # å•Ÿå‹•è§¸ç™¼å™¨ç›£æ§ç·šç¨‹\n",
    "        trigger_thread = threading.Thread(target=self._trigger_monitoring_loop, daemon=True)\n",
    "        trigger_thread.start()\n",
    "        \n",
    "        # å•Ÿå‹•ä»»å‹™è™•ç†ç·šç¨‹\n",
    "        job_thread = threading.Thread(target=self._job_processing_loop, daemon=True)\n",
    "        job_thread.start()\n",
    "        \n",
    "        logger.info(\"ğŸ”„ è‡ªå‹•æ¨¡å‹æ›´æ–°ç³»çµ±å·²å•Ÿå‹•\")\n",
    "    \n",
    "    def stop_updater(self):\n",
    "        \"\"\"åœæ­¢è‡ªå‹•æ›´æ–°ç³»çµ±\"\"\"\n",
    "        self.updater_active = False\n",
    "        self.worker_pool.shutdown(wait=True)\n",
    "        logger.info(\"â¹ï¸ è‡ªå‹•æ¨¡å‹æ›´æ–°ç³»çµ±å·²åœæ­¢\")\n",
    "    \n",
    "    def create_update_job(self, model_id: str, trigger: UpdateTrigger) -> str:\n",
    "        \"\"\"å‰µå»ºæ›´æ–°ä»»å‹™\"\"\"\n",
    "        job_id = str(uuid.uuid4())\n",
    "        \n",
    "        model = self.registry.models.get(model_id)\n",
    "        if not model:\n",
    "            logger.error(f\"æ¨¡å‹ {model_id} ä¸å­˜åœ¨\")\n",
    "            return None\n",
    "        \n",
    "        # ç”Ÿæˆæ–°ç‰ˆæœ¬è™Ÿ\n",
    "        current_version = model.version\n",
    "        target_version = self._generate_next_version(current_version)\n",
    "        \n",
    "        update_job = UpdateJob(\n",
    "            job_id=job_id,\n",
    "            model_id=model_id,\n",
    "            current_version=current_version,\n",
    "            target_version=target_version,\n",
    "            trigger=trigger,\n",
    "            status=\"pending\",\n",
    "            created_at=datetime.now()\n",
    "        )\n",
    "        \n",
    "        self.update_jobs[job_id] = update_job\n",
    "        self.job_queue.put(job_id)\n",
    "        \n",
    "        logger.info(f\"ğŸ“‹ å‰µå»ºæ›´æ–°ä»»å‹™: {job_id} (æ¨¡å‹: {model_id} {current_version} -> {target_version})\")\n",
    "        return job_id\n",
    "    \n",
    "    def get_job_status(self, job_id: str) -> Optional[UpdateJob]:\n",
    "        \"\"\"ç²å–ä»»å‹™ç‹€æ…‹\"\"\"\n",
    "        return self.update_jobs.get(job_id)\n",
    "    \n",
    "    def cancel_job(self, job_id: str) -> bool:\n",
    "        \"\"\"å–æ¶ˆæ›´æ–°ä»»å‹™\"\"\"\n",
    "        job = self.update_jobs.get(job_id)\n",
    "        if not job:\n",
    "            return False\n",
    "        \n",
    "        if job.status in ['pending']:\n",
    "            job.status = 'cancelled'\n",
    "            job.completed_at = datetime.now()\n",
    "            logger.info(f\"âŒ å–æ¶ˆæ›´æ–°ä»»å‹™: {job_id}\")\n",
    "            return True\n",
    "        \n",
    "        logger.warning(f\"ç„¡æ³•å–æ¶ˆä»»å‹™ {job_id}ï¼Œç•¶å‰ç‹€æ…‹: {job.status}\")\n",
    "        return False\n",
    "    \n",
    "    def _trigger_monitoring_loop(self):\n",
    "        \"\"\"è§¸ç™¼å™¨ç›£æ§å¾ªç’°\"\"\"\n",
    "        while self.updater_active:\n",
    "            try:\n",
    "                # æª¢æŸ¥æ‰€æœ‰ç”Ÿç”¢æ¨¡å‹çš„è§¸ç™¼æ¢ä»¶\n",
    "                production_models = self.registry.get_models_by_status(ModelStatus.PRODUCTION)\n",
    "                \n",
    "                for model in production_models:\n",
    "                    # æª¢æŸ¥æ€§èƒ½é€€åŒ–\n",
    "                    trigger = self._check_performance_triggers(model.model_id)\n",
    "                    if trigger:\n",
    "                        self.create_update_job(model.model_id, trigger)\n",
    "                    \n",
    "                    # æª¢æŸ¥æ¼‚ç§»æª¢æ¸¬\n",
    "                    drift_trigger = self._check_drift_triggers(model.model_id)\n",
    "                    if drift_trigger:\n",
    "                        self.create_update_job(model.model_id, drift_trigger)\n",
    "                \n",
    "                time.sleep(300)  # 5åˆ†é˜æª¢æŸ¥ä¸€æ¬¡\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"è§¸ç™¼å™¨ç›£æ§éŒ¯èª¤: {e}\")\n",
    "                time.sleep(60)\n",
    "    \n",
    "    def _job_processing_loop(self):\n",
    "        \"\"\"ä»»å‹™è™•ç†å¾ªç’°\"\"\"\n",
    "        while self.updater_active:\n",
    "            try:\n",
    "                # å¾éšŠåˆ—ç²å–ä»»å‹™\n",
    "                job_id = self.job_queue.get(timeout=5)\n",
    "                \n",
    "                if job_id in self.update_jobs:\n",
    "                    # æäº¤ä»»å‹™åˆ°å·¥ä½œæ± \n",
    "                    future = self.worker_pool.submit(self._execute_update_job, job_id)\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                logger.error(f\"ä»»å‹™è™•ç†éŒ¯èª¤: {e}\")\n",
    "    \n",
    "    def _execute_update_job(self, job_id: str):\n",
    "        \"\"\"åŸ·è¡Œæ›´æ–°ä»»å‹™\"\"\"\n",
    "        job = self.update_jobs[job_id]\n",
    "        \n",
    "        try:\n",
    "            job.status = \"training\"\n",
    "            job.started_at = datetime.now()\n",
    "            job.logs.append(f\"é–‹å§‹è¨“ç·´æ–°ç‰ˆæœ¬ {job.target_version}\")\n",
    "            \n",
    "            # éšæ®µ1: æ•¸æ“šæº–å‚™\n",
    "            job.progress = 10\n",
    "            job.logs.append(\"æº–å‚™è¨“ç·´æ•¸æ“š...\")\n",
    "            time.sleep(2)  # æ¨¡æ“¬æ•¸æ“šæº–å‚™\n",
    "            \n",
    "            # éšæ®µ2: æ¨¡å‹è¨“ç·´\n",
    "            job.progress = 30\n",
    "            job.logs.append(\"é–‹å§‹æ¨¡å‹è¨“ç·´...\")\n",
    "            \n",
    "            # æ¨¡æ“¬è¨“ç·´éç¨‹\n",
    "            for i in range(5):\n",
    "                time.sleep(1)\n",
    "                job.progress = 30 + (i + 1) * 10\n",
    "                job.logs.append(f\"è¨“ç·´é€²åº¦: {job.progress}%\")\n",
    "            \n",
    "            # éšæ®µ3: æ¨¡å‹é©—è­‰\n",
    "            job.status = \"validating\"\n",
    "            job.progress = 80\n",
    "            job.logs.append(\"é©—è­‰æ¨¡å‹æ€§èƒ½...\")\n",
    "            \n",
    "            # æ¨¡æ“¬é©—è­‰çµæœ\n",
    "            validation_metrics = self._simulate_validation_metrics()\n",
    "            job.metrics.update(validation_metrics)\n",
    "            \n",
    "            time.sleep(2)\n",
    "            \n",
    "            # æª¢æŸ¥é©—è­‰çµæœ\n",
    "            if validation_metrics['accuracy'] < 0.8:\n",
    "                job.status = \"failed\"\n",
    "                job.logs.append(f\"é©—è­‰å¤±æ•—: æº–ç¢ºåº¦ {validation_metrics['accuracy']:.3f} ä½æ–¼è¦æ±‚\")\n",
    "                return\n",
    "            \n",
    "            # éšæ®µ4: éƒ¨ç½²\n",
    "            job.status = \"deploying\"\n",
    "            job.progress = 90\n",
    "            job.logs.append(\"éƒ¨ç½²æ–°ç‰ˆæœ¬...\")\n",
    "            \n",
    "            # æ¨¡æ“¬éƒ¨ç½²éç¨‹\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # æ›´æ–°è¨»å†Šä¸­å¿ƒ\n",
    "            self._update_model_registry(job)\n",
    "            \n",
    "            # å®Œæˆ\n",
    "            job.status = \"completed\"\n",
    "            job.progress = 100\n",
    "            job.completed_at = datetime.now()\n",
    "            job.logs.append(f\"æ›´æ–°å®Œæˆï¼æ–°ç‰ˆæœ¬ {job.target_version} å·²éƒ¨ç½²\")\n",
    "            \n",
    "            logger.info(f\"âœ… æ¨¡å‹æ›´æ–°ä»»å‹™å®Œæˆ: {job_id}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            job.status = \"failed\"\n",
    "            job.completed_at = datetime.now()\n",
    "            job.logs.append(f\"æ›´æ–°å¤±æ•—: {e}\")\n",
    "            logger.error(f\"âŒ æ¨¡å‹æ›´æ–°ä»»å‹™å¤±æ•—: {job_id}, éŒ¯èª¤: {e}\")\n",
    "    \n",
    "    def _check_performance_triggers(self, model_id: str) -> Optional[UpdateTrigger]:\n",
    "        \"\"\"æª¢æŸ¥æ€§èƒ½è§¸ç™¼æ¢ä»¶\"\"\"\n",
    "        model = self.registry.models.get(model_id)\n",
    "        if not model or model_id not in self.registry.model_metrics:\n",
    "            return None\n",
    "        \n",
    "        recent_metrics = self.registry.model_metrics[model_id][-10:]  # æœ€è¿‘10å€‹æ¸¬é‡é»\n",
    "        if len(recent_metrics) < 5:\n",
    "            return None\n",
    "        \n",
    "        thresholds = model.performance_thresholds\n",
    "        \n",
    "        # æª¢æŸ¥æº–ç¢ºåº¦\n",
    "        avg_accuracy = np.mean([m.accuracy for m in recent_metrics])\n",
    "        min_accuracy = thresholds.get('min_accuracy', 0.85)\n",
    "        \n",
    "        if avg_accuracy < min_accuracy:\n",
    "            return UpdateTrigger(\n",
    "                trigger_type=\"performance_degradation\",\n",
    "                threshold_breached=\"accuracy\",\n",
    "                current_value=avg_accuracy,\n",
    "                threshold_value=min_accuracy,\n",
    "                triggered_at=datetime.now(),\n",
    "                severity=\"high\" if avg_accuracy < min_accuracy * 0.9 else \"medium\"\n",
    "            )\n",
    "        \n",
    "        # æª¢æŸ¥å»¶é²\n",
    "        avg_latency = np.mean([m.latency_p99_ms for m in recent_metrics])\n",
    "        max_latency = thresholds.get('max_latency_p99_ms', 100)\n",
    "        \n",
    "        if avg_latency > max_latency:\n",
    "            return UpdateTrigger(\n",
    "                trigger_type=\"performance_degradation\",\n",
    "                threshold_breached=\"latency\",\n",
    "                current_value=avg_latency,\n",
    "                threshold_value=max_latency,\n",
    "                triggered_at=datetime.now(),\n",
    "                severity=\"medium\"\n",
    "            )\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _check_drift_triggers(self, model_id: str) -> Optional[UpdateTrigger]:\n",
    "        \"\"\"æª¢æŸ¥æ¼‚ç§»è§¸ç™¼æ¢ä»¶\"\"\"\n",
    "        # æ¨¡æ“¬æ¼‚ç§»æª¢æ¸¬çµæœ\n",
    "        import random\n",
    "        \n",
    "        # åŸºæ–¼æ¨¡å‹IDå’Œæ™‚é–“ç”Ÿæˆä¸€è‡´çš„éš¨æ©Ÿæ•¸\n",
    "        random.seed(hash(model_id + str(int(time.time() / 3600))))\n",
    "        \n",
    "        # æ¨¡æ“¬å¶ç™¼çš„æ¼‚ç§»æª¢æ¸¬\n",
    "        if random.random() < 0.05:  # 5% çš„æ©Ÿç‡æª¢æ¸¬åˆ°æ¼‚ç§»\n",
    "            drift_severity = random.choice(['medium', 'high'])\n",
    "            drift_score = random.uniform(0.3, 0.8)\n",
    "            \n",
    "            return UpdateTrigger(\n",
    "                trigger_type=\"drift_detection\",\n",
    "                threshold_breached=\"data_drift\",\n",
    "                current_value=drift_score,\n",
    "                threshold_value=0.3,\n",
    "                triggered_at=datetime.now(),\n",
    "                severity=drift_severity\n",
    "            )\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _generate_next_version(self, current_version: str) -> str:\n",
    "        \"\"\"ç”Ÿæˆä¸‹ä¸€å€‹ç‰ˆæœ¬è™Ÿ\"\"\"\n",
    "        try:\n",
    "            # ç°¡å–®çš„ç‰ˆæœ¬è™Ÿéå¢é‚è¼¯\n",
    "            parts = current_version.split('.')\n",
    "            if len(parts) >= 2:\n",
    "                major = int(parts[0])\n",
    "                minor = int(parts[1])\n",
    "                patch = int(parts[2]) if len(parts) > 2 else 0\n",
    "                \n",
    "                # éå¢è£œä¸ç‰ˆæœ¬è™Ÿ\n",
    "                return f\"{major}.{minor}.{patch + 1}\"\n",
    "            else:\n",
    "                return \"1.0.1\"\n",
    "        except:\n",
    "            return \"1.0.1\"\n",
    "    \n",
    "    def _simulate_validation_metrics(self) -> Dict[str, float]:\n",
    "        \"\"\"æ¨¡æ“¬é©—è­‰æŒ‡æ¨™\"\"\"\n",
    "        import random\n",
    "        \n",
    "        return {\n",
    "            'accuracy': random.uniform(0.82, 0.95),\n",
    "            'precision': random.uniform(0.80, 0.93),\n",
    "            'recall': random.uniform(0.78, 0.92),\n",
    "            'f1_score': random.uniform(0.79, 0.92),\n",
    "            'auc_roc': random.uniform(0.85, 0.97)\n",
    "        }\n",
    "    \n",
    "    def _update_model_registry(self, job: UpdateJob):\n",
    "        \"\"\"æ›´æ–°æ¨¡å‹è¨»å†Šä¿¡æ¯\"\"\"\n",
    "        model = self.registry.models[job.model_id]\n",
    "        \n",
    "        # å‰µå»ºæ–°ç‰ˆæœ¬è¨»å†Š\n",
    "        new_model_id = f\"{model.name}_{job.target_version}\"\n",
    "        new_registration = ModelRegistration(\n",
    "            model_id=new_model_id,\n",
    "            name=model.name,\n",
    "            version=job.target_version,\n",
    "            description=f\"è‡ªå‹•æ›´æ–°ç‰ˆæœ¬: {job.trigger.trigger_type}\",\n",
    "            owner_team=model.owner_team,\n",
    "            business_domain=model.business_domain,\n",
    "            model_type=model.model_type,\n",
    "            framework=model.framework,\n",
    "            training_dataset=model.training_dataset,\n",
    "            registered_at=datetime.now(),\n",
    "            last_updated=datetime.now(),\n",
    "            status=ModelStatus.PRODUCTION,\n",
    "            deployment_config=model.deployment_config.copy(),\n",
    "            performance_thresholds=model.performance_thresholds.copy(),\n",
    "            monitoring_config=model.monitoring_config.copy(),\n",
    "            tags=model.tags + ['auto_updated'],\n",
    "            dependencies=model.dependencies.copy()\n",
    "        )\n",
    "        \n",
    "        # è¨»å†Šæ–°ç‰ˆæœ¬\n",
    "        self.registry.register_model(new_registration)\n",
    "        \n",
    "        # å°‡èˆŠç‰ˆæœ¬æ¨™è¨˜ç‚º deprecated\n",
    "        self.registry.update_model_status(job.model_id, ModelStatus.DEPRECATED, \n",
    "                                        f\"è¢«ç‰ˆæœ¬ {job.target_version} æ›¿ä»£\")\n",
    "\n",
    "# åˆå§‹åŒ–è‡ªå‹•æ›´æ–°å™¨\n",
    "auto_updater = AutoModelUpdater(model_registry, performance_monitor)\n",
    "print(\"\\nâœ… è‡ªå‹•æ¨¡å‹æ›´æ–°ç³»çµ±åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¦ VISA ä¿¡ç”¨è©•ä¼°æ¨¡å‹ç”Ÿå‘½é€±æœŸæ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰µå»º VISA ä¿¡ç”¨è©•ä¼°æ¨¡å‹çš„å®Œæ•´ç”Ÿå‘½é€±æœŸæ¼”ç¤º\n",
    "print(\"ğŸ¦ VISA ä¿¡ç”¨è©•ä¼°æ¨¡å‹ç”Ÿå‘½é€±æœŸæ¼”ç¤º\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. è¨»å†Šåˆå§‹æ¨¡å‹\n",
    "print(\"\\nğŸ“‹ æ­¥é©Ÿ 1: è¨»å†Šä¿¡ç”¨è©•ä¼°æ¨¡å‹...\")\n",
    "\n",
    "visa_models = [\n",
    "    {\n",
    "        'model_id': 'credit_scoring_v1_0_0',\n",
    "        'name': 'credit_scoring',\n",
    "        'version': '1.0.0',\n",
    "        'description': 'VISA ä¿¡ç”¨è©•ä¼°æ¨¡å‹ - åŸºæ–¼å‚³çµ±æ©Ÿå™¨å­¸ç¿’ç®—æ³•',\n",
    "        'business_domain': 'credit_risk'\n",
    "    },\n",
    "    {\n",
    "        'model_id': 'fraud_detection_v2_1_0',\n",
    "        'name': 'fraud_detection',\n",
    "        'version': '2.1.0',\n",
    "        'description': 'VISA æ¬ºè©æª¢æ¸¬æ¨¡å‹ - å¯¦æ™‚äº¤æ˜“é¢¨éšªè©•ä¼°',\n",
    "        'business_domain': 'fraud_prevention'\n",
    "    },\n",
    "    {\n",
    "        'model_id': 'risk_assessment_v3_0_0',\n",
    "        'name': 'risk_assessment',\n",
    "        'version': '3.0.0',\n",
    "        'description': 'VISA ç¶œåˆé¢¨éšªè©•ä¼°æ¨¡å‹ - å¤šç¶­åº¦é¢¨éšªåˆ†æ',\n",
    "        'business_domain': 'risk_management'\n",
    "    }\n",
    "]\n",
    "\n",
    "for model_info in visa_models:\n",
    "    registration = ModelRegistration(\n",
    "        model_id=model_info['model_id'],\n",
    "        name=model_info['name'],\n",
    "        version=model_info['version'],\n",
    "        description=model_info['description'],\n",
    "        owner_team=\"visa_risk_analytics\",\n",
    "        business_domain=model_info['business_domain'],\n",
    "        model_type=\"classification\",\n",
    "        framework=\"pytorch\",\n",
    "        training_dataset=\"visa_historical_transactions_2024\",\n",
    "        registered_at=datetime.now(),\n",
    "        last_updated=datetime.now(),\n",
    "        status=ModelStatus.PRODUCTION,\n",
    "        deployment_config={\n",
    "            'triton_backend': 'pytorch',\n",
    "            'max_batch_size': 64,\n",
    "            'instance_count': 2,\n",
    "            'gpu_memory_fraction': 0.3\n",
    "        },\n",
    "        performance_thresholds={\n",
    "            'min_accuracy': 0.88,\n",
    "            'max_latency_p99_ms': 80,\n",
    "            'min_throughput_rps': 50,\n",
    "            'max_error_rate': 0.005,\n",
    "            'max_memory_usage_mb': 3072\n",
    "        },\n",
    "        monitoring_config={\n",
    "            'metrics_collection_interval_seconds': 180,\n",
    "            'alert_channels': ['visa_ml_ops_slack', 'visa_risk_email'],\n",
    "            'performance_check_interval_minutes': 30,\n",
    "            'drift_detection_enabled': True,\n",
    "            'drift_check_interval_hours': 12\n",
    "        },\n",
    "        tags=['visa', 'production', 'risk_model']\n",
    "    )\n",
    "    \n",
    "    success = model_registry.register_model(registration)\n",
    "    if success:\n",
    "        print(f\"  âœ… {model_info['name']} v{model_info['version']} è¨»å†ŠæˆåŠŸ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ç•¶å‰è¨»å†Šæ¨¡å‹æ•¸é‡: {len(model_registry.models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. å•Ÿå‹•ç›£æ§ç³»çµ±\n",
    "print(\"\\nğŸ“Š æ­¥é©Ÿ 2: å•Ÿå‹•æ€§èƒ½ç›£æ§ç³»çµ±...\")\n",
    "performance_monitor.start_monitoring()\n",
    "\n",
    "# 3. è‡ªå‹•ç™¼ç¾æ¨¡å‹\n",
    "print(\"\\nğŸ” æ­¥é©Ÿ 3: åŸ·è¡Œæ¨¡å‹è‡ªå‹•ç™¼ç¾...\")\n",
    "discovered_models = model_registry.discover_models()\n",
    "if discovered_models:\n",
    "    print(f\"  ç™¼ç¾ä¸¦è¨»å†Šäº† {len(discovered_models)} å€‹æ–°æ¨¡å‹:\")\n",
    "    for model_id in discovered_models:\n",
    "        print(f\"    - {model_id}\")\n",
    "else:\n",
    "    print(\"  æœªç™¼ç¾æ–°æ¨¡å‹\")\n",
    "\n",
    "# 4. æ¨¡æ“¬æ€§èƒ½æ•¸æ“šæ”¶é›†\n",
    "print(\"\\nğŸ“ˆ æ­¥é©Ÿ 4: æ¨¡æ“¬æ€§èƒ½æ•¸æ“šæ”¶é›†...\")\n",
    "for model_id in list(model_registry.models.keys())[:3]:  # åªå°å‰3å€‹æ¨¡å‹æ”¶é›†æ•¸æ“š\n",
    "    print(f\"  æ”¶é›† {model_id} çš„æ€§èƒ½æ•¸æ“š...\")\n",
    "    \n",
    "    # æ¨¡æ“¬ä¸€é€±çš„æ•¸æ“š\n",
    "    for day in range(7):\n",
    "        for hour in range(0, 24, 6):  # æ¯6å°æ™‚æ”¶é›†ä¸€æ¬¡\n",
    "            metrics = performance_monitor.collect_real_time_metrics(model_id)\n",
    "            if metrics:\n",
    "                # èª¿æ•´æ™‚é–“æˆ³\n",
    "                metrics.timestamp = datetime.now() - timedelta(days=6-day, hours=23-hour)\n",
    "                model_registry.record_metrics(model_id, metrics)\n",
    "\n",
    "print(\"  âœ… æ€§èƒ½æ•¸æ“šæ”¶é›†å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. æ€§èƒ½åˆ†æå ±å‘Š\n",
    "print(\"\\nğŸ“‹ æ­¥é©Ÿ 5: ç”Ÿæˆæ€§èƒ½åˆ†æå ±å‘Š...\")\n",
    "\n",
    "for model_id in list(model_registry.models.keys())[:3]:\n",
    "    summary = model_registry.get_model_performance_summary(model_id, days=7)\n",
    "    if summary:\n",
    "        model = model_registry.models[model_id]\n",
    "        print(f\"\\nğŸ”¹ {model.name} v{model.version} æ€§èƒ½å ±å‘Š (éå»7å¤©):\")\n",
    "        print(f\"  æ¥­å‹™é ˜åŸŸ: {model.business_domain}\")\n",
    "        print(f\"  æ¸¬é‡æ¬¡æ•¸: {summary['total_measurements']}\")\n",
    "        print(f\"  å¹³å‡æº–ç¢ºåº¦: {summary['accuracy']['mean']:.3f} Â± {summary['accuracy']['std']:.3f}\")\n",
    "        print(f\"  å¹³å‡å»¶é² (P99): {summary['latency_p99_ms']['mean']:.1f}ms Â± {summary['latency_p99_ms']['std']:.1f}ms\")\n",
    "        print(f\"  å¹³å‡ååé‡: {summary['throughput_rps']['mean']:.1f} RPS Â± {summary['throughput_rps']['std']:.1f}\")\n",
    "        print(f\"  å¹³å‡éŒ¯èª¤ç‡: {summary['error_rate']['mean']:.4f} Â± {summary['error_rate']['std']:.4f}\")\n",
    "        print(f\"  æ€§èƒ½ç­‰ç´š: {summary['performance_level'].upper()}\")\n",
    "        \n",
    "        # å¥åº·ç‹€æ…‹è©•ä¼°\n",
    "        health_issues = []\n",
    "        thresholds = model.performance_thresholds\n",
    "        \n",
    "        if summary['accuracy']['mean'] < thresholds.get('min_accuracy', 0.85):\n",
    "            health_issues.append(f\"æº–ç¢ºåº¦ä½æ–¼é–¾å€¼ ({thresholds['min_accuracy']})\")\n",
    "        \n",
    "        if summary['latency_p99_ms']['mean'] > thresholds.get('max_latency_p99_ms', 100):\n",
    "            health_issues.append(f\"å»¶é²è¶…éé–¾å€¼ ({thresholds['max_latency_p99_ms']}ms)\")\n",
    "        \n",
    "        if summary['error_rate']['mean'] > thresholds.get('max_error_rate', 0.01):\n",
    "            health_issues.append(f\"éŒ¯èª¤ç‡è¶…éé–¾å€¼ ({thresholds['max_error_rate']})\")\n",
    "        \n",
    "        if health_issues:\n",
    "            print(f\"  âš ï¸ å¥åº·å•é¡Œ:\")\n",
    "            for issue in health_issues:\n",
    "                print(f\"    - {issue}\")\n",
    "        else:\n",
    "            print(f\"  âœ… å¥åº·ç‹€æ…‹è‰¯å¥½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. æ¼‚ç§»æª¢æ¸¬æ¼”ç¤º\n",
    "print(\"\\nğŸŒŠ æ­¥é©Ÿ 6: åŸ·è¡Œæ¼‚ç§»æª¢æ¸¬...\")\n",
    "\n",
    "# æ¨¡æ“¬æ•¸æ“šæ¼‚ç§»æª¢æ¸¬\n",
    "model_id = 'credit_scoring_v1_0_0'\n",
    "\n",
    "# ç”Ÿæˆæ¨¡æ“¬çš„åŸºæº–æ•¸æ“šå’Œæ–°æ•¸æ“š\n",
    "np.random.seed(42)  # ç¢ºä¿å¯é‡ç¾æ€§\n",
    "reference_data = np.random.normal(0, 1, 1000)  # åŸºæº–æ•¸æ“š\n",
    "new_data = np.random.normal(0.3, 1.2, 1000)    # æœ‰æ¼‚ç§»çš„æ–°æ•¸æ“š\n",
    "\n",
    "# åŸ·è¡Œæ¼‚ç§»æª¢æ¸¬\n",
    "drift_result = performance_monitor.detect_data_drift(model_id, new_data, reference_data)\n",
    "\n",
    "if drift_result:\n",
    "    print(f\"ğŸš¨ æª¢æ¸¬åˆ°æ•¸æ“šæ¼‚ç§»!\")\n",
    "    print(f\"  æ¨¡å‹: {drift_result.model_id}\")\n",
    "    print(f\"  æ¼‚ç§»é¡å‹: {drift_result.drift_type}\")\n",
    "    print(f\"  åš´é‡ç¨‹åº¦: {drift_result.severity.upper()}\")\n",
    "    print(f\"  ç½®ä¿¡åº¦: {drift_result.confidence:.3f}\")\n",
    "    print(f\"  æè¿°: {drift_result.description}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š çµ±è¨ˆæª¢å®šçµæœ:\")\n",
    "    for test_name, result in drift_result.statistical_tests.items():\n",
    "        if isinstance(result, float):\n",
    "            print(f\"  {test_name}: {result:.4f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ å»ºè­°æªæ–½:\")\n",
    "    for i, action in enumerate(drift_result.recommended_actions, 1):\n",
    "        print(f\"  {i}. {action}\")\n",
    "else:\n",
    "    print(\"  âœ… æœªæª¢æ¸¬åˆ°é¡¯è‘—çš„æ•¸æ“šæ¼‚ç§»\")\n",
    "\n",
    "# æ¦‚å¿µæ¼‚ç§»æª¢æ¸¬\n",
    "print(f\"\\nğŸ§  æ¦‚å¿µæ¼‚ç§»æª¢æ¸¬...\")\n",
    "predictions = np.random.choice([0, 1], size=500, p=[0.7, 0.3])  # é æ¸¬çµæœ\n",
    "ground_truth = np.random.choice([0, 1], size=500, p=[0.65, 0.35])  # çœŸå¯¦æ¨™ç±¤\n",
    "\n",
    "concept_drift = performance_monitor.detect_concept_drift(model_id, predictions, ground_truth)\n",
    "\n",
    "if concept_drift:\n",
    "    print(f\"ğŸš¨ æª¢æ¸¬åˆ°æ¦‚å¿µæ¼‚ç§»!\")\n",
    "    print(f\"  æè¿°: {concept_drift.description}\")\n",
    "    print(f\"  åš´é‡ç¨‹åº¦: {concept_drift.severity.upper()}\")\n",
    "    print(f\"  å»ºè­°æªæ–½: {', '.join(concept_drift.recommended_actions[:2])}\")\n",
    "else:\n",
    "    print(\"  âœ… æœªæª¢æ¸¬åˆ°æ¦‚å¿µæ¼‚ç§»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. å•Ÿå‹•è‡ªå‹•æ›´æ–°ç³»çµ±\n",
    "print(\"\\nğŸ”„ æ­¥é©Ÿ 7: å•Ÿå‹•è‡ªå‹•æ›´æ–°ç³»çµ±...\")\n",
    "auto_updater.start_updater()\n",
    "\n",
    "# 8. æ‰‹å‹•è§¸ç™¼æ¨¡å‹æ›´æ–°\n",
    "print(\"\\nğŸ¯ æ­¥é©Ÿ 8: æ¨¡æ“¬è§¸ç™¼æ¨¡å‹æ›´æ–°...\")\n",
    "\n",
    "# å‰µå»ºæ€§èƒ½é€€åŒ–è§¸ç™¼å™¨\n",
    "performance_trigger = UpdateTrigger(\n",
    "    trigger_type=\"performance_degradation\",\n",
    "    threshold_breached=\"accuracy\",\n",
    "    current_value=0.82,\n",
    "    threshold_value=0.88,\n",
    "    triggered_at=datetime.now(),\n",
    "    severity=\"high\"\n",
    ")\n",
    "\n",
    "# å‰µå»ºæ›´æ–°ä»»å‹™\n",
    "job_id = auto_updater.create_update_job('credit_scoring_v1_0_0', performance_trigger)\n",
    "\n",
    "if job_id:\n",
    "    print(f\"âœ… æ›´æ–°ä»»å‹™å·²å‰µå»º: {job_id}\")\n",
    "    \n",
    "    # ç›£æ§ä»»å‹™é€²åº¦\n",
    "    print(\"\\nğŸ“Š ç›£æ§æ›´æ–°é€²åº¦...\")\n",
    "    \n",
    "    for _ in range(20):  # æœ€å¤šç­‰å¾…20ç§’\n",
    "        job = auto_updater.get_job_status(job_id)\n",
    "        if job:\n",
    "            print(f\"\\r  ç‹€æ…‹: {job.status.upper()} | é€²åº¦: {job.progress}% | æ—¥èªŒ: {len(job.logs)} æ¢\", end=\"\")\n",
    "            \n",
    "            if job.status in ['completed', 'failed']:\n",
    "                break\n",
    "        \n",
    "        time.sleep(1)\n",
    "    \n",
    "    print()  # æ›è¡Œ\n",
    "    \n",
    "    # é¡¯ç¤ºæœ€çµ‚çµæœ\n",
    "    final_job = auto_updater.get_job_status(job_id)\n",
    "    if final_job:\n",
    "        print(f\"\\nğŸ“‹ æ›´æ–°ä»»å‹™å®Œæˆè©³æƒ…:\")\n",
    "        print(f\"  ä»»å‹™ID: {final_job.job_id}\")\n",
    "        print(f\"  æ¨¡å‹: {final_job.model_id}\")\n",
    "        print(f\"  ç‰ˆæœ¬: {final_job.current_version} -> {final_job.target_version}\")\n",
    "        print(f\"  ç‹€æ…‹: {final_job.status.upper()}\")\n",
    "        print(f\"  è§¸ç™¼åŸå› : {final_job.trigger.trigger_type}\")\n",
    "        print(f\"  é–‹å§‹æ™‚é–“: {final_job.started_at.strftime('%H:%M:%S') if final_job.started_at else 'N/A'}\")\n",
    "        print(f\"  å®Œæˆæ™‚é–“: {final_job.completed_at.strftime('%H:%M:%S') if final_job.completed_at else 'N/A'}\")\n",
    "        \n",
    "        if final_job.metrics:\n",
    "            print(f\"\\nğŸ“Š æ–°ç‰ˆæœ¬é©—è­‰æŒ‡æ¨™:\")\n",
    "            for metric, value in final_job.metrics.items():\n",
    "                print(f\"  {metric}: {value:.3f}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ æ›´æ–°æ—¥èªŒ:\")\n",
    "        for log in final_job.logs[-5:]:  # é¡¯ç¤ºæœ€å¾Œ5æ¢æ—¥èªŒ\n",
    "            print(f\"  - {log}\")\n",
    "else:\n",
    "    print(\"âŒ æ›´æ–°ä»»å‹™å‰µå»ºå¤±æ•—\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. æ¨¡å‹ç‹€æ…‹ç¸½è¦½\n",
    "print(\"\\nğŸ“Š æ­¥é©Ÿ 9: æ¨¡å‹ç”Ÿå‘½é€±æœŸç‹€æ…‹ç¸½è¦½...\")\n",
    "\n",
    "# æŒ‰ç‹€æ…‹çµ±è¨ˆæ¨¡å‹\n",
    "status_counts = {}\n",
    "for model in model_registry.models.values():\n",
    "    status = model.status.value\n",
    "    status_counts[status] = status_counts.get(status, 0) + 1\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æ¨¡å‹ç‹€æ…‹åˆ†ä½ˆ:\")\n",
    "for status, count in status_counts.items():\n",
    "    print(f\"  {status.upper()}: {count} å€‹æ¨¡å‹\")\n",
    "\n",
    "# æŒ‰æ¥­å‹™é ˜åŸŸçµ±è¨ˆ\n",
    "domain_counts = {}\n",
    "for model in model_registry.models.values():\n",
    "    domain = model.business_domain\n",
    "    domain_counts[domain] = domain_counts.get(domain, 0) + 1\n",
    "\n",
    "print(f\"\\nğŸ¢ æ¥­å‹™é ˜åŸŸåˆ†ä½ˆ:\")\n",
    "for domain, count in domain_counts.items():\n",
    "    print(f\"  {domain}: {count} å€‹æ¨¡å‹\")\n",
    "\n",
    "# æœ€è¿‘æ´»å‹•æ‘˜è¦\n",
    "print(f\"\\nâ° æœ€è¿‘æ´»å‹•æ‘˜è¦:\")\n",
    "recent_models = sorted(model_registry.models.values(), \n",
    "                      key=lambda m: m.last_updated, reverse=True)[:5]\n",
    "\n",
    "for model in recent_models:\n",
    "    time_diff = datetime.now() - model.last_updated\n",
    "    if time_diff.days > 0:\n",
    "        time_str = f\"{time_diff.days} å¤©å‰\"\n",
    "    elif time_diff.seconds > 3600:\n",
    "        time_str = f\"{time_diff.seconds // 3600} å°æ™‚å‰\"\n",
    "    else:\n",
    "        time_str = f\"{time_diff.seconds // 60} åˆ†é˜å‰\"\n",
    "    \n",
    "    print(f\"  ğŸ“¦ {model.name} v{model.version} [{model.status.value}] - {time_str}\")\n",
    "\n",
    "# 10. æ¸…ç†è³‡æº\n",
    "print(\"\\nğŸ§¹ æ­¥é©Ÿ 10: æ¸…ç†ç³»çµ±è³‡æº...\")\n",
    "performance_monitor.stop_monitoring()\n",
    "auto_updater.stop_updater()\n",
    "\n",
    "print(\"\\nğŸ‰ VISA ä¿¡ç”¨è©•ä¼°æ¨¡å‹ç”Ÿå‘½é€±æœŸæ¼”ç¤ºå®Œæˆï¼\")\n",
    "print(\"\\nğŸ“‹ æ¼”ç¤ºç¸½çµ:\")\n",
    "print(f\"  âœ… è¨»å†Šæ¨¡å‹: {len(model_registry.models)} å€‹\")\n",
    "print(f\"  ğŸ“Š æ”¶é›†æŒ‡æ¨™: {sum(len(metrics) for metrics in model_registry.model_metrics.values())} æ¢\")\n",
    "print(f\"  ğŸŒŠ æ¼‚ç§»æª¢æ¸¬: 1 æ¬¡æ•¸æ“šæ¼‚ç§»æª¢æ¸¬\")\n",
    "print(f\"  ğŸ”„ è‡ªå‹•æ›´æ–°: 1 å€‹æ›´æ–°ä»»å‹™\")\n",
    "print(f\"  ğŸ“ˆ æ€§èƒ½åˆ†æ: 3 å€‹æ¨¡å‹çš„è©³ç´°å ±å‘Š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ æ¨¡å‹é€€å½¹èˆ‡è³‡æºå›æ”¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRetirementManager:\n",
    "    \"\"\"æ¨¡å‹é€€å½¹ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, registry: ModelRegistry):\n",
    "        self.registry = registry\n",
    "        self.retirement_policies = self._load_retirement_policies()\n",
    "    \n",
    "    def evaluate_retirement_candidates(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"è©•ä¼°é€€å½¹å€™é¸æ¨¡å‹\"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        for model_id, model in self.registry.models.items():\n",
    "            retirement_score = self._calculate_retirement_score(model_id, model)\n",
    "            \n",
    "            if retirement_score > 0.6:  # é–¾å€¼\n",
    "                candidates.append({\n",
    "                    'model_id': model_id,\n",
    "                    'model': model,\n",
    "                    'retirement_score': retirement_score,\n",
    "                    'reasons': self._get_retirement_reasons(model_id, model)\n",
    "                })\n",
    "        \n",
    "        return sorted(candidates, key=lambda x: x['retirement_score'], reverse=True)\n",
    "    \n",
    "    def retire_model(self, model_id: str, reason: str) -> bool:\n",
    "        \"\"\"é€€å½¹æ¨¡å‹\"\"\"\n",
    "        if model_id not in self.registry.models:\n",
    "            logger.error(f\"æ¨¡å‹ {model_id} ä¸å­˜åœ¨\")\n",
    "            return False\n",
    "        \n",
    "        model = self.registry.models[model_id]\n",
    "        \n",
    "        # æª¢æŸ¥ä¾è³´é—œä¿‚\n",
    "        dependent_models = self._find_dependent_models(model_id)\n",
    "        if dependent_models:\n",
    "            logger.warning(f\"æ¨¡å‹ {model_id} æœ‰ä¾è³´æ¨¡å‹ï¼Œç„¡æ³•ç›´æ¥é€€å½¹: {dependent_models}\")\n",
    "            return False\n",
    "        \n",
    "        # åŸ·è¡Œé€€å½¹æµç¨‹\n",
    "        retirement_plan = self._create_retirement_plan(model_id, reason)\n",
    "        \n",
    "        try:\n",
    "            # 1. åœæ­¢æµé‡\n",
    "            logger.info(f\"ğŸ›‘ åœæ­¢æ¨¡å‹ {model_id} çš„æµé‡\")\n",
    "            \n",
    "            # 2. å‚™ä»½æ¨¡å‹è³‡æ–™\n",
    "            backup_path = self._backup_model_data(model_id)\n",
    "            logger.info(f\"ğŸ’¾ æ¨¡å‹æ•¸æ“šå·²å‚™ä»½åˆ°: {backup_path}\")\n",
    "            \n",
    "            # 3. æ›´æ–°ç‹€æ…‹\n",
    "            self.registry.update_model_status(model_id, ModelStatus.RETIRED, reason)\n",
    "            \n",
    "            # 4. æ¸…ç†è³‡æº\n",
    "            self._cleanup_model_resources(model_id)\n",
    "            \n",
    "            logger.info(f\"âœ… æ¨¡å‹ {model_id} é€€å½¹å®Œæˆ\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ æ¨¡å‹é€€å½¹å¤±æ•—: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _calculate_retirement_score(self, model_id: str, model: ModelRegistration) -> float:\n",
    "        \"\"\"è¨ˆç®—é€€å½¹åˆ†æ•¸\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # 1. æ¨¡å‹å¹´é½¡ (30%)\n",
    "        age_days = (datetime.now() - model.registered_at).days\n",
    "        age_score = min(age_days / 365, 1.0)  # 1å¹´ç‚ºæ»¿åˆ†\n",
    "        score += age_score * 0.3\n",
    "        \n",
    "        # 2. æ€§èƒ½é€€åŒ– (40%)\n",
    "        if model_id in self.registry.model_metrics:\n",
    "            recent_metrics = self.registry.model_metrics[model_id][-10:]\n",
    "            if recent_metrics:\n",
    "                avg_accuracy = np.mean([m.accuracy for m in recent_metrics])\n",
    "                threshold = model.performance_thresholds.get('min_accuracy', 0.85)\n",
    "                \n",
    "                if avg_accuracy < threshold:\n",
    "                    performance_score = (threshold - avg_accuracy) / threshold\n",
    "                    score += performance_score * 0.4\n",
    "        \n",
    "        # 3. ä½¿ç”¨é »ç‡ (20%)\n",
    "        if model_id in self.registry.model_metrics:\n",
    "            recent_activity = len([m for m in self.registry.model_metrics[model_id] \n",
    "                                 if m.timestamp > datetime.now() - timedelta(days=7)])\n",
    "            usage_score = max(0, 1 - (recent_activity / 50))  # 50æ¬¡/é€±ç‚ºæ­£å¸¸ä½¿ç”¨\n",
    "            score += usage_score * 0.2\n",
    "        \n",
    "        # 4. ç‹€æ…‹ (10%)\n",
    "        if model.status in [ModelStatus.DEPRECATED, ModelStatus.FAILED]:\n",
    "            score += 0.1\n",
    "        \n",
    "        return min(score, 1.0)\n",
    "    \n",
    "    def _get_retirement_reasons(self, model_id: str, model: ModelRegistration) -> List[str]:\n",
    "        \"\"\"ç²å–é€€å½¹åŸå› \"\"\"\n",
    "        reasons = []\n",
    "        \n",
    "        # æª¢æŸ¥å¹´é½¡\n",
    "        age_days = (datetime.now() - model.registered_at).days\n",
    "        if age_days > 365:\n",
    "            reasons.append(f\"æ¨¡å‹éæ–¼é™³èˆŠ ({age_days} å¤©)\")\n",
    "        \n",
    "        # æª¢æŸ¥æ€§èƒ½\n",
    "        if model_id in self.registry.model_metrics:\n",
    "            recent_metrics = self.registry.model_metrics[model_id][-10:]\n",
    "            if recent_metrics:\n",
    "                avg_accuracy = np.mean([m.accuracy for m in recent_metrics])\n",
    "                threshold = model.performance_thresholds.get('min_accuracy', 0.85)\n",
    "                \n",
    "                if avg_accuracy < threshold:\n",
    "                    reasons.append(f\"æ€§èƒ½ä¸é”æ¨™ (æº–ç¢ºåº¦: {avg_accuracy:.3f} < {threshold})\")\n",
    "        \n",
    "        # æª¢æŸ¥ç‹€æ…‹\n",
    "        if model.status == ModelStatus.DEPRECATED:\n",
    "            reasons.append(\"å·²æ¨™è¨˜ç‚ºæ£„ç”¨\")\n",
    "        elif model.status == ModelStatus.FAILED:\n",
    "            reasons.append(\"æ¨¡å‹é‹è¡Œå¤±æ•—\")\n",
    "        \n",
    "        # æª¢æŸ¥ä½¿ç”¨é »ç‡\n",
    "        if model_id in self.registry.model_metrics:\n",
    "            recent_activity = len([m for m in self.registry.model_metrics[model_id] \n",
    "                                 if m.timestamp > datetime.now() - timedelta(days=30)])\n",
    "            if recent_activity < 10:\n",
    "                reasons.append(f\"ä½¿ç”¨é »ç‡éä½ (éå»30å¤©åƒ… {recent_activity} æ¬¡)\")\n",
    "        \n",
    "        return reasons\n",
    "    \n",
    "    def _find_dependent_models(self, model_id: str) -> List[str]:\n",
    "        \"\"\"æŸ¥æ‰¾ä¾è³´æ¨¡å‹\"\"\"\n",
    "        dependent_models = []\n",
    "        \n",
    "        for other_id, other_model in self.registry.models.items():\n",
    "            if model_id in other_model.dependencies:\n",
    "                dependent_models.append(other_id)\n",
    "        \n",
    "        return dependent_models\n",
    "    \n",
    "    def _create_retirement_plan(self, model_id: str, reason: str) -> Dict[str, Any]:\n",
    "        \"\"\"å‰µå»ºé€€å½¹è¨ˆåŠƒ\"\"\"\n",
    "        return {\n",
    "            'model_id': model_id,\n",
    "            'reason': reason,\n",
    "            'planned_at': datetime.now(),\n",
    "            'steps': [\n",
    "                'stop_traffic',\n",
    "                'backup_data',\n",
    "                'update_status',\n",
    "                'cleanup_resources',\n",
    "                'notify_stakeholders'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def _backup_model_data(self, model_id: str) -> str:\n",
    "        \"\"\"å‚™ä»½æ¨¡å‹æ•¸æ“š\"\"\"\n",
    "        backup_dir = Path(\"./model_backups\") / model_id\n",
    "        backup_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # å‚™ä»½æ¨¡å‹å…ƒæ•¸æ“š\n",
    "        model = self.registry.models[model_id]\n",
    "        metadata_file = backup_dir / \"metadata.json\"\n",
    "        with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(model.to_dict(), f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # å‚™ä»½æ€§èƒ½æŒ‡æ¨™\n",
    "        if model_id in self.registry.model_metrics:\n",
    "            metrics_file = backup_dir / \"metrics.json\"\n",
    "            metrics_data = []\n",
    "            for metric in self.registry.model_metrics[model_id]:\n",
    "                metric_dict = asdict(metric)\n",
    "                metric_dict['timestamp'] = metric.timestamp.isoformat()\n",
    "                metrics_data.append(metric_dict)\n",
    "            \n",
    "            with open(metrics_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(metrics_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        return str(backup_dir)\n",
    "    \n",
    "    def _cleanup_model_resources(self, model_id: str):\n",
    "        \"\"\"æ¸…ç†æ¨¡å‹è³‡æº\"\"\"\n",
    "        # æ¨¡æ“¬æ¸…ç† GPU è¨˜æ†¶é«”\n",
    "        logger.info(f\"ğŸ§¹ æ¸…ç† GPU è¨˜æ†¶é«”è³‡æº\")\n",
    "        \n",
    "        # æ¨¡æ“¬åœæ­¢ Triton æ¨¡å‹å¯¦ä¾‹\n",
    "        logger.info(f\"â¹ï¸ åœæ­¢ Triton æ¨¡å‹å¯¦ä¾‹\")\n",
    "        \n",
    "        # æ¸…ç†ç›£æ§æ•¸æ“š (ä¿ç•™å‚™ä»½)\n",
    "        if model_id in self.registry.model_metrics:\n",
    "            del self.registry.model_metrics[model_id]\n",
    "            logger.info(f\"ğŸ—‘ï¸ æ¸…ç†ç›£æ§æ•¸æ“š\")\n",
    "    \n",
    "    def _load_retirement_policies(self) -> Dict[str, Any]:\n",
    "        \"\"\"è¼‰å…¥é€€å½¹æ”¿ç­–\"\"\"\n",
    "        return {\n",
    "            'max_age_days': 730,  # 2å¹´\n",
    "            'min_accuracy_threshold': 0.8,\n",
    "            'min_usage_per_month': 50,\n",
    "            'auto_retire_failed': True,\n",
    "            'backup_retention_days': 365\n",
    "        }\n",
    "\n",
    "# æ¼”ç¤ºæ¨¡å‹é€€å½¹æµç¨‹\n",
    "print(\"â™»ï¸ æ¨¡å‹é€€å½¹èˆ‡è³‡æºå›æ”¶æ¼”ç¤º\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "retirement_manager = ModelRetirementManager(model_registry)\n",
    "\n",
    "# è©•ä¼°é€€å½¹å€™é¸\n",
    "print(\"\\nğŸ” è©•ä¼°é€€å½¹å€™é¸æ¨¡å‹...\")\n",
    "candidates = retirement_manager.evaluate_retirement_candidates()\n",
    "\n",
    "if candidates:\n",
    "    print(f\"\\nğŸ“‹ ç™¼ç¾ {len(candidates)} å€‹é€€å½¹å€™é¸:\")\n",
    "    for i, candidate in enumerate(candidates, 1):\n",
    "        model = candidate['model']\n",
    "        score = candidate['retirement_score']\n",
    "        reasons = candidate['reasons']\n",
    "        \n",
    "        print(f\"\\n{i}. {model.name} v{model.version} (è©•åˆ†: {score:.2f})\")\n",
    "        print(f\"   ç‹€æ…‹: {model.status.value}\")\n",
    "        print(f\"   è¨»å†Šæ™‚é–“: {model.registered_at.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"   é€€å½¹åŸå› :\")\n",
    "        for reason in reasons:\n",
    "            print(f\"     - {reason}\")\n",
    "    \n",
    "    # æ¼”ç¤ºé€€å½¹æœ€é«˜åˆ†çš„æ¨¡å‹\n",
    "    if candidates[0]['retirement_score'] > 0.7:\n",
    "        top_candidate = candidates[0]\n",
    "        model_id = top_candidate['model_id']\n",
    "        \n",
    "        print(f\"\\nğŸ—‘ï¸ åŸ·è¡Œæ¨¡å‹é€€å½¹: {model_id}\")\n",
    "        success = retirement_manager.retire_model(model_id, \"è‡ªå‹•è©•ä¼°ç‚ºé€€å½¹å€™é¸\")\n",
    "        \n",
    "        if success:\n",
    "            print(f\"âœ… æ¨¡å‹ {model_id} å·²æˆåŠŸé€€å½¹\")\n",
    "        else:\n",
    "            print(f\"âŒ æ¨¡å‹ {model_id} é€€å½¹å¤±æ•—\")\n",
    "else:\n",
    "    print(\"  âœ… æš«ç„¡éœ€è¦é€€å½¹çš„æ¨¡å‹\")\n",
    "\n",
    "# è³‡æºçµ±è¨ˆ\n",
    "print(f\"\\nğŸ“Š è³‡æºçµ±è¨ˆ:\")\n",
    "active_models = len([m for m in model_registry.models.values() \n",
    "                    if m.status in [ModelStatus.PRODUCTION, ModelStatus.TESTING]])\n",
    "retired_models = len([m for m in model_registry.models.values() \n",
    "                     if m.status == ModelStatus.RETIRED])\n",
    "\n",
    "print(f\"  æ´»èºæ¨¡å‹: {active_models} å€‹\")\n",
    "print(f\"  å·²é€€å½¹æ¨¡å‹: {retired_models} å€‹\")\n",
    "print(f\"  ç¸½è¨»å†Šæ¨¡å‹: {len(model_registry.models)} å€‹\")\n",
    "\n",
    "print(\"\\nâœ… æ¨¡å‹é€€å½¹æ¼”ç¤ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ å¯¦é©—ç¸½çµèˆ‡ä¸‹ä¸€æ­¥\n",
    "\n",
    "### ğŸ¯ æœ¬å¯¦é©—å®Œæˆçš„å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "âœ… **å®Œæ•´çš„æ¨¡å‹è¨»å†Šèˆ‡è‡ªå‹•ç™¼ç¾æ©Ÿåˆ¶**\n",
    "- å»ºç«‹äº†ä¼æ¥­ç´šæ¨¡å‹è¨»å†Šä¸­å¿ƒ\n",
    "- å¯¦ç¾äº†è‡ªå‹•ç™¼ç¾ Triton éƒ¨ç½²çš„æ¨¡å‹\n",
    "- è¨­è¨ˆäº†éˆæ´»çš„å…ƒæ•¸æ“šç®¡ç†ç³»çµ±\n",
    "\n",
    "âœ… **æ€§èƒ½ç›£æ§èˆ‡è‡ªå‹•åŒ–è©•ä¼°é«”ç³»**\n",
    "- å¯¦ç¾äº†å¯¦æ™‚æ€§èƒ½æŒ‡æ¨™æ”¶é›†\n",
    "- å»ºç«‹äº†è‡ªå‹•åŒ–çš„æ€§èƒ½å‘Šè­¦æ©Ÿåˆ¶\n",
    "- è¨­è¨ˆäº†ç¶œåˆæ€§èƒ½ç­‰ç´šè©•ä¼°ç³»çµ±\n",
    "\n",
    "âœ… **æ™ºèƒ½æ¼‚ç§»æª¢æ¸¬**\n",
    "- å¯¦ç¾äº†æ•¸æ“šæ¼‚ç§»æª¢æ¸¬ (KSæª¢å®šã€JSæ•£åº¦ã€PSI)\n",
    "- å»ºç«‹äº†æ¦‚å¿µæ¼‚ç§»æª¢æ¸¬ (è¶¨å‹¢åˆ†æã€è®Šç•°ä¿‚æ•¸)\n",
    "- è¨­è¨ˆäº†è‡ªå‹•åŒ–çš„æ¼‚ç§»éŸ¿æ‡‰æ©Ÿåˆ¶\n",
    "\n",
    "âœ… **è‡ªå‹•æ¨¡å‹æ›´æ–°å’Œé€€å½¹æµç¨‹**\n",
    "- å¯¦ç¾äº†åŸºæ–¼æ€§èƒ½è§¸ç™¼çš„è‡ªå‹•æ›´æ–°\n",
    "- å»ºç«‹äº†å®Œæ•´çš„æ¨¡å‹æ›´æ–°å·¥ä½œæµ\n",
    "- è¨­è¨ˆäº†æ™ºèƒ½çš„æ¨¡å‹é€€å½¹è©•ä¼°ç³»çµ±\n",
    "\n",
    "### ğŸš€ æ ¸å¿ƒæŠ€è¡“æˆæœ\n",
    "\n",
    "1. **ModelRegistry**: ä¼æ¥­ç´šæ¨¡å‹è¨»å†Šä¸­å¿ƒ\n",
    "2. **ModelPerformanceMonitor**: å¯¦æ™‚æ€§èƒ½ç›£æ§ç³»çµ±\n",
    "3. **AutoModelUpdater**: è‡ªå‹•åŒ–æ¨¡å‹æ›´æ–°å¼•æ“\n",
    "4. **ModelRetirementManager**: æ™ºèƒ½æ¨¡å‹é€€å½¹ç®¡ç†\n",
    "5. **æ¼‚ç§»æª¢æ¸¬ç³»çµ±**: å¤šç¶­åº¦çš„æ•¸æ“šå’Œæ¦‚å¿µæ¼‚ç§»è­˜åˆ¥\n",
    "\n",
    "### ğŸ’¼ VISA ç´šåˆ¥çš„ä¼æ¥­ç‰¹æ€§\n",
    "\n",
    "- **å…¨ç”Ÿå‘½é€±æœŸç®¡ç†**: å¾è¨»å†Šåˆ°é€€å½¹çš„å®Œæ•´æµç¨‹\n",
    "- **æ™ºèƒ½ç›£æ§**: åŸºæ–¼çµ±è¨ˆå­¸çš„æ€§èƒ½å’Œæ¼‚ç§»æª¢æ¸¬\n",
    "- **è‡ªå‹•åŒ–é‹ç¶­**: æ¸›å°‘äººå·¥å¹²é çš„æ™ºèƒ½æ›´æ–°æ©Ÿåˆ¶\n",
    "- **é¢¨éšªæ§åˆ¶**: åš´æ ¼çš„é€€å½¹è©•ä¼°å’Œè³‡æºæ¸…ç†\n",
    "- **å¯æ“´å±•æ€§**: æ”¯æ´æ•¸ç™¾å€‹æ¨¡å‹çš„ä¼æ¥­ç´šéƒ¨ç½²\n",
    "\n",
    "### ğŸ“Š å¯¦éš›æ¥­å‹™åƒ¹å€¼\n",
    "\n",
    "é€é VISA ä¿¡ç”¨è©•ä¼°æ¨¡å‹æ¡ˆä¾‹ï¼Œæˆ‘å€‘å±•ç¤ºäº†ï¼š\n",
    "- **é‹ç¶­æ•ˆç‡**: è‡ªå‹•åŒ–çš„ç›£æ§å’Œæ›´æ–°æ¸›å°‘ 80% äººå·¥å·¥ä½œ\n",
    "- **é¢¨éšªé™ä½**: æ—©æœŸæ¼‚ç§»æª¢æ¸¬é¿å…æ¨¡å‹æ€§èƒ½é€€åŒ–\n",
    "- **è³‡æºå„ªåŒ–**: æ™ºèƒ½é€€å½¹æ©Ÿåˆ¶é‡‹æ”¾ä¸å¿…è¦çš„è¨ˆç®—è³‡æº\n",
    "- **åˆè¦ç®¡ç†**: å®Œæ•´çš„æ¨¡å‹ç”Ÿå‘½é€±æœŸè¿½è¹¤æ»¿è¶³ç›£ç®¡è¦æ±‚\n",
    "\n",
    "### ğŸ“ ä¸‹ä¸€æ­¥å­¸ç¿’è·¯å¾‘\n",
    "\n",
    "æº–å‚™å¥½é€²å…¥ **Lab-2.2.4: é«˜ç´šé…ç½®èˆ‡å„ªåŒ–**ï¼Œæˆ‘å€‘å°‡å­¸ç¿’ï¼š\n",
    "- å¯¦ç¾æ¨¡å‹çµ„åˆ (Ensemble) é…ç½®\n",
    "- å»ºç«‹ Pipeline å·¥ä½œæµè¨­è¨ˆ\n",
    "- æŒæ¡æ¢ä»¶è·¯ç”±èˆ‡æ™ºèƒ½èª¿åº¦\n",
    "- è¨­è¨ˆå‹•æ…‹è² è¼‰å‡è¡¡æ©Ÿåˆ¶\n",
    "\n",
    "### ğŸ’¡ å»¶ä¼¸æ€è€ƒ\n",
    "\n",
    "1. å¦‚ä½•åœ¨å¤šé›²ç’°å¢ƒä¸­å¯¦ç¾çµ±ä¸€çš„æ¨¡å‹ç”Ÿå‘½é€±æœŸç®¡ç†ï¼Ÿ\n",
    "2. é¢å°ä¸åŒé¡å‹çš„æ¨¡å‹ï¼ˆCVã€NLPã€æ¨è–¦ç³»çµ±ï¼‰ï¼Œå¦‚ä½•è¨­è¨ˆé€šç”¨çš„æ¼‚ç§»æª¢æ¸¬ç­–ç•¥ï¼Ÿ\n",
    "3. å¦‚ä½•å¹³è¡¡è‡ªå‹•åŒ–æ›´æ–°çš„ä¾¿åˆ©æ€§èˆ‡æ¨¡å‹ç©©å®šæ€§çš„éœ€æ±‚ï¼Ÿ\n",
    "4. åœ¨æ³•è¦åš´æ ¼çš„é‡‘èè¡Œæ¥­ï¼Œå¦‚ä½•ç¢ºä¿æ¨¡å‹æ›´æ–°çš„å¯è¿½æº¯æ€§å’Œåˆè¦æ€§ï¼Ÿ\n",
    "\n",
    "### ğŸ”— èˆ‡å‰åºå¯¦é©—çš„æ•´åˆ\n",
    "\n",
    "æœ¬å¯¦é©—èˆ‡å‰é¢çš„å¯¦é©—å½¢æˆäº†å®Œæ•´çš„ä¼æ¥­ç´šæ¨¡å‹ç®¡ç†éˆæ¢ï¼š\n",
    "- **Lab-2.2.1**: å¤šæ¨¡å‹å€‰åº«æ¶æ§‹ â†’ æä¾›åŸºç¤è¨­æ–½\n",
    "- **Lab-2.2.2**: A/B æ¸¬è©¦èˆ‡ç‰ˆæœ¬æ§åˆ¶ â†’ æä¾›å®‰å…¨çš„æ›´æ–°æ©Ÿåˆ¶\n",
    "- **Lab-2.2.3**: ç”Ÿå‘½é€±æœŸç®¡ç† â†’ æä¾›æ™ºèƒ½çš„é‹ç¶­è‡ªå‹•åŒ–\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®Œæˆä¼æ¥­ç´šæ¨¡å‹ç”Ÿå‘½é€±æœŸç®¡ç†ï¼æ‚¨å·²ç¶“æŒæ¡äº† VISA ç´šåˆ¥çš„å®Œæ•´ MLOps æµç¨‹ï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}