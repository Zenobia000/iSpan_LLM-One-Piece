# å®‰è£æ³¨æ„äº‹é …
## Installation Notes

**æœ€å¾Œæ›´æ–°**: 2025-10-09

---

## âš ï¸ Poetry ä¾è³´è§£æå•é¡Œ

### å•é¡Œæè¿°
Poetry 2.1.4 åœ¨è§£ææŸäº›ä¾è³´æ™‚å‡ºç¾ `Could not parse version constraint: <empty>` éŒ¯èª¤ã€‚

### è§£æ±ºæ–¹æ¡ˆ

**æ–¹æ³• 1: ä½¿ç”¨ pip å®‰è£å¯é¸ä¾è³´** (æ¨è–¦)

```bash
# 1. å®‰è£æ ¸å¿ƒä¾è³´ (Poetry)
cd 00-Course_Setup
poetry install

# 2. æ¿€æ´»è™›æ“¬ç’°å¢ƒ
source .venv/bin/activate

# 3. ä½¿ç”¨ pip å®‰è£å¯é¸ä¾è³´
pip install vllm>=0.6.0
pip install flash-attn --no-build-isolation
```

**æ–¹æ³• 2: ç›´æ¥ä½¿ç”¨ pip** (æ›¿ä»£æ–¹æ¡ˆ)

```bash
# 1. å‰µå»ºè™›æ“¬ç’°å¢ƒ
python3.10 -m venv .venv
source .venv/bin/activate

# 2. å®‰è£ PyTorch (CUDA 12.1)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 3. å®‰è£æ ¸å¿ƒä¾è³´
pip install transformers>=4.57 peft>=0.7 datasets>=2.14 accelerate>=0.24
pip install bitsandbytes sentencepiece protobuf

# 4. å®‰è£é–‹ç™¼å·¥å…·
pip install jupyterlab ipywidgets matplotlib seaborn tqdm pandas scikit-learn

# 5. å®‰è£å¯é¸ä¾è³´
pip install vllm>=0.6.0
pip install fastapi uvicorn
pip install flash-attn --no-build-isolation  # éœ€è¦ç·¨è­¯
```

---

## ğŸ“¦ å·²å®‰è£çš„ä¾è³´ (ç•¶å‰ç’°å¢ƒ)

### æ ¸å¿ƒæ¡†æ¶
- PyTorch 2.5.1+cu121
- Transformers 4.57+
- PEFT 0.7+
- Datasets 2.14+

### é–‹ç™¼å·¥å…·
- JupyterLab 4.4+
- Matplotlib, Seaborn
- Pandas, NumPy

### å¯é¸ä¾è³´
- vLLM 0.7.3 (å·²å®‰è£)
- flash-attn (éœ€æ‰‹å‹•å®‰è£)

---

## ğŸ”§ Flash-Attention å®‰è£

**è¦æ±‚**:
- CUDA 11.6+
- GPU Compute Capability â‰¥ 7.5 (Turing æ¶æ§‹ä»¥ä¸Š)
- è¶³å¤ çš„ç·¨è­¯è³‡æº (RAM >16GB å»ºè­°)

**å®‰è£å‘½ä»¤**:
```bash
pip install flash-attn --no-build-isolation
```

**å¦‚æœç·¨è­¯å¤±æ•—**:
```bash
# é™åˆ¶ä¸¦è¡Œç·¨è­¯
MAX_JOBS=2 pip install flash-attn --no-build-isolation

# æˆ–å¾ wheel å®‰è£ (å¦‚æœå¯ç”¨)
pip install flash-attn --find-links https://github.com/Dao-AILab/flash-attention/releases
```

---

## âœ… é©—è­‰å®‰è£

```python
# æ¸¬è©¦æ ¸å¿ƒä¾è³´
import torch
import transformers
import peft
print(f"PyTorch: {torch.__version__}")
print(f"CUDA: {torch.cuda.is_available()}")
print(f"Transformers: {transformers.__version__}")
print(f"PEFT: {peft.__version__}")

# æ¸¬è©¦å¯é¸ä¾è³´
try:
    import vllm
    print(f"vLLM: {vllm.__version__}")
except ImportError:
    print("vLLM: Not installed")

try:
    import flash_attn
    print("Flash-Attention: Installed")
except ImportError:
    print("Flash-Attention: Not installed")
```

---

## ğŸ“ å·²çŸ¥å•é¡Œ

### Poetry ä¾è³´è§£æéŒ¯èª¤
- **å•é¡Œ**: `Could not parse version constraint: <empty>`
- **å½±éŸ¿**: `poetry install`, `poetry show`, `poetry update` å‘½ä»¤å¤±æ•—
- **è‡¨æ™‚æ–¹æ¡ˆ**: ä½¿ç”¨ pip å®‰è£å¯é¸ä¾è³´
- **é•·æœŸæ–¹æ¡ˆ**: ç­‰å¾… Poetry 2.2 ä¿®å¾©æˆ–é™ç´šåˆ° Poetry 1.x

### è§£æ±ºé€²åº¦
- âœ… å·²å¾ Poetry extras ç§»é™¤ flash-attn
- âœ… å·²æ›´æ–° protobuf ç‰ˆæœ¬ç´„æŸ
- âœ… å·²æä¾› pip å®‰è£æ›¿ä»£æ–¹æ¡ˆ
- â¸ï¸ ç­‰å¾… Poetry å®˜æ–¹ä¿®å¾©

---

**ç¶­è­·è€…**: LLM æ•™å­¸å°ˆæ¡ˆåœ˜éšŠ
**å•é¡Œè¿½è¹¤**: æŒçºŒç›£æ§ Poetry æ›´æ–°
