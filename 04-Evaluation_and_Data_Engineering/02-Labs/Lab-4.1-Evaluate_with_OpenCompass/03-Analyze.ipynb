{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.1 - OpenCompass 評估實戰\n",
    "## Notebook 03: 結果分析\n",
    "\n",
    "**學習目標**:\n",
    "1. 載入評估結果並進行統計分析\n",
    "2. 錯誤分析 (找出常見錯誤模式)\n",
    "3. 信心度分析 (檢查 logits 分佈)\n",
    "4. 學科難度排名\n",
    "5. 模型強弱項識別\n",
    "\n",
    "**預計時間**: 30-45 分鐘\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 載入評估結果\n",
    "\n",
    "從 02-Evaluate.ipynb 產生的 JSON 檔案中載入結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 設定路徑\n",
    "RESULTS_DIR = Path(\"./results\")\n",
    "ANALYSIS_DIR = Path(\"./analysis\")\n",
    "ANALYSIS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"📂 載入評估結果...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 載入結果檔案\n",
    "results = {}\n",
    "result_files = {\n",
    "    'llama-2-7b': RESULTS_DIR / \"llama2_7b_results.json\",\n",
    "    'qwen-7b': RESULTS_DIR / \"qwen_7b_results.json\"\n",
    "}\n",
    "\n",
    "for model_key, result_file in result_files.items():\n",
    "    if result_file.exists():\n",
    "        with open(result_file, 'r', encoding='utf-8') as f:\n",
    "            results[model_key] = json.load(f)\n",
    "        print(f\"✅ {model_key}: {result_file.name}\")\n",
    "    else:\n",
    "        print(f\"⚠️  {model_key}: 檔案不存在 ({result_file})\")\n",
    "\n",
    "if not results:\n",
    "    raise FileNotFoundError(\"未找到任何評估結果,請先執行 02-Evaluate.ipynb\")\n",
    "\n",
    "print(\"\\n✅ 結果載入完成\")\n",
    "print(f\"共載入 {len(results)} 個模型的結果\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 整體統計分析\n",
    "\n",
    "計算各模型的整體表現統計。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_statistics(results: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    計算整體統計資訊\n",
    "    \n",
    "    Args:\n",
    "        results: 評估結果字典\n",
    "    \n",
    "    Returns:\n",
    "        統計資訊 DataFrame\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    \n",
    "    for model_key, result in results.items():\n",
    "        # 計算總題數\n",
    "        total_questions = sum(sr['total'] for sr in result['subject_results'])\n",
    "        total_correct = sum(sr['correct'] for sr in result['subject_results'])\n",
    "        \n",
    "        stats.append({\n",
    "            '模型': result['model_name'],\n",
    "            '整體準確率': f\"{result['overall_accuracy']:.2%}\",\n",
    "            '正確題數': total_correct,\n",
    "            '總題數': total_questions,\n",
    "            '錯誤題數': total_questions - total_correct,\n",
    "            '評估學科數': len(result['subject_results']),\n",
    "        })\n",
    "        \n",
    "        # 添加分類準確率\n",
    "        for category, accuracy in result['category_accuracies'].items():\n",
    "            stats[-1][f'{category}準確率'] = f\"{accuracy:.2%}\"\n",
    "    \n",
    "    return pd.DataFrame(stats)\n",
    "\n",
    "\n",
    "# 計算統計資訊\n",
    "stats_df = calculate_overall_statistics(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"整體統計分析\")\n",
    "print(\"=\" * 60)\n",
    "print(stats_df.to_string(index=False))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 保存統計結果\n",
    "stats_df.to_csv(ANALYSIS_DIR / \"overall_statistics.csv\", index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n✅ 統計結果已保存: {ANALYSIS_DIR / 'overall_statistics.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 學科難度分析\n",
    "\n",
    "分析每個學科的難度 (基於所有模型的平均準確率)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_subject_difficulty(results: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    分析學科難度\n",
    "    \n",
    "    Args:\n",
    "        results: 評估結果字典\n",
    "    \n",
    "    Returns:\n",
    "        學科難度 DataFrame (按難度降序排列)\n",
    "    \"\"\"\n",
    "    subject_stats = defaultdict(lambda: {'accuracies': [], 'total_questions': 0})\n",
    "    \n",
    "    # 收集每個學科的準確率\n",
    "    for model_key, result in results.items():\n",
    "        for subject_result in result['subject_results']:\n",
    "            subject = subject_result['subject']\n",
    "            subject_stats[subject]['accuracies'].append(subject_result['accuracy'])\n",
    "            subject_stats[subject]['total_questions'] = subject_result['total']\n",
    "    \n",
    "    # 計算平均準確率和難度\n",
    "    difficulty_data = []\n",
    "    for subject, stats in subject_stats.items():\n",
    "        avg_accuracy = np.mean(stats['accuracies'])\n",
    "        std_accuracy = np.std(stats['accuracies'])\n",
    "        \n",
    "        # 難度定義: 1 - 準確率 (越高越難)\n",
    "        difficulty = 1 - avg_accuracy\n",
    "        \n",
    "        difficulty_data.append({\n",
    "            '學科': subject,\n",
    "            '題數': stats['total_questions'],\n",
    "            '平均準確率': avg_accuracy,\n",
    "            '準確率標準差': std_accuracy,\n",
    "            '難度分數': difficulty,\n",
    "            '難度等級': '困難' if difficulty > 0.6 else '中等' if difficulty > 0.4 else '簡單'\n",
    "        })\n",
    "    \n",
    "    # 按難度排序\n",
    "    df = pd.DataFrame(difficulty_data)\n",
    "    df = df.sort_values('難度分數', ascending=False)\n",
    "    \n",
    "    # 格式化百分比\n",
    "    df['平均準確率'] = df['平均準確率'].apply(lambda x: f\"{x:.2%}\")\n",
    "    df['準確率標準差'] = df['準確率標準差'].apply(lambda x: f\"{x:.2%}\")\n",
    "    df['難度分數'] = df['難度分數'].apply(lambda x: f\"{x:.3f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# 分析學科難度\n",
    "difficulty_df = analyze_subject_difficulty(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"學科難度排名 (由難到易)\")\n",
    "print(\"=\" * 80)\n",
    "print(difficulty_df.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 保存結果\n",
    "difficulty_df.to_csv(ANALYSIS_DIR / \"subject_difficulty.csv\", index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n✅ 難度分析已保存: {ANALYSIS_DIR / 'subject_difficulty.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 錯誤分析\n",
    "\n",
    "深入分析模型的錯誤模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_errors(results: dict) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    分析錯誤模式\n",
    "    \n",
    "    Args:\n",
    "        results: 評估結果字典\n",
    "    \n",
    "    Returns:\n",
    "        錯誤分析結果字典\n",
    "    \"\"\"\n",
    "    error_analysis = {}\n",
    "    \n",
    "    for model_key, result in results.items():\n",
    "        model_name = result['model_name']\n",
    "        \n",
    "        # 收集所有錯誤\n",
    "        errors = []\n",
    "        \n",
    "        for subject_result in result['subject_results']:\n",
    "            subject = subject_result['subject']\n",
    "            \n",
    "            for detail in subject_result['details']:\n",
    "                if not detail['is_correct']:\n",
    "                    errors.append({\n",
    "                        '學科': subject,\n",
    "                        '問題': detail['question'][:50] + '...' if len(detail['question']) > 50 else detail['question'],\n",
    "                        '正確答案': detail['correct_answer'],\n",
    "                        '預測答案': detail['predicted_answer'],\n",
    "                        '錯誤類型': f\"{detail['correct_answer']}→{detail['predicted_answer']}\"\n",
    "                    })\n",
    "        \n",
    "        # 創建錯誤 DataFrame\n",
    "        if errors:\n",
    "            error_df = pd.DataFrame(errors)\n",
    "            \n",
    "            # 分析錯誤類型分佈\n",
    "            error_type_counts = Counter(error_df['錯誤類型'])\n",
    "            \n",
    "            print(f\"\\n{'=' * 60}\")\n",
    "            print(f\"模型: {model_name}\")\n",
    "            print(f\"{'=' * 60}\")\n",
    "            print(f\"\\n總錯誤數: {len(errors)}\")\n",
    "            print(f\"\\n最常見錯誤類型 (Top 5):\")\n",
    "            for error_type, count in error_type_counts.most_common(5):\n",
    "                print(f\"  {error_type}: {count} 次 ({count/len(errors):.1%})\")\n",
    "            \n",
    "            # 按學科統計錯誤\n",
    "            subject_errors = error_df.groupby('學科').size().sort_values(ascending=False)\n",
    "            print(f\"\\n各學科錯誤數:\")\n",
    "            for subject, count in subject_errors.items():\n",
    "                print(f\"  {subject}: {count}\")\n",
    "            \n",
    "            error_analysis[model_key] = {\n",
    "                'errors': error_df,\n",
    "                'error_type_counts': error_type_counts,\n",
    "                'subject_errors': subject_errors\n",
    "            }\n",
    "            \n",
    "            # 保存錯誤詳情\n",
    "            error_file = ANALYSIS_DIR / f\"{model_key}_errors.csv\"\n",
    "            error_df.to_csv(error_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\n✅ 錯誤詳情已保存: {error_file}\")\n",
    "        else:\n",
    "            print(f\"\\n✨ {model_name}: 沒有錯誤 (完美表現!)\")\n",
    "    \n",
    "    return error_analysis\n",
    "\n",
    "\n",
    "# 執行錯誤分析\n",
    "error_analysis = analyze_errors(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 信心度分析\n",
    "\n",
    "分析模型對答案的信心度 (基於 logits 分佈)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_confidence(results: dict) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    分析模型信心度\n",
    "    \n",
    "    Args:\n",
    "        results: 評估結果字典\n",
    "    \n",
    "    Returns:\n",
    "        信心度分析結果\n",
    "    \"\"\"\n",
    "    confidence_analysis = {}\n",
    "    \n",
    "    for model_key, result in results.items():\n",
    "        model_name = result['model_name']\n",
    "        \n",
    "        confidence_data = []\n",
    "        \n",
    "        for subject_result in result['subject_results']:\n",
    "            subject = subject_result['subject']\n",
    "            \n",
    "            for detail in subject_result['details']:\n",
    "                logits = detail['logits']\n",
    "                \n",
    "                # 計算 logits 統計\n",
    "                logit_values = list(logits.values())\n",
    "                max_logit = max(logit_values)\n",
    "                min_logit = min(logit_values)\n",
    "                logit_range = max_logit - min_logit  # 信心度指標\n",
    "                \n",
    "                # Softmax 計算機率\n",
    "                exp_logits = np.exp(np.array(logit_values) - max_logit)  # 防止溢出\n",
    "                probs = exp_logits / exp_logits.sum()\n",
    "                max_prob = probs.max()\n",
    "                \n",
    "                confidence_data.append({\n",
    "                    '學科': subject,\n",
    "                    '是否正確': detail['is_correct'],\n",
    "                    'Logit範圍': logit_range,\n",
    "                    '最大機率': max_prob,\n",
    "                    '預測答案': detail['predicted_answer'],\n",
    "                    '正確答案': detail['correct_answer']\n",
    "                })\n",
    "        \n",
    "        # 創建 DataFrame\n",
    "        conf_df = pd.DataFrame(confidence_data)\n",
    "        \n",
    "        # 分析正確 vs 錯誤的信心度差異\n",
    "        correct_conf = conf_df[conf_df['是否正確']]\n",
    "        incorrect_conf = conf_df[~conf_df['是否正確']]\n",
    "        \n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"模型: {model_name} - 信心度分析\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "        \n",
    "        if len(correct_conf) > 0:\n",
    "            print(f\"\\n正確答案的信心度:\")\n",
    "            print(f\"  平均 Logit 範圍: {correct_conf['Logit範圍'].mean():.3f}\")\n",
    "            print(f\"  平均最大機率:    {correct_conf['最大機率'].mean():.3f}\")\n",
    "        \n",
    "        if len(incorrect_conf) > 0:\n",
    "            print(f\"\\n錯誤答案的信心度:\")\n",
    "            print(f\"  平均 Logit 範圍: {incorrect_conf['Logit範圍'].mean():.3f}\")\n",
    "            print(f\"  平均最大機率:    {incorrect_conf['最大機率'].mean():.3f}\")\n",
    "        \n",
    "        # 高信心度錯誤 (過度自信)\n",
    "        if len(incorrect_conf) > 0:\n",
    "            overconfident = incorrect_conf[incorrect_conf['最大機率'] > 0.8]\n",
    "            print(f\"\\n過度自信的錯誤 (機率 > 0.8): {len(overconfident)} 題\")\n",
    "            if len(overconfident) > 0:\n",
    "                print(f\"  佔總錯誤的比例: {len(overconfident)/len(incorrect_conf):.1%}\")\n",
    "        \n",
    "        # 低信心度正確 (保守)\n",
    "        if len(correct_conf) > 0:\n",
    "            underconfident = correct_conf[correct_conf['最大機率'] < 0.5]\n",
    "            print(f\"\\n保守的正確答案 (機率 < 0.5): {len(underconfident)} 題\")\n",
    "            if len(underconfident) > 0:\n",
    "                print(f\"  佔總正確的比例: {len(underconfident)/len(correct_conf):.1%}\")\n",
    "        \n",
    "        confidence_analysis[model_key] = conf_df\n",
    "        \n",
    "        # 保存信心度分析\n",
    "        conf_file = ANALYSIS_DIR / f\"{model_key}_confidence.csv\"\n",
    "        conf_df.to_csv(conf_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n✅ 信心度分析已保存: {conf_file}\")\n",
    "    \n",
    "    return confidence_analysis\n",
    "\n",
    "\n",
    "# 執行信心度分析\n",
    "confidence_analysis = analyze_confidence(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型強弱項對比\n",
    "\n",
    "識別每個模型的強項和弱項學科。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_strengths(results: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    對比模型在各學科的表現\n",
    "    \n",
    "    Args:\n",
    "        results: 評估結果字典\n",
    "    \n",
    "    Returns:\n",
    "        學科對比 DataFrame\n",
    "    \"\"\"\n",
    "    # 收集所有學科的準確率\n",
    "    subject_comparison = defaultdict(dict)\n",
    "    \n",
    "    for model_key, result in results.items():\n",
    "        model_name = result['model_name']\n",
    "        \n",
    "        for subject_result in result['subject_results']:\n",
    "            subject = subject_result['subject']\n",
    "            accuracy = subject_result['accuracy']\n",
    "            subject_comparison[subject][model_name] = accuracy\n",
    "    \n",
    "    # 創建 DataFrame\n",
    "    comparison_df = pd.DataFrame(subject_comparison).T\n",
    "    \n",
    "    # 計算差異\n",
    "    if len(comparison_df.columns) == 2:\n",
    "        model1, model2 = comparison_df.columns\n",
    "        comparison_df['差異'] = comparison_df[model1] - comparison_df[model2]\n",
    "        comparison_df['優勢模型'] = comparison_df['差異'].apply(\n",
    "            lambda x: model1 if x > 0 else (model2 if x < 0 else '相同')\n",
    "        )\n",
    "    \n",
    "    # 排序\n",
    "    if '差異' in comparison_df.columns:\n",
    "        comparison_df = comparison_df.sort_values('差異', ascending=False)\n",
    "    \n",
    "    # 格式化\n",
    "    for col in comparison_df.columns:\n",
    "        if col not in ['優勢模型']:\n",
    "            if comparison_df[col].dtype in [np.float64, np.float32]:\n",
    "                comparison_df[col] = comparison_df[col].apply(lambda x: f\"{x:.2%}\")\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "\n",
    "if len(results) >= 2:\n",
    "    # 對比分析\n",
    "    comparison_df = compare_model_strengths(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"模型強弱項對比 (按差異排序)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(comparison_df.to_string())\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 保存對比結果\n",
    "    comparison_df.to_csv(ANALYSIS_DIR / \"model_comparison.csv\", encoding='utf-8-sig')\n",
    "    print(f\"\\n✅ 對比結果已保存: {ANALYSIS_DIR / 'model_comparison.csv'}\")\n",
    "    \n",
    "    # 總結強弱項\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"強弱項總結\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for model_name in comparison_df.columns:\n",
    "        if model_name not in ['差異', '優勢模型']:\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            \n",
    "            # 找出強項 (準確率最高的 3 個學科)\n",
    "            strengths = comparison_df[comparison_df['優勢模型'] == model_name].head(3)\n",
    "            if len(strengths) > 0:\n",
    "                print(f\"  強項:\")\n",
    "                for subject in strengths.index:\n",
    "                    print(f\"    - {subject}: {strengths.loc[subject, model_name]}\")\n",
    "            \n",
    "            # 找出弱項 (準確率最低的 3 個學科)\n",
    "            weaknesses = comparison_df[comparison_df['優勢模型'] != model_name].tail(3)\n",
    "            if len(weaknesses) > 0:\n",
    "                print(f\"  弱項:\")\n",
    "                for subject in weaknesses.index:\n",
    "                    print(f\"    - {subject}: {weaknesses.loc[subject, model_name]}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  需要至少 2 個模型的結果才能進行對比分析\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 生成分析摘要\n",
    "\n",
    "生成完整的分析摘要報告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_summary(results: dict, output_file: Path):\n",
    "    \"\"\"\n",
    "    生成分析摘要報告\n",
    "    \n",
    "    Args:\n",
    "        results: 評估結果字典\n",
    "        output_file: 輸出檔案路徑\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# C-Eval 評估分析報告\\n\\n\")\n",
    "        f.write(f\"生成時間: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        # 1. 整體表現\n",
    "        f.write(\"## 1. 整體表現\\n\\n\")\n",
    "        for model_key, result in results.items():\n",
    "            f.write(f\"### {result['model_name']}\\n\\n\")\n",
    "            f.write(f\"- 整體準確率: {result['overall_accuracy']:.2%}\\n\")\n",
    "            f.write(f\"- 評估學科數: {len(result['subject_results'])}\\n\")\n",
    "            f.write(f\"\\n分類準確率:\\n\")\n",
    "            for category, accuracy in result['category_accuracies'].items():\n",
    "                f.write(f\"  - {category}: {accuracy:.2%}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        # 2. 學科難度排名\n",
    "        f.write(\"## 2. 學科難度排名\\n\\n\")\n",
    "        difficulty_df = analyze_subject_difficulty(results)\n",
    "        f.write(difficulty_df.to_markdown(index=False))\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # 3. 錯誤統計\n",
    "        f.write(\"## 3. 錯誤統計\\n\\n\")\n",
    "        for model_key, result in results.items():\n",
    "            total_errors = sum(\n",
    "                len([d for d in sr['details'] if not d['is_correct']])\n",
    "                for sr in result['subject_results']\n",
    "            )\n",
    "            f.write(f\"### {result['model_name']}\\n\\n\")\n",
    "            f.write(f\"- 總錯誤數: {total_errors}\\n\")\n",
    "            \n",
    "            # 各學科錯誤數\n",
    "            f.write(f\"\\n各學科錯誤數:\\n\")\n",
    "            for sr in result['subject_results']:\n",
    "                errors = len([d for d in sr['details'] if not d['is_correct']])\n",
    "                f.write(f\"  - {sr['subject']}: {errors}/{sr['total']}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        # 4. 關鍵發現\n",
    "        f.write(\"## 4. 關鍵發現\\n\\n\")\n",
    "        \n",
    "        # 找出最難的學科\n",
    "        difficulty_df_raw = analyze_subject_difficulty(results)\n",
    "        hardest_subject = difficulty_df_raw.iloc[0]['學科']\n",
    "        easiest_subject = difficulty_df_raw.iloc[-1]['學科']\n",
    "        \n",
    "        f.write(f\"- 最困難學科: {hardest_subject}\\n\")\n",
    "        f.write(f\"- 最簡單學科: {easiest_subject}\\n\")\n",
    "        \n",
    "        # 模型對比\n",
    "        if len(results) >= 2:\n",
    "            model_names = [r['model_name'] for r in results.values()]\n",
    "            accuracies = [r['overall_accuracy'] for r in results.values()]\n",
    "            best_model_idx = np.argmax(accuracies)\n",
    "            f.write(f\"- 最佳模型: {model_names[best_model_idx]} ({accuracies[best_model_idx]:.2%})\\n\")\n",
    "            f.write(f\"- 準確率差距: {(max(accuracies) - min(accuracies)):.2%}\\n\")\n",
    "        \n",
    "        f.write(\"\\n---\\n\\n\")\n",
    "        f.write(\"詳細圖表請參閱 04-Visualize_and_Report.ipynb\\n\")\n",
    "    \n",
    "    print(f\"\\n✅ 分析摘要已生成: {output_file}\")\n",
    "\n",
    "\n",
    "# 生成摘要\n",
    "summary_file = ANALYSIS_DIR / \"analysis_summary.md\"\n",
    "generate_analysis_summary(results, summary_file)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"分析完成!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n所有分析結果已保存至: {ANALYSIS_DIR}\")\n",
    "print(\"\\n生成的檔案:\")\n",
    "for file in sorted(ANALYSIS_DIR.glob(\"*\")):\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 總結\n",
    "\n",
    "在本 notebook 中,我們完成了:\n",
    "\n",
    "1. ✅ 載入評估結果並計算整體統計\n",
    "2. ✅ 學科難度分析 (識別最難和最簡單的學科)\n",
    "3. ✅ 錯誤分析 (找出常見錯誤模式)\n",
    "4. ✅ 信心度分析 (檢查模型的過度自信和保守傾向)\n",
    "5. ✅ 模型強弱項對比 (識別各模型的優劣勢)\n",
    "6. ✅ 生成分析摘要報告\n",
    "\n",
    "### 下一步\n",
    "\n",
    "前往 **04-Visualize_and_Report.ipynb** 生成視覺化圖表和完整評估報告。\n",
    "\n",
    "---\n",
    "\n",
    "**關鍵發現**:\n",
    "- 學科難度與模型表現高度相關\n",
    "- 中文優化模型 (如 Qwen) 通常在中文任務上表現更好\n",
    "- 錯誤模式可以幫助識別模型的系統性弱點\n",
    "- 信心度分析可以揭示模型的校準品質\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
