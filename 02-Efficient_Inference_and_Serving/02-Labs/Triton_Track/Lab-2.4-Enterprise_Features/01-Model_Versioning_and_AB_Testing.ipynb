{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Lab 2.4.1 - 模型版本管理與 A/B 測試\n",
    "\n",
    "## 🎯 實驗目標\n",
    "\n",
    "本實驗將教您如何：\n",
    "1. 實現企業級模型版本管理策略\n",
    "2. 設計和執行 A/B 測試框架\n",
    "3. 實現漸進式模型部署 (Canary Deployment)\n",
    "4. 構建模型性能監控和回滾機制\n",
    "5. 設置流量分配和路由策略\n",
    "\n",
    "## 📋 前置需求\n",
    "\n",
    "- 完成 Lab 2.1（Triton 基礎設置）\n",
    "- 熟悉容器技術和 Kubernetes\n",
    "- 了解 CI/CD 流程和版本控制\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 📚 理論背景\n",
    "\n",
    "### 企業級模型管理挑戰\n",
    "\n",
    "**1. 版本管理複雜性**\n",
    "- 多個模型版本並存\n",
    "- 不同環境間的版本同步\n",
    "- 回滾策略和數據一致性\n",
    "\n",
    "**2. A/B 測試需求**\n",
    "- 業務指標評估\n",
    "- 用戶體驗比較\n",
    "- 風險控制和漸進部署\n",
    "\n",
    "**3. 生產環境穩定性**\n",
    "- 零停機部署\n",
    "- 性能監控和告警\n",
    "- 自動故障恢復\n",
    "\n",
    "### Triton 版本管理架構\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Model Repository] --> B[Version 1]\n",
    "    A --> C[Version 2]\n",
    "    A --> D[Version 3]\n",
    "    \n",
    "    B --> E[Production 80%]\n",
    "    C --> F[Canary 15%]\n",
    "    D --> G[Shadow 5%]\n",
    "    \n",
    "    E --> H[Load Balancer]\n",
    "    F --> H\n",
    "    G --> I[Metrics Only]\n",
    "    \n",
    "    H --> J[User Traffic]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 🛠️ 環境準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Triton 客戶端\n",
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import InferenceServerException\n",
    "\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 設置樣式\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"Environment ready at {datetime.now()}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置實驗環境\n",
    "BASE_DIR = \"/opt/tritonserver\"\n",
    "MODEL_REPO = f\"{BASE_DIR}/models\"\n",
    "EXPERIMENT_DIR = f\"{BASE_DIR}/experiments/ab_testing\"\n",
    "\n",
    "# 創建實驗目錄\n",
    "os.makedirs(EXPERIMENT_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{EXPERIMENT_DIR}/metrics\", exist_ok=True)\n",
    "os.makedirs(f\"{EXPERIMENT_DIR}/configs\", exist_ok=True)\n",
    "os.makedirs(f\"{EXPERIMENT_DIR}/logs\", exist_ok=True)\n",
    "\n",
    "print(f\"📁 實驗目錄: {EXPERIMENT_DIR}\")\n",
    "print(f\"📁 模型倉庫: {MODEL_REPO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 🎯 實驗 1：模型版本管理系統"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 1.1 版本管理類設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelVersion:\n",
    "    \"\"\"模型版本信息\"\"\"\n",
    "    name: str\n",
    "    version: int\n",
    "    created_at: datetime\n",
    "    status: str  # \"active\", \"inactive\", \"testing\", \"deprecated\"\n",
    "    traffic_percentage: float\n",
    "    performance_metrics: Dict[str, float]\n",
    "    metadata: Dict[str, str]\n",
    "\n",
    "\n",
    "class ModelVersionManager:\n",
    "    \"\"\"模型版本管理器\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, triton_url: str = \"localhost:8000\"):\n",
    "        self.model_name = model_name\n",
    "        self.triton_url = triton_url\n",
    "        self.client = httpclient.InferenceServerClient(url=triton_url)\n",
    "        self.versions: Dict[int, ModelVersion] = {}\n",
    "        self.traffic_rules = {}\n",
    "        \n",
    "        # 加載現有版本\n",
    "        self._discover_versions()\n",
    "    \n",
    "    def _discover_versions(self):\n",
    "        \"\"\"發現現有模型版本\"\"\"\n",
    "        try:\n",
    "            model_config = self.client.get_model_config(self.model_name)\n",
    "            print(f\"✅ 發現模型: {self.model_name}\")\n",
    "            \n",
    "            # 模擬版本發現（在實際環境中會從模型倉庫讀取）\n",
    "            for version in [1, 2, 3]:\n",
    "                self.versions[version] = ModelVersion(\n",
    "                    name=self.model_name,\n",
    "                    version=version,\n",
    "                    created_at=datetime.now() - timedelta(days=version*10),\n",
    "                    status=\"active\" if version == 2 else \"inactive\",\n",
    "                    traffic_percentage=100.0 if version == 2 else 0.0,\n",
    "                    performance_metrics={\n",
    "                        \"latency_p99\": random.uniform(50, 200),\n",
    "                        \"throughput\": random.uniform(100, 1000),\n",
    "                        \"error_rate\": random.uniform(0, 0.05)\n",
    "                    },\n",
    "                    metadata={\n",
    "                        \"framework\": \"pytorch\",\n",
    "                        \"precision\": \"fp16\" if version > 1 else \"fp32\"\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 模型發現失敗: {str(e)}\")\n",
    "    \n",
    "    def register_version(self, version: int, metadata: Dict[str, str] = None) -> bool:\n",
    "        \"\"\"註冊新模型版本\"\"\"\n",
    "        try:\n",
    "            new_version = ModelVersion(\n",
    "                name=self.model_name,\n",
    "                version=version,\n",
    "                created_at=datetime.now(),\n",
    "                status=\"inactive\",\n",
    "                traffic_percentage=0.0,\n",
    "                performance_metrics={},\n",
    "                metadata=metadata or {}\n",
    "            )\n",
    "            \n",
    "            self.versions[version] = new_version\n",
    "            \n",
    "            print(f\"✅ 版本 {version} 註冊成功\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 版本註冊失敗: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def get_version_info(self, version: int) -> Optional[ModelVersion]:\n",
    "        \"\"\"獲取版本信息\"\"\"\n",
    "        return self.versions.get(version)\n",
    "    \n",
    "    def list_versions(self) -> List[ModelVersion]:\n",
    "        \"\"\"列出所有版本\"\"\"\n",
    "        return list(self.versions.values())\n",
    "    \n",
    "    def set_traffic_split(self, traffic_config: Dict[int, float]):\n",
    "        \"\"\"設置流量分配\"\"\"\n",
    "        total_percentage = sum(traffic_config.values())\n",
    "        \n",
    "        if abs(total_percentage - 100.0) > 0.001:\n",
    "            raise ValueError(f\"流量分配總和必須為 100%，當前為 {total_percentage}%\")\n",
    "        \n",
    "        # 更新版本流量\n",
    "        for version_num, version in self.versions.items():\n",
    "            version.traffic_percentage = traffic_config.get(version_num, 0.0)\n",
    "            version.status = \"active\" if version.traffic_percentage > 0 else \"inactive\"\n",
    "        \n",
    "        self.traffic_rules = traffic_config\n",
    "        \n",
    "        print(f\"✅ 流量分配已更新: {traffic_config}\")\n",
    "    \n",
    "    def get_version_for_request(self, request_id: str = None) -> int:\n",
    "        \"\"\"根據流量規則選擇版本\"\"\"\n",
    "        if not self.traffic_rules:\n",
    "            # 默認使用最新的活躍版本\n",
    "            active_versions = [v for v in self.versions.values() if v.status == \"active\"]\n",
    "            if active_versions:\n",
    "                return max(active_versions, key=lambda x: x.version).version\n",
    "            return max(self.versions.keys())\n",
    "        \n",
    "        # 基於權重隨機選擇\n",
    "        rand_val = random.uniform(0, 100)\n",
    "        cumulative = 0\n",
    "        \n",
    "        for version, percentage in sorted(self.traffic_rules.items()):\n",
    "            cumulative += percentage\n",
    "            if rand_val <= cumulative:\n",
    "                return version\n",
    "        \n",
    "        # 回退到默認版本\n",
    "        return max(self.traffic_rules.keys())\n",
    "    \n",
    "    def export_config(self, filepath: str):\n",
    "        \"\"\"導出配置到文件\"\"\"\n",
    "        config = {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"versions\": {},\n",
    "            \"traffic_rules\": self.traffic_rules,\n",
    "            \"exported_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        for version_num, version in self.versions.items():\n",
    "            config[\"versions\"][str(version_num)] = {\n",
    "                \"status\": version.status,\n",
    "                \"traffic_percentage\": version.traffic_percentage,\n",
    "                \"performance_metrics\": version.performance_metrics,\n",
    "                \"metadata\": version.metadata,\n",
    "                \"created_at\": version.created_at.isoformat()\n",
    "            }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        print(f\"✅ 配置已導出到: {filepath}\")\n",
    "\n",
    "\n",
    "# 創建版本管理器實例\n",
    "print(\"🔧 創建模型版本管理器...\")\n",
    "version_manager = ModelVersionManager(\"text_classifier\")\n",
    "print(f\"📊 發現版本數量: {len(version_manager.versions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 1.2 版本信息展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示所有版本信息\n",
    "def display_version_summary(manager: ModelVersionManager):\n",
    "    \"\"\"顯示版本摘要\"\"\"\n",
    "    print(f\"\\n📋 模型 '{manager.model_name}' 版本摘要\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for version in sorted(manager.list_versions(), key=lambda x: x.version):\n",
    "        print(f\"\\n🏷️  版本 {version.version} ({version.status.upper()})\")\n",
    "        print(f\"   📅 創建時間: {version.created_at.strftime('%Y-%m-%d %H:%M')}\")\n",
    "        print(f\"   🚦 流量比例: {version.traffic_percentage:.1f}%\")\n",
    "        print(f\"   📊 性能指標:\")\n",
    "        for metric, value in version.performance_metrics.items():\n",
    "            if metric == \"error_rate\":\n",
    "                print(f\"      • {metric}: {value:.3f}\")\n",
    "            else:\n",
    "                print(f\"      • {metric}: {value:.1f}\")\n",
    "        print(f\"   🏷️  元數據: {version.metadata}\")\n",
    "\n",
    "\n",
    "display_version_summary(version_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化版本性能對比\n",
    "def plot_version_performance(manager: ModelVersionManager):\n",
    "    \"\"\"可視化版本性能\"\"\"\n",
    "    versions = manager.list_versions()\n",
    "    \n",
    "    if not versions:\n",
    "        print(\"❌ 沒有版本數據可供分析\")\n",
    "        return\n",
    "    \n",
    "    # 準備數據\n",
    "    version_nums = [v.version for v in versions]\n",
    "    latencies = [v.performance_metrics.get(\"latency_p99\", 0) for v in versions]\n",
    "    throughputs = [v.performance_metrics.get(\"throughput\", 0) for v in versions]\n",
    "    error_rates = [v.performance_metrics.get(\"error_rate\", 0) * 100 for v in versions]\n",
    "    traffic = [v.traffic_percentage for v in versions]\n",
    "    \n",
    "    # 創建子圖\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 延遲對比\n",
    "    bars1 = ax1.bar(version_nums, latencies, alpha=0.7, color='skyblue')\n",
    "    ax1.set_title('P99 延遲對比 (ms)', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('版本')\n",
    "    ax1.set_ylabel('延遲 (ms)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 添加數值標籤\n",
    "    for bar, val in zip(bars1, latencies):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                f'{val:.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 吞吐量對比\n",
    "    bars2 = ax2.bar(version_nums, throughputs, alpha=0.7, color='lightgreen')\n",
    "    ax2.set_title('吞吐量對比 (QPS)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('版本')\n",
    "    ax2.set_ylabel('吞吐量 (QPS)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, val in zip(bars2, throughputs):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
    "                f'{val:.0f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 錯誤率對比\n",
    "    bars3 = ax3.bar(version_nums, error_rates, alpha=0.7, color='salmon')\n",
    "    ax3.set_title('錯誤率對比 (%)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('版本')\n",
    "    ax3.set_ylabel('錯誤率 (%)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, val in zip(bars3, error_rates):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                f'{val:.2f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # 流量分配\n",
    "    colors = ['gold', 'lightcoral', 'lightblue']\n",
    "    wedges, texts, autotexts = ax4.pie(traffic, labels=[f'V{v}' for v in version_nums],\n",
    "                                      autopct='%1.1f%%', colors=colors[:len(version_nums)])\n",
    "    ax4.set_title('流量分配', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_version_performance(version_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 🎯 實驗 2：A/B 測試框架"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 2.1 A/B 測試管理器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ABTestConfig:\n",
    "    \"\"\"A/B 測試配置\"\"\"\n",
    "    test_name: str\n",
    "    model_name: str\n",
    "    control_version: int\n",
    "    treatment_version: int\n",
    "    traffic_split: float  # treatment 版本的流量比例\n",
    "    start_time: datetime\n",
    "    end_time: datetime\n",
    "    success_metrics: List[str]\n",
    "    min_sample_size: int\n",
    "    significance_level: float\n",
    "    status: str  # \"planned\", \"running\", \"completed\", \"stopped\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TestMetrics:\n",
    "    \"\"\"測試指標數據\"\"\"\n",
    "    version: int\n",
    "    request_count: int\n",
    "    success_count: int\n",
    "    total_latency: float\n",
    "    error_count: int\n",
    "    timestamp: datetime\n",
    "\n",
    "\n",
    "class ABTestManager:\n",
    "    \"\"\"A/B 測試管理器\"\"\"\n",
    "    \n",
    "    def __init__(self, version_manager: ModelVersionManager):\n",
    "        self.version_manager = version_manager\n",
    "        self.active_tests: Dict[str, ABTestConfig] = {}\n",
    "        self.test_metrics: Dict[str, List[TestMetrics]] = {}\n",
    "        self.test_results: Dict[str, Dict] = {}\n",
    "    \n",
    "    def create_test(self, config: ABTestConfig) -> bool:\n",
    "        \"\"\"創建新的 A/B 測試\"\"\"\n",
    "        try:\n",
    "            # 驗證版本存在\n",
    "            control_version = self.version_manager.get_version_info(config.control_version)\n",
    "            treatment_version = self.version_manager.get_version_info(config.treatment_version)\n",
    "            \n",
    "            if not control_version or not treatment_version:\n",
    "                raise ValueError(\"指定的版本不存在\")\n",
    "            \n",
    "            # 檢查時間配置\n",
    "            if config.start_time >= config.end_time:\n",
    "                raise ValueError(\"結束時間必須晚於開始時間\")\n",
    "            \n",
    "            # 添加到活躍測試\n",
    "            self.active_tests[config.test_name] = config\n",
    "            self.test_metrics[config.test_name] = []\n",
    "            \n",
    "            print(f\"✅ A/B 測試 '{config.test_name}' 創建成功\")\n",
    "            print(f\"   📊 控制組: V{config.control_version} ({100-config.traffic_split:.1f}%)\")\n",
    "            print(f\"   🧪 實驗組: V{config.treatment_version} ({config.traffic_split:.1f}%)\")\n",
    "            print(f\"   ⏰ 測試期間: {config.start_time.strftime('%Y-%m-%d')} - {config.end_time.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ A/B 測試創建失敗: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def start_test(self, test_name: str) -> bool:\n",
    "        \"\"\"啟動 A/B 測試\"\"\"\n",
    "        if test_name not in self.active_tests:\n",
    "            print(f\"❌ 測試 '{test_name}' 不存在\")\n",
    "            return False\n",
    "        \n",
    "        test_config = self.active_tests[test_name]\n",
    "        \n",
    "        if datetime.now() < test_config.start_time:\n",
    "            print(f\"❌ 測試尚未到達開始時間\")\n",
    "            return False\n",
    "        \n",
    "        # 更新流量分配\n",
    "        traffic_config = {\n",
    "            test_config.control_version: 100 - test_config.traffic_split,\n",
    "            test_config.treatment_version: test_config.traffic_split\n",
    "        }\n",
    "        \n",
    "        self.version_manager.set_traffic_split(traffic_config)\n",
    "        test_config.status = \"running\"\n",
    "        \n",
    "        print(f\"🚀 A/B 測試 '{test_name}' 已啟動\")\n",
    "        return True\n",
    "    \n",
    "    def stop_test(self, test_name: str, reason: str = \"Manual stop\") -> bool:\n",
    "        \"\"\"停止 A/B 測試\"\"\"\n",
    "        if test_name not in self.active_tests:\n",
    "            print(f\"❌ 測試 '{test_name}' 不存在\")\n",
    "            return False\n",
    "        \n",
    "        test_config = self.active_tests[test_name]\n",
    "        test_config.status = \"stopped\"\n",
    "        \n",
    "        # 恢復到控制組版本\n",
    "        self.version_manager.set_traffic_split({test_config.control_version: 100.0})\n",
    "        \n",
    "        print(f\"⏹️  A/B 測試 '{test_name}' 已停止\")\n",
    "        print(f\"   📝 原因: {reason}\")\n",
    "        return True\n",
    "    \n",
    "    def record_metrics(self, test_name: str, version: int, \n",
    "                      latency: float, success: bool):\n",
    "        \"\"\"記錄測試指標\"\"\"\n",
    "        if test_name not in self.test_metrics:\n",
    "            self.test_metrics[test_name] = []\n",
    "        \n",
    "        # 尋找或創建該版本的指標記錄\n",
    "        current_time = datetime.now()\n",
    "        \n",
    "        # 找到當前分鐘的指標記錄\n",
    "        minute_key = current_time.replace(second=0, microsecond=0)\n",
    "        \n",
    "        # 查找現有記錄\n",
    "        existing_metric = None\n",
    "        for metric in self.test_metrics[test_name]:\n",
    "            if (metric.version == version and \n",
    "                metric.timestamp.replace(second=0, microsecond=0) == minute_key):\n",
    "                existing_metric = metric\n",
    "                break\n",
    "        \n",
    "        if existing_metric:\n",
    "            # 更新現有記錄\n",
    "            existing_metric.request_count += 1\n",
    "            existing_metric.total_latency += latency\n",
    "            if success:\n",
    "                existing_metric.success_count += 1\n",
    "            else:\n",
    "                existing_metric.error_count += 1\n",
    "        else:\n",
    "            # 創建新記錄\n",
    "            new_metric = TestMetrics(\n",
    "                version=version,\n",
    "                request_count=1,\n",
    "                success_count=1 if success else 0,\n",
    "                total_latency=latency,\n",
    "                error_count=0 if success else 1,\n",
    "                timestamp=current_time\n",
    "            )\n",
    "            self.test_metrics[test_name].append(new_metric)\n",
    "    \n",
    "    def get_test_summary(self, test_name: str) -> Dict:\n",
    "        \"\"\"獲取測試摘要\"\"\"\n",
    "        if test_name not in self.active_tests:\n",
    "            return {\"error\": \"測試不存在\"}\n",
    "        \n",
    "        test_config = self.active_tests[test_name]\n",
    "        metrics = self.test_metrics.get(test_name, [])\n",
    "        \n",
    "        # 按版本分組統計\n",
    "        control_metrics = [m for m in metrics if m.version == test_config.control_version]\n",
    "        treatment_metrics = [m for m in metrics if m.version == test_config.treatment_version]\n",
    "        \n",
    "        def calculate_stats(metric_list):\n",
    "            if not metric_list:\n",
    "                return {\n",
    "                    \"requests\": 0,\n",
    "                    \"success_rate\": 0.0,\n",
    "                    \"avg_latency\": 0.0,\n",
    "                    \"error_rate\": 0.0\n",
    "                }\n",
    "            \n",
    "            total_requests = sum(m.request_count for m in metric_list)\n",
    "            total_success = sum(m.success_count for m in metric_list)\n",
    "            total_latency = sum(m.total_latency for m in metric_list)\n",
    "            total_errors = sum(m.error_count for m in metric_list)\n",
    "            \n",
    "            return {\n",
    "                \"requests\": total_requests,\n",
    "                \"success_rate\": (total_success / total_requests * 100) if total_requests > 0 else 0,\n",
    "                \"avg_latency\": (total_latency / total_requests) if total_requests > 0 else 0,\n",
    "                \"error_rate\": (total_errors / total_requests * 100) if total_requests > 0 else 0\n",
    "            }\n",
    "        \n",
    "        control_stats = calculate_stats(control_metrics)\n",
    "        treatment_stats = calculate_stats(treatment_metrics)\n",
    "        \n",
    "        return {\n",
    "            \"test_name\": test_name,\n",
    "            \"status\": test_config.status,\n",
    "            \"control_version\": test_config.control_version,\n",
    "            \"treatment_version\": test_config.treatment_version,\n",
    "            \"control_stats\": control_stats,\n",
    "            \"treatment_stats\": treatment_stats,\n",
    "            \"total_requests\": control_stats[\"requests\"] + treatment_stats[\"requests\"],\n",
    "            \"test_duration\": (datetime.now() - test_config.start_time).total_seconds() / 3600\n",
    "        }\n",
    "\n",
    "\n",
    "# 創建 A/B 測試管理器\n",
    "ab_test_manager = ABTestManager(version_manager)\n",
    "print(\"✅ A/B 測試管理器已創建\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### 2.2 創建和啟動 A/B 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 A/B 測試配置\n",
    "ab_test_config = ABTestConfig(\n",
    "    test_name=\"model_v2_vs_v3_performance\",\n",
    "    model_name=\"text_classifier\",\n",
    "    control_version=2,\n",
    "    treatment_version=3,\n",
    "    traffic_split=20.0,  # 20% 流量到新版本\n",
    "    start_time=datetime.now(),\n",
    "    end_time=datetime.now() + timedelta(hours=24),\n",
    "    success_metrics=[\"latency\", \"accuracy\", \"error_rate\"],\n",
    "    min_sample_size=1000,\n",
    "    significance_level=0.05,\n",
    "    status=\"planned\"\n",
    ")\n",
    "\n",
    "# 創建測試\n",
    "ab_test_manager.create_test(ab_test_config)\n",
    "\n",
    "# 啟動測試\n",
    "ab_test_manager.start_test(\"model_v2_vs_v3_performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### 2.3 模擬測試數據收集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模擬請求和數據收集\n",
    "def simulate_ab_test_traffic(ab_manager: ABTestManager, test_name: str, \n",
    "                           num_requests: int = 500):\n",
    "    \"\"\"模擬 A/B 測試流量\"\"\"\n",
    "    if test_name not in ab_manager.active_tests:\n",
    "        print(f\"❌ 測試 '{test_name}' 不存在\")\n",
    "        return\n",
    "    \n",
    "    test_config = ab_manager.active_tests[test_name]\n",
    "    print(f\"📊 開始模擬 {num_requests} 個請求的 A/B 測試流量...\")\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        # 根據流量分配選擇版本\n",
    "        if random.uniform(0, 100) < test_config.traffic_split:\n",
    "            version = test_config.treatment_version\n",
    "            # Treatment 版本通常有不同的性能特性\n",
    "            base_latency = 80\n",
    "            base_success_rate = 0.96\n",
    "        else:\n",
    "            version = test_config.control_version\n",
    "            # Control 版本的基準性能\n",
    "            base_latency = 100\n",
    "            base_success_rate = 0.95\n",
    "        \n",
    "        # 模擬請求延遲（添加隨機變化）\n",
    "        latency = base_latency + random.gauss(0, 20)\n",
    "        latency = max(10, latency)  # 確保延遲為正數\n",
    "        \n",
    "        # 模擬成功率\n",
    "        success = random.random() < base_success_rate\n",
    "        \n",
    "        # 記錄指標\n",
    "        ab_manager.record_metrics(test_name, version, latency, success)\n",
    "        \n",
    "        # 每100個請求顯示進度\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"   📈 已處理 {i + 1}/{num_requests} 請求\")\n",
    "        \n",
    "        # 模擬請求間隔\n",
    "        time.sleep(0.001)\n",
    "    \n",
    "    print(f\"✅ 模擬完成，共處理 {num_requests} 個請求\")\n",
    "\n",
    "\n",
    "# 執行模擬\n",
    "simulate_ab_test_traffic(ab_test_manager, \"model_v2_vs_v3_performance\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 2.4 A/B 測試結果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示測試摘要\n",
    "def display_ab_test_results(ab_manager: ABTestManager, test_name: str):\n",
    "    \"\"\"顯示 A/B 測試結果\"\"\"\n",
    "    summary = ab_manager.get_test_summary(test_name)\n",
    "    \n",
    "    if \"error\" in summary:\n",
    "        print(f\"❌ {summary['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n📊 A/B 測試結果報告: {test_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"🔬 測試狀態: {summary['status'].upper()}\")\n",
    "    print(f\"⏱️  測試時長: {summary['test_duration']:.1f} 小時\")\n",
    "    print(f\"📈 總請求數: {summary['total_requests']}\")\n",
    "    \n",
    "    print(\"\\n🅰️  控制組 (Version {}):\".format(summary['control_version']))\n",
    "    control = summary['control_stats']\n",
    "    print(f\"   📊 請求數: {control['requests']}\")\n",
    "    print(f\"   ✅ 成功率: {control['success_rate']:.2f}%\")\n",
    "    print(f\"   ⏱️  平均延遲: {control['avg_latency']:.1f}ms\")\n",
    "    print(f\"   ❌ 錯誤率: {control['error_rate']:.2f}%\")\n",
    "    \n",
    "    print(\"\\n🅱️  實驗組 (Version {}):\".format(summary['treatment_version']))\n",
    "    treatment = summary['treatment_stats']\n",
    "    print(f\"   📊 請求數: {treatment['requests']}\")\n",
    "    print(f\"   ✅ 成功率: {treatment['success_rate']:.2f}%\")\n",
    "    print(f\"   ⏱️  平均延遲: {treatment['avg_latency']:.1f}ms\")\n",
    "    print(f\"   ❌ 錯誤率: {treatment['error_rate']:.2f}%\")\n",
    "    \n",
    "    # 計算改進度\n",
    "    if control['avg_latency'] > 0 and treatment['avg_latency'] > 0:\n",
    "        latency_improvement = ((control['avg_latency'] - treatment['avg_latency']) / \n",
    "                              control['avg_latency']) * 100\n",
    "        success_improvement = treatment['success_rate'] - control['success_rate']\n",
    "        \n",
    "        print(\"\\n📈 性能對比:\")\n",
    "        print(f\"   ⚡ 延遲改善: {latency_improvement:+.1f}%\")\n",
    "        print(f\"   ✅ 成功率變化: {success_improvement:+.2f}%\")\n",
    "        \n",
    "        # 簡單的統計顯著性判斷\n",
    "        min_sample_size = 100\n",
    "        if (control['requests'] >= min_sample_size and \n",
    "            treatment['requests'] >= min_sample_size):\n",
    "            \n",
    "            if abs(latency_improvement) > 5:\n",
    "                significance = \"顯著\" if abs(latency_improvement) > 10 else \"中等\"\n",
    "                print(f\"   🔬 延遲差異: {significance}\")\n",
    "            \n",
    "            if abs(success_improvement) > 1:\n",
    "                significance = \"顯著\" if abs(success_improvement) > 2 else \"中等\"\n",
    "                print(f\"   🔬 成功率差異: {significance}\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  樣本量不足，需要更多數據進行統計推斷\")\n",
    "\n",
    "\n",
    "# 顯示測試結果\n",
    "display_ab_test_results(ab_test_manager, \"model_v2_vs_v3_performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化 A/B 測試結果\n",
    "def plot_ab_test_comparison(ab_manager: ABTestManager, test_name: str):\n",
    "    \"\"\"可視化 A/B 測試對比\"\"\"\n",
    "    summary = ab_manager.get_test_summary(test_name)\n",
    "    \n",
    "    if \"error\" in summary:\n",
    "        print(f\"❌ {summary['error']}\")\n",
    "        return\n",
    "    \n",
    "    control = summary['control_stats']\n",
    "    treatment = summary['treatment_stats']\n",
    "    \n",
    "    # 創建對比圖\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 延遲對比\n",
    "    versions = ['Control (V{})'.format(summary['control_version']), \n",
    "               'Treatment (V{})'.format(summary['treatment_version'])]\n",
    "    latencies = [control['avg_latency'], treatment['avg_latency']]\n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    \n",
    "    bars1 = ax1.bar(versions, latencies, color=colors, alpha=0.7)\n",
    "    ax1.set_title('平均延遲對比 (ms)', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('延遲 (ms)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, val in zip(bars1, latencies):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                f'{val:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 成功率對比\n",
    "    success_rates = [control['success_rate'], treatment['success_rate']]\n",
    "    bars2 = ax2.bar(versions, success_rates, color=colors, alpha=0.7)\n",
    "    ax2.set_title('成功率對比 (%)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('成功率 (%)')\n",
    "    ax2.set_ylim(90, 100)  # 聚焦在相關範圍\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, val in zip(bars2, success_rates):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                f'{val:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 請求量分布\n",
    "    request_counts = [control['requests'], treatment['requests']]\n",
    "    bars3 = ax3.bar(versions, request_counts, color=colors, alpha=0.7)\n",
    "    ax3.set_title('請求量分布', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('請求數')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, val in zip(bars3, request_counts):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "                f'{val}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 錯誤率對比\n",
    "    error_rates = [control['error_rate'], treatment['error_rate']]\n",
    "    bars4 = ax4.bar(versions, error_rates, color=['#e67e22', '#e67e22'], alpha=0.7)\n",
    "    ax4.set_title('錯誤率對比 (%)', fontsize=14, fontweight='bold')\n",
    "    ax4.set_ylabel('錯誤率 (%)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, val in zip(bars4, error_rates):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "                f'{val:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(f'A/B 測試結果對比: {test_name}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_ab_test_comparison(ab_test_manager, \"model_v2_vs_v3_performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 🎯 實驗 3：漸進式部署 (Canary Deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### 3.1 Canary 部署管理器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CanaryConfig:\n",
    "    \"\"\"Canary 部署配置\"\"\"\n",
    "    deployment_name: str\n",
    "    model_name: str\n",
    "    stable_version: int\n",
    "    canary_version: int\n",
    "    initial_traffic: float\n",
    "    target_traffic: float\n",
    "    increment_step: float\n",
    "    step_duration: int  # 分鐘\n",
    "    success_threshold: Dict[str, float]\n",
    "    rollback_threshold: Dict[str, float]\n",
    "    auto_promote: bool\n",
    "\n",
    "\n",
    "class CanaryDeploymentManager:\n",
    "    \"\"\"Canary 部署管理器\"\"\"\n",
    "    \n",
    "    def __init__(self, version_manager: ModelVersionManager):\n",
    "        self.version_manager = version_manager\n",
    "        self.active_deployments: Dict[str, CanaryConfig] = {}\n",
    "        self.deployment_metrics: Dict[str, List] = {}\n",
    "        self.deployment_history: Dict[str, List] = {}\n",
    "    \n",
    "    def create_canary_deployment(self, config: CanaryConfig) -> bool:\n",
    "        \"\"\"創建 Canary 部署\"\"\"\n",
    "        try:\n",
    "            # 驗證版本\n",
    "            stable_version = self.version_manager.get_version_info(config.stable_version)\n",
    "            canary_version = self.version_manager.get_version_info(config.canary_version)\n",
    "            \n",
    "            if not stable_version or not canary_version:\n",
    "                raise ValueError(\"指定的版本不存在\")\n",
    "            \n",
    "            # 設置初始流量分配\n",
    "            initial_traffic_config = {\n",
    "                config.stable_version: 100 - config.initial_traffic,\n",
    "                config.canary_version: config.initial_traffic\n",
    "            }\n",
    "            \n",
    "            self.version_manager.set_traffic_split(initial_traffic_config)\n",
    "            self.active_deployments[config.deployment_name] = config\n",
    "            self.deployment_metrics[config.deployment_name] = []\n",
    "            self.deployment_history[config.deployment_name] = []\n",
    "            \n",
    "            # 記錄初始狀態\n",
    "            self.deployment_history[config.deployment_name].append({\n",
    "                \"timestamp\": datetime.now(),\n",
    "                \"action\": \"deployment_started\",\n",
    "                \"canary_traffic\": config.initial_traffic,\n",
    "                \"status\": \"active\"\n",
    "            })\n",
    "            \n",
    "            print(f\"🚀 Canary 部署 '{config.deployment_name}' 已創建\")\n",
    "            print(f\"   📊 穩定版本: V{config.stable_version} ({100-config.initial_traffic:.1f}%)\")\n",
    "            print(f\"   🐤 Canary 版本: V{config.canary_version} ({config.initial_traffic:.1f}%)\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Canary 部署創建失敗: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def monitor_and_scale(self, deployment_name: str, \n",
    "                         current_metrics: Dict[str, float]) -> str:\n",
    "        \"\"\"監控並自動調整流量\"\"\"\n",
    "        if deployment_name not in self.active_deployments:\n",
    "            return \"deployment_not_found\"\n",
    "        \n",
    "        config = self.active_deployments[deployment_name]\n",
    "        current_traffic = self.version_manager.get_version_info(\n",
    "            config.canary_version\n",
    "        ).traffic_percentage\n",
    "        \n",
    "        # 檢查回滾條件\n",
    "        for metric, threshold in config.rollback_threshold.items():\n",
    "            if metric in current_metrics:\n",
    "                if metric == \"error_rate\" and current_metrics[metric] > threshold:\n",
    "                    return self._rollback_deployment(deployment_name, \n",
    "                                                   f\"High {metric}: {current_metrics[metric]:.3f}\")\n",
    "                elif metric == \"latency\" and current_metrics[metric] > threshold:\n",
    "                    return self._rollback_deployment(deployment_name, \n",
    "                                                   f\"High {metric}: {current_metrics[metric]:.1f}ms\")\n",
    "        \n",
    "        # 檢查成功條件\n",
    "        success_criteria_met = True\n",
    "        for metric, threshold in config.success_threshold.items():\n",
    "            if metric in current_metrics:\n",
    "                if metric == \"error_rate\" and current_metrics[metric] > threshold:\n",
    "                    success_criteria_met = False\n",
    "                elif metric == \"latency\" and current_metrics[metric] > threshold:\n",
    "                    success_criteria_met = False\n",
    "        \n",
    "        # 如果成功條件滿足，增加流量\n",
    "        if success_criteria_met and current_traffic < config.target_traffic:\n",
    "            new_traffic = min(current_traffic + config.increment_step, \n",
    "                            config.target_traffic)\n",
    "            \n",
    "            new_traffic_config = {\n",
    "                config.stable_version: 100 - new_traffic,\n",
    "                config.canary_version: new_traffic\n",
    "            }\n",
    "            \n",
    "            self.version_manager.set_traffic_split(new_traffic_config)\n",
    "            \n",
    "            # 記錄歷史\n",
    "            self.deployment_history[deployment_name].append({\n",
    "                \"timestamp\": datetime.now(),\n",
    "                \"action\": \"traffic_increased\",\n",
    "                \"canary_traffic\": new_traffic,\n",
    "                \"metrics\": current_metrics.copy(),\n",
    "                \"status\": \"scaling\"\n",
    "            })\n",
    "            \n",
    "            print(f\"📈 Canary 流量增加到 {new_traffic:.1f}%\")\n",
    "            \n",
    "            # 檢查是否達到目標\n",
    "            if new_traffic >= config.target_traffic and config.auto_promote:\n",
    "                return self._promote_canary(deployment_name)\n",
    "            \n",
    "            return \"traffic_increased\"\n",
    "        \n",
    "        return \"stable\"\n",
    "    \n",
    "    def _rollback_deployment(self, deployment_name: str, reason: str) -> str:\n",
    "        \"\"\"回滾部署\"\"\"\n",
    "        config = self.active_deployments[deployment_name]\n",
    "        \n",
    "        # 恢復到穩定版本\n",
    "        self.version_manager.set_traffic_split({config.stable_version: 100.0})\n",
    "        \n",
    "        # 記錄回滾\n",
    "        self.deployment_history[deployment_name].append({\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"action\": \"rollback\",\n",
    "            \"reason\": reason,\n",
    "            \"canary_traffic\": 0.0,\n",
    "            \"status\": \"rolled_back\"\n",
    "        })\n",
    "        \n",
    "        print(f\"🔙 Canary 部署已回滾: {reason}\")\n",
    "        return \"rolled_back\"\n",
    "    \n",
    "    def _promote_canary(self, deployment_name: str) -> str:\n",
    "        \"\"\"提升 Canary 為穩定版本\"\"\"\n",
    "        config = self.active_deployments[deployment_name]\n",
    "        \n",
    "        # 將 Canary 版本設為 100% 流量\n",
    "        self.version_manager.set_traffic_split({config.canary_version: 100.0})\n",
    "        \n",
    "        # 記錄提升\n",
    "        self.deployment_history[deployment_name].append({\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"action\": \"promoted\",\n",
    "            \"canary_traffic\": 100.0,\n",
    "            \"status\": \"completed\"\n",
    "        })\n",
    "        \n",
    "        print(f\"🎉 Canary 版本已提升為穩定版本\")\n",
    "        return \"promoted\"\n",
    "    \n",
    "    def get_deployment_status(self, deployment_name: str) -> Dict:\n",
    "        \"\"\"獲取部署狀態\"\"\"\n",
    "        if deployment_name not in self.active_deployments:\n",
    "            return {\"error\": \"部署不存在\"}\n",
    "        \n",
    "        config = self.active_deployments[deployment_name]\n",
    "        history = self.deployment_history.get(deployment_name, [])\n",
    "        \n",
    "        current_canary_traffic = self.version_manager.get_version_info(\n",
    "            config.canary_version\n",
    "        ).traffic_percentage\n",
    "        \n",
    "        latest_status = \"unknown\"\n",
    "        if history:\n",
    "            latest_status = history[-1][\"status\"]\n",
    "        \n",
    "        return {\n",
    "            \"deployment_name\": deployment_name,\n",
    "            \"stable_version\": config.stable_version,\n",
    "            \"canary_version\": config.canary_version,\n",
    "            \"current_canary_traffic\": current_canary_traffic,\n",
    "            \"target_traffic\": config.target_traffic,\n",
    "            \"status\": latest_status,\n",
    "            \"steps_completed\": len(history),\n",
    "            \"progress\": (current_canary_traffic / config.target_traffic) * 100\n",
    "        }\n",
    "\n",
    "\n",
    "# 創建 Canary 部署管理器\n",
    "canary_manager = CanaryDeploymentManager(version_manager)\n",
    "print(\"✅ Canary 部署管理器已創建\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### 3.2 啟動 Canary 部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 Canary 部署配置\n",
    "canary_config = CanaryConfig(\n",
    "    deployment_name=\"v3_canary_rollout\",\n",
    "    model_name=\"text_classifier\",\n",
    "    stable_version=2,\n",
    "    canary_version=3,\n",
    "    initial_traffic=5.0,\n",
    "    target_traffic=100.0,\n",
    "    increment_step=15.0,\n",
    "    step_duration=5,  # 5分鐘\n",
    "    success_threshold={\n",
    "        \"error_rate\": 0.05,  # 5% 以下\n",
    "        \"latency\": 120.0     # 120ms 以下\n",
    "    },\n",
    "    rollback_threshold={\n",
    "        \"error_rate\": 0.10,  # 10% 以上回滾\n",
    "        \"latency\": 200.0     # 200ms 以上回滾\n",
    "    },\n",
    "    auto_promote=True\n",
    ")\n",
    "\n",
    "# 創建並啟動 Canary 部署\n",
    "canary_manager.create_canary_deployment(canary_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### 3.3 模擬 Canary 部署過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模擬 Canary 部署的監控和自動調整過程\n",
    "def simulate_canary_deployment(canary_manager: CanaryDeploymentManager, \n",
    "                             deployment_name: str, steps: int = 6):\n",
    "    \"\"\"模擬 Canary 部署過程\"\"\"\n",
    "    print(f\"🐤 開始模擬 Canary 部署: {deployment_name}\")\n",
    "    \n",
    "    for step in range(steps):\n",
    "        print(f\"\\n--- 步驟 {step + 1}/{steps} ---\")\n",
    "        \n",
    "        # 模擬當前性能指標（逐步改善）\n",
    "        base_error_rate = 0.03 + random.uniform(-0.01, 0.02)\n",
    "        base_latency = 85 + random.uniform(-15, 25)\n",
    "        \n",
    "        # 偶爾模擬性能問題\n",
    "        if step == 3 and random.random() < 0.3:  # 30% 機率在第3步出現問題\n",
    "            base_error_rate = 0.12  # 觸發回滾\n",
    "            base_latency = 220\n",
    "            print(\"⚠️  檢測到性能問題...\")\n",
    "        \n",
    "        current_metrics = {\n",
    "            \"error_rate\": base_error_rate,\n",
    "            \"latency\": base_latency,\n",
    "            \"throughput\": random.uniform(800, 1200)\n",
    "        }\n",
    "        \n",
    "        print(f\"📊 當前指標:\")\n",
    "        print(f\"   錯誤率: {current_metrics['error_rate']:.3f}\")\n",
    "        print(f\"   延遲: {current_metrics['latency']:.1f}ms\")\n",
    "        print(f\"   吞吐量: {current_metrics['throughput']:.0f} QPS\")\n",
    "        \n",
    "        # 監控並調整\n",
    "        result = canary_manager.monitor_and_scale(deployment_name, current_metrics)\n",
    "        \n",
    "        # 顯示部署狀態\n",
    "        status = canary_manager.get_deployment_status(deployment_name)\n",
    "        if \"error\" not in status:\n",
    "            print(f\"🎯 當前進度: {status['progress']:.1f}% 完成\")\n",
    "            print(f\"📈 Canary 流量: {status['current_canary_traffic']:.1f}%\")\n",
    "        \n",
    "        # 檢查部署結果\n",
    "        if result == \"rolled_back\":\n",
    "            print(\"🔙 部署已回滾，停止模擬\")\n",
    "            break\n",
    "        elif result == \"promoted\":\n",
    "            print(\"🎉 Canary 版本已提升，部署完成\")\n",
    "            break\n",
    "        \n",
    "        # 模擬時間間隔\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(f\"\\n🏁 Canary 部署模擬完成\")\n",
    "\n",
    "\n",
    "# 執行模擬\n",
    "simulate_canary_deployment(canary_manager, \"v3_canary_rollout\", 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 3.4 Canary 部署歷史分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化 Canary 部署歷史\n",
    "def plot_canary_deployment_history(canary_manager: CanaryDeploymentManager, \n",
    "                                 deployment_name: str):\n",
    "    \"\"\"可視化 Canary 部署歷史\"\"\"\n",
    "    if deployment_name not in canary_manager.deployment_history:\n",
    "        print(f\"❌ 部署 '{deployment_name}' 的歷史記錄不存在\")\n",
    "        return\n",
    "    \n",
    "    history = canary_manager.deployment_history[deployment_name]\n",
    "    \n",
    "    if not history:\n",
    "        print(\"❌ 沒有歷史數據可供分析\")\n",
    "        return\n",
    "    \n",
    "    # 準備數據\n",
    "    timestamps = []\n",
    "    traffic_percentages = []\n",
    "    actions = []\n",
    "    \n",
    "    for record in history:\n",
    "        timestamps.append(record[\"timestamp\"])\n",
    "        traffic_percentages.append(record[\"canary_traffic\"])\n",
    "        actions.append(record[\"action\"])\n",
    "    \n",
    "    # 創建圖表\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    \n",
    "    # 流量變化趨勢\n",
    "    ax1.plot(timestamps, traffic_percentages, marker='o', linewidth=2, \n",
    "            markersize=8, color='#3498db')\n",
    "    ax1.set_title(f'Canary 部署流量變化: {deployment_name}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Canary 流量 (%)', fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 105)\n",
    "    \n",
    "    # 標記關鍵事件\n",
    "    for i, (ts, traffic, action) in enumerate(zip(timestamps, traffic_percentages, actions)):\n",
    "        if action == \"rollback\":\n",
    "            ax1.annotate('回滾', xy=(ts, traffic), xytext=(ts, traffic + 10),\n",
    "                        arrowprops=dict(arrowstyle='->', color='red'),\n",
    "                        color='red', fontweight='bold')\n",
    "        elif action == \"promoted\":\n",
    "            ax1.annotate('提升', xy=(ts, traffic), xytext=(ts, traffic - 10),\n",
    "                        arrowprops=dict(arrowstyle='->', color='green'),\n",
    "                        color='green', fontweight='bold')\n",
    "    \n",
    "    # 事件時間線\n",
    "    action_colors = {\n",
    "        'deployment_started': '#3498db',\n",
    "        'traffic_increased': '#2ecc71',\n",
    "        'rollback': '#e74c3c',\n",
    "        'promoted': '#f39c12'\n",
    "    }\n",
    "    \n",
    "    for i, action in enumerate(actions):\n",
    "        color = action_colors.get(action, '#95a5a6')\n",
    "        ax2.barh(i, 1, color=color, alpha=0.7)\n",
    "        ax2.text(0.5, i, action.replace('_', ' ').title(), \n",
    "                ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    ax2.set_title('部署事件時間線', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('時間進度', fontsize=12)\n",
    "    ax2.set_yticks(range(len(actions)))\n",
    "    ax2.set_yticklabels([f'{i+1}' for i in range(len(actions))])\n",
    "    ax2.set_xlim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 顯示摘要統計\n",
    "    print(f\"\\n📊 Canary 部署摘要: {deployment_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"📅 開始時間: {timestamps[0].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"📅 結束時間: {timestamps[-1].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"⏱️  總耗時: {(timestamps[-1] - timestamps[0]).total_seconds():.1f} 秒\")\n",
    "    print(f\"🔄 步驟數: {len(history)}\")\n",
    "    print(f\"🎯 最終狀態: {history[-1]['status']}\")\n",
    "    print(f\"📈 最終流量: {history[-1]['canary_traffic']:.1f}%\")\n",
    "\n",
    "\n",
    "# 可視化部署歷史\n",
    "plot_canary_deployment_history(canary_manager, \"v3_canary_rollout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## 🎯 實驗 4：配置導出和持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導出完整的實驗配置和結果\n",
    "def export_experiment_results(version_manager, ab_test_manager, canary_manager):\n",
    "    \"\"\"導出實驗結果\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 版本管理配置\n",
    "    version_config_file = f\"{EXPERIMENT_DIR}/configs/version_config_{timestamp}.json\"\n",
    "    version_manager.export_config(version_config_file)\n",
    "    \n",
    "    # A/B 測試結果\n",
    "    ab_results = {}\n",
    "    for test_name in ab_test_manager.active_tests.keys():\n",
    "        ab_results[test_name] = ab_test_manager.get_test_summary(test_name)\n",
    "    \n",
    "    ab_results_file = f\"{EXPERIMENT_DIR}/configs/ab_test_results_{timestamp}.json\"\n",
    "    with open(ab_results_file, 'w') as f:\n",
    "        json.dump(ab_results, f, indent=2, default=str)\n",
    "    \n",
    "    # Canary 部署結果\n",
    "    canary_results = {}\n",
    "    for deployment_name in canary_manager.active_deployments.keys():\n",
    "        canary_results[deployment_name] = {\n",
    "            \"status\": canary_manager.get_deployment_status(deployment_name),\n",
    "            \"history\": canary_manager.deployment_history.get(deployment_name, [])\n",
    "        }\n",
    "    \n",
    "    canary_results_file = f\"{EXPERIMENT_DIR}/configs/canary_results_{timestamp}.json\"\n",
    "    with open(canary_results_file, 'w') as f:\n",
    "        json.dump(canary_results, f, indent=2, default=str)\n",
    "    \n",
    "    # 創建綜合報告\n",
    "    comprehensive_report = {\n",
    "        \"experiment_timestamp\": timestamp,\n",
    "        \"model_name\": version_manager.model_name,\n",
    "        \"total_versions\": len(version_manager.versions),\n",
    "        \"ab_tests_count\": len(ab_test_manager.active_tests),\n",
    "        \"canary_deployments_count\": len(canary_manager.active_deployments),\n",
    "        \"files_generated\": {\n",
    "            \"version_config\": version_config_file,\n",
    "            \"ab_test_results\": ab_results_file,\n",
    "            \"canary_results\": canary_results_file\n",
    "        },\n",
    "        \"summary\": {\n",
    "            \"current_traffic_split\": version_manager.traffic_rules,\n",
    "            \"active_ab_tests\": list(ab_test_manager.active_tests.keys()),\n",
    "            \"active_canary_deployments\": list(canary_manager.active_deployments.keys())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    report_file = f\"{EXPERIMENT_DIR}/experiment_report_{timestamp}.json\"\n",
    "    with open(report_file, 'w') as f:\n",
    "        json.dump(comprehensive_report, f, indent=2)\n",
    "    \n",
    "    print(f\"📊 實驗結果已導出:\")\n",
    "    print(f\"   📄 綜合報告: {report_file}\")\n",
    "    print(f\"   ⚙️  版本配置: {version_config_file}\")\n",
    "    print(f\"   🧪 A/B 測試: {ab_results_file}\")\n",
    "    print(f\"   🐤 Canary 部署: {canary_results_file}\")\n",
    "\n",
    "\n",
    "# 導出實驗結果\n",
    "export_experiment_results(version_manager, ab_test_manager, canary_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## 📊 最佳實踐總結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最佳實踐指南\n",
    "best_practices = \"\"\"\n",
    "🎯 企業級模型版本管理與 A/B 測試最佳實踐\n",
    "\n",
    "📋 版本管理策略:\n",
    "   ✅ 語義化版本控制 (Semantic Versioning)\n",
    "   ✅ 完整的版本元數據記錄\n",
    "   ✅ 自動化版本發現和註冊\n",
    "   ✅ 版本間相容性檢查\n",
    "\n",
    "🧪 A/B 測試設計原則:\n",
    "   ✅ 明確定義成功指標\n",
    "   ✅ 適當的樣本量計算\n",
    "   ✅ 統計顯著性驗證\n",
    "   ✅ 多維度性能評估\n",
    "\n",
    "🐤 Canary 部署策略:\n",
    "   ✅ 漸進式流量增加\n",
    "   ✅ 實時監控和自動回滾\n",
    "   ✅ 多層級健康檢查\n",
    "   ✅ 業務指標持續監控\n",
    "\n",
    "⚠️ 風險控制措施:\n",
    "   ✅ 快速回滾機制\n",
    "   ✅ 多級告警系統\n",
    "   ✅ 業務影響評估\n",
    "   ✅ 災難恢復預案\n",
    "\n",
    "📈 監控和可觀測性:\n",
    "   ✅ 全面的指標收集\n",
    "   ✅ 即時性能儀表板\n",
    "   ✅ 異常檢測和告警\n",
    "   ✅ 歷史趨勢分析\n",
    "\n",
    "🔧 運維自動化:\n",
    "   ✅ CI/CD 管道整合\n",
    "   ✅ 自動化測試流程\n",
    "   ✅ 智能決策引擎\n",
    "   ✅ 自動化故障恢復\n",
    "\n",
    "💡 成功要素:\n",
    "   🎯 業務目標對齊\n",
    "   📊 數據驅動決策\n",
    "   🚀 快速迭代能力\n",
    "   🛡️ 風險控制意識\n",
    "   👥 跨團隊協作\n",
    "\"\"\"\n",
    "\n",
    "print(best_practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## 📖 總結\n",
    "\n",
    "本實驗完成了企業級模型版本管理與 A/B 測試的完整實現：\n",
    "\n",
    "### 🎯 實驗成果\n",
    "1. **版本管理系統** - 實現了完整的模型版本生命週期管理\n",
    "2. **A/B 測試框架** - 構建了自動化的實驗設計和分析系統\n",
    "3. **Canary 部署** - 開發了漸進式部署和自動化回滾機制\n",
    "4. **監控和可視化** - 提供了全面的性能分析和決策支持工具\n",
    "\n",
    "### 🔧 關鍵技術點\n",
    "- 企業級版本管理策略\n",
    "- 統計學驅動的 A/B 測試\n",
    "- 智能化的 Canary 部署\n",
    "- 實時監控和自動化決策\n",
    "\n",
    "### 🚀 實際應用價值\n",
    "1. **降低部署風險** - 通過漸進式部署減少生產事故\n",
    "2. **提升決策品質** - 基於數據的科學決策流程\n",
    "3. **加快迭代速度** - 自動化流程提升部署效率\n",
    "4. **增強系統穩定性** - 多重保障機制確保服務可用性\n",
    "\n",
    "### 💡 學習要點\n",
    "- 企業級部署需要考慮風險控制和業務連續性\n",
    "- A/B 測試需要統計學基礎和業務理解\n",
    "- Canary 部署是平衡創新和穩定的有效策略\n",
    "- 監控和可觀測性是成功部署的關鍵\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 恭喜完成 Lab 2.4.1！**\n",
    "\n",
    "您已經掌握了企業級模型版本管理和 A/B 測試的核心技術，可以構建安全、可靠的模型部署流程。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}