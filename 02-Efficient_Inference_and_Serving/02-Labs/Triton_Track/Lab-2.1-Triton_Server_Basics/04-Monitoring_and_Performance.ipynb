{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-2.1.4: 監控與性能優化\n",
    "\n",
    "## 🎯 學習目標\n",
    "\n",
    "1. **建立企業級監控體系**\n",
    "   - Prometheus 指標收集\n",
    "   - Grafana 儀表板設計\n",
    "   - 告警和通知系統\n",
    "\n",
    "2. **實現自動化性能調優**\n",
    "   - 動態資源調配\n",
    "   - 負載平衡優化\n",
    "   - SLA 監控和保證\n",
    "\n",
    "3. **建構完整運維流程**\n",
    "   - 健康檢查機制\n",
    "   - 故障檢測和恢復\n",
    "   - 容量規劃和擴展\n",
    "\n",
    "## 📋 企業案例背景\n",
    "\n",
    "**場景**: Netflix 推薦系統需要：\n",
    "- 99.99% 可用性 (年停機時間 < 53分鐘)\n",
    "- P99 延遲 < 50ms\n",
    "- 支援 10M+ 並發用戶\n",
    "- 自動故障恢復\n",
    "\n",
    "**技術挑戰**: 如何設計可觀測性系統確保服務品質？\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prometheus 指標收集系統\n",
    "\n",
    "### 1.1 指標定義和收集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import threading\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict, deque\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 模擬 Prometheus 客戶端\n",
    "class MockPrometheusMetrics:\n",
    "    \"\"\"\n",
    "    模擬 Prometheus 指標收集器\n",
    "    (實際部署中使用 prometheus_client)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.counters = defaultdict(float)\n",
    "        self.histograms = defaultdict(list)\n",
    "        self.gauges = defaultdict(float)\n",
    "        self.summaries = defaultdict(list)\n",
    "    \n",
    "    def counter_inc(self, name: str, labels: Dict[str, str] = None, value: float = 1.0):\n",
    "        key = self._make_key(name, labels)\n",
    "        self.counters[key] += value\n",
    "    \n",
    "    def histogram_observe(self, name: str, labels: Dict[str, str] = None, value: float = 0.0):\n",
    "        key = self._make_key(name, labels)\n",
    "        self.histograms[key].append(value)\n",
    "    \n",
    "    def gauge_set(self, name: str, labels: Dict[str, str] = None, value: float = 0.0):\n",
    "        key = self._make_key(name, labels)\n",
    "        self.gauges[key] = value\n",
    "    \n",
    "    def _make_key(self, name: str, labels: Dict[str, str] = None) -> str:\n",
    "        if labels:\n",
    "            label_str = ','.join([f'{k}=\"{v}\"' for k, v in sorted(labels.items())])\n",
    "            return f'{name}{{{label_str}}}'\n",
    "        return name\n",
    "\n",
    "class TritonMetricsCollector:\n",
    "    \"\"\"\n",
    "    Triton 專用指標收集器\n",
    "    \n",
    "    收集指標:\n",
    "    - 推理延遲和吞吐量\n",
    "    - 資源使用情況\n",
    "    - 錯誤率和成功率\n",
    "    - 商業指標\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, model_version: str = \"1\"):\n",
    "        self.model_name = model_name\n",
    "        self.model_version = model_version\n",
    "        self.metrics = MockPrometheusMetrics()\n",
    "        \n",
    "        # 基礎標籤\n",
    "        self.base_labels = {\n",
    "            \"model_name\": model_name,\n",
    "            \"model_version\": model_version,\n",
    "            \"instance\": \"triton-0\"\n",
    "        }\n",
    "        \n",
    "        print(f\"📊 Triton 指標收集器已初始化: {model_name} v{model_version}\")\n",
    "    \n",
    "    def record_inference_request(\n",
    "        self, \n",
    "        latency_ms: float,\n",
    "        batch_size: int,\n",
    "        success: bool = True,\n",
    "        backend: str = \"pytorch\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        記錄推理請求指標\n",
    "        \"\"\"\n",
    "        labels = {**self.base_labels, \"backend\": backend}\n",
    "        \n",
    "        # 請求計數\n",
    "        status = \"success\" if success else \"error\"\n",
    "        self.metrics.counter_inc(\n",
    "            \"triton_inference_requests_total\",\n",
    "            {**labels, \"status\": status}\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            # 延遲直方圖\n",
    "            self.metrics.histogram_observe(\n",
    "                \"triton_inference_latency_ms\",\n",
    "                labels,\n",
    "                latency_ms\n",
    "            )\n",
    "            \n",
    "            # 批量大小\n",
    "            self.metrics.histogram_observe(\n",
    "                \"triton_inference_batch_size\",\n",
    "                labels,\n",
    "                batch_size\n",
    "            )\n",
    "            \n",
    "            # 吞吐量 (samples/sec)\n",
    "            throughput = batch_size / (latency_ms / 1000)\n",
    "            self.metrics.gauge_set(\n",
    "                \"triton_inference_throughput_samples_per_sec\",\n",
    "                labels,\n",
    "                throughput\n",
    "            )\n",
    "    \n",
    "    def record_resource_usage(\n",
    "        self,\n",
    "        gpu_utilization: float,\n",
    "        gpu_memory_used_gb: float,\n",
    "        gpu_memory_total_gb: float,\n",
    "        cpu_utilization: float\n",
    "    ):\n",
    "        \"\"\"\n",
    "        記錄資源使用指標\n",
    "        \"\"\"\n",
    "        labels = self.base_labels\n",
    "        \n",
    "        # GPU 指標\n",
    "        self.metrics.gauge_set(\n",
    "            \"triton_gpu_utilization_percent\", labels, gpu_utilization\n",
    "        )\n",
    "        self.metrics.gauge_set(\n",
    "            \"triton_gpu_memory_used_gb\", labels, gpu_memory_used_gb\n",
    "        )\n",
    "        self.metrics.gauge_set(\n",
    "            \"triton_gpu_memory_utilization_percent\", \n",
    "            labels, \n",
    "            (gpu_memory_used_gb / gpu_memory_total_gb) * 100\n",
    "        )\n",
    "        \n",
    "        # CPU 指標\n",
    "        self.metrics.gauge_set(\n",
    "            \"triton_cpu_utilization_percent\", labels, cpu_utilization\n",
    "        )\n",
    "    \n",
    "    def record_business_metrics(\n",
    "        self,\n",
    "        decisions: List[str],\n",
    "        fraud_detected: int,\n",
    "        false_positives: int = 0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        記錄業務指標 (以反詐騙為例)\n",
    "        \"\"\"\n",
    "        labels = self.base_labels\n",
    "        \n",
    "        # 決策分佈\n",
    "        for decision in ['APPROVE', 'BLOCK', 'REVIEW']:\n",
    "            count = decisions.count(decision)\n",
    "            self.metrics.counter_inc(\n",
    "                \"triton_business_decisions_total\",\n",
    "                {**labels, \"decision\": decision.lower()},\n",
    "                count\n",
    "            )\n",
    "        \n",
    "        # 詐騙檢測\n",
    "        self.metrics.counter_inc(\n",
    "            \"triton_fraud_detected_total\", labels, fraud_detected\n",
    "        )\n",
    "        \n",
    "        # 誤報\n",
    "        if false_positives > 0:\n",
    "            self.metrics.counter_inc(\n",
    "                \"triton_false_positives_total\", labels, false_positives\n",
    "            )\n",
    "    \n",
    "    def get_metrics_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        獲取指標摘要\n",
    "        \"\"\"\n",
    "        summary = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"model\": f\"{self.model_name}:{self.model_version}\",\n",
    "            \"counters\": dict(self.metrics.counters),\n",
    "            \"gauges\": dict(self.metrics.gauges),\n",
    "            \"histograms\": {}\n",
    "        }\n",
    "        \n",
    "        # 計算直方圖統計\n",
    "        for key, values in self.metrics.histograms.items():\n",
    "            if values:\n",
    "                summary[\"histograms\"][key] = {\n",
    "                    \"count\": len(values),\n",
    "                    \"sum\": sum(values),\n",
    "                    \"mean\": np.mean(values),\n",
    "                    \"p50\": np.percentile(values, 50),\n",
    "                    \"p90\": np.percentile(values, 90),\n",
    "                    \"p95\": np.percentile(values, 95),\n",
    "                    \"p99\": np.percentile(values, 99)\n",
    "                }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# 創建指標收集器\n",
    "metrics_collector = TritonMetricsCollector(\n",
    "    model_name=\"netflix_recommendation_v2_prod\",\n",
    "    model_version=\"2\"\n",
    ")\n",
    "\n",
    "print(\"✅ Prometheus 指標收集系統已啟動\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 模擬監控數據收集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simulate_production_workload(duration_seconds: int = 60):\n",
    "    \"\"\"\n",
    "    模擬生產環境工作負載\n",
    "    \"\"\"\n",
    "    print(f\"🔄 模擬生產環境工作負載 ({duration_seconds} 秒)...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    request_count = 0\n",
    "    \n",
    "    while time.time() - start_time < duration_seconds:\n",
    "        # 模擬不同時段的負載模式\n",
    "        elapsed = time.time() - start_time\n",
    "        load_factor = 1 + 0.5 * np.sin(elapsed / 10)  # 週期性負載變化\n",
    "        \n",
    "        # 請求頻率 (QPS)\n",
    "        base_qps = 50\n",
    "        current_qps = base_qps * load_factor\n",
    "        \n",
    "        # 模擬請求\n",
    "        if random.random() < current_qps / 100:  # 調整概率\n",
    "            # 批量大小分佈\n",
    "            batch_size = random.choices(\n",
    "                [1, 2, 4, 8, 16], \n",
    "                weights=[0.3, 0.2, 0.2, 0.2, 0.1]\n",
    "            )[0]\n",
    "            \n",
    "            # 延遲模擬 (正常分佈 + 偶爾的異常值)\n",
    "            if random.random() < 0.95:  # 95% 正常請求\n",
    "                base_latency = 15 + 5 * batch_size  # 基礎延遲隨批量增加\n",
    "                latency = max(1, np.random.normal(base_latency, 5))\n",
    "                success = random.random() > 0.001  # 99.9% 成功率\n",
    "            else:  # 5% 異常請求\n",
    "                latency = np.random.exponential(100)  # 長尾延遲\n",
    "                success = random.random() > 0.1  # 90% 成功率\n",
    "            \n",
    "            # 記錄推理指標\n",
    "            metrics_collector.record_inference_request(\n",
    "                latency_ms=latency,\n",
    "                batch_size=batch_size,\n",
    "                success=success\n",
    "            )\n",
    "            \n",
    "            # 模擬資源使用\n",
    "            if request_count % 10 == 0:  # 每10個請求記錄一次資源\n",
    "                gpu_util = min(100, 30 + 20 * load_factor + np.random.normal(0, 5))\n",
    "                gpu_memory = min(8, 2 + 1.5 * load_factor + np.random.normal(0, 0.5))\n",
    "                cpu_util = min(100, 20 + 15 * load_factor + np.random.normal(0, 3))\n",
    "                \n",
    "                metrics_collector.record_resource_usage(\n",
    "                    gpu_utilization=max(0, gpu_util),\n",
    "                    gpu_memory_used_gb=max(0, gpu_memory),\n",
    "                    gpu_memory_total_gb=8.0,\n",
    "                    cpu_utilization=max(0, cpu_util)\n",
    "                )\n",
    "            \n",
    "            # 模擬業務決策\n",
    "            if success and request_count % 5 == 0:\n",
    "                decisions = random.choices(\n",
    "                    ['APPROVE', 'BLOCK', 'REVIEW'],\n",
    "                    weights=[0.85, 0.10, 0.05],\n",
    "                    k=batch_size\n",
    "                )\n",
    "                \n",
    "                fraud_detected = decisions.count('BLOCK')\n",
    "                \n",
    "                metrics_collector.record_business_metrics(\n",
    "                    decisions=decisions,\n",
    "                    fraud_detected=fraud_detected\n",
    "                )\n",
    "            \n",
    "            request_count += 1\n",
    "        \n",
    "        time.sleep(0.1)  # 控制模擬速度\n",
    "    \n",
    "    print(f\"✅ 模擬完成，總計處理 {request_count} 個請求\")\n",
    "    return request_count\n",
    "\n",
    "# 執行工作負載模擬\n",
    "total_requests = simulate_production_workload(30)  # 30秒模擬\n",
    "\n",
    "# 獲取指標摘要\n",
    "summary = metrics_collector.get_metrics_summary()\n",
    "\n",
    "print(\"\\n📊 指標收集摘要:\")\n",
    "print(f\"   📈 總請求數: {total_requests}\")\n",
    "print(f\"   ⏱️  平均延遲: {summary['histograms'].get('triton_inference_latency_ms', {}).get('mean', 0):.2f} ms\")\n",
    "print(f\"   📊 P95 延遲: {summary['histograms'].get('triton_inference_latency_ms', {}).get('p95', 0):.2f} ms\")\n",
    "print(f\"   🚀 平均批量: {summary['histograms'].get('triton_inference_batch_size', {}).get('mean', 0):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SLA 監控和告警系統\n",
    "\n",
    "### 2.1 SLA 定義和監控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SLATarget:\n",
    "    \"\"\"\n",
    "    SLA 目標定義\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    target_value: float\n",
    "    operator: str  # '<', '>', '<=', '>=', '=='\n",
    "    measurement_window: int  # 秒\n",
    "    severity: str  # 'critical', 'warning', 'info'\n",
    "\n",
    "class SLAMonitor:\n",
    "    \"\"\"\n",
    "    SLA 監控和告警系統\n",
    "    \n",
    "    監控指標:\n",
    "    - 可用性 (Availability)\n",
    "    - 延遲 (Latency)\n",
    "    - 吞吐量 (Throughput)\n",
    "    - 錯誤率 (Error Rate)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, service_name: str):\n",
    "        self.service_name = service_name\n",
    "        self.sla_targets = self._define_sla_targets()\n",
    "        self.metrics_history = defaultdict(list)\n",
    "        self.alerts = []\n",
    "        \n",
    "        print(f\"🎯 SLA 監控系統已啟動: {service_name}\")\n",
    "        self._print_sla_targets()\n",
    "    \n",
    "    def _define_sla_targets(self) -> List[SLATarget]:\n",
    "        \"\"\"\n",
    "        定義企業級 SLA 目標\n",
    "        \"\"\"\n",
    "        return [\n",
    "            SLATarget(\n",
    "                name=\"availability\",\n",
    "                description=\"服務可用性\",\n",
    "                target_value=99.99,  # 99.99%\n",
    "                operator=\">=\",\n",
    "                measurement_window=300,  # 5分鐘\n",
    "                severity=\"critical\"\n",
    "            ),\n",
    "            SLATarget(\n",
    "                name=\"latency_p95\",\n",
    "                description=\"P95 延遲\",\n",
    "                target_value=50.0,  # 50ms\n",
    "                operator=\"<=\",\n",
    "                measurement_window=60,  # 1分鐘\n",
    "                severity=\"warning\"\n",
    "            ),\n",
    "            SLATarget(\n",
    "                name=\"latency_p99\",\n",
    "                description=\"P99 延遲\",\n",
    "                target_value=100.0,  # 100ms\n",
    "                operator=\"<=\",\n",
    "                measurement_window=60,\n",
    "                severity=\"critical\"\n",
    "            ),\n",
    "            SLATarget(\n",
    "                name=\"error_rate\",\n",
    "                description=\"錯誤率\",\n",
    "                target_value=0.1,  # 0.1%\n",
    "                operator=\"<=\",\n",
    "                measurement_window=300,\n",
    "                severity=\"critical\"\n",
    "            ),\n",
    "            SLATarget(\n",
    "                name=\"throughput\",\n",
    "                description=\"最小吞吐量\",\n",
    "                target_value=100.0,  # 100 QPS\n",
    "                operator=\">=\",\n",
    "                measurement_window=60,\n",
    "                severity=\"warning\"\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def _print_sla_targets(self):\n",
    "        \"\"\"\n",
    "        打印 SLA 目標\n",
    "        \"\"\"\n",
    "        print(\"\\n📋 SLA 目標定義:\")\n",
    "        for target in self.sla_targets:\n",
    "            severity_icon = {\n",
    "                'critical': '🔴',\n",
    "                'warning': '🟡', \n",
    "                'info': '🔵'\n",
    "            }[target.severity]\n",
    "            \n",
    "            print(f\"   {severity_icon} {target.description}: {target.operator} {target.target_value}\")\n",
    "            print(f\"      測量窗口: {target.measurement_window}秒, 級別: {target.severity}\")\n",
    "    \n",
    "    def record_metrics(\n",
    "        self,\n",
    "        timestamp: float,\n",
    "        latency_ms: float,\n",
    "        success: bool,\n",
    "        throughput_qps: float\n",
    "    ):\n",
    "        \"\"\"\n",
    "        記錄指標用於 SLA 計算\n",
    "        \"\"\"\n",
    "        metric_point = {\n",
    "            'timestamp': timestamp,\n",
    "            'latency_ms': latency_ms,\n",
    "            'success': success,\n",
    "            'throughput_qps': throughput_qps\n",
    "        }\n",
    "        \n",
    "        self.metrics_history['points'].append(metric_point)\n",
    "        \n",
    "        # 保持最近1小時的數據\n",
    "        cutoff_time = timestamp - 3600\n",
    "        self.metrics_history['points'] = [\n",
    "            p for p in self.metrics_history['points']\n",
    "            if p['timestamp'] > cutoff_time\n",
    "        ]\n",
    "    \n",
    "    def calculate_sla_metrics(self, window_seconds: int = 300) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        計算指定時間窗口內的 SLA 指標\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        cutoff_time = current_time - window_seconds\n",
    "        \n",
    "        # 獲取窗口內的數據\n",
    "        window_data = [\n",
    "            p for p in self.metrics_history['points']\n",
    "            if p['timestamp'] > cutoff_time\n",
    "        ]\n",
    "        \n",
    "        if not window_data:\n",
    "            return {}\n",
    "        \n",
    "        # 計算指標\n",
    "        total_requests = len(window_data)\n",
    "        successful_requests = sum(1 for p in window_data if p['success'])\n",
    "        latencies = [p['latency_ms'] for p in window_data if p['success']]\n",
    "        throughputs = [p['throughput_qps'] for p in window_data]\n",
    "        \n",
    "        metrics = {\n",
    "            'availability': (successful_requests / total_requests) * 100 if total_requests > 0 else 0,\n",
    "            'error_rate': ((total_requests - successful_requests) / total_requests) * 100 if total_requests > 0 else 0,\n",
    "            'throughput': np.mean(throughputs) if throughputs else 0\n",
    "        }\n",
    "        \n",
    "        if latencies:\n",
    "            metrics.update({\n",
    "                'latency_p50': np.percentile(latencies, 50),\n",
    "                'latency_p95': np.percentile(latencies, 95),\n",
    "                'latency_p99': np.percentile(latencies, 99),\n",
    "                'latency_max': np.max(latencies)\n",
    "            })\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def check_sla_violations(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        檢查 SLA 違反情況\n",
    "        \"\"\"\n",
    "        violations = []\n",
    "        \n",
    "        for target in self.sla_targets:\n",
    "            metrics = self.calculate_sla_metrics(target.measurement_window)\n",
    "            \n",
    "            if target.name not in metrics:\n",
    "                continue\n",
    "            \n",
    "            current_value = metrics[target.name]\n",
    "            target_value = target.target_value\n",
    "            \n",
    "            violated = False\n",
    "            if target.operator == '<=' and current_value > target_value:\n",
    "                violated = True\n",
    "            elif target.operator == '>=' and current_value < target_value:\n",
    "                violated = True\n",
    "            elif target.operator == '<' and current_value >= target_value:\n",
    "                violated = True\n",
    "            elif target.operator == '>' and current_value <= target_value:\n",
    "                violated = True\n",
    "            elif target.operator == '==' and abs(current_value - target_value) > 0.01:\n",
    "                violated = True\n",
    "            \n",
    "            if violated:\n",
    "                violation = {\n",
    "                    'timestamp': time.time(),\n",
    "                    'sla_name': target.name,\n",
    "                    'description': target.description,\n",
    "                    'target_value': target_value,\n",
    "                    'current_value': current_value,\n",
    "                    'operator': target.operator,\n",
    "                    'severity': target.severity,\n",
    "                    'window_seconds': target.measurement_window\n",
    "                }\n",
    "                violations.append(violation)\n",
    "        \n",
    "        return violations\n",
    "    \n",
    "    def generate_sla_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        生成 SLA 報告\n",
    "        \"\"\"\n",
    "        current_metrics = self.calculate_sla_metrics(300)  # 5分鐘窗口\n",
    "        violations = self.check_sla_violations()\n",
    "        \n",
    "        report = {\n",
    "            'service_name': self.service_name,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'current_metrics': current_metrics,\n",
    "            'sla_targets': [\n",
    "                {\n",
    "                    'name': target.name,\n",
    "                    'description': target.description,\n",
    "                    'target': f\"{target.operator} {target.target_value}\",\n",
    "                    'current': current_metrics.get(target.name, 'N/A'),\n",
    "                    'status': 'PASS' if target.name not in [v['sla_name'] for v in violations] else 'FAIL'\n",
    "                }\n",
    "                for target in self.sla_targets\n",
    "            ],\n",
    "            'violations': violations,\n",
    "            'overall_status': 'HEALTHY' if not violations else 'DEGRADED'\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "\n",
    "# 初始化 SLA 監控\n",
    "sla_monitor = SLAMonitor(\"netflix-recommendation-service\")\n",
    "\n",
    "# 模擬指標收集\n",
    "print(\"\\n🔄 模擬 SLA 指標收集...\")\n",
    "current_time = time.time()\n",
    "\n",
    "# 模擬不同性能場景\n",
    "for i in range(100):\n",
    "    # 時間進展\n",
    "    timestamp = current_time + i * 3  # 每3秒一個數據點\n",
    "    \n",
    "    # 模擬不同階段的性能\n",
    "    if i < 30:  # 正常階段\n",
    "        latency = np.random.normal(25, 5)\n",
    "        success_rate = 0.999\n",
    "        throughput = np.random.normal(150, 20)\n",
    "    elif i < 60:  # 性能退化階段\n",
    "        latency = np.random.normal(45, 15)\n",
    "        success_rate = 0.995\n",
    "        throughput = np.random.normal(120, 25)\n",
    "    else:  # 恢復階段\n",
    "        latency = np.random.normal(30, 8)\n",
    "        success_rate = 0.998\n",
    "        throughput = np.random.normal(140, 15)\n",
    "    \n",
    "    success = np.random.random() < success_rate\n",
    "    \n",
    "    sla_monitor.record_metrics(\n",
    "        timestamp=timestamp,\n",
    "        latency_ms=max(1, latency),\n",
    "        success=success,\n",
    "        throughput_qps=max(0, throughput)\n",
    "    )\n",
    "\n",
    "print(\"✅ SLA 指標收集完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SLA 報告和告警"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成 SLA 報告\n",
    "sla_report = sla_monitor.generate_sla_report()\n",
    "\n",
    "print(\"📋 SLA 監控報告\")\n",
    "print(\"═\" * 60)\n",
    "print(f\"🏷️  服務: {sla_report['service_name']}\")\n",
    "print(f\"🕐 時間: {sla_report['timestamp']}\")\n",
    "print(f\"📊 整體狀態: {sla_report['overall_status']}\")\n",
    "print()\n",
    "\n",
    "# 當前指標\n",
    "print(\"📈 當前性能指標 (5分鐘窗口):\")\n",
    "current_metrics = sla_report['current_metrics']\n",
    "for metric, value in current_metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        if 'latency' in metric:\n",
    "            print(f\"   ⏱️  {metric}: {value:.2f} ms\")\n",
    "        elif 'rate' in metric or 'availability' in metric:\n",
    "            print(f\"   📊 {metric}: {value:.2f}%\")\n",
    "        elif 'throughput' in metric:\n",
    "            print(f\"   🚀 {metric}: {value:.1f} QPS\")\n",
    "        else:\n",
    "            print(f\"   📈 {metric}: {value:.2f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# SLA 目標檢查\n",
    "print(\"🎯 SLA 目標檢查:\")\n",
    "for target in sla_report['sla_targets']:\n",
    "    status_icon = '✅' if target['status'] == 'PASS' else '❌'\n",
    "    current_val = target['current']\n",
    "    \n",
    "    if current_val != 'N/A':\n",
    "        if isinstance(current_val, (int, float)):\n",
    "            current_str = f\"{current_val:.2f}\"\n",
    "        else:\n",
    "            current_str = str(current_val)\n",
    "    else:\n",
    "        current_str = 'N/A'\n",
    "    \n",
    "    print(f\"   {status_icon} {target['description']}: {current_str} (目標: {target['target']})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 違反情況\n",
    "if sla_report['violations']:\n",
    "    print(\"🚨 SLA 違反告警:\")\n",
    "    for violation in sla_report['violations']:\n",
    "        severity_icon = {\n",
    "            'critical': '🔴',\n",
    "            'warning': '🟡',\n",
    "            'info': '🔵'\n",
    "        }[violation['severity']]\n",
    "        \n",
    "        print(f\"   {severity_icon} {violation['description']}:\")\n",
    "        print(f\"      目標: {violation['operator']} {violation['target_value']}\")\n",
    "        print(f\"      當前: {violation['current_value']:.2f}\")\n",
    "        print(f\"      級別: {violation['severity'].upper()}\")\n",
    "        print(f\"      時間窗口: {violation['window_seconds']}秒\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"✅ 所有 SLA 目標均達成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 自動化性能調優系統\n",
    "\n",
    "### 3.1 自適應資源調配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoScalingController:\n",
    "    \"\"\"\n",
    "    自動化性能調優控制器\n",
    "    \n",
    "    功能:\n",
    "    - 動態實例調整\n",
    "    - 負載平衡優化\n",
    "    - 資源使用優化\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, service_name: str):\n",
    "        self.service_name = service_name\n",
    "        self.current_instances = 2\n",
    "        self.min_instances = 1\n",
    "        self.max_instances = 10\n",
    "        \n",
    "        # 調整策略參數\n",
    "        self.scale_up_threshold = {\n",
    "            'cpu_utilization': 70,  # %\n",
    "            'memory_utilization': 80,  # %\n",
    "            'latency_p95': 50,  # ms\n",
    "            'queue_length': 10  # 請求數\n",
    "        }\n",
    "        \n",
    "        self.scale_down_threshold = {\n",
    "            'cpu_utilization': 30,  # %\n",
    "            'memory_utilization': 40,  # %\n",
    "            'latency_p95': 20,  # ms\n",
    "            'queue_length': 2  # 請求數\n",
    "        }\n",
    "        \n",
    "        self.scaling_history = []\n",
    "        self.last_scaling_time = 0\n",
    "        self.cooldown_period = 300  # 5分鐘冷卻期\n",
    "        \n",
    "        print(f\"🎛️  自動調整控制器已啟動: {service_name}\")\n",
    "        print(f\"   📊 當前實例數: {self.current_instances}\")\n",
    "        print(f\"   📈 實例範圍: {self.min_instances}-{self.max_instances}\")\n",
    "    \n",
    "    def analyze_metrics(self, metrics: Dict[str, float]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        分析當前指標並生成調整建議\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # 檢查冷卻期\n",
    "        if current_time - self.last_scaling_time < self.cooldown_period:\n",
    "            return {\n",
    "                'action': 'wait',\n",
    "                'reason': f'冷卻期內 ({self.cooldown_period - (current_time - self.last_scaling_time):.0f}秒)',\n",
    "                'current_instances': self.current_instances\n",
    "            }\n",
    "        \n",
    "        # 檢查擴容條件\n",
    "        scale_up_signals = []\n",
    "        scale_down_signals = []\n",
    "        \n",
    "        for metric, value in metrics.items():\n",
    "            if metric in self.scale_up_threshold:\n",
    "                threshold = self.scale_up_threshold[metric]\n",
    "                if metric in ['cpu_utilization', 'memory_utilization', 'latency_p95', 'queue_length']:\n",
    "                    if value > threshold:\n",
    "                        scale_up_signals.append(f\"{metric}: {value:.1f} > {threshold}\")\n",
    "            \n",
    "            if metric in self.scale_down_threshold:\n",
    "                threshold = self.scale_down_threshold[metric]\n",
    "                if metric in ['cpu_utilization', 'memory_utilization', 'latency_p95', 'queue_length']:\n",
    "                    if value < threshold:\n",
    "                        scale_down_signals.append(f\"{metric}: {value:.1f} < {threshold}\")\n",
    "        \n",
    "        # 決策邏輯\n",
    "        if len(scale_up_signals) >= 2 and self.current_instances < self.max_instances:\n",
    "            return {\n",
    "                'action': 'scale_up',\n",
    "                'reason': f'多個指標觸發擴容: {scale_up_signals}',\n",
    "                'target_instances': min(self.current_instances + 1, self.max_instances),\n",
    "                'current_instances': self.current_instances\n",
    "            }\n",
    "        elif len(scale_down_signals) >= 3 and self.current_instances > self.min_instances:\n",
    "            return {\n",
    "                'action': 'scale_down',\n",
    "                'reason': f'多個指標支持縮容: {scale_down_signals}',\n",
    "                'target_instances': max(self.current_instances - 1, self.min_instances),\n",
    "                'current_instances': self.current_instances\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'action': 'maintain',\n",
    "                'reason': f'指標正常，維持當前實例數',\n",
    "                'current_instances': self.current_instances\n",
    "            }\n",
    "    \n",
    "    def execute_scaling(self, decision: Dict[str, Any]) -> bool:\n",
    "        \"\"\"\n",
    "        執行調整操作\n",
    "        \"\"\"\n",
    "        action = decision['action']\n",
    "        \n",
    "        if action == 'scale_up':\n",
    "            old_instances = self.current_instances\n",
    "            self.current_instances = decision['target_instances']\n",
    "            self.last_scaling_time = time.time()\n",
    "            \n",
    "            scaling_event = {\n",
    "                'timestamp': time.time(),\n",
    "                'action': 'scale_up',\n",
    "                'from_instances': old_instances,\n",
    "                'to_instances': self.current_instances,\n",
    "                'reason': decision['reason']\n",
    "            }\n",
    "            self.scaling_history.append(scaling_event)\n",
    "            \n",
    "            print(f\"📈 執行擴容: {old_instances} → {self.current_instances} 實例\")\n",
    "            print(f\"   💡 原因: {decision['reason']}\")\n",
    "            \n",
    "            # 模擬擴容過程\n",
    "            print(f\"   🔄 啟動新實例...\")\n",
    "            time.sleep(1)\n",
    "            print(f\"   ✅ 擴容完成\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        elif action == 'scale_down':\n",
    "            old_instances = self.current_instances\n",
    "            self.current_instances = decision['target_instances']\n",
    "            self.last_scaling_time = time.time()\n",
    "            \n",
    "            scaling_event = {\n",
    "                'timestamp': time.time(),\n",
    "                'action': 'scale_down',\n",
    "                'from_instances': old_instances,\n",
    "                'to_instances': self.current_instances,\n",
    "                'reason': decision['reason']\n",
    "            }\n",
    "            self.scaling_history.append(scaling_event)\n",
    "            \n",
    "            print(f\"📉 執行縮容: {old_instances} → {self.current_instances} 實例\")\n",
    "            print(f\"   💡 原因: {decision['reason']}\")\n",
    "            \n",
    "            # 模擬縮容過程\n",
    "            print(f\"   🔄 優雅關閉實例...\")\n",
    "            time.sleep(1)\n",
    "            print(f\"   ✅ 縮容完成\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def get_scaling_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        獲取調整歷史報告\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'service_name': self.service_name,\n",
    "            'current_instances': self.current_instances,\n",
    "            'instance_range': f\"{self.min_instances}-{self.max_instances}\",\n",
    "            'scaling_history': self.scaling_history[-10:],  # 最近10次\n",
    "            'total_scaling_events': len(self.scaling_history)\n",
    "        }\n",
    "\n",
    "# 初始化自動調整控制器\n",
    "autoscaling = AutoScalingController(\"netflix-recommendation-service\")\n",
    "\n",
    "# 模擬自動調整場景\n",
    "print(\"\\n🎛️  模擬自動調整場景...\")\n",
    "\n",
    "# 場景1: 高負載觸發擴容\n",
    "print(\"\\n📈 場景1: 高負載期間\")\n",
    "high_load_metrics = {\n",
    "    'cpu_utilization': 85.0,\n",
    "    'memory_utilization': 78.0,\n",
    "    'latency_p95': 65.0,\n",
    "    'queue_length': 15\n",
    "}\n",
    "\n",
    "decision = autoscaling.analyze_metrics(high_load_metrics)\n",
    "print(f\"📊 分析結果: {decision['action']} - {decision['reason']}\")\n",
    "autoscaling.execute_scaling(decision)\n",
    "\n",
    "# 場景2: 持續高負載\n",
    "print(\"\\n📈 場景2: 持續高負載\")\n",
    "time.sleep(2)  # 模擬時間經過\n",
    "autoscaling.last_scaling_time -= 310  # 繞過冷卻期\n",
    "\n",
    "extreme_load_metrics = {\n",
    "    'cpu_utilization': 92.0,\n",
    "    'memory_utilization': 88.0,\n",
    "    'latency_p95': 120.0,\n",
    "    'queue_length': 25\n",
    "}\n",
    "\n",
    "decision = autoscaling.analyze_metrics(extreme_load_metrics)\n",
    "print(f\"📊 分析結果: {decision['action']} - {decision['reason']}\")\n",
    "autoscaling.execute_scaling(decision)\n",
    "\n",
    "# 場景3: 負載降低觸發縮容\n",
    "print(\"\\n📉 場景3: 負載降低期間\")\n",
    "time.sleep(2)\n",
    "autoscaling.last_scaling_time -= 310\n",
    "\n",
    "low_load_metrics = {\n",
    "    'cpu_utilization': 25.0,\n",
    "    'memory_utilization': 35.0,\n",
    "    'latency_p95': 15.0,\n",
    "    'queue_length': 1\n",
    "}\n",
    "\n",
    "decision = autoscaling.analyze_metrics(low_load_metrics)\n",
    "print(f\"📊 分析結果: {decision['action']} - {decision['reason']}\")\n",
    "autoscaling.execute_scaling(decision)\n",
    "\n",
    "# 獲取調整報告\n",
    "scaling_report = autoscaling.get_scaling_report()\n",
    "\n",
    "print(\"\\n📋 自動調整歷史報告:\")\n",
    "print(f\"   🏷️  服務: {scaling_report['service_name']}\")\n",
    "print(f\"   📊 當前實例: {scaling_report['current_instances']}\")\n",
    "print(f\"   📈 實例範圍: {scaling_report['instance_range']}\")\n",
    "print(f\"   🔄 調整次數: {scaling_report['total_scaling_events']}\")\n",
    "\n",
    "print(\"\\n📝 調整歷史:\")\n",
    "for event in scaling_report['scaling_history']:\n",
    "    action_icon = '📈' if event['action'] == 'scale_up' else '📉'\n",
    "    timestamp = datetime.fromtimestamp(event['timestamp']).strftime('%H:%M:%S')\n",
    "    print(f\"   {action_icon} {timestamp}: {event['from_instances']} → {event['to_instances']} ({event['action']})\")\n",
    "    print(f\"      理由: {event['reason'][:80]}...\" if len(event['reason']) > 80 else f\"      理由: {event['reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 健康檢查和故障恢復\n",
    "\n",
    "### 4.1 多層次健康檢查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Callable\n",
    "\n",
    "class HealthStatus(Enum):\n",
    "    HEALTHY = \"healthy\"\n",
    "    DEGRADED = \"degraded\"\n",
    "    UNHEALTHY = \"unhealthy\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "@dataclass\n",
    "class HealthCheck:\n",
    "    name: str\n",
    "    description: str\n",
    "    check_function: Callable\n",
    "    timeout_seconds: int\n",
    "    critical: bool  # 是否為關鍵檢查\n",
    "    interval_seconds: int\n",
    "\n",
    "class ComprehensiveHealthMonitor:\n",
    "    \"\"\"\n",
    "    綜合健康監控系統\n",
    "    \n",
    "    多層次檢查:\n",
    "    - 基礎設施層 (Infrastructure)\n",
    "    - 應用層 (Application)\n",
    "    - 業務層 (Business)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, service_name: str):\n",
    "        self.service_name = service_name\n",
    "        self.health_checks = self._setup_health_checks()\n",
    "        self.health_history = defaultdict(list)\n",
    "        self.alert_thresholds = {\n",
    "            'consecutive_failures': 3,\n",
    "            'failure_rate_threshold': 0.2  # 20%\n",
    "        }\n",
    "        \n",
    "        print(f\"🏥 綜合健康監控系統已啟動: {service_name}\")\n",
    "        print(f\"   📋 健康檢查項目: {len(self.health_checks)}\")\n",
    "    \n",
    "    def _setup_health_checks(self) -> List[HealthCheck]:\n",
    "        \"\"\"\n",
    "        設置健康檢查項目\n",
    "        \"\"\"\n",
    "        return [\n",
    "            # 基礎設施層檢查\n",
    "            HealthCheck(\n",
    "                name=\"gpu_availability\",\n",
    "                description=\"GPU 可用性檢查\",\n",
    "                check_function=self._check_gpu_availability,\n",
    "                timeout_seconds=5,\n",
    "                critical=True,\n",
    "                interval_seconds=30\n",
    "            ),\n",
    "            HealthCheck(\n",
    "                name=\"memory_usage\",\n",
    "                description=\"記憶體使用率檢查\",\n",
    "                check_function=self._check_memory_usage,\n",
    "                timeout_seconds=3,\n",
    "                critical=True,\n",
    "                interval_seconds=15\n",
    "            ),\n",
    "            HealthCheck(\n",
    "                name=\"disk_space\",\n",
    "                description=\"磁碟空間檢查\",\n",
    "                check_function=self._check_disk_space,\n",
    "                timeout_seconds=5,\n",
    "                critical=False,\n",
    "                interval_seconds=60\n",
    "            ),\n",
    "            \n",
    "            # 應用層檢查\n",
    "            HealthCheck(\n",
    "                name=\"model_inference\",\n",
    "                description=\"模型推理功能檢查\",\n",
    "                check_function=self._check_model_inference,\n",
    "                timeout_seconds=10,\n",
    "                critical=True,\n",
    "                interval_seconds=30\n",
    "            ),\n",
    "            HealthCheck(\n",
    "                name=\"api_endpoint\",\n",
    "                description=\"API 端點可達性檢查\",\n",
    "                check_function=self._check_api_endpoint,\n",
    "                timeout_seconds=5,\n",
    "                critical=True,\n",
    "                interval_seconds=15\n",
    "            ),\n",
    "            \n",
    "            # 業務層檢查\n",
    "            HealthCheck(\n",
    "                name=\"response_quality\",\n",
    "                description=\"響應品質檢查\",\n",
    "                check_function=self._check_response_quality,\n",
    "                timeout_seconds=15,\n",
    "                critical=False,\n",
    "                interval_seconds=120\n",
    "            ),\n",
    "            HealthCheck(\n",
    "                name=\"business_metrics\",\n",
    "                description=\"業務指標健康度檢查\",\n",
    "                check_function=self._check_business_metrics,\n",
    "                timeout_seconds=10,\n",
    "                critical=False,\n",
    "                interval_seconds=180\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def _check_gpu_availability(self) -> Dict[str, Any]:\n",
    "        \"\"\"檢查 GPU 可用性\"\"\"\n",
    "        try:\n",
    "            # 模擬 GPU 檢查\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_count = torch.cuda.device_count()\n",
    "                current_device = torch.cuda.current_device()\n",
    "                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "                \n",
    "                return {\n",
    "                    'status': HealthStatus.HEALTHY,\n",
    "                    'details': {\n",
    "                        'gpu_count': gpu_count,\n",
    "                        'current_device': current_device,\n",
    "                        'total_memory_gb': gpu_memory\n",
    "                    },\n",
    "                    'message': f'{gpu_count} GPU(s) 可用'\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'status': HealthStatus.UNHEALTHY,\n",
    "                    'details': {},\n",
    "                    'message': 'GPU 不可用'\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': HealthStatus.UNKNOWN,\n",
    "                'details': {'error': str(e)},\n",
    "                'message': f'GPU 檢查失敗: {str(e)}'\n",
    "            }\n",
    "    \n",
    "    def _check_memory_usage(self) -> Dict[str, Any]:\n",
    "        \"\"\"檢查記憶體使用率\"\"\"\n",
    "        try:\n",
    "            # 模擬記憶體檢查\n",
    "            if torch.cuda.is_available():\n",
    "                allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "                cached = torch.cuda.memory_reserved(0) / (1024**3)\n",
    "                total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "                \n",
    "                usage_ratio = allocated / total\n",
    "                \n",
    "                if usage_ratio < 0.8:\n",
    "                    status = HealthStatus.HEALTHY\n",
    "                elif usage_ratio < 0.9:\n",
    "                    status = HealthStatus.DEGRADED\n",
    "                else:\n",
    "                    status = HealthStatus.UNHEALTHY\n",
    "                \n",
    "                return {\n",
    "                    'status': status,\n",
    "                    'details': {\n",
    "                        'allocated_gb': allocated,\n",
    "                        'cached_gb': cached,\n",
    "                        'total_gb': total,\n",
    "                        'usage_ratio': usage_ratio\n",
    "                    },\n",
    "                    'message': f'GPU 記憶體使用率: {usage_ratio:.1%}'\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'status': HealthStatus.HEALTHY,\n",
    "                    'details': {},\n",
    "                    'message': 'CPU 模式，跳過 GPU 記憶體檢查'\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': HealthStatus.UNKNOWN,\n",
    "                'details': {'error': str(e)},\n",
    "                'message': f'記憶體檢查失敗: {str(e)}'\n",
    "            }\n",
    "    \n",
    "    def _check_disk_space(self) -> Dict[str, Any]:\n",
    "        \"\"\"檢查磁碟空間\"\"\"\n",
    "        try:\n",
    "            import shutil\n",
    "            total, used, free = shutil.disk_usage(\"/\")\n",
    "            \n",
    "            usage_ratio = used / total\n",
    "            \n",
    "            if usage_ratio < 0.8:\n",
    "                status = HealthStatus.HEALTHY\n",
    "            elif usage_ratio < 0.9:\n",
    "                status = HealthStatus.DEGRADED\n",
    "            else:\n",
    "                status = HealthStatus.UNHEALTHY\n",
    "            \n",
    "            return {\n",
    "                'status': status,\n",
    "                'details': {\n",
    "                    'total_gb': total / (1024**3),\n",
    "                    'used_gb': used / (1024**3),\n",
    "                    'free_gb': free / (1024**3),\n",
    "                    'usage_ratio': usage_ratio\n",
    "                },\n",
    "                'message': f'磁碟使用率: {usage_ratio:.1%}'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': HealthStatus.UNKNOWN,\n",
    "                'details': {'error': str(e)},\n",
    "                'message': f'磁碟檢查失敗: {str(e)}'\n",
    "            }\n",
    "    \n",
    "    def _check_model_inference(self) -> Dict[str, Any]:\n",
    "        \"\"\"檢查模型推理功能\"\"\"\n",
    "        try:\n",
    "            # 模擬推理測試\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # 模擬推理過程\n",
    "            time.sleep(0.1)  # 模擬推理時間\n",
    "            \n",
    "            inference_time = (time.time() - start_time) * 1000\n",
    "            \n",
    "            if inference_time < 50:\n",
    "                status = HealthStatus.HEALTHY\n",
    "            elif inference_time < 100:\n",
    "                status = HealthStatus.DEGRADED\n",
    "            else:\n",
    "                status = HealthStatus.UNHEALTHY\n",
    "            \n",
    "            return {\n",
    "                'status': status,\n",
    "                'details': {\n",
    "                    'inference_time_ms': inference_time,\n",
    "                    'test_successful': True\n",
    "                },\n",
    "                'message': f'推理測試成功，耗時 {inference_time:.1f}ms'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': HealthStatus.UNHEALTHY,\n",
    "                'details': {'error': str(e)},\n",
    "                'message': f'推理測試失敗: {str(e)}'\n",
    "            }\n",
    "    \n",
    "    def _check_api_endpoint(self) -> Dict[str, Any]:\n",
    "        \"\"\"檢查 API 端點可達性\"\"\"\n",
    "        try:\n",
    "            # 模擬 API 健康檢查\n",
    "            response_time = np.random.normal(20, 5)  # 模擬響應時間\n",
    "            \n",
    "            if response_time < 100:\n",
    "                status = HealthStatus.HEALTHY\n",
    "            elif response_time < 500:\n",
    "                status = HealthStatus.DEGRADED\n",
    "            else:\n",
    "                status = HealthStatus.UNHEALTHY\n",
    "            \n",
    "            return {\n",
    "                'status': status,\n",
    "                'details': {\n",
    "                    'response_time_ms': response_time,\n",
    "                    'endpoint_reachable': True\n",
    "                },\n",
    "                'message': f'API 端點可達，響應時間 {response_time:.1f}ms'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': HealthStatus.UNHEALTHY,\n",
    "                'details': {'error': str(e)},\n",
    "                'message': f'API 端點檢查失敗: {str(e)}'\n",
    "            }\n",
    "    \n",
    "    def _check_response_quality(self) -> Dict[str, Any]:\n",
    "        \"\"\"檢查響應品質\"\"\"\n",
    "        try:\n",
    "            # 模擬品質檢查\n",
    "            accuracy = np.random.normal(0.95, 0.02)  # 模擬準確率\n",
    "            consistency = np.random.normal(0.98, 0.01)  # 模擬一致性\n",
    "            \n",
    "            quality_score = (accuracy + consistency) / 2\n",
    "            \n",
    "            if quality_score > 0.95:\n",
    "                status = HealthStatus.HEALTHY\n",
    "            elif quality_score > 0.90:\n",
    "                status = HealthStatus.DEGRADED\n",
    "            else:\n",
    "                status = HealthStatus.UNHEALTHY\n",
    "            \n",
    "            return {\n",
    "                'status': status,\n",
    "                'details': {\n",
    "                    'accuracy': accuracy,\n",
    "                    'consistency': consistency,\n",
    "                    'quality_score': quality_score\n",
    "                },\n",
    "                'message': f'響應品質: {quality_score:.1%}'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': HealthStatus.UNKNOWN,\n",
    "                'details': {'error': str(e)},\n",
    "                'message': f'品質檢查失敗: {str(e)}'\n",
    "            }\n",
    "    \n",
    "    def _check_business_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"檢查業務指標健康度\"\"\"\n",
    "        try:\n",
    "            # 模擬業務指標檢查\n",
    "            fraud_detection_rate = np.random.normal(0.85, 0.05)\n",
    "            false_positive_rate = np.random.normal(0.03, 0.01)\n",
    "            customer_satisfaction = np.random.normal(0.92, 0.03)\n",
    "            \n",
    "            # 綜合評分\n",
    "            business_health = (fraud_detection_rate + (1 - false_positive_rate) + customer_satisfaction) / 3\n",
    "            \n",
    "            if business_health > 0.90:\n",
    "                status = HealthStatus.HEALTHY\n",
    "            elif business_health > 0.80:\n",
    "                status = HealthStatus.DEGRADED\n",
    "            else:\n",
    "                status = HealthStatus.UNHEALTHY\n",
    "            \n",
    "            return {\n",
    "                'status': status,\n",
    "                'details': {\n",
    "                    'fraud_detection_rate': fraud_detection_rate,\n",
    "                    'false_positive_rate': false_positive_rate,\n",
    "                    'customer_satisfaction': customer_satisfaction,\n",
    "                    'business_health_score': business_health\n",
    "                },\n",
    "                'message': f'業務健康度: {business_health:.1%}'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': HealthStatus.UNKNOWN,\n",
    "                'details': {'error': str(e)},\n",
    "                'message': f'業務指標檢查失敗: {str(e)}'\n",
    "            }\n",
    "    \n",
    "    def run_all_health_checks(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        執行所有健康檢查\n",
    "        \"\"\"\n",
    "        print(\"🏥 執行綜合健康檢查...\")\n",
    "        \n",
    "        results = {\n",
    "            'timestamp': time.time(),\n",
    "            'service_name': self.service_name,\n",
    "            'checks': {},\n",
    "            'summary': {\n",
    "                'total_checks': len(self.health_checks),\n",
    "                'healthy': 0,\n",
    "                'degraded': 0,\n",
    "                'unhealthy': 0,\n",
    "                'unknown': 0,\n",
    "                'critical_failures': 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for check in self.health_checks:\n",
    "            try:\n",
    "                print(f\"   🔍 {check.description}...\")\n",
    "                \n",
    "                start_time = time.time()\n",
    "                result = check.check_function()\n",
    "                execution_time = time.time() - start_time\n",
    "                \n",
    "                result['execution_time_ms'] = execution_time * 1000\n",
    "                result['check_name'] = check.name\n",
    "                result['critical'] = check.critical\n",
    "                \n",
    "                results['checks'][check.name] = result\n",
    "                \n",
    "                # 更新統計\n",
    "                status = result['status']\n",
    "                if status == HealthStatus.HEALTHY:\n",
    "                    results['summary']['healthy'] += 1\n",
    "                    print(f\"      ✅ 健康\")\n",
    "                elif status == HealthStatus.DEGRADED:\n",
    "                    results['summary']['degraded'] += 1\n",
    "                    print(f\"      🟡 降級\")\n",
    "                elif status == HealthStatus.UNHEALTHY:\n",
    "                    results['summary']['unhealthy'] += 1\n",
    "                    if check.critical:\n",
    "                        results['summary']['critical_failures'] += 1\n",
    "                    print(f\"      ❌ 不健康\")\n",
    "                else:\n",
    "                    results['summary']['unknown'] += 1\n",
    "                    print(f\"      ❓ 未知\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      💥 檢查執行失敗: {str(e)}\")\n",
    "                results['checks'][check.name] = {\n",
    "                    'status': HealthStatus.UNKNOWN,\n",
    "                    'details': {'error': str(e)},\n",
    "                    'message': f'檢查執行失敗: {str(e)}',\n",
    "                    'critical': check.critical\n",
    "                }\n",
    "                results['summary']['unknown'] += 1\n",
    "        \n",
    "        # 計算整體健康狀態\n",
    "        if results['summary']['critical_failures'] > 0:\n",
    "            results['overall_status'] = HealthStatus.UNHEALTHY\n",
    "        elif results['summary']['unhealthy'] > 0 or results['summary']['degraded'] > 2:\n",
    "            results['overall_status'] = HealthStatus.DEGRADED\n",
    "        elif results['summary']['degraded'] > 0:\n",
    "            results['overall_status'] = HealthStatus.DEGRADED\n",
    "        else:\n",
    "            results['overall_status'] = HealthStatus.HEALTHY\n",
    "        \n",
    "        return results\n",
    "\n",
    "# 創建健康監控系統\n",
    "health_monitor = ComprehensiveHealthMonitor(\"netflix-recommendation-service\")\n",
    "\n",
    "# 執行健康檢查\n",
    "health_results = health_monitor.run_all_health_checks()\n",
    "\n",
    "print(\"\\n📋 健康檢查結果摘要:\")\n",
    "print(f\"   🏷️  服務: {health_results['service_name']}\")\n",
    "print(f\"   📊 整體狀態: {health_results['overall_status'].value.upper()}\")\n",
    "print(f\"   📈 檢查統計:\")\n",
    "print(f\"      ✅ 健康: {health_results['summary']['healthy']}\")\n",
    "print(f\"      🟡 降級: {health_results['summary']['degraded']}\")\n",
    "print(f\"      ❌ 不健康: {health_results['summary']['unhealthy']}\")\n",
    "print(f\"      ❓ 未知: {health_results['summary']['unknown']}\")\n",
    "print(f\"      🔴 關鍵失敗: {health_results['summary']['critical_failures']}\")\n",
    "\n",
    "print(\"\\n🔍 詳細檢查結果:\")\n",
    "for check_name, result in health_results['checks'].items():\n",
    "    status_icon = {\n",
    "        HealthStatus.HEALTHY: '✅',\n",
    "        HealthStatus.DEGRADED: '🟡',\n",
    "        HealthStatus.UNHEALTHY: '❌',\n",
    "        HealthStatus.UNKNOWN: '❓'\n",
    "    }[result['status']]\n",
    "    \n",
    "    critical_marker = ' 🔴' if result.get('critical', False) else ''\n",
    "    print(f\"   {status_icon} {check_name}{critical_marker}: {result['message']}\")\n",
    "    print(f\"      執行時間: {result.get('execution_time_ms', 0):.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 本章總結\n",
    "\n",
    "### 核心學習成果\n",
    "\n",
    "通過本實驗室，您已經掌握了：\n",
    "\n",
    "1. **📊 企業級監控體系**\n",
    "   - Prometheus 指標收集和管理\n",
    "   - 多維度性能監控\n",
    "   - 實時告警和通知機制\n",
    "\n",
    "2. **🎯 SLA 監控和保證**\n",
    "   - 99.99% 可用性監控\n",
    "   - P95/P99 延遲追蹤\n",
    "   - 自動化 SLA 違反檢測\n",
    "\n",
    "3. **🎛️  自動化運維能力**\n",
    "   - 智能資源調配\n",
    "   - 動態擴縮容決策\n",
    "   - 負載預測和優化\n",
    "\n",
    "4. **🏥 健康檢查和故障恢復**\n",
    "   - 多層次健康監控\n",
    "   - 預防性故障檢測\n",
    "   - 自動化恢復流程\n",
    "\n",
    "### 企業級運維技能\n",
    "\n",
    "您現在具備了：\n",
    "- **Netflix 級別**的可觀測性設計能力\n",
    "- **金融級別**的 SLA 監控技能\n",
    "- **雲原生**的自動化運維經驗\n",
    "- **生產級別**的故障處理能力\n",
    "\n",
    "### 完整 Lab-2.1 學習成果\n",
    "\n",
    "完成整個 **Lab-2.1: Triton Server Basics** 後，您已經具備：\n",
    "\n",
    "1. **Triton Server 完整部署能力**\n",
    "2. **企業級 Model Repository 設計**\n",
    "3. **PyTorch Backend 深度優化**\n",
    "4. **生產級監控和運維**\n",
    "\n",
    "### 下一步學習路徑\n",
    "\n",
    "準備進入 **Lab-2.2: Multi-Model Management**：\n",
    "- 多模型統一管理平台\n",
    "- A/B 測試自動化\n",
    "- 模型生命週期管理\n",
    "- 企業級模型治理\n",
    "\n",
    "---\n",
    "\n",
    "**🏆 恭喜！您已經完成了 Triton Server 基礎的企業級監控與性能優化！**\n",
    "\n",
    "**📈 技能提升總結：從基礎部署提升到企業級運維專家！**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}