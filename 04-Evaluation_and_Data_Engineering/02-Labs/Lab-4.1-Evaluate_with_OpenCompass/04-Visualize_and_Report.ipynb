{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.1 - OpenCompass è©•ä¼°å¯¦æˆ°\n",
    "## Notebook 04: è¦–è¦ºåŒ–èˆ‡å ±å‘Šç”Ÿæˆ\n",
    "\n",
    "**å­¸ç¿’ç›®æ¨™**:\n",
    "1. ç¹ªè£½é›·é”åœ– (å¤šç¶­åº¦èƒ½åŠ›åˆ†ä½ˆ)\n",
    "2. ç¹ªè£½ç†±åŠ›åœ– (å­¸ç§‘è¡¨ç¾çŸ©é™£)\n",
    "3. ç¹ªè£½æŸ±ç‹€åœ– (æ¨¡å‹å°æ¯”)\n",
    "4. ç”Ÿæˆå®Œæ•´çš„è©•ä¼°å ±å‘Š (Markdown/HTML)\n",
    "5. åŒ¯å‡ºåœ–è¡¨ç‚º PNG æª”æ¡ˆ\n",
    "\n",
    "**é è¨ˆæ™‚é–“**: 30-45 åˆ†é˜\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šèˆ‡æ•¸æ“šè¼‰å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è¨­å®šä¸­æ–‡å­—é«” (è§£æ±ºä¸­æ–‡é¡¯ç¤ºå•é¡Œ)\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei', 'Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False  # è§£æ±ºè² è™Ÿé¡¯ç¤ºå•é¡Œ\n",
    "\n",
    "# è¨­å®šé¢¨æ ¼\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# è¨­å®šè·¯å¾‘\n",
    "RESULTS_DIR = Path(\"./results\")\n",
    "ANALYSIS_DIR = Path(\"./analysis\")\n",
    "CHARTS_DIR = Path(\"./charts\")\n",
    "CHARTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"ğŸ“Š è¦–è¦ºåŒ–ç’°å¢ƒæº–å‚™ä¸­...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# è¼‰å…¥è©•ä¼°çµæœ\n",
    "results = {}\n",
    "result_files = {\n",
    "    'llama-2-7b': RESULTS_DIR / \"llama2_7b_results.json\",\n",
    "    'qwen-7b': RESULTS_DIR / \"qwen_7b_results.json\"\n",
    "}\n",
    "\n",
    "for model_key, result_file in result_files.items():\n",
    "    if result_file.exists():\n",
    "        with open(result_file, 'r', encoding='utf-8') as f:\n",
    "            results[model_key] = json.load(f)\n",
    "        print(f\"âœ… è¼‰å…¥: {result_file.name}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  æœªæ‰¾åˆ°: {result_file.name}\")\n",
    "\n",
    "if not results:\n",
    "    raise FileNotFoundError(\"æœªæ‰¾åˆ°è©•ä¼°çµæœ,è«‹å…ˆåŸ·è¡Œ 02-Evaluate.ipynb\")\n",
    "\n",
    "print(f\"\\nâœ… å…±è¼‰å…¥ {len(results)} å€‹æ¨¡å‹çš„çµæœ\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ•´é«”è¡¨ç¾å°æ¯” - æŸ±ç‹€åœ–\n",
    "\n",
    "ä½¿ç”¨æŸ±ç‹€åœ–å°æ¯”æ¨¡å‹çš„æ•´é«”è¡¨ç¾å’Œåˆ†é¡è¡¨ç¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_comparison(results: dict, save_path: Path = None):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½æ•´é«”è¡¨ç¾å°æ¯”æŸ±ç‹€åœ–\n",
    "    \n",
    "    Args:\n",
    "        results: è©•ä¼°çµæœå­—å…¸\n",
    "        save_path: å„²å­˜è·¯å¾‘\n",
    "    \"\"\"\n",
    "    # æº–å‚™æ•¸æ“š\n",
    "    model_names = [r['model_name'] for r in results.values()]\n",
    "    overall_accs = [r['overall_accuracy'] * 100 for r in results.values()]\n",
    "    \n",
    "    # æ”¶é›†åˆ†é¡æº–ç¢ºç‡\n",
    "    categories = list(list(results.values())[0]['category_accuracies'].keys())\n",
    "    category_data = {cat: [] for cat in categories}\n",
    "    \n",
    "    for result in results.values():\n",
    "        for cat in categories:\n",
    "            category_data[cat].append(result['category_accuracies'][cat] * 100)\n",
    "    \n",
    "    # å‰µå»ºåœ–è¡¨\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # å­åœ– 1: æ•´é«”æº–ç¢ºç‡\n",
    "    ax1 = axes[0]\n",
    "    bars1 = ax1.bar(model_names, overall_accs, color=['#3498db', '#e74c3c'], alpha=0.8, edgecolor='black')\n",
    "    ax1.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Overall Accuracy Comparison', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "    for bar, acc in zip(bars1, overall_accs):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{acc:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # å­åœ– 2: åˆ†é¡æº–ç¢ºç‡\n",
    "    ax2 = axes[1]\n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "    \n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    for i, (model_name, color) in enumerate(zip(model_names, colors)):\n",
    "        values = [category_data[cat][i] for cat in categories]\n",
    "        bars = ax2.bar(x + i*width, values, width, label=model_name, color=color, alpha=0.8, edgecolor='black')\n",
    "        \n",
    "        # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "        for bar, val in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{val:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Category-wise Accuracy Comparison', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax2.set_xticks(x + width / 2)\n",
    "    ax2.set_xticklabels(categories, rotation=15, ha='right')\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.legend(loc='upper right', framealpha=0.9)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… åœ–è¡¨å·²å„²å­˜: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ç¹ªè£½æ•´é«”å°æ¯”åœ–\n",
    "plot_overall_comparison(results, CHARTS_DIR / \"01_overall_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å­¸ç§‘è¡¨ç¾ç†±åŠ›åœ–\n",
    "\n",
    "ä½¿ç”¨ç†±åŠ›åœ–å±•ç¤ºæ‰€æœ‰å­¸ç§‘çš„è¡¨ç¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subject_heatmap(results: dict, save_path: Path = None):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½å­¸ç§‘è¡¨ç¾ç†±åŠ›åœ–\n",
    "    \n",
    "    Args:\n",
    "        results: è©•ä¼°çµæœå­—å…¸\n",
    "        save_path: å„²å­˜è·¯å¾‘\n",
    "    \"\"\"\n",
    "    # æº–å‚™æ•¸æ“š\n",
    "    model_names = [r['model_name'] for r in results.values()]\n",
    "    subjects = list(list(results.values())[0]['subject_results'][0].keys())\n",
    "    \n",
    "    # æ”¶é›†æ‰€æœ‰å­¸ç§‘çš„æº–ç¢ºç‡\n",
    "    heatmap_data = []\n",
    "    subject_names = []\n",
    "    \n",
    "    # ç²å–æ‰€æœ‰å­¸ç§‘\n",
    "    all_subjects = [sr['subject'] for sr in list(results.values())[0]['subject_results']]\n",
    "    \n",
    "    for subject in all_subjects:\n",
    "        row = []\n",
    "        for result in results.values():\n",
    "            # æ‰¾åˆ°å°æ‡‰å­¸ç§‘çš„æº–ç¢ºç‡\n",
    "            subject_result = next(\n",
    "                (sr for sr in result['subject_results'] if sr['subject'] == subject),\n",
    "                None\n",
    "            )\n",
    "            if subject_result:\n",
    "                row.append(subject_result['accuracy'] * 100)\n",
    "        \n",
    "        if row:\n",
    "            heatmap_data.append(row)\n",
    "            # ç°¡åŒ–å­¸ç§‘åç¨± (å¦‚æœå¤ªé•·)\n",
    "            display_name = subject.replace('_', ' ').title()\n",
    "            if len(display_name) > 30:\n",
    "                display_name = display_name[:27] + '...'\n",
    "            subject_names.append(display_name)\n",
    "    \n",
    "    # å‰µå»º DataFrame\n",
    "    df = pd.DataFrame(heatmap_data, columns=model_names, index=subject_names)\n",
    "    \n",
    "    # ç¹ªè£½ç†±åŠ›åœ–\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    sns.heatmap(\n",
    "        df,\n",
    "        annot=True,\n",
    "        fmt='.1f',\n",
    "        cmap='RdYlGn',\n",
    "        center=50,\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "        cbar_kws={'label': 'Accuracy (%)'},\n",
    "        linewidths=0.5,\n",
    "        linecolor='gray',\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Subject Performance Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Subject', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… åœ–è¡¨å·²å„²å­˜: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ç¹ªè£½ç†±åŠ›åœ–\n",
    "plot_subject_heatmap(results, CHARTS_DIR / \"02_subject_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. èƒ½åŠ›é›·é”åœ–\n",
    "\n",
    "ä½¿ç”¨é›·é”åœ–å±•ç¤ºæ¨¡å‹åœ¨ä¸åŒå­¸ç§‘é¡åˆ¥çš„å¤šç¶­åº¦èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_radar_chart(results: dict, save_path: Path = None):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½èƒ½åŠ›é›·é”åœ–\n",
    "    \n",
    "    Args:\n",
    "        results: è©•ä¼°çµæœå­—å…¸\n",
    "        save_path: å„²å­˜è·¯å¾‘\n",
    "    \"\"\"\n",
    "    # æº–å‚™æ•¸æ“š\n",
    "    categories = list(list(results.values())[0]['category_accuracies'].keys())\n",
    "    num_vars = len(categories)\n",
    "    \n",
    "    # è¨ˆç®—è§’åº¦\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # é–‰åˆåœ–å½¢\n",
    "    \n",
    "    # å‰µå»ºåœ–è¡¨\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    # é¡è‰²å’Œæ¨™è¨˜\n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "    markers = ['o', 's', '^', 'D']\n",
    "    \n",
    "    # ç¹ªè£½æ¯å€‹æ¨¡å‹\n",
    "    for i, (model_key, result) in enumerate(results.items()):\n",
    "        model_name = result['model_name']\n",
    "        values = [result['category_accuracies'][cat] * 100 for cat in categories]\n",
    "        values += values[:1]  # é–‰åˆåœ–å½¢\n",
    "        \n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=model_name, \n",
    "                color=colors[i % len(colors)], marker=markers[i % len(markers)], markersize=8)\n",
    "        ax.fill(angles, values, alpha=0.15, color=colors[i % len(colors)])\n",
    "    \n",
    "    # è¨­å®šæ¨™ç±¤\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories, fontsize=12)\n",
    "    \n",
    "    # è¨­å®š y è»¸\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_yticks([20, 40, 60, 80, 100])\n",
    "    ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'], fontsize=10)\n",
    "    ax.set_rlabel_position(0)\n",
    "    \n",
    "    # æ·»åŠ ç¶²æ ¼\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # æ¨™é¡Œå’Œåœ–ä¾‹\n",
    "    ax.set_title('Multi-Dimensional Capability Radar Chart', \n",
    "                 fontsize=16, fontweight='bold', pad=30)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11, framealpha=0.9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… åœ–è¡¨å·²å„²å­˜: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ç¹ªè£½é›·é”åœ–\n",
    "plot_radar_chart(results, CHARTS_DIR / \"03_radar_chart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å­¸ç§‘è¡¨ç¾è©³ç´°å°æ¯”\n",
    "\n",
    "ç¹ªè£½æ¯å€‹å­¸ç§‘çš„è©³ç´°å°æ¯”æŸ±ç‹€åœ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detailed_subject_comparison(results: dict, save_path: Path = None):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½å­¸ç§‘è©³ç´°å°æ¯”æŸ±ç‹€åœ–\n",
    "    \n",
    "    Args:\n",
    "        results: è©•ä¼°çµæœå­—å…¸\n",
    "        save_path: å„²å­˜è·¯å¾‘\n",
    "    \"\"\"\n",
    "    # æº–å‚™æ•¸æ“š\n",
    "    model_names = [r['model_name'] for r in results.values()]\n",
    "    all_subjects = [sr['subject'] for sr in list(results.values())[0]['subject_results']]\n",
    "    \n",
    "    # æ”¶é›†æ•¸æ“š\n",
    "    data = {model: [] for model in model_names}\n",
    "    subject_display_names = []\n",
    "    \n",
    "    for subject in all_subjects:\n",
    "        for model_name, result in zip(model_names, results.values()):\n",
    "            subject_result = next(\n",
    "                (sr for sr in result['subject_results'] if sr['subject'] == subject),\n",
    "                None\n",
    "            )\n",
    "            if subject_result:\n",
    "                data[model_name].append(subject_result['accuracy'] * 100)\n",
    "        \n",
    "        # ç°¡åŒ–é¡¯ç¤ºåç¨±\n",
    "        display_name = subject.replace('_', ' ').title()\n",
    "        if len(display_name) > 25:\n",
    "            display_name = display_name[:22] + '...'\n",
    "        subject_display_names.append(display_name)\n",
    "    \n",
    "    # å‰µå»ºåœ–è¡¨\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    x = np.arange(len(all_subjects))\n",
    "    width = 0.35\n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    \n",
    "    for i, (model_name, color) in enumerate(zip(model_names, colors)):\n",
    "        offset = width * (i - len(model_names)/2 + 0.5)\n",
    "        bars = ax.bar(x + offset, data[model_name], width, label=model_name, \n",
    "                     color=color, alpha=0.8, edgecolor='black')\n",
    "        \n",
    "        # æ·»åŠ æ•¸å€¼æ¨™ç±¤ (åªåœ¨è¼ƒé«˜çš„æŸ±å­ä¸Šé¡¯ç¤º)\n",
    "        for bar, val in zip(bars, data[model_name]):\n",
    "            if val > 30:  # åªåœ¨é«˜æ–¼ 30% æ™‚é¡¯ç¤º\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height - 3,\n",
    "                       f'{val:.0f}', ha='center', va='top', fontsize=8, color='white', fontweight='bold')\n",
    "    \n",
    "    # è¨­å®šæ¨™ç±¤å’Œæ¨™é¡Œ\n",
    "    ax.set_xlabel('Subject', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Detailed Subject-wise Performance Comparison', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(subject_display_names, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.legend(loc='upper right', framealpha=0.9)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… åœ–è¡¨å·²å„²å­˜: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ç¹ªè£½è©³ç´°å°æ¯”åœ–\n",
    "plot_detailed_subject_comparison(results, CHARTS_DIR / \"04_detailed_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. éŒ¯èª¤ç‡åˆ†æåœ–\n",
    "\n",
    "è¦–è¦ºåŒ–éŒ¯èª¤ç‡åˆ†ä½ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_analysis(results: dict, save_path: Path = None):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½éŒ¯èª¤ç‡åˆ†æåœ–\n",
    "    \n",
    "    Args:\n",
    "        results: è©•ä¼°çµæœå­—å…¸\n",
    "        save_path: å„²å­˜è·¯å¾‘\n",
    "    \"\"\"\n",
    "    # æº–å‚™æ•¸æ“š\n",
    "    model_names = [r['model_name'] for r in results.values()]\n",
    "    all_subjects = [sr['subject'] for sr in list(results.values())[0]['subject_results']]\n",
    "    \n",
    "    # æ”¶é›†éŒ¯èª¤ç‡æ•¸æ“š\n",
    "    error_data = {model: [] for model in model_names}\n",
    "    \n",
    "    for subject in all_subjects:\n",
    "        for model_name, result in zip(model_names, results.values()):\n",
    "            subject_result = next(\n",
    "                (sr for sr in result['subject_results'] if sr['subject'] == subject),\n",
    "                None\n",
    "            )\n",
    "            if subject_result:\n",
    "                error_rate = (1 - subject_result['accuracy']) * 100\n",
    "                error_data[model_name].append(error_rate)\n",
    "    \n",
    "    # å‰µå»ºåœ–è¡¨\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # å­åœ– 1: éŒ¯èª¤ç‡åˆ†ä½ˆ (ç®±å‹åœ–)\n",
    "    ax1 = axes[0]\n",
    "    positions = np.arange(len(model_names)) + 1\n",
    "    bp = ax1.boxplot(\n",
    "        [error_data[model] for model in model_names],\n",
    "        positions=positions,\n",
    "        labels=model_names,\n",
    "        patch_artist=True,\n",
    "        notch=True,\n",
    "        showmeans=True\n",
    "    )\n",
    "    \n",
    "    # è¨­å®šç®±å‹åœ–é¡è‰²\n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.6)\n",
    "    \n",
    "    ax1.set_ylabel('Error Rate (%)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Error Rate Distribution', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # å­åœ– 2: ç¸½éŒ¯èª¤æ•¸å°æ¯”\n",
    "    ax2 = axes[1]\n",
    "    total_errors = []\n",
    "    total_questions = []\n",
    "    \n",
    "    for result in results.values():\n",
    "        errors = sum(sr['total'] - sr['correct'] for sr in result['subject_results'])\n",
    "        total = sum(sr['total'] for sr in result['subject_results'])\n",
    "        total_errors.append(errors)\n",
    "        total_questions.append(total)\n",
    "    \n",
    "    bars = ax2.bar(model_names, total_errors, color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax2.set_ylabel('Number of Errors', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Total Error Count', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "    for bar, errors, total in zip(bars, total_errors, total_questions):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{errors}\\n({errors/total*100:.1f}%)', \n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… åœ–è¡¨å·²å„²å­˜: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ç¹ªè£½éŒ¯èª¤åˆ†æåœ–\n",
    "plot_error_analysis(results, CHARTS_DIR / \"05_error_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ç”Ÿæˆå®Œæ•´è©•ä¼°å ±å‘Š\n",
    "\n",
    "è‡ªå‹•ç”ŸæˆåŒ…å«æ‰€æœ‰åœ–è¡¨å’Œåˆ†æçš„ Markdown/HTML å ±å‘Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_report(results: dict, charts_dir: Path, output_file: Path):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆå®Œæ•´è©•ä¼°å ±å‘Š\n",
    "    \n",
    "    Args:\n",
    "        results: è©•ä¼°çµæœå­—å…¸\n",
    "        charts_dir: åœ–è¡¨ç›®éŒ„\n",
    "        output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        # å ±å‘Šæ¨™é¡Œ\n",
    "        f.write(\"# C-Eval æ¨¡å‹è©•ä¼°å®Œæ•´å ±å‘Š\\n\\n\")\n",
    "        f.write(f\"**ç”Ÿæˆæ™‚é–“**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        # 1. åŸ·è¡Œæ‘˜è¦\n",
    "        f.write(\"## 1. åŸ·è¡Œæ‘˜è¦\\n\\n\")\n",
    "        \n",
    "        model_names = [r['model_name'] for r in results.values()]\n",
    "        overall_accs = [r['overall_accuracy'] for r in results.values()]\n",
    "        \n",
    "        if len(results) >= 2:\n",
    "            best_idx = np.argmax(overall_accs)\n",
    "            f.write(f\"- **æœ€ä½³æ¨¡å‹**: {model_names[best_idx]} ({overall_accs[best_idx]:.2%})\\n\")\n",
    "            f.write(f\"- **æº–ç¢ºç‡å·®è·**: {(max(overall_accs) - min(overall_accs)):.2%}\\n\")\n",
    "        \n",
    "        f.write(f\"- **è©•ä¼°å­¸ç§‘æ•¸**: {len(list(results.values())[0]['subject_results'])}\\n\")\n",
    "        f.write(f\"- **ç¸½è©•ä¼°é¡Œæ•¸**: {sum(sr['total'] for sr in list(results.values())[0]['subject_results'])}\\n\\n\")\n",
    "        \n",
    "        # 2. æ•´é«”è¡¨ç¾\n",
    "        f.write(\"## 2. æ•´é«”è¡¨ç¾\\n\\n\")\n",
    "        f.write(\"### 2.1 æº–ç¢ºç‡å°æ¯”\\n\\n\")\n",
    "        f.write(\"![æ•´é«”å°æ¯”](./charts/01_overall_comparison.png)\\n\\n\")\n",
    "        \n",
    "        f.write(\"### 2.2 è©³ç´°çµ±è¨ˆ\\n\\n\")\n",
    "        f.write(\"| æ¨¡å‹ | æ•´é«”æº–ç¢ºç‡ | STEM | Humanities | Social Science |\\n\")\n",
    "        f.write(\"|------|-----------|------|------------|----------------|\\n\")\n",
    "        \n",
    "        for result in results.values():\n",
    "            model_name = result['model_name']\n",
    "            overall = result['overall_accuracy']\n",
    "            cats = result['category_accuracies']\n",
    "            f.write(f\"| {model_name} | {overall:.2%} | \")\n",
    "            f.write(f\"{cats.get('STEM', 0):.2%} | \")\n",
    "            f.write(f\"{cats.get('Humanities', 0):.2%} | \")\n",
    "            f.write(f\"{cats.get('Social Science', 0):.2%} |\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # 3. å­¸ç§‘è¡¨ç¾\n",
    "        f.write(\"## 3. å­¸ç§‘è¡¨ç¾åˆ†æ\\n\\n\")\n",
    "        f.write(\"### 3.1 å­¸ç§‘è¡¨ç¾ç†±åŠ›åœ–\\n\\n\")\n",
    "        f.write(\"![å­¸ç§‘ç†±åŠ›åœ–](./charts/02_subject_heatmap.png)\\n\\n\")\n",
    "        \n",
    "        f.write(\"### 3.2 è©³ç´°å­¸ç§‘å°æ¯”\\n\\n\")\n",
    "        f.write(\"![è©³ç´°å°æ¯”](./charts/04_detailed_comparison.png)\\n\\n\")\n",
    "        \n",
    "        # 4. èƒ½åŠ›é›·é”åœ–\n",
    "        f.write(\"## 4. å¤šç¶­åº¦èƒ½åŠ›åˆ†æ\\n\\n\")\n",
    "        f.write(\"![èƒ½åŠ›é›·é”åœ–](./charts/03_radar_chart.png)\\n\\n\")\n",
    "        \n",
    "        # 5. éŒ¯èª¤åˆ†æ\n",
    "        f.write(\"## 5. éŒ¯èª¤åˆ†æ\\n\\n\")\n",
    "        f.write(\"![éŒ¯èª¤åˆ†æ](./charts/05_error_analysis.png)\\n\\n\")\n",
    "        \n",
    "        f.write(\"### 5.1 éŒ¯èª¤çµ±è¨ˆ\\n\\n\")\n",
    "        f.write(\"| æ¨¡å‹ | ç¸½éŒ¯èª¤æ•¸ | éŒ¯èª¤ç‡ | æœ€æ˜“éŒ¯å­¸ç§‘ |\\n\")\n",
    "        f.write(\"|------|----------|--------|-----------|\\n\")\n",
    "        \n",
    "        for result in results.values():\n",
    "            model_name = result['model_name']\n",
    "            total_errors = sum(sr['total'] - sr['correct'] for sr in result['subject_results'])\n",
    "            total = sum(sr['total'] for sr in result['subject_results'])\n",
    "            error_rate = total_errors / total\n",
    "            \n",
    "            # æ‰¾å‡ºéŒ¯èª¤ç‡æœ€é«˜çš„å­¸ç§‘\n",
    "            worst_subject = min(result['subject_results'], key=lambda x: x['accuracy'])\n",
    "            \n",
    "            f.write(f\"| {model_name} | {total_errors} | {error_rate:.2%} | \")\n",
    "            f.write(f\"{worst_subject['subject']} ({worst_subject['accuracy']:.2%}) |\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # 6. é—œéµç™¼ç¾\n",
    "        f.write(\"## 6. é—œéµç™¼ç¾èˆ‡å»ºè­°\\n\\n\")\n",
    "        f.write(\"### 6.1 ä¸»è¦ç™¼ç¾\\n\\n\")\n",
    "        \n",
    "        # è¨ˆç®—ä¸€äº›é—œéµæŒ‡æ¨™\n",
    "        if len(results) >= 2:\n",
    "            model1, model2 = list(results.values())\n",
    "            \n",
    "            # æ‰¾å‡ºå·®ç•°æœ€å¤§çš„å­¸ç§‘\n",
    "            max_diff = 0\n",
    "            max_diff_subject = \"\"\n",
    "            \n",
    "            for sr1 in model1['subject_results']:\n",
    "                sr2 = next((sr for sr in model2['subject_results'] if sr['subject'] == sr1['subject']), None)\n",
    "                if sr2:\n",
    "                    diff = abs(sr1['accuracy'] - sr2['accuracy'])\n",
    "                    if diff > max_diff:\n",
    "                        max_diff = diff\n",
    "                        max_diff_subject = sr1['subject']\n",
    "            \n",
    "            f.write(f\"1. **æ•´é«”è¡¨ç¾**: {model_names[best_idx]} ä»¥ {overall_accs[best_idx]:.2%} çš„æº–ç¢ºç‡é ˜å…ˆ\\n\")\n",
    "            f.write(f\"2. **æœ€å¤§å·®ç•°å­¸ç§‘**: {max_diff_subject} (å·®è· {max_diff:.2%})\\n\")\n",
    "            \n",
    "            # åˆ†æå„é¡åˆ¥\n",
    "            for category in ['STEM', 'Humanities', 'Social Science']:\n",
    "                cat1 = model1['category_accuracies'].get(category, 0)\n",
    "                cat2 = model2['category_accuracies'].get(category, 0)\n",
    "                better_model = model1['model_name'] if cat1 > cat2 else model2['model_name']\n",
    "                f.write(f\"3. **{category}**: {better_model} è¡¨ç¾è¼ƒä½³ ({max(cat1, cat2):.2%})\\n\")\n",
    "        \n",
    "        f.write(\"\\n### 6.2 æ”¹é€²å»ºè­°\\n\\n\")\n",
    "        f.write(\"1. **æ•¸æ“šå¢å¼·**: é‡å°éŒ¯èª¤ç‡é«˜çš„å­¸ç§‘å¢åŠ è¨“ç·´æ•¸æ“š\\n\")\n",
    "        f.write(\"2. **æ¨¡å‹å¾®èª¿**: è€ƒæ…®é‡å°å¼±é …å­¸ç§‘é€²è¡Œå°ˆé–€å¾®èª¿\\n\")\n",
    "        f.write(\"3. **é›†æˆæ–¹æ³•**: å¯ä»¥è€ƒæ…®çµåˆå…©å€‹æ¨¡å‹çš„å„ªå‹¢\\n\")\n",
    "        f.write(\"4. **æç¤ºå·¥ç¨‹**: å„ªåŒ–æç¤ºè©ä»¥æé«˜ç‰¹å®šå­¸ç§‘çš„è¡¨ç¾\\n\\n\")\n",
    "        \n",
    "        # 7. é™„éŒ„\n",
    "        f.write(\"## 7. é™„éŒ„\\n\\n\")\n",
    "        f.write(\"### 7.1 è©³ç´°æ•¸æ“š\\n\\n\")\n",
    "        f.write(\"å®Œæ•´çš„è©•ä¼°æ•¸æ“šå’Œåˆ†æçµæœå¯åœ¨ä»¥ä¸‹ç›®éŒ„æ‰¾åˆ°:\\n\\n\")\n",
    "        f.write(\"- è©•ä¼°çµæœ: `./results/`\\n\")\n",
    "        f.write(\"- åˆ†ææ•¸æ“š: `./analysis/`\\n\")\n",
    "        f.write(\"- åœ–è¡¨æª”æ¡ˆ: `./charts/`\\n\\n\")\n",
    "        \n",
    "        f.write(\"---\\n\\n\")\n",
    "        f.write(\"*æœ¬å ±å‘Šç”± Lab 4.1 - OpenCompass è©•ä¼°å¯¦æˆ°è‡ªå‹•ç”Ÿæˆ*\\n\")\n",
    "    \n",
    "    print(f\"\\nâœ… è©•ä¼°å ±å‘Šå·²ç”Ÿæˆ: {output_file}\")\n",
    "\n",
    "\n",
    "# ç”Ÿæˆå ±å‘Š\n",
    "report_file = Path(\"./EVALUATION_REPORT.md\")\n",
    "generate_evaluation_report(results, CHARTS_DIR, report_file)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"å ±å‘Šç”Ÿæˆå®Œæˆ!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç”Ÿæˆ HTML å ±å‘Š (å¯é¸)\n",
    "\n",
    "å°‡ Markdown å ±å‘Šè½‰æ›ç‚º HTML æ ¼å¼ä»¥ä¾¿ç€è¦½å™¨æŸ¥çœ‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_to_html(md_file: Path, html_file: Path):\n",
    "    \"\"\"\n",
    "    å°‡ Markdown è½‰æ›ç‚º HTML\n",
    "    \n",
    "    Args:\n",
    "        md_file: Markdown æª”æ¡ˆè·¯å¾‘\n",
    "        html_file: HTML æª”æ¡ˆè·¯å¾‘\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import markdown\n",
    "        \n",
    "        # è®€å– Markdown\n",
    "        with open(md_file, 'r', encoding='utf-8') as f:\n",
    "            md_content = f.read()\n",
    "        \n",
    "        # è½‰æ›ç‚º HTML\n",
    "        html_content = markdown.markdown(\n",
    "            md_content,\n",
    "            extensions=['tables', 'fenced_code', 'codehilite']\n",
    "        )\n",
    "        \n",
    "        # æ·»åŠ  HTML æ¡†æ¶å’Œæ¨£å¼\n",
    "        full_html = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"zh-TW\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>C-Eval è©•ä¼°å ±å‘Š</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            max-width: 1200px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            background-color: #f5f5f5;\n",
    "        }}\n",
    "        h1, h2, h3 {{\n",
    "            color: #333;\n",
    "            border-bottom: 2px solid #3498db;\n",
    "            padding-bottom: 10px;\n",
    "        }}\n",
    "        table {{\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "            margin: 20px 0;\n",
    "            background-color: white;\n",
    "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        th, td {{\n",
    "            border: 1px solid #ddd;\n",
    "            padding: 12px;\n",
    "            text-align: left;\n",
    "        }}\n",
    "        th {{\n",
    "            background-color: #3498db;\n",
    "            color: white;\n",
    "        }}\n",
    "        tr:nth-child(even) {{\n",
    "            background-color: #f9f9f9;\n",
    "        }}\n",
    "        img {{\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "            display: block;\n",
    "            margin: 20px auto;\n",
    "            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "            border-radius: 8px;\n",
    "        }}\n",
    "        code {{\n",
    "            background-color: #f4f4f4;\n",
    "            padding: 2px 6px;\n",
    "            border-radius: 3px;\n",
    "            font-family: 'Courier New', monospace;\n",
    "        }}\n",
    "        hr {{\n",
    "            border: none;\n",
    "            border-top: 2px solid #3498db;\n",
    "            margin: 40px 0;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    {html_content}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "        \n",
    "        # å¯«å…¥ HTML æª”æ¡ˆ\n",
    "        with open(html_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(full_html)\n",
    "        \n",
    "        print(f\"âœ… HTML å ±å‘Šå·²ç”Ÿæˆ: {html_file}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"âš ï¸  markdown å¥—ä»¶æœªå®‰è£,è·³é HTML ç”Ÿæˆ\")\n",
    "        print(\"   å®‰è£æ–¹å¼: pip install markdown\")\n",
    "\n",
    "\n",
    "# ç”Ÿæˆ HTML å ±å‘Š\n",
    "html_file = Path(\"./EVALUATION_REPORT.html\")\n",
    "markdown_to_html(report_file, html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. æª”æ¡ˆç¸½çµ\n",
    "\n",
    "åˆ—å‡ºæ‰€æœ‰ç”Ÿæˆçš„æª”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ç”Ÿæˆæª”æ¡ˆç¸½çµ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ“Š åœ–è¡¨æª”æ¡ˆ:\")\n",
    "chart_files = sorted(CHARTS_DIR.glob(\"*.png\"))\n",
    "for i, chart_file in enumerate(chart_files, 1):\n",
    "    size = chart_file.stat().st_size / 1024  # KB\n",
    "    print(f\"  {i}. {chart_file.name} ({size:.1f} KB)\")\n",
    "\n",
    "print(\"\\nğŸ“„ å ±å‘Šæª”æ¡ˆ:\")\n",
    "report_files = [\n",
    "    Path(\"./EVALUATION_REPORT.md\"),\n",
    "    Path(\"./EVALUATION_REPORT.html\")\n",
    "]\n",
    "for report in report_files:\n",
    "    if report.exists():\n",
    "        size = report.stat().st_size / 1024  # KB\n",
    "        print(f\"  - {report.name} ({size:.1f} KB)\")\n",
    "\n",
    "print(\"\\nğŸ“ å…¶ä»–è³‡æ–™:\")\n",
    "print(f\"  - è©•ä¼°çµæœ: {RESULTS_DIR}\")\n",
    "print(f\"  - åˆ†ææ•¸æ“š: {ANALYSIS_DIR}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… æ‰€æœ‰è¦–è¦ºåŒ–å’Œå ±å‘Šç”Ÿæˆå®Œæˆ!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ’¡ æç¤º:\")\n",
    "print(\"  - ä½¿ç”¨ç€è¦½å™¨é–‹å•Ÿ EVALUATION_REPORT.html æŸ¥çœ‹å®Œæ•´å ±å‘Š\")\n",
    "print(\"  - æ‰€æœ‰åœ–è¡¨å·²å„²å­˜ç‚ºé«˜è§£æåº¦ PNG (300 DPI)\")\n",
    "print(\"  - å¯ç›´æ¥ä½¿ç”¨é€™äº›åœ–è¡¨æ–¼è«–æ–‡æˆ–ç°¡å ±ä¸­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ç¸½çµ\n",
    "\n",
    "åœ¨æœ¬ notebook ä¸­,æˆ‘å€‘å®Œæˆäº†:\n",
    "\n",
    "1. âœ… æ•´é«”è¡¨ç¾å°æ¯”æŸ±ç‹€åœ–\n",
    "2. âœ… å­¸ç§‘è¡¨ç¾ç†±åŠ›åœ–\n",
    "3. âœ… å¤šç¶­åº¦èƒ½åŠ›é›·é”åœ–\n",
    "4. âœ… å­¸ç§‘è©³ç´°å°æ¯”åœ–\n",
    "5. âœ… éŒ¯èª¤ç‡åˆ†æåœ–\n",
    "6. âœ… å®Œæ•´è©•ä¼°å ±å‘Š (Markdown/HTML)\n",
    "7. âœ… æ‰€æœ‰åœ–è¡¨åŒ¯å‡ºç‚º PNG æª”æ¡ˆ\n",
    "\n",
    "### Lab 4.1 å®Œæ•´æµç¨‹å›é¡§\n",
    "\n",
    "1. **01-Setup.ipynb**: ç’°å¢ƒé…ç½®èˆ‡æ•¸æ“šæº–å‚™\n",
    "2. **02-Evaluate.ipynb**: åŸ·è¡Œæ¨¡å‹è©•ä¼°\n",
    "3. **03-Analyze.ipynb**: æ·±å…¥çµæœåˆ†æ\n",
    "4. **04-Visualize_and_Report.ipynb**: è¦–è¦ºåŒ–èˆ‡å ±å‘Šç”Ÿæˆ âœ…\n",
    "\n",
    "---\n",
    "\n",
    "**ä¸‹ä¸€æ­¥å»ºè­°**:\n",
    "- å˜—è©¦è©•ä¼°æ›´å¤šæ¨¡å‹ (Mistral, Gemma ç­‰)\n",
    "- ä½¿ç”¨å®Œæ•´çš„ C-Eval æ•¸æ“šé›† (52 å€‹å­¸ç§‘)\n",
    "- æ¢ç´¢å…¶ä»–è©•ä¼°åŸºæº– (MMLU, AGIEval ç­‰)\n",
    "- å¯¦é©—ä¸åŒçš„æç¤ºå·¥ç¨‹ç­–ç•¥\n",
    "- åˆ†ææ¨¡å‹åœ¨ä¸åŒé›£åº¦é¡Œç›®ä¸Šçš„è¡¨ç¾\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
