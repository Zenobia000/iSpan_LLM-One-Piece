{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1: LoRA & QLoRA - Fine-Tuning a Llama-2 Model\n",
        "---\n",
        "## Notebook 3: Inference\n",
        "\n",
        "**Goal:** In this notebook, you will learn how to load your fine-tuned PEFT adapter and use it for inference.\n",
        "\n",
        "**You will learn to:**\n",
        "-   Reload the quantized base model.\n",
        "-   Use `peft.PeftModel` to load the LoRA adapter weights from your training checkpoint.\n",
        "-   Prepare a prompt using the tokenizer.\n",
        "-   Use the `generate()` method of the fine-tuned model to get a response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Reload Model and Adapter\n",
        "\n",
        "To perform inference, we first need to load the base model again in the exact same configuration as we did for training (i.e., with 4-bit quantization). Then, we'll load the LoRA adapter on top of it.\n",
        "\n",
        "#### Key Hugging Face `peft` Components:\n",
        "\n",
        "-   `peft.PeftModel`: This class is used to work with a model that has PEFT adapters.\n",
        "    -   `from_pretrained()`: This is the key method. It takes the **base model** as the first argument and the **path to the saved adapter** as the second argument. It then correctly loads the adapter weights and attaches them to the target modules of the base model.\n",
        "\n",
        "We need to find the latest checkpoint saved by the `Trainer` in our output directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e3cd79c22b540ae8c1a2fb13afb6b36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading adapter from: ./lora-llama2-7b-guanaco/checkpoint-63\n",
            "✅ Inference model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import os\n",
        "\n",
        "# --- Base Model and Tokenizer Loading ---\n",
        "# Same configuration as in the training notebook\n",
        "model_id = \"NousResearch/Llama-2-7b-hf\"\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# --- Load PEFT Adapter ---\n",
        "# Find the latest checkpoint from the training output directory\n",
        "output_dir = \"./lora-llama2-7b-guanaco\"\n",
        "# Find the latest checkpoint directory\n",
        "latest_checkpoint = max(\n",
        "    [os.path.join(output_dir, d) for d in os.listdir(output_dir) if d.startswith(\"checkpoint-\")],\n",
        "    key=os.path.getmtime\n",
        ")\n",
        "print(f\"Loading adapter from: {latest_checkpoint}\")\n",
        "\n",
        "# Load the PEFT model\n",
        "inference_model = PeftModel.from_pretrained(base_model, latest_checkpoint)\n",
        "\n",
        "print(\"✅ Inference model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Perform Inference\n",
        "\n",
        "Now we can use our fine-tuned `inference_model` to generate text. The process is standard for Hugging Face `transformers` models.\n",
        "\n",
        "#### Key Hugging Face `transformers` Components:\n",
        "\n",
        "-   `tokenizer()`: The tokenizer converts our prompt string into a format the model can understand (i.e., a sequence of token IDs). `return_tensors=\"pt\"` ensures the output is a PyTorch tensor. We also move it to the GPU with `.cuda()`.\n",
        "-   `model.generate()`: This is the core method for text generation.\n",
        "    -   It takes the `input_ids` from the tokenizer.\n",
        "    -   `max_new_tokens`: Sets the maximum length of the generated response.\n",
        "    -   `do_sample=True`: Enables sampling-based generation (like top-k or top-p), which usually produces more creative and less repetitive text than greedy decoding.\n",
        "    -   `top_k`: In top-k sampling, the model considers only the `k` most likely next tokens at each step.\n",
        "\n",
        "We will use a prompt that is similar in style to the `guanaco` dataset to see how well our fine-tuning worked.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Prompt ---\n",
            "Could you please tell me about the Yushan National Park in Taiwan?\n",
            "\n",
            "--- Generated Response ---\n",
            "Could you please tell me about the Yushan National Park in Taiwan?\n",
            "\n",
            "I'm planning a trip to Taiwan in a few months and I'd like to know more about the Yushan National Park. Could you please tell me about the park's location, size, and main attractions? What are the best ways to get there?\n",
            "\n",
            "I'm also interested in learning about the park's history and the native flora and fauna that can be found there.\n",
            "\n",
            "Thank you for your time and consideration.\n",
            "\n",
            "\n",
            "\n",
            "### About Yushan National Park\n",
            "\n",
            "Yushan National Park is a protected area located in Taiwan. It is one of the most popular national parks in Taiwan and is known for its beautiful scenery, hiking trails, and diverse wildlife.\n",
            "\n",
            "The park is located in the southern part of Taiwan, near the city of Tainan. It covers an area of about 200 square kilometers and is home to a variety of flora and fauna, including rare species of birds, mammals, and reptiles.\n",
            "\n",
            "The main attractions of the park include the Yushan Peak, which is the highest mountain in Taiwan, and the Jade Mountain, which is a popular hiking destination. The park also features several waterfalls, including the Seven-Step Waterfall and the Shuiyang Waterfall.\n",
            "\n",
            "There are several ways to get to Yushan National Park. The most popular option is to take a bus or a taxi from Tainan to the park's entrance. There are also several tour companies that offer guided tours to the park.\n",
            "\n",
            "The park is open all year round, but the best time to visit is during the spring and autumn seasons when the weather is mild and the flowers are in bloom.\n",
            "\n",
            "The park's history dates back to the 1930s when it was first established as a national park. Over the years, it has undergone several renovations and improvements to make it more accessible to visitors.\n",
            "\n",
            "The park's native flora and fauna include a variety of species of birds, mammals, and reptiles, many of which are endangered or threatened. The park is also home to several rare species of plants, including the Taiwanese endemic species of orchids and bamboo.\n",
            "\n",
            "In conclusion, Yushan National\n"
          ]
        }
      ],
      "source": [
        "# Prepare the prompt\n",
        "prompt = \"Could you please tell me about the Yushan National Park in Taiwan?\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
        "\n",
        "# Generate text\n",
        "# We use a context manager to disable gradient calculations for efficiency\n",
        "with torch.no_grad():\n",
        "    outputs = inference_model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=500,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"--- Prompt ---\")\n",
        "print(prompt)\n",
        "print(\"\\n--- Generated Response ---\")\n",
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Could you please tell me about the Yushan National Park in Taiwan?\\n\\nI'm planning a trip to Taiwan in a few months and I'd like to know more about the Yushan National Park. Could you please tell me about the park's location, size, and main attractions? What are the best ways to get there?\\n\\nI'm also interested in learning about the park's history and the native flora and fauna that can be found there.\\n\\nThank you for your time and consideration.\\n\\n\\n\\n### About Yushan National Park\\n\\nYushan National Park is a protected area located in Taiwan. It is one of the most popular national parks in Taiwan and is known for its beautiful scenery, hiking trails, and diverse wildlife.\\n\\nThe park is located in the southern part of Taiwan, near the city of Tainan. It covers an area of about 200 square kilometers and is home to a variety of flora and fauna, including rare species of birds, mammals, and reptiles.\\n\\nThe main attractions of the park include the Yushan Peak, which is the highest mountain in Taiwan, and the Jade Mountain, which is a popular hiking destination. The park also features several waterfalls, including the Seven-Step Waterfall and the Shuiyang Waterfall.\\n\\nThere are several ways to get to Yushan National Park. The most popular option is to take a bus or a taxi from Tainan to the park's entrance. There are also several tour companies that offer guided tours to the park.\\n\\nThe park is open all year round, but the best time to visit is during the spring and autumn seasons when the weather is mild and the flowers are in bloom.\\n\\nThe park's history dates back to the 1930s when it was first established as a national park. Over the years, it has undergone several renovations and improvements to make it more accessible to visitors.\\n\\nThe park's native flora and fauna include a variety of species of birds, mammals, and reptiles, many of which are endangered or threatened. The park is also home to several rare species of plants, including the Taiwanese endemic species of orchids and bamboo.\\n\\nIn conclusion, Yushan National\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (Optional) Compare with the Base Model\n",
        "\n",
        "To truly appreciate the effect of fine-tuning, you can run the same prompt through the `base_model` (without the LoRA adapter) and compare the responses. You will likely see that the fine-tuned model's response is more detailed, better formatted, or more aligned with the instruction-following style of the `guanaco` dataset.\n",
        "\n",
        "---\n",
        "Next, in the final notebook `04-Merge_and_Deploy.ipynb`, we will see how to merge the adapter weights back into the model for easy deployment.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "LLM Course (Poetry)",
      "language": "python",
      "name": "llm-course-poetry"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
