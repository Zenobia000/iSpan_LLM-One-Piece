# Lab-1.3: ä½¿ç”¨ DeepSpeed å¾®èª¿ Alpaca æ¨¡å‹
## Finetune Alpaca with DeepSpeed

---

## âš ï¸ ç’°å¢ƒé™åˆ¶è²æ˜

æœ¬å¯¦é©—å®¤çš„**å®Œæ•´å¯¦é©—**éœ€è¦**å¤šGPUç’°å¢ƒ**æ‰èƒ½å±•ç¤º DeepSpeed çš„å…¨éƒ¨åŠŸèƒ½ï¼Œç›®å‰å°ˆæ¡ˆé–‹ç™¼ç’°å¢ƒç‚ºå–®GPUï¼Œå› æ­¤**éƒ¨åˆ†é€²éšå…§å®¹æš«æœªé–‹ç™¼**ã€‚

### ç‚ºä½•éœ€è¦å¤šGPU?
- **DeepSpeed ZeRO-3** çš„æ ¸å¿ƒå„ªå‹¢åœ¨æ–¼è·¨GPUçš„è¨˜æ†¶é«”å„ªåŒ–
- **å¤šGPUæ€§èƒ½å°æ¯”**éœ€è¦çœŸå¯¦çš„åˆ†æ•£å¼ç’°å¢ƒ
- **3Då¹³è¡ŒåŒ–** (æ•¸æ“š+å¼µé‡+æµæ°´ç·š) éœ€è¦å¤šGPUå”ä½œ

### å–®GPUå¯ç”¨åŠŸèƒ½ âœ…
- DeepSpeed ZeRO-2 (å„ªåŒ–å™¨ç‹€æ…‹ + æ¢¯åº¦åˆ†ç‰‡)
- æ··åˆç²¾åº¦è¨“ç·´
- æ¢¯åº¦ç´¯ç©èˆ‡æª¢æŸ¥é»
- åŸºç¤é…ç½®èˆ‡èª¿å„ª

---

## ğŸ“š å¯¦é©—å®¤æ¦‚è¿°

### å­¸ç¿’ç›®æ¨™
é€šéæœ¬å¯¦é©—å®¤ï¼Œæ‚¨å°‡å­¸ç¿’å¦‚ä½•ä½¿ç”¨ **DeepSpeed** æ¡†æ¶é«˜æ•ˆå¾®èª¿å¤§å‹èªè¨€æ¨¡å‹ã€‚å³ä½¿åœ¨å–®GPUç’°å¢ƒï¼Œæ‚¨ä¹Ÿèƒ½æŒæ¡ DeepSpeed çš„æ ¸å¿ƒæ¦‚å¿µèˆ‡é…ç½®æŠ€å·§ã€‚

### æŠ€è¡“æ£§
- **DeepSpeed**: å¾®è»Ÿé–‹æºçš„åˆ†æ•£å¼è¨“ç·´æ¡†æ¶
- **ZeRO (Zero Redundancy Optimizer)**: è¨˜æ†¶é«”å„ªåŒ–æ ¸å¿ƒæŠ€è¡“
- **Alpaca æ•¸æ“šé›†**: Stanford çš„æŒ‡ä»¤å¾®èª¿æ•¸æ“šé›†
- **Llama-2-7B**: Meta çš„é–‹æºåŸºç¤æ¨¡å‹

---

## ğŸ¯ DeepSpeed æ ¸å¿ƒæŠ€è¡“

### ZeRO å„ªåŒ–å™¨ (Zero Redundancy Optimizer)

DeepSpeed çš„æ ¸å¿ƒå‰µæ–°æ˜¯ **ZeRO**ï¼Œé€šéæ¶ˆé™¤è¨˜æ†¶é«”å†—é¤˜ä¾†å¯¦ç¾å¤§æ¨¡å‹è¨“ç·´ã€‚

#### ZeRO ä¸‰å€‹éšæ®µå°æ¯”

| Stage | å„ªåŒ–å…§å®¹ | è¨˜æ†¶é«”ç¯€çœ | é€šè¨Šé–‹éŠ· | å–®GPUå¯ç”¨ |
|-------|---------|-----------|---------|----------|
| **ZeRO-1** | å„ªåŒ–å™¨ç‹€æ…‹åˆ†ç‰‡ | 4x | 1.5x | âœ… æ˜¯ |
| **ZeRO-2** | + æ¢¯åº¦åˆ†ç‰‡ | 8x | 1.5x | âœ… æ˜¯ |
| **ZeRO-3** | + åƒæ•¸åˆ†ç‰‡ | Nå€ (N=GPUæ•¸) | 1.5x | âš ï¸ å¤šGPUæ›´å„ª |

#### è¨˜æ†¶é«”å ç”¨åˆ†æ
æ¨™æº–è¨“ç·´ (FP16 + Adam):
```
ç¸½è¨˜æ†¶é«” = æ¨¡å‹åƒæ•¸ + æ¢¯åº¦ + å„ªåŒ–å™¨ç‹€æ…‹
         = 2P + 2P + 12P = 16P

å…¶ä¸­ P = åƒæ•¸é‡
```

ZeRO-2 å„ªåŒ–å¾Œ (Nå€‹GPU):
```
æ¯GPUè¨˜æ†¶é«” = 2P + (2P + 12P) / N
            â‰ˆ 2P (ç•¶Nè¼ƒå¤§æ™‚)
```

---

## ğŸ”§ DeepSpeed é…ç½®è©³è§£

### é…ç½®æ–‡ä»¶çµæ§‹

DeepSpeed ä½¿ç”¨ JSON é…ç½®æ–‡ä»¶æ§åˆ¶è¨“ç·´è¡Œç‚º:

#### åŸºç¤é…ç½® (ds_config_zero2.json)
```json
{
  "train_batch_size": 32,
  "train_micro_batch_size_per_gpu": 1,
  "gradient_accumulation_steps": 32,

  "optimizer": {
    "type": "AdamW",
    "params": {
      "lr": 2e-5,
      "betas": [0.9, 0.999],
      "eps": 1e-8,
      "weight_decay": 0.01
    }
  },

  "scheduler": {
    "type": "WarmupDecayLR",
    "params": {
      "warmup_min_lr": 0,
      "warmup_max_lr": 2e-5,
      "warmup_num_steps": 100,
      "total_num_steps": 1000
    }
  },

  "fp16": {
    "enabled": true,
    "loss_scale": 0,
    "loss_scale_window": 1000,
    "hysteresis": 2,
    "min_loss_scale": 1
  },

  "zero_optimization": {
    "stage": 2,
    "offload_optimizer": {
      "device": "cpu",
      "pin_memory": true
    },
    "allgather_partitions": true,
    "allgather_bucket_size": 2e8,
    "reduce_scatter": true,
    "reduce_bucket_size": 2e8,
    "overlap_comm": true,
    "contiguous_gradients": true
  },

  "gradient_clipping": 1.0,
  "wall_clock_breakdown": false
}
```

### é…ç½®åƒæ•¸è©³è§£

#### 1. æ‰¹æ¬¡å¤§å°é…ç½®
```json
"train_batch_size": 32,              // å…¨å±€æœ‰æ•ˆæ‰¹æ¬¡
"train_micro_batch_size_per_gpu": 1, // æ¯GPUæ¯æ¬¡è™•ç†
"gradient_accumulation_steps": 32    // æ¢¯åº¦ç´¯ç©æ¬¡æ•¸
```
**é—œä¿‚**: `train_batch_size = micro_batch_size Ã— accumulation Ã— GPUæ•¸é‡`

#### 2. ZeRO Stage 2 é…ç½®
```json
"zero_optimization": {
  "stage": 2,                    // ZeRO-2: å„ªåŒ–å™¨ + æ¢¯åº¦åˆ†ç‰‡
  "offload_optimizer": {
    "device": "cpu",             // å°‡å„ªåŒ–å™¨ç‹€æ…‹å¸è¼‰åˆ°CPU
    "pin_memory": true           // ä½¿ç”¨å›ºå®šè¨˜æ†¶é«”åŠ é€Ÿå‚³è¼¸
  },
  "overlap_comm": true,          // é€šè¨Šèˆ‡è¨ˆç®—é‡ç–Š
  "contiguous_gradients": true   // æ¢¯åº¦é€£çºŒå„²å­˜
}
```

#### 3. æ··åˆç²¾åº¦é…ç½®
```json
"fp16": {
  "enabled": true,               // å•Ÿç”¨FP16è¨“ç·´
  "loss_scale": 0,               // å‹•æ…‹æå¤±ç¸®æ”¾ (0=è‡ªå‹•)
  "loss_scale_window": 1000,     // æå¤±ç¸®æ”¾èª¿æ•´çª—å£
  "min_loss_scale": 1            // æœ€å°æå¤±ç¸®æ”¾å€¼
}
```

---

## ğŸ“– ç†è«–å­¸ç¿’ (å®Œæ•´å¯ç”¨) âœ…

### ç›¸é—œç†è«–æ–‡ä»¶
è«‹åƒé–±ä»¥ä¸‹å®Œæ•´çš„ç†è«–æ•™å­¸:

1. **`01-Theory/1.2-Distributed_Training.md`** ç¬¬3ç« : DeepSpeed æ¡†æ¶
   - DeepSpeed æ¶æ§‹èˆ‡è¨­è¨ˆå“²å­¸
   - ZeRO-1/2/3 è©³ç´°åŸç†
   - 3D å¹³è¡ŒåŒ–ç­–ç•¥
   - é…ç½®æœ€ä½³å¯¦è¸

2. **`01-Theory/1.3-Optimization_and_Alignment.md`** ç›¸é—œç« ç¯€
   - æ··åˆç²¾åº¦è¨“ç·´
   - æ¢¯åº¦ç´¯ç©èˆ‡æª¢æŸ¥é»
   - è¨˜æ†¶é«”å„ªåŒ–æŠ€è¡“

### æ ¸å¿ƒä»£ç¢¼ç¯„ä¾‹ (ä¾†è‡ªç†è«–æ–‡ä»¶)

#### DeepSpeed åˆå§‹åŒ–
```python
import deepspeed
from transformers import AutoModelForCausalLM, AutoTokenizer

# è¼‰å…¥æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")
tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")

# DeepSpeed åˆå§‹åŒ–
model_engine, optimizer, _, _ = deepspeed.initialize(
    model=model,
    config="ds_config_zero2.json"
)

# è¨“ç·´å¾ªç’°
for batch in dataloader:
    inputs = tokenizer(batch["text"], return_tensors="pt",
                      padding=True, truncation=True)
    inputs = {k: v.to(model_engine.device) for k, v in inputs.items()}

    outputs = model_engine(**inputs, labels=inputs["input_ids"])
    loss = outputs.loss

    model_engine.backward(loss)
    model_engine.step()
```

#### å–®GPU DeepSpeed è¨“ç·´
```bash
# å–®GPUè¨“ç·´ (ä½¿ç”¨ ZeRO-2)
deepspeed train.py --deepspeed ds_config_zero2.json

# å¤šGPUè¨“ç·´ (ä½¿ç”¨ ZeRO-3)
deepspeed --num_gpus=4 train.py --deepspeed ds_config_zero3.json
```

---

## ğŸ“ å­¸ç¿’è·¯å¾‘

### éšæ®µ 1: ç†è«–ç†è§£ âœ… (å–®GPUå¯å®Œæˆ)
- [x] é–±è®€ `1.2-Distributed_Training.md` ç¬¬3ç« 
- [x] ç†è§£ ZeRO çš„ä¸‰å€‹éšæ®µåŸç†
- [x] æŒæ¡ DeepSpeed é…ç½®æ–‡ä»¶çµæ§‹
- [x] ç†è§£è¨˜æ†¶é«”å„ªåŒ–ç­–ç•¥

### éšæ®µ 2: é…ç½®å¯¦è¸ âœ… (å–®GPUå¯å®Œæˆ)
- [x] åˆ†æä¸åŒ ZeRO Stage é…ç½®æ–‡ä»¶
- [x] ç†è§£æ‰¹æ¬¡å¤§å°èˆ‡æ¢¯åº¦ç´¯ç©é—œä¿‚
- [x] å­¸ç¿’æ··åˆç²¾åº¦é…ç½®åƒæ•¸
- [x] æŒæ¡å„ªåŒ–å™¨å¸è¼‰ç­–ç•¥

### éšæ®µ 3: å–®GPUå¯¦é©— ğŸŸ¡ (éƒ¨åˆ†å¯å®Œæˆ)
- [x] åœ¨å–®GPUä¸Šä½¿ç”¨ DeepSpeed ZeRO-2
- [x] å°æ¯”æœ‰ç„¡ DeepSpeed çš„è¨˜æ†¶é«”å ç”¨
- [x] æ¸¬è©¦æ¢¯åº¦ç´¯ç©èˆ‡æ‰¹æ¬¡å¤§å°é…ç½®
- [ ] âš ï¸ ç„¡æ³•æ¸¬è©¦ ZeRO-3 çš„å®Œæ•´æ•ˆæœ (éœ€å¤šGPU)

### éšæ®µ 4: å¤šGPUå¯¦é©— â¸ï¸ (éœ€å¤šGPUç’°å¢ƒ)
- [ ] å°æ¯” ZeRO-1/2/3 çš„æ€§èƒ½å·®ç•°
- [ ] æ¸¬è©¦ 3D å¹³è¡ŒåŒ–é…ç½®
- [ ] æ¸¬é‡é€šè¨Šé–‹éŠ·èˆ‡æ“´å±•æ€§
- [ ] å„ªåŒ–å¤§è¦æ¨¡è¨“ç·´é…ç½®

---

## ğŸ”¬ å–®GPUç’°å¢ƒå¯¦é©—å»ºè­°

é›–ç„¶ç„¡æ³•å±•ç¤ºå¤šGPUçš„å®Œæ•´åŠŸèƒ½ï¼Œæ‚¨ä»å¯åœ¨å–®GPUä¸Šé€²è¡Œæœ‰åƒ¹å€¼çš„å¯¦é©—:

### å¯¦é©— 1: DeepSpeed vs æ¨™æº–è¨“ç·´
**ç›®æ¨™**: å°æ¯” DeepSpeed ZeRO-2 èˆ‡æ¨™æº–è¨“ç·´çš„è¨˜æ†¶é«”æ•ˆç‡

```python
# æ¨™æº–è¨“ç·´
# é æœŸGPUè¨˜æ†¶é«”å ç”¨: ~12-14GB (Llama-2-7B)

# DeepSpeed ZeRO-2 + CPU Offload
# é æœŸGPUè¨˜æ†¶é«”å ç”¨: ~8-10GB (ç¯€çœ 20-30%)
```

### å¯¦é©— 2: é…ç½®åƒæ•¸èª¿å„ª
**ç›®æ¨™**: æ¸¬è©¦ä¸åŒé…ç½®å°è¨“ç·´çš„å½±éŸ¿

æ¸¬è©¦åƒæ•¸:
- `train_micro_batch_size_per_gpu`: 1, 2, 4
- `gradient_accumulation_steps`: 8, 16, 32
- `offload_optimizer`: true/false
- `overlap_comm`: true/false

### å¯¦é©— 3: è¨˜æ†¶é«”åˆ†æ
**ç›®æ¨™**: æ·±å…¥ç†è§£ DeepSpeed çš„è¨˜æ†¶é«”å„ªåŒ–

```python
import torch

# è¨“ç·´å‰è¨˜æ†¶é«”
torch.cuda.empty_cache()
mem_before = torch.cuda.memory_allocated()

# è¨“ç·´éç¨‹
model_engine.train()
for step, batch in enumerate(dataloader):
    # ... è¨“ç·´ä»£ç¢¼
    if step % 10 == 0:
        mem_current = torch.cuda.memory_allocated()
        print(f"Step {step}: {mem_current / 1e9:.2f} GB")

# è¨“ç·´å¾Œè¨˜æ†¶é«”
mem_after = torch.cuda.memory_allocated()
print(f"è¨˜æ†¶é«”å¢é•·: {(mem_after - mem_before) / 1e9:.2f} GB")
```

---

## ğŸ“Š é…ç½®æ–‡ä»¶ç¯„ä¾‹åº«

### ZeRO-1 é…ç½® (å–®GPUå‹å¥½)
```json
{
  "zero_optimization": {
    "stage": 1,
    "offload_optimizer": {
      "device": "cpu"
    }
  }
}
```

### ZeRO-2 é…ç½® (æ¨è–¦å–®GPU)
```json
{
  "zero_optimization": {
    "stage": 2,
    "offload_optimizer": {
      "device": "cpu",
      "pin_memory": true
    },
    "offload_param": {
      "device": "cpu",
      "pin_memory": true
    }
  }
}
```

### ZeRO-3 é…ç½® (å¤šGPUæ¨è–¦)
```json
{
  "zero_optimization": {
    "stage": 3,
    "offload_optimizer": {
      "device": "cpu"
    },
    "offload_param": {
      "device": "cpu"
    },
    "overlap_comm": true,
    "contiguous_gradients": true,
    "sub_group_size": 1e9,
    "reduce_bucket_size": "auto",
    "stage3_prefetch_bucket_size": "auto",
    "stage3_param_persistence_threshold": "auto",
    "stage3_max_live_parameters": 1e9,
    "stage3_max_reuse_distance": 1e9
  }
}
```

---

## ğŸš€ å¤šGPUç’°å¢ƒåŸ·è¡ŒæŒ‡å—

ç•¶æ‚¨æœ‰å¤šGPUç’°å¢ƒæ™‚ï¼Œå¯ä»¥åŸ·è¡Œå®Œæ•´çš„ DeepSpeed è¨“ç·´:

### å‰ç½®æº–å‚™
```bash
# å®‰è£ DeepSpeed
pip install deepspeed

# æª¢æŸ¥å®‰è£
ds_report

# é©—è­‰å¤šGPUå¯è¦‹æ€§
python -c "import torch; print(torch.cuda.device_count())"
```

### åŸ·è¡Œå‘½ä»¤

#### å–®ç¯€é»å¤šGPU
```bash
# 4 GPUè¨“ç·´ (ZeRO-2)
deepspeed --num_gpus=4 train.py \
  --deepspeed ds_config_zero2.json \
  --model_name meta-llama/Llama-2-7b-hf \
  --dataset alpaca

# 4 GPUè¨“ç·´ (ZeRO-3)
deepspeed --num_gpus=4 train.py \
  --deepspeed ds_config_zero3.json
```

#### å¤šç¯€é»å¤šGPU
```bash
# Master ç¯€é»
deepspeed --num_nodes=2 --num_gpus=4 \
  --master_addr=192.168.1.1 --master_port=29500 \
  --node_rank=0 train.py --deepspeed ds_config_zero3.json

# Worker ç¯€é»
deepspeed --num_nodes=2 --num_gpus=4 \
  --master_addr=192.168.1.1 --master_port=29500 \
  --node_rank=1 train.py --deepspeed ds_config_zero3.json
```

---

## ğŸ“ˆ æ€§èƒ½é æœŸ

### è¨˜æ†¶é«”ç¯€çœ (Llama-2-7B ç‚ºä¾‹)

| é…ç½® | GPUè¨˜æ†¶é«” | æ”¯æ´batch size | ç›¸å°ç¯€çœ |
|------|----------|---------------|---------|
| æ¨™æº–è¨“ç·´ (FP32) | ~28GB | 1 | - |
| æ¨™æº–è¨“ç·´ (FP16) | ~14GB | 1 | 50% |
| DeepSpeed ZeRO-1 | ~12GB | 2 | 57% |
| DeepSpeed ZeRO-2 | ~10GB | 4 | 64% |
| DeepSpeed ZeRO-3 (4 GPU) | ~8GB/GPU | 8 | 71% |

### è¨“ç·´é€Ÿåº¦ (ç›¸å°æ–¼å–®GPU)

| é…ç½® | ç›¸å°é€Ÿåº¦ | å‚™è¨» |
|------|---------|------|
| 1 GPU (æ¨™æº–) | 1.0x | åŸºæº– |
| 1 GPU (DeepSpeed ZeRO-2) | 0.95x | è¼•å¾®é–‹éŠ· |
| 4 GPU (DeepSpeed ZeRO-2) | 3.6x | è¿‘ç·šæ€§æ“´å±• |
| 4 GPU (DeepSpeed ZeRO-3) | 3.4x | é€šè¨Šé–‹éŠ·ç¨å¤§ |

---

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. è¨˜æ†¶é«”ä¸è¶³ (OOM)
```bash
# è§£æ±ºæ–¹æ¡ˆ:
# 1. é™ä½ micro_batch_size
# 2. å¢åŠ  gradient_accumulation_steps
# 3. å•Ÿç”¨ optimizer offload
# 4. ä½¿ç”¨ ZeRO-3
```

#### 2. DeepSpeed æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶
```bash
# ç¢ºä¿è·¯å¾‘æ­£ç¢º
deepspeed train.py --deepspeed ./configs/ds_config.json
```

#### 3. NCCL åˆå§‹åŒ–å¤±æ•—
```bash
# è¨­ç½®ç’°å¢ƒè®Šæ•¸
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=1  # ç¦ç”¨ InfiniBand (å¦‚æœä¸æ”¯æ´)
```

---

## ğŸ“š å»¶ä¼¸å­¸ç¿’è³‡æº

### å®˜æ–¹è³‡æº
- [DeepSpeed å®˜æ–¹æ–‡æª”](https://www.deepspeed.ai/)
- [DeepSpeed GitHub](https://github.com/microsoft/DeepSpeed)
- [DeepSpeed Configuration](https://www.deepspeed.ai/docs/config-json/)
- [ZeRO Paper](https://arxiv.org/abs/1910.02054)

### ç†è«–å­¸ç¿’
- **`01-Theory/1.2-Distributed_Training.md`** ç¬¬3ç« : DeepSpeed å®Œæ•´è¬›è§£
- **`01-Theory/1.3-Optimization_and_Alignment.md`**: å„ªåŒ–æŠ€è¡“

### HuggingFace æ•´åˆ
- [Transformers + DeepSpeed](https://huggingface.co/docs/transformers/main_classes/deepspeed)
- [Accelerate + DeepSpeed](https://huggingface.co/docs/accelerate/usage_guides/deepspeed)

---

## ğŸ¯ æœªä¾†å¯¦é©—å®¤è¨ˆåŠƒ

ç•¶å°ˆæ¡ˆç²å¾—å¤šGPUç’°å¢ƒå¾Œï¼Œå°‡è£œå……å®Œæ•´å¯¦é©—å…§å®¹:

### è¨ˆåŠƒä¸­çš„å¯¦é©—å…§å®¹
- [ ] **01-Setup.ipynb**: ç’°å¢ƒé©—è­‰èˆ‡ DeepSpeed é…ç½®
- [ ] **02-Train_ZeRO2.ipynb**: ZeRO-2 å–®GPU/å¤šGPUè¨“ç·´
- [ ] **03-Train_ZeRO3.ipynb**: ZeRO-3 å¤§è¦æ¨¡è¨“ç·´
- [ ] **04-Performance_Analysis.ipynb**: æ€§èƒ½å°æ¯”èˆ‡å„ªåŒ–

### å¯¦é©—ç›®æ¨™
- å±•ç¤º ZeRO-1/2/3 çš„è¨˜æ†¶é«”ç¯€çœæ•ˆæœ
- å°æ¯”ä¸åŒé…ç½®çš„è¨“ç·´é€Ÿåº¦
- æ¼”ç¤º 3D å¹³è¡ŒåŒ–é…ç½®
- æä¾›ç”Ÿç”¢ç´šè¨“ç·´ç¯„ä¾‹

---

## ğŸ’¡ çµ¦å­¸ç¿’è€…çš„å»ºè­°

### å–®GPUå­¸ç¿’è€…
1. âœ… **ç†è«–å…ˆè¡Œ**: å¾¹åº•ç†è§£ ZeRO çš„å·¥ä½œåŸç†
2. âœ… **é…ç½®ç†Ÿæ‚‰**: ç ”è®€å„ç¨®é…ç½®åƒæ•¸çš„å«ç¾©
3. âœ… **å–®GPUå¯¦é©—**: åœ¨å–®GPUä¸Šæ¸¬è©¦ ZeRO-2 + CPU Offload
4. âœ… **è¨˜æ†¶é«”åˆ†æ**: å°æ¯”æœ‰ç„¡ DeepSpeed çš„è¨˜æ†¶é«”ä½¿ç”¨

### å¤šGPUå­¸ç¿’è€…
1. âœ… **å®Œæ•´å¯¦é©—**: æ¸¬è©¦ ZeRO-1/2/3 çš„å®Œæ•´åŠŸèƒ½
2. âœ… **æ€§èƒ½å°æ¯”**: æ¸¬é‡ä¸åŒé…ç½®çš„è¨“ç·´é€Ÿåº¦èˆ‡è¨˜æ†¶é«”
3. âœ… **æ“´å±•æ€§**: æ¸¬è©¦å¾2GPUåˆ°8GPUçš„æ“´å±•æ•ˆæœ
4. âœ… **å„ªåŒ–èª¿åƒ**: æ ¹æ“šç¡¬é«”èª¿æ•´é…ç½®åƒæ•¸

---

**ç‹€æ…‹**: ğŸŸ¡ éƒ¨åˆ†å¯ç”¨ (å–®GPU: ZeRO-2, å¤šGPU: å®Œæ•´åŠŸèƒ½)
**æœ€å¾Œæ›´æ–°**: 2025-10-08
**ç›¸é—œæ–‡ä»¶**:
- ç†è«–: `01-Theory/1.2-Distributed_Training.md` (ç¬¬3ç« )
- ç†è«–: `01-Theory/1.3-Optimization_and_Alignment.md`
- å¯¦é©—å®¤: `Lab-1.2-PyTorch_DDP_Basics` (å¤šGPU)
