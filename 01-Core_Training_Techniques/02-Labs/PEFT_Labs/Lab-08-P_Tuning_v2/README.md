# Lab 8: P-Tuning v2 - 深度提示調優的通用框架

## 概述

**P-Tuning v2** 是 P-Tuning 的進化版本，透過在每個 Transformer 層都添加可訓練的提示參數，實現了在各種規模和任務上與全參數微調相媲美的性能。本實驗將深入探討 P-Tuning v2 的核心創新、技術實現與通用性優勢。

![P-Tuning v2 深度架構](https://pica.zhimg.com/v2-d2eaf41d3da078a87ebe9e63b4c199d8_1440w.jpg)

---

## 1. 技術背景與演進動機

### 1.1 P-Tuning v1 的局限性

儘管 P-Tuning v1 在 NLU 任務上表現優異，但仍存在以下限制：

- **表達能力受限**：僅在輸入層添加提示，對深層特徵的影響有限
- **任務適應性不足**：在某些複雜任務上仍無法匹敵全參數微調
- **規模敏感性**：在不同模型規模上的表現不夠一致
- **生成任務劣勢**：在文本生成任務上表現不如 Prefix Tuning

### 1.2 P-Tuning v2 的突破性改進

P-Tuning v2 針對上述問題提出了系統性解決方案：

1. **深度提示設計**：在每個 Transformer 層都添加可訓練提示
2. **任務無關架構**：統一的框架支持理解和生成任務
3. **規模不變性**：在各種模型規模上都能達到優異性能
4. **參數高效性**：極低的參數開銷實現全參數微調級別的效果

---

## 2. P-Tuning v2 核心創新

### 2.1 深度提示機制

**P-Tuning v2** 的核心創新是：**在每個 Transformer 層的開始位置都添加可訓練的連續提示，形成深度的、層次化的提示表示系統**。

![深度提示架構](https://pic2.zhimg.com/v2-06a7fd88bd29877341a3b6fc0bbcbb69_1440w.jpg)

### 2.2 與前代和同類方法的對比

| 技術特徵 | P-Tuning v1 | P-Tuning v2 | Prefix Tuning | Prompt Tuning |
|:---|:---|:---|:---|:---|
| **提示位置** | 僅輸入層 | **每個Transformer層** | 每個層的K,V | 僅輸入層 |
| **MLP編碼器** | ✅ | **❌ (簡化設計)** | ✅ | ❌ |
| **任務通用性** | NLU優勢 | **理解+生成通用** | 生成優勢 | 生成優勢 |
| **參數效率** | 中等 | **極高** | 中等 | **極高** |
| **實現複雜度** | 中等 | **低** | 高 | **極低** |

### 2.3 深度提示的數學表示

對於一個 $L$ 層的 Transformer，P-Tuning v2 在每層 $l$ 都添加提示：

$$h_l = \text{TransformerLayer}_l([P_l^{(1)}, P_l^{(2)}, ..., P_l^{(k)}, h_{l-1}])$$

其中：
- $P_l^{(i)} \in \mathbb{R}^d$ 是第 $l$ 層的第 $i$ 個提示向量
- $k$ 是每層的提示長度
- 所有提示向量都是可訓練參數

---

## 3. P-Tuning v2 vs P-Tuning v1：全面對比

### 3.1 架構設計差異

![架構對比示意圖](https://picx.zhimg.com/v2-57f517168ec95f694ec9f5020b95b4cf_1440w.jpg)

| 設計維度 | P-Tuning v1 | P-Tuning v2 |
|:---|:---|:---|
| **提示深度** | 單層（輸入層） | **多層（所有層）** |
| **編碼器需求** | 必需 MLP 編碼器 | **無需編碼器** |
| **參數初始化** | 隨機或編碼器生成 | **隨機初始化** |
| **訓練穩定性** | 需要仔細調參 | **高度穩定** |
| **實現複雜度** | 中等 | **極簡** |

### 3.2 性能表現對比

| 任務類型 | P-Tuning v1 | P-Tuning v2 | 全參數微調 | P-Tuning v2 優勢 |
|:---|:---|:---|:---|:---|
| **SuperGLUE** | 86.2% | **91.4%** | 91.8% | **接近全參數性能** |
| **SQuAD v1** | 88.1% | **89.7%** | 90.2% | **大幅提升** |
| **CoNLL 2003 NER** | 90.3% | **92.1%** | 92.5% | **顯著改善** |
| **WebNLG** | 47.2 BLEU | **52.8 BLEU** | 53.1 BLEU | **生成任務突破** |

---

## 4. 通用性與規模不變性

### 4.1 跨任務通用性驗證

![跨任務性能表現](https://pica.zhimg.com/v2-d0e8a236f95fc534595511377775d352_1440w.jpg)

**理解任務表現**：
- **文本分類**：SuperGLUE 各子任務平均 91.4%
- **序列標注**：CoNLL NER 達到 92.1% F1
- **閱讀理解**：SQuAD v1 89.7% EM，v2 85.3% EM

**生成任務表現**：
- **數據轉文本**：WebNLG 52.8 BLEU
- **摘要生成**：CNN/DM 38.2 ROUGE-L
- **對話生成**：PersonaChat 17.8 perplexity

### 4.2 規模不變性分析

| 模型規模 | P-Tuning v2 vs 全參數微調差距 | 參數效率 |
|:---|:---|:---|
| **BERT-base (110M)** | -0.4% | **0.1%** |
| **BERT-large (340M)** | -0.2% | **0.05%** |
| **T5-base (220M)** | -0.3% | **0.08%** |
| **T5-large (770M)** | -0.1% | **0.04%** |
| **T5-xl (3B)** | **+0.1%** | **0.02%** |

**關鍵發現**：隨著模型規模增大，P-Tuning v2 與全參數微調的性能差距不斷縮小，甚至在超大模型上略有超越。

---

## 5. 實現原理與技術細節

### 5.1 深度提示的實現機制

```python
class PtuningV2Config:
    def __init__(self):
        self.num_virtual_tokens = 100        # 每層提示長度
        self.num_transformer_layers = 12     # Transformer層數
        self.hidden_size = 768              # 隱藏維度
        self.prompt_projection = False       # 不使用投影層
        self.prompt_init = "random"         # 隨機初始化

class PtuningV2Model(nn.Module):
    def __init__(self, base_model, config):
        super().__init__()
        self.base_model = base_model
        self.config = config
        
        # 為每層創建獨立的提示參數
        self.prompt_embeddings = nn.ParameterList([
            nn.Parameter(torch.randn(
                config.num_virtual_tokens, 
                config.hidden_size
            )) for _ in range(config.num_transformer_layers)
        ])
    
    def forward(self, input_ids, attention_mask=None):
        # 獲取基礎嵌入
        embeddings = self.base_model.embeddings(input_ids)
        
        # 處理每個Transformer層
        hidden_states = embeddings
        for layer_idx, transformer_layer in enumerate(self.base_model.encoder.layer):
            # 添加當前層的提示
            batch_size = hidden_states.size(0)
            layer_prompts = self.prompt_embeddings[layer_idx].unsqueeze(0).expand(
                batch_size, -1, -1
            )
            
            # 拼接提示和隱藏狀態
            hidden_states = torch.cat([layer_prompts, hidden_states], dim=1)
            
            # 調整注意力掩碼
            if attention_mask is not None:
                prompt_mask = torch.ones(
                    batch_size, self.config.num_virtual_tokens,
                    dtype=attention_mask.dtype, device=attention_mask.device
                )
                attention_mask = torch.cat([prompt_mask, attention_mask], dim=1)
            
            # 通過Transformer層
            hidden_states = transformer_layer(hidden_states, attention_mask)[0]
            
            # 移除提示部分，保留原始序列
            hidden_states = hidden_states[:, self.config.num_virtual_tokens:]
            if attention_mask is not None:
                attention_mask = attention_mask[:, self.config.num_virtual_tokens:]
        
        return hidden_states
```

### 5.2 關鍵設計決策

| 設計選擇 | P-Tuning v2 決策 | 理由 |
|:---|:---|:---|
| **MLP 編碼器** | **移除** | 簡化架構，降低複雜度 |
| **提示初始化** | **隨機初始化** | 避免引入先驗偏置 |
| **提示長度** | **固定長度** | 平衡性能與效率 |
| **層間共享** | **獨立參數** | 最大化表達能力 |

---

## 6. 實驗設計與實作

### 6.1 實驗環境配置

- **基礎模型**: BERT-base, T5-base
- **任務覆蓋**: 分類、NER、閱讀理解、生成
- **數據集**: SuperGLUE, CoNLL 2003, SQuAD, WebNLG
- **評估指標**: Accuracy, F1, BLEU, ROUGE

### 6.2 三階段實驗流程

#### 階段一：環境準備 (`01-Setup.ipynb`)
```bash
# 核心依賴配置
transformers>=4.25.0    # 支援深度提示的版本
peft>=0.5.0            # P-Tuning v2 支援
datasets>=2.5.0        # 多任務數據集支援
accelerate>=0.25.0     # 高效訓練框架
```

#### 階段二：模型訓練 (`02-Train.ipynb`)
```python
# P-Tuning v2 配置示例
ptuning_v2_config = PromptTuningConfig(
    task_type=TaskType.SEQ_CLS,           # 支援多種任務類型
    prompt_tuning_init="RANDOM",          # 隨機初始化
    num_virtual_tokens=100,               # 較長的提示序列
    prompt_tuning_init_text=None,         # 不使用文本初始化
    num_transformer_submodules=12,        # 所有層都添加提示
    token_dim=768                         # 匹配模型隱藏維度
)
```

#### 階段三：推理測試 (`03-Inference.ipynb`)
- 多任務性能評估
- 與其他 PEFT 方法對比
- 參數效率分析

### 6.3 多任務訓練策略

```python
# 多任務 P-Tuning v2 訓練
class MultiTaskPtuningV2:
    def __init__(self, tasks):
        self.tasks = tasks
        self.task_configs = {
            task: self.create_task_config(task) 
            for task in tasks
        }
    
    def create_task_config(self, task_name):
        base_config = PromptTuningConfig(
            num_virtual_tokens=100,
            prompt_tuning_init="RANDOM"
        )
        
        # 任務特定調整
        if task_name in ["classification", "NER"]:
            base_config.task_type = TaskType.SEQ_CLS
        elif task_name in ["generation", "summarization"]:
            base_config.task_type = TaskType.SEQ_2_SEQ_LM
        
        return base_config
```

---

## 7. 高級應用與最佳實踐

### 7.1 自適應提示長度策略

| 任務複雜度 | 推薦提示長度 | 層數建議 | 預期性能 |
|:---|:---|:---|:---|
| **簡單分類** | 50-100 tokens | 全部層 | 接近全參數微調 |
| **複雜理解** | 100-150 tokens | 全部層 | 匹配全參數微調 |
| **生成任務** | 150-200 tokens | 全部層 | 超越 Prefix Tuning |

### 7.2 任務特定優化策略

```python
# 任務適應性配置
def get_optimal_config(task_type, model_size):
    base_config = {
        "num_virtual_tokens": 100,
        "prompt_tuning_init": "RANDOM"
    }
    
    # 根據任務類型調整
    if task_type == "seq_classification":
        base_config["num_virtual_tokens"] = 50
    elif task_type == "token_classification":
        base_config["num_virtual_tokens"] = 100  
    elif task_type == "seq2seq":
        base_config["num_virtual_tokens"] = 150
    
    # 根據模型規模調整
    if model_size > 1_000_000_000:  # 1B+ 參數
        base_config["num_virtual_tokens"] //= 2  # 大模型需要較少提示
    
    return base_config
```

---

## 8. 性能基準與對比分析

### 8.1 PEFT 方法全面對比

| 方法 | SuperGLUE | SQuAD v1 | CoNLL NER | WebNLG | 參數效率 |
|:---|:---|:---|:---|:---|:---|
| **P-Tuning v2** | **91.4%** | **89.7%** | **92.1%** | **52.8** | **0.1%** |
| **P-Tuning v1** | 86.2% | 88.1% | 90.3% | 47.2 | 0.1% |
| **Prefix Tuning** | 89.8% | 87.3% | 89.5% | **53.1** | 0.2% |
| **LoRA** | **91.1%** | 88.9% | 91.4% | 51.2 | 0.3% |
| **全參數微調** | **91.8%** | **90.2%** | **92.5%** | **53.1** | 100% |

### 8.2 規模擴展性驗證

![規模擴展性圖表](https://picx.zhimg.com/v2-57f517168ec95f694ec9f5020b95b4cf_1440w.jpg)

**關鍵發現**：
- **小模型 (<1B)**：P-Tuning v2 與全參數微調有 1-2% 差距
- **中型模型 (1-10B)**：差距縮小至 0.5% 以內  
- **大型模型 (>10B)**：P-Tuning v2 **達到或超越**全參數微調性能

---

## 9. 方法選擇指引

### 9.1 最佳應用場景

| 使用場景 | 推薦理由 | 配置建議 |
|:---|:---|:---|
| **需要通用性** | 理解+生成任務都表現優異 | 標準配置(100 tokens) |
| **極致參數效率** | 0.1% 參數實現全參數效果 | 適當減少提示長度 |
| **多任務系統** | 統一架構支持多種任務 | 任務特定提示長度 |
| **大規模模型** | 規模越大效果越好 | 可減少提示長度 |

### 9.2 技術選型決策樹

```python
def recommend_peft_method(task_diversity, model_scale, resource_constraint):
    """
    PEFT 方法推薦系統
    """
    if task_diversity == "high":  # 多種類型任務
        return "P-Tuning v2"  # 最佳通用性
    
    elif model_scale > 10_000_000_000:  # 10B+ 模型
        if resource_constraint == "extreme":
            return "P-Tuning v2"  # 極致效率
        else:
            return "P-Tuning v2"  # 性能最佳
    
    elif task_type == "understanding":
        return "P-Tuning v2"  # NLU 任務最佳選擇
        
    elif task_type == "generation":
        return "P-Tuning v2" if model_scale > 1e9 else "Prefix Tuning"
    
    else:
        return "LoRA"  # 通用後備選擇
```

---

## 10. 技術限制與未來方向

### 10.1 當前技術限制

| 限制項目 | 具體表現 | 改進方向 |
|:---|:---|:---|
| **記憶體開銷** | 每層添加提示增加序列長度 | 動態提示長度調整 |
| **推理延遲** | 較長序列增加計算開銷 | 提示壓縮技術 |
| **層間耦合** | 各層提示缺乏交互 | 層間提示通信機制 |

### 10.2 未來研究方向

- **動態深度提示**：根據任務複雜度自適應調整提示深度
- **分層提示優化**：設計不同層使用不同類型的提示
- **跨模態擴展**：將深度提示擴展到多模態模型
- **硬體友好設計**：優化提示結構以減少計算開銷

---

## 11. 實驗結論與學習價值

### 11.1 核心技術收穫

通過本實驗，您將深入掌握：

1. **深度理解** P-Tuning v2 的深度提示機制與通用性設計
2. **實踐經驗** 在多種任務類型上應用 P-Tuning v2 的完整流程
3. **性能調優** 掌握提示長度、層間配置等關鍵優化策略
4. **對比分析** 理解 P-Tuning v2 相對其他 PEFT 方法的獨特優勢

### 11.2 工程實踐意義

- **通用微調框架**：學會設計支持多任務的統一微調架構
- **深度參數控制**：掌握在深層網路中精確控制參數的技巧
- **規模化思維**：理解技術方法隨模型規模演化的規律
- **效率優化策略**：學會在極低參數開銷下實現最大性能

P-Tuning v2 代表了 PEFT 領域中「深度整合」和「通用性」的技術方向，通過在每個層級都施加影響，實現了前所未有的任務適應能力。這為未來的深度模型微調和通用人工智能系統提供了重要的技術基礎。

---

## 12. 參考資料與延伸閱讀

### 核心論文
- **P-Tuning v2**: Liu, X., et al. (2022). *P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks*. ACL 2022.

### 相關研究
- **P-Tuning v1**: Liu, X., et al. (2021). *GPT Understands, Too*. arXiv:2103.10385.
- **Prefix-Tuning**: Li, X. L., & Liang, P. (2021). *Prefix-Tuning: Optimizing Continuous Prompts for Generation*. ACL 2021.
- **Prompt Tuning**: Lester, B., et al. (2021). *The Power of Scale for Parameter-Efficient Prompt Tuning*. EMNLP 2021.

### 技術實現
- **Hugging Face PEFT**: [https://github.com/huggingface/peft](https://github.com/huggingface/peft)
- **THU P-Tuning**: [https://github.com/THUDM/P-tuning-v2](https://github.com/THUDM/P-tuning-v2)
- **官方實現**: [https://github.com/thunlp/P-tuning-v2](https://github.com/thunlp/P-tuning-v2)

### 數據集與評估
- **SuperGLUE**: [https://super.gluebenchmark.com/](https://super.gluebenchmark.com/)
- **SQuAD**: [https://rajpurkar.github.io/SQuAD-explorer/](https://rajpurkar.github.io/SQuAD-explorer/)
- **CoNLL 2003**: [https://www.clips.uantwerpen.be/conll2003/ner/](https://www.clips.uantwerpen.be/conll2003/ner/)

---

**準備好體驗深度提示調優的通用威力了嗎？讓我們開始 P-Tuning v2 的深度微調之旅！** 🚀
