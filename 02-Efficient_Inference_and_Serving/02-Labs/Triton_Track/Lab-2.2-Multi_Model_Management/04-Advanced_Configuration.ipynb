{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-2.2.4: é«˜ç´šé…ç½®èˆ‡æ™ºèƒ½å„ªåŒ–\n",
    "\n",
    "## ğŸ¯ å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "- å»ºç«‹æ¨¡å‹çµ„åˆ (Ensemble) çš„é«˜ç´šé…ç½®ç­–ç•¥\n",
    "- å¯¦ç¾ Pipeline å·¥ä½œæµçš„è¨­è¨ˆèˆ‡å„ªåŒ–\n",
    "- æŒæ¡æ¢ä»¶è·¯ç”±èˆ‡æ™ºèƒ½èª¿åº¦æ©Ÿåˆ¶\n",
    "- è¨­è¨ˆå‹•æ…‹è² è¼‰å‡è¡¡èˆ‡è³‡æºæœ€ä½³åŒ–\n",
    "- å¯¦ç¾è‡ªé©æ‡‰é…ç½®èª¿æ•´ç³»çµ±\n",
    "\n",
    "## ğŸ¢ ä¼æ¥­æ¡ˆä¾‹: Google Ads æ™ºèƒ½ç«¶åƒ¹ç³»çµ±\n",
    "\n",
    "Google Ads ç®¡ç†è‘—å…¨çƒæœ€å¤§çš„å»£å‘Šç«¶åƒ¹ç³»çµ±ï¼Œæ¯ç§’è™•ç†æ•¸ç™¾è¬æ¬¡ç«¶åƒ¹è«‹æ±‚ï¼š\n",
    "- **æ¨¡å‹çµ„åˆ**: çµåˆå¤šå€‹å°ˆæ¥­æ¨¡å‹ (CTRã€CVRã€è³ªé‡åˆ†æ•¸) é€²è¡Œç¶œåˆæ±ºç­–\n",
    "- **Pipeline å·¥ä½œæµ**: å¤šéšæ®µçš„è«‹æ±‚è™•ç†ï¼ŒåŒ…æ‹¬ç‰¹å¾µæå–ã€æ¨¡å‹æ¨ç†ã€å¾Œè™•ç†\n",
    "- **æ¢ä»¶è·¯ç”±**: æ ¹æ“šå»£å‘Šé¡å‹ã€åœ°å€ã€è¨­å‚™è‡ªå‹•é¸æ“‡æœ€é©åˆçš„æ¨¡å‹\n",
    "- **å‹•æ…‹è² è¼‰å‡è¡¡**: åŸºæ–¼æ¨¡å‹æ€§èƒ½å’Œè³‡æºä½¿ç”¨è‡ªå‹•èª¿æ•´æµé‡åˆ†é…\n",
    "- **è‡ªé©æ‡‰å„ªåŒ–**: æ ¹æ“šå¯¦æ™‚åé¥‹è‡ªå‹•èª¿æ•´æ¨¡å‹æ¬Šé‡å’Œé–¾å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple, Union, Callable\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import queue\n",
    "import heapq\n",
    "import random\n",
    "from collections import defaultdict, deque\n",
    "import hashlib\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# è¨­å®šæ—¥èªŒ\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"ğŸš€ é«˜ç´šé…ç½®èˆ‡æ™ºèƒ½å„ªåŒ– - ç’°å¢ƒæª¢æŸ¥\")\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
    "\n",
    "# æª¢æŸ¥å¿…è¦çš„ä¾è³´\n",
    "required_packages = ['numpy', 'pandas']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"âœ… {package}: å·²å®‰è£\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package}: æœªå®‰è£\")\n",
    "\n",
    "print(\"\\nâœ… ç’°å¢ƒæª¢æŸ¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ­ æ¨¡å‹çµ„åˆ (Ensemble) é…ç½®ç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleMethod(Enum):\n",
    "    \"\"\"é›†æˆæ–¹æ³•æšèˆ‰\"\"\"\n",
    "    VOTING = \"voting\"                    # æŠ•ç¥¨æ³•\n",
    "    AVERAGING = \"averaging\"              # å¹³å‡æ³•\n",
    "    WEIGHTED_AVERAGE = \"weighted_avg\"    # åŠ æ¬Šå¹³å‡\n",
    "    STACKING = \"stacking\"                # å †ç–Šæ³•\n",
    "    BOOSTING = \"boosting\"                # å¢å¼·æ³•\n",
    "    BLENDING = \"blending\"                # æ··åˆæ³•\n",
    "    DYNAMIC_WEIGHTING = \"dynamic_weight\" # å‹•æ…‹æ¬Šé‡\n",
    "\n",
    "class RoutingStrategy(Enum):\n",
    "    \"\"\"è·¯ç”±ç­–ç•¥æšèˆ‰\"\"\"\n",
    "    ROUND_ROBIN = \"round_robin\"          # è¼ªè©¢\n",
    "    RANDOM = \"random\"                    # éš¨æ©Ÿ\n",
    "    WEIGHTED_RANDOM = \"weighted_random\"  # åŠ æ¬Šéš¨æ©Ÿ\n",
    "    LEAST_LOADED = \"least_loaded\"        # æœ€å°‘è² è¼‰\n",
    "    FASTEST_RESPONSE = \"fastest\"         # æœ€å¿«éŸ¿æ‡‰\n",
    "    CONDITION_BASED = \"condition_based\"  # æ¢ä»¶è·¯ç”±\n",
    "    PERFORMANCE_BASED = \"performance\"    # æ€§èƒ½è·¯ç”±\n",
    "\n",
    "@dataclass\n",
    "class ModelEndpoint:\n",
    "    \"\"\"æ¨¡å‹ç«¯é»é…ç½®\"\"\"\n",
    "    model_id: str\n",
    "    endpoint_url: str\n",
    "    model_type: str\n",
    "    version: str\n",
    "    weight: float = 1.0\n",
    "    max_concurrent_requests: int = 10\n",
    "    timeout_ms: int = 1000\n",
    "    health_check_interval: int = 30\n",
    "    is_healthy: bool = True\n",
    "    current_load: int = 0\n",
    "    avg_response_time_ms: float = 0.0\n",
    "    success_rate: float = 1.0\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class EnsembleConfig:\n",
    "    \"\"\"é›†æˆé…ç½®\"\"\"\n",
    "    ensemble_id: str\n",
    "    name: str\n",
    "    method: EnsembleMethod\n",
    "    models: List[ModelEndpoint]\n",
    "    routing_strategy: RoutingStrategy\n",
    "    min_models_required: int = 1\n",
    "    consensus_threshold: float = 0.5\n",
    "    timeout_ms: int = 5000\n",
    "    retry_attempts: int = 2\n",
    "    fallback_model: Optional[str] = None\n",
    "    performance_weights: Dict[str, float] = field(default_factory=dict)\n",
    "    routing_conditions: Dict[str, Any] = field(default_factory=dict)\n",
    "    auto_scaling_enabled: bool = True\n",
    "    created_at: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "class EnsembleManager:\n",
    "    \"\"\"æ¨¡å‹çµ„åˆç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ensembles: Dict[str, EnsembleConfig] = {}\n",
    "        self.performance_history: Dict[str, List[Dict[str, Any]]] = defaultdict(list)\n",
    "        self.load_balancer = LoadBalancer()\n",
    "        self.health_monitor = HealthMonitor()\n",
    "        self.adaptive_optimizer = AdaptiveOptimizer()\n",
    "    \n",
    "    def create_ensemble(self, config: EnsembleConfig) -> bool:\n",
    "        \"\"\"å‰µå»ºæ¨¡å‹çµ„åˆ\"\"\"\n",
    "        try:\n",
    "            # é©—è­‰é…ç½®\n",
    "            self._validate_ensemble_config(config)\n",
    "            \n",
    "            # åˆå§‹åŒ–æ¨¡å‹æ¬Šé‡\n",
    "            if config.method == EnsembleMethod.WEIGHTED_AVERAGE:\n",
    "                self._initialize_weights(config)\n",
    "            \n",
    "            # è¨»å†Šé›†æˆ\n",
    "            self.ensembles[config.ensemble_id] = config\n",
    "            \n",
    "            # å•Ÿå‹•å¥åº·ç›£æ§\n",
    "            self.health_monitor.register_ensemble(config)\n",
    "            \n",
    "            logger.info(f\"âœ… é›†æˆ {config.name} å‰µå»ºæˆåŠŸ\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ é›†æˆå‰µå»ºå¤±æ•—: {e}\")\n",
    "            return False\n",
    "    \n",
    "    async def predict(self, ensemble_id: str, input_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"åŸ·è¡Œé›†æˆé æ¸¬\"\"\"\n",
    "        if ensemble_id not in self.ensembles:\n",
    "            raise ValueError(f\"é›†æˆ {ensemble_id} ä¸å­˜åœ¨\")\n",
    "        \n",
    "        config = self.ensembles[ensemble_id]\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # é¸æ“‡å¯ç”¨æ¨¡å‹\n",
    "            selected_models = self._select_models(config, input_data)\n",
    "            \n",
    "            if len(selected_models) < config.min_models_required:\n",
    "                raise RuntimeError(f\"å¯ç”¨æ¨¡å‹ä¸è¶³: {len(selected_models)} < {config.min_models_required}\")\n",
    "            \n",
    "            # ä¸¦è¡ŒåŸ·è¡Œé æ¸¬\n",
    "            predictions = await self._execute_parallel_predictions(selected_models, input_data)\n",
    "            \n",
    "            # åˆä½µé æ¸¬çµæœ\n",
    "            final_result = self._combine_predictions(config, predictions)\n",
    "            \n",
    "            # è¨˜éŒ„æ€§èƒ½æ•¸æ“š\n",
    "            elapsed_time = (time.time() - start_time) * 1000\n",
    "            self._record_performance(ensemble_id, elapsed_time, len(predictions), True)\n",
    "            \n",
    "            return {\n",
    "                'prediction': final_result,\n",
    "                'ensemble_id': ensemble_id,\n",
    "                'models_used': [p['model_id'] for p in predictions],\n",
    "                'response_time_ms': elapsed_time,\n",
    "                'confidence': self._calculate_confidence(predictions)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            elapsed_time = (time.time() - start_time) * 1000\n",
    "            self._record_performance(ensemble_id, elapsed_time, 0, False)\n",
    "            \n",
    "            # å˜—è©¦é™ç´šåˆ°å‚™ç”¨æ¨¡å‹\n",
    "            if config.fallback_model:\n",
    "                return await self._fallback_prediction(config.fallback_model, input_data)\n",
    "            \n",
    "            raise e\n",
    "    \n",
    "    def update_model_weight(self, ensemble_id: str, model_id: str, new_weight: float):\n",
    "        \"\"\"æ›´æ–°æ¨¡å‹æ¬Šé‡\"\"\"\n",
    "        if ensemble_id not in self.ensembles:\n",
    "            return False\n",
    "        \n",
    "        config = self.ensembles[ensemble_id]\n",
    "        for model in config.models:\n",
    "            if model.model_id == model_id:\n",
    "                model.weight = new_weight\n",
    "                logger.info(f\"ğŸ”„ æ›´æ–°æ¨¡å‹ {model_id} æ¬Šé‡ç‚º {new_weight}\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def get_ensemble_status(self, ensemble_id: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"ç²å–é›†æˆç‹€æ…‹\"\"\"\n",
    "        if ensemble_id not in self.ensembles:\n",
    "            return None\n",
    "        \n",
    "        config = self.ensembles[ensemble_id]\n",
    "        recent_performance = self.performance_history[ensemble_id][-100:]  # æœ€è¿‘100æ¬¡\n",
    "        \n",
    "        if recent_performance:\n",
    "            avg_response_time = np.mean([p['response_time_ms'] for p in recent_performance])\n",
    "            success_rate = np.mean([p['success'] for p in recent_performance])\n",
    "            avg_models_used = np.mean([p['models_used'] for p in recent_performance])\n",
    "        else:\n",
    "            avg_response_time = 0\n",
    "            success_rate = 0\n",
    "            avg_models_used = 0\n",
    "        \n",
    "        healthy_models = sum(1 for model in config.models if model.is_healthy)\n",
    "        \n",
    "        return {\n",
    "            'ensemble_id': ensemble_id,\n",
    "            'name': config.name,\n",
    "            'method': config.method.value,\n",
    "            'total_models': len(config.models),\n",
    "            'healthy_models': healthy_models,\n",
    "            'avg_response_time_ms': avg_response_time,\n",
    "            'success_rate': success_rate,\n",
    "            'avg_models_used': avg_models_used,\n",
    "            'total_requests': len(self.performance_history[ensemble_id])\n",
    "        }\n",
    "    \n",
    "    def _validate_ensemble_config(self, config: EnsembleConfig):\n",
    "        \"\"\"é©—è­‰é›†æˆé…ç½®\"\"\"\n",
    "        if not config.models:\n",
    "            raise ValueError(\"é›†æˆå¿…é ˆåŒ…å«è‡³å°‘ä¸€å€‹æ¨¡å‹\")\n",
    "        \n",
    "        if config.min_models_required > len(config.models):\n",
    "            raise ValueError(\"æœ€å°æ¨¡å‹è¦æ±‚æ•¸é‡ä¸èƒ½è¶…éç¸½æ¨¡å‹æ•¸é‡\")\n",
    "        \n",
    "        total_weight = sum(model.weight for model in config.models)\n",
    "        if config.method == EnsembleMethod.WEIGHTED_AVERAGE and total_weight == 0:\n",
    "            raise ValueError(\"åŠ æ¬Šå¹³å‡æ³•è¦æ±‚è‡³å°‘ä¸€å€‹æ¨¡å‹æœ‰æ­£æ¬Šé‡\")\n",
    "    \n",
    "    def _initialize_weights(self, config: EnsembleConfig):\n",
    "        \"\"\"åˆå§‹åŒ–æ¨¡å‹æ¬Šé‡\"\"\"\n",
    "        if not any(model.weight > 0 for model in config.models):\n",
    "            # å¦‚æœæ²’æœ‰è¨­ç½®æ¬Šé‡ï¼Œä½¿ç”¨ç­‰æ¬Šé‡\n",
    "            equal_weight = 1.0 / len(config.models)\n",
    "            for model in config.models:\n",
    "                model.weight = equal_weight\n",
    "    \n",
    "    def _select_models(self, config: EnsembleConfig, input_data: Dict[str, Any]) -> List[ModelEndpoint]:\n",
    "        \"\"\"é¸æ“‡å¯ç”¨æ¨¡å‹\"\"\"\n",
    "        available_models = [model for model in config.models if model.is_healthy]\n",
    "        \n",
    "        # æ‡‰ç”¨æ¢ä»¶è·¯ç”±\n",
    "        if config.routing_strategy == RoutingStrategy.CONDITION_BASED:\n",
    "            available_models = self._apply_condition_routing(available_models, config.routing_conditions, input_data)\n",
    "        \n",
    "        # æ‡‰ç”¨è² è¼‰å¹³è¡¡\n",
    "        if config.routing_strategy == RoutingStrategy.LEAST_LOADED:\n",
    "            available_models.sort(key=lambda m: m.current_load)\n",
    "        elif config.routing_strategy == RoutingStrategy.FASTEST_RESPONSE:\n",
    "            available_models.sort(key=lambda m: m.avg_response_time_ms)\n",
    "        \n",
    "        return available_models\n",
    "    \n",
    "    def _apply_condition_routing(self, models: List[ModelEndpoint], conditions: Dict[str, Any], \n",
    "                               input_data: Dict[str, Any]) -> List[ModelEndpoint]:\n",
    "        \"\"\"æ‡‰ç”¨æ¢ä»¶è·¯ç”±\"\"\"\n",
    "        filtered_models = []\n",
    "        \n",
    "        for model in models:\n",
    "            if self._model_matches_conditions(model, conditions, input_data):\n",
    "                filtered_models.append(model)\n",
    "        \n",
    "        return filtered_models if filtered_models else models  # å¦‚æœæ²’æœ‰åŒ¹é…ï¼Œè¿”å›æ‰€æœ‰æ¨¡å‹\n",
    "    \n",
    "    def _model_matches_conditions(self, model: ModelEndpoint, conditions: Dict[str, Any], \n",
    "                                 input_data: Dict[str, Any]) -> bool:\n",
    "        \"\"\"æª¢æŸ¥æ¨¡å‹æ˜¯å¦ç¬¦åˆæ¢ä»¶\"\"\"\n",
    "        # ç¤ºä¾‹æ¢ä»¶åŒ¹é…é‚è¼¯\n",
    "        if 'model_type' in conditions:\n",
    "            if model.model_type not in conditions['model_type']:\n",
    "                return False\n",
    "        \n",
    "        if 'data_type' in conditions and 'data_type' in input_data:\n",
    "            required_types = conditions['data_type']\n",
    "            if input_data['data_type'] not in required_types:\n",
    "                return False\n",
    "        \n",
    "        if 'min_confidence' in conditions:\n",
    "            if model.success_rate < conditions['min_confidence']:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    async def _execute_parallel_predictions(self, models: List[ModelEndpoint], \n",
    "                                           input_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ä¸¦è¡ŒåŸ·è¡Œé æ¸¬\"\"\"\n",
    "        tasks = []\n",
    "        \n",
    "        for model in models:\n",
    "            task = asyncio.create_task(self._single_model_prediction(model, input_data))\n",
    "            tasks.append(task)\n",
    "        \n",
    "        results = []\n",
    "        for completed_task in asyncio.as_completed(tasks):\n",
    "            try:\n",
    "                result = await completed_task\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"æ¨¡å‹é æ¸¬å¤±æ•—: {e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    async def _single_model_prediction(self, model: ModelEndpoint, \n",
    "                                      input_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"å–®å€‹æ¨¡å‹é æ¸¬\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # æ¨¡æ“¬æ¨¡å‹é æ¸¬ï¼ˆå¯¦éš›ç’°å¢ƒä¸­æœƒèª¿ç”¨çœŸå¯¦çš„æ¨¡å‹APIï¼‰\n",
    "            await asyncio.sleep(random.uniform(0.01, 0.05))  # æ¨¡æ“¬ç¶²çµ¡å»¶é²\n",
    "            \n",
    "            # æ¨¡æ“¬é æ¸¬çµæœ\n",
    "            if model.model_type == 'ctr_model':\n",
    "                prediction = random.uniform(0.01, 0.1)  # CTRé æ¸¬\n",
    "            elif model.model_type == 'cvr_model':\n",
    "                prediction = random.uniform(0.001, 0.05)  # CVRé æ¸¬\n",
    "            elif model.model_type == 'quality_model':\n",
    "                prediction = random.uniform(0.7, 0.95)  # è³ªé‡åˆ†æ•¸\n",
    "            else:\n",
    "                prediction = random.uniform(0, 1)  # é€šç”¨é æ¸¬\n",
    "            \n",
    "            # æ›´æ–°æ¨¡å‹çµ±è¨ˆ\n",
    "            response_time = (time.time() - start_time) * 1000\n",
    "            model.avg_response_time_ms = (model.avg_response_time_ms + response_time) / 2\n",
    "            \n",
    "            return {\n",
    "                'model_id': model.model_id,\n",
    "                'prediction': prediction,\n",
    "                'confidence': random.uniform(0.8, 0.95),\n",
    "                'response_time_ms': response_time,\n",
    "                'weight': model.weight\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"æ¨¡å‹ {model.model_id} é æ¸¬å¤±æ•—: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _combine_predictions(self, config: EnsembleConfig, \n",
    "                           predictions: List[Dict[str, Any]]) -> float:\n",
    "        \"\"\"åˆä½µé æ¸¬çµæœ\"\"\"\n",
    "        if not predictions:\n",
    "            raise ValueError(\"æ²’æœ‰å¯ç”¨çš„é æ¸¬çµæœ\")\n",
    "        \n",
    "        if config.method == EnsembleMethod.AVERAGING:\n",
    "            return np.mean([p['prediction'] for p in predictions])\n",
    "        \n",
    "        elif config.method == EnsembleMethod.WEIGHTED_AVERAGE:\n",
    "            total_weight = sum(p['weight'] for p in predictions)\n",
    "            if total_weight == 0:\n",
    "                return np.mean([p['prediction'] for p in predictions])\n",
    "            \n",
    "            weighted_sum = sum(p['prediction'] * p['weight'] for p in predictions)\n",
    "            return weighted_sum / total_weight\n",
    "        \n",
    "        elif config.method == EnsembleMethod.VOTING:\n",
    "            # äºŒåˆ†é¡æŠ•ç¥¨\n",
    "            votes = [1 if p['prediction'] > 0.5 else 0 for p in predictions]\n",
    "            return 1 if sum(votes) > len(votes) / 2 else 0\n",
    "        \n",
    "        elif config.method == EnsembleMethod.DYNAMIC_WEIGHTING:\n",
    "            # åŸºæ–¼ç½®ä¿¡åº¦çš„å‹•æ…‹æ¬Šé‡\n",
    "            confidences = [p['confidence'] for p in predictions]\n",
    "            total_confidence = sum(confidences)\n",
    "            \n",
    "            if total_confidence == 0:\n",
    "                return np.mean([p['prediction'] for p in predictions])\n",
    "            \n",
    "            weighted_sum = sum(p['prediction'] * p['confidence'] for p in predictions)\n",
    "            return weighted_sum / total_confidence\n",
    "        \n",
    "        else:\n",
    "            # é è¨­ä½¿ç”¨å¹³å‡æ³•\n",
    "            return np.mean([p['prediction'] for p in predictions])\n",
    "    \n",
    "    def _calculate_confidence(self, predictions: List[Dict[str, Any]]) -> float:\n",
    "        \"\"\"è¨ˆç®—é›†æˆç½®ä¿¡åº¦\"\"\"\n",
    "        if not predictions:\n",
    "            return 0.0\n",
    "        \n",
    "        # åŸºæ–¼é æ¸¬ä¸€è‡´æ€§å’Œå€‹åˆ¥ç½®ä¿¡åº¦è¨ˆç®—\n",
    "        pred_values = [p['prediction'] for p in predictions]\n",
    "        confidences = [p['confidence'] for p in predictions]\n",
    "        \n",
    "        # é æ¸¬æ–¹å·®ï¼ˆä¸€è‡´æ€§ï¼‰\n",
    "        consistency = 1.0 / (1.0 + np.var(pred_values))\n",
    "        \n",
    "        # å¹³å‡ç½®ä¿¡åº¦\n",
    "        avg_confidence = np.mean(confidences)\n",
    "        \n",
    "        # ç¶œåˆç½®ä¿¡åº¦\n",
    "        return (consistency + avg_confidence) / 2\n",
    "    \n",
    "    async def _fallback_prediction(self, fallback_model_id: str, \n",
    "                                  input_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"å‚™ç”¨æ¨¡å‹é æ¸¬\"\"\"\n",
    "        # ç°¡åŒ–çš„å‚™ç”¨é æ¸¬é‚è¼¯\n",
    "        fallback_result = random.uniform(0, 1)\n",
    "        \n",
    "        return {\n",
    "            'prediction': fallback_result,\n",
    "            'ensemble_id': 'fallback',\n",
    "            'models_used': [fallback_model_id],\n",
    "            'response_time_ms': 50,\n",
    "            'confidence': 0.5,\n",
    "            'is_fallback': True\n",
    "        }\n",
    "    \n",
    "    def _record_performance(self, ensemble_id: str, response_time: float, \n",
    "                          models_used: int, success: bool):\n",
    "        \"\"\"è¨˜éŒ„æ€§èƒ½æ•¸æ“š\"\"\"\n",
    "        self.performance_history[ensemble_id].append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'response_time_ms': response_time,\n",
    "            'models_used': models_used,\n",
    "            'success': success\n",
    "        })\n",
    "        \n",
    "        # åªä¿ç•™æœ€è¿‘1000æ¢è¨˜éŒ„\n",
    "        if len(self.performance_history[ensemble_id]) > 1000:\n",
    "            self.performance_history[ensemble_id] = self.performance_history[ensemble_id][-1000:]\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹çµ„åˆç®¡ç†å™¨\n",
    "ensemble_manager = EnsembleManager()\n",
    "print(\"\\nâœ… æ¨¡å‹çµ„åˆç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Pipeline å·¥ä½œæµè¨­è¨ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineStage(ABC):\n",
    "    \"\"\"Pipeline éšæ®µæŠ½è±¡åŸºé¡\"\"\"\n",
    "    \n",
    "    def __init__(self, stage_id: str, name: str):\n",
    "        self.stage_id = stage_id\n",
    "        self.name = name\n",
    "        self.execution_count = 0\n",
    "        self.total_execution_time = 0.0\n",
    "        self.error_count = 0\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def execute(self, data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"åŸ·è¡Œéšæ®µè™•ç†\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"ç²å–éšæ®µçµ±è¨ˆä¿¡æ¯\"\"\"\n",
    "        avg_time = self.total_execution_time / max(self.execution_count, 1)\n",
    "        error_rate = self.error_count / max(self.execution_count, 1)\n",
    "        \n",
    "        return {\n",
    "            'stage_id': self.stage_id,\n",
    "            'name': self.name,\n",
    "            'execution_count': self.execution_count,\n",
    "            'avg_execution_time_ms': avg_time,\n",
    "            'error_rate': error_rate\n",
    "        }\n",
    "\n",
    "class FeatureExtractionStage(PipelineStage):\n",
    "    \"\"\"ç‰¹å¾µæå–éšæ®µ\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_config: Dict[str, Any]):\n",
    "        super().__init__(\"feature_extraction\", \"ç‰¹å¾µæå–\")\n",
    "        self.feature_config = feature_config\n",
    "    \n",
    "    async def execute(self, data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # æ¨¡æ“¬ç‰¹å¾µæå–\n",
    "            await asyncio.sleep(random.uniform(0.01, 0.03))\n",
    "            \n",
    "            features = {\n",
    "                'user_features': {\n",
    "                    'age': random.randint(18, 65),\n",
    "                    'gender': random.choice(['M', 'F']),\n",
    "                    'location': random.choice(['US', 'EU', 'ASIA']),\n",
    "                    'device_type': random.choice(['mobile', 'desktop', 'tablet'])\n",
    "                },\n",
    "                'ad_features': {\n",
    "                    'category': random.choice(['tech', 'fashion', 'food', 'travel']),\n",
    "                    'bid_amount': random.uniform(0.1, 2.0),\n",
    "                    'quality_score': random.uniform(0.7, 1.0)\n",
    "                },\n",
    "                'context_features': {\n",
    "                    'time_of_day': datetime.now().hour,\n",
    "                    'day_of_week': datetime.now().weekday(),\n",
    "                    'page_type': random.choice(['search', 'content', 'social'])\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # æ›´æ–°çµ±è¨ˆ\n",
    "            execution_time = (time.time() - start_time) * 1000\n",
    "            self.execution_count += 1\n",
    "            self.total_execution_time += execution_time\n",
    "            \n",
    "            return {\n",
    "                **data,\n",
    "                'features': features,\n",
    "                'feature_extraction_time_ms': execution_time\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.error_count += 1\n",
    "            raise e\n",
    "\n",
    "class ModelInferenceStage(PipelineStage):\n",
    "    \"\"\"æ¨¡å‹æ¨ç†éšæ®µ\"\"\"\n",
    "    \n",
    "    def __init__(self, ensemble_manager: EnsembleManager):\n",
    "        super().__init__(\"model_inference\", \"æ¨¡å‹æ¨ç†\")\n",
    "        self.ensemble_manager = ensemble_manager\n",
    "    \n",
    "    async def execute(self, data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # é¸æ“‡é›†æˆé…ç½®\n",
    "            ensemble_id = context.get('ensemble_id', 'default_ensemble')\n",
    "            \n",
    "            # åŸ·è¡Œé›†æˆé æ¸¬\n",
    "            inference_result = await self.ensemble_manager.predict(ensemble_id, data)\n",
    "            \n",
    "            # æ›´æ–°çµ±è¨ˆ\n",
    "            execution_time = (time.time() - start_time) * 1000\n",
    "            self.execution_count += 1\n",
    "            self.total_execution_time += execution_time\n",
    "            \n",
    "            return {\n",
    "                **data,\n",
    "                'inference_result': inference_result,\n",
    "                'inference_time_ms': execution_time\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.error_count += 1\n",
    "            raise e\n",
    "\n",
    "class PostProcessingStage(PipelineStage):\n",
    "    \"\"\"å¾Œè™•ç†éšæ®µ\"\"\"\n",
    "    \n",
    "    def __init__(self, processing_config: Dict[str, Any]):\n",
    "        super().__init__(\"post_processing\", \"å¾Œè™•ç†\")\n",
    "        self.processing_config = processing_config\n",
    "    \n",
    "    async def execute(self, data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # æ¨¡æ“¬å¾Œè™•ç†é‚è¼¯\n",
    "            await asyncio.sleep(random.uniform(0.005, 0.015))\n",
    "            \n",
    "            inference_result = data.get('inference_result', {})\n",
    "            prediction = inference_result.get('prediction', 0)\n",
    "            confidence = inference_result.get('confidence', 0)\n",
    "            \n",
    "            # æ‡‰ç”¨æ¥­å‹™è¦å‰‡\n",
    "            adjusted_prediction = self._apply_business_rules(prediction, data.get('features', {}), context)\n",
    "            \n",
    "            # è¨ˆç®—æœ€çµ‚å‡ºåƒ¹\n",
    "            final_bid = self._calculate_bid(adjusted_prediction, data.get('features', {}), context)\n",
    "            \n",
    "            # ç”Ÿæˆè§£é‡‹\n",
    "            explanation = self._generate_explanation(adjusted_prediction, confidence, inference_result)\n",
    "            \n",
    "            # æ›´æ–°çµ±è¨ˆ\n",
    "            execution_time = (time.time() - start_time) * 1000\n",
    "            self.execution_count += 1\n",
    "            self.total_execution_time += execution_time\n",
    "            \n",
    "            return {\n",
    "                **data,\n",
    "                'final_result': {\n",
    "                    'prediction': adjusted_prediction,\n",
    "                    'confidence': confidence,\n",
    "                    'bid_amount': final_bid,\n",
    "                    'explanation': explanation\n",
    "                },\n",
    "                'post_processing_time_ms': execution_time\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.error_count += 1\n",
    "            raise e\n",
    "    \n",
    "    def _apply_business_rules(self, prediction: float, features: Dict[str, Any], \n",
    "                            context: Dict[str, Any]) -> float:\n",
    "        \"\"\"æ‡‰ç”¨æ¥­å‹™è¦å‰‡\"\"\"\n",
    "        adjusted = prediction\n",
    "        \n",
    "        # æ™‚æ®µèª¿æ•´\n",
    "        hour = features.get('context_features', {}).get('time_of_day', 12)\n",
    "        if 9 <= hour <= 17:  # å·¥ä½œæ™‚é–“\n",
    "            adjusted *= 1.2\n",
    "        elif 18 <= hour <= 22:  # æ™šä¸Šé»ƒé‡‘æ™‚æ®µ\n",
    "            adjusted *= 1.5\n",
    "        \n",
    "        # è¨­å‚™é¡å‹èª¿æ•´\n",
    "        device = features.get('user_features', {}).get('device_type', 'desktop')\n",
    "        if device == 'mobile':\n",
    "            adjusted *= 1.3\n",
    "        \n",
    "        # åœ°å€èª¿æ•´\n",
    "        location = features.get('user_features', {}).get('location', 'US')\n",
    "        if location == 'US':\n",
    "            adjusted *= 1.1\n",
    "        \n",
    "        return min(adjusted, 1.0)  # ç¢ºä¿ä¸è¶…é1\n",
    "    \n",
    "    def _calculate_bid(self, prediction: float, features: Dict[str, Any], \n",
    "                      context: Dict[str, Any]) -> float:\n",
    "        \"\"\"è¨ˆç®—å‡ºåƒ¹\"\"\"\n",
    "        base_bid = features.get('ad_features', {}).get('bid_amount', 1.0)\n",
    "        quality_score = features.get('ad_features', {}).get('quality_score', 0.8)\n",
    "        \n",
    "        # åŸºæ–¼é æ¸¬å€¼å’Œè³ªé‡åˆ†æ•¸èª¿æ•´å‡ºåƒ¹\n",
    "        adjusted_bid = base_bid * prediction * quality_score\n",
    "        \n",
    "        return round(adjusted_bid, 3)\n",
    "    \n",
    "    def _generate_explanation(self, prediction: float, confidence: float, \n",
    "                            inference_result: Dict[str, Any]) -> str:\n",
    "        \"\"\"ç”Ÿæˆè§£é‡‹\"\"\"\n",
    "        models_used = inference_result.get('models_used', [])\n",
    "        \n",
    "        explanation = f\"é æ¸¬å€¼: {prediction:.3f}, ç½®ä¿¡åº¦: {confidence:.3f}\"\n",
    "        if models_used:\n",
    "            explanation += f\", ä½¿ç”¨æ¨¡å‹: {', '.join(models_used)}\"\n",
    "        \n",
    "        return explanation\n",
    "\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"Pipeline é…ç½®\"\"\"\n",
    "    pipeline_id: str\n",
    "    name: str\n",
    "    stages: List[PipelineStage]\n",
    "    timeout_ms: int = 5000\n",
    "    retry_attempts: int = 2\n",
    "    parallel_stages: Dict[str, List[str]] = field(default_factory=dict)\n",
    "    conditional_stages: Dict[str, Dict[str, Any]] = field(default_factory=dict)\n",
    "    error_handling: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "class PipelineManager:\n",
    "    \"\"\"Pipeline ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipelines: Dict[str, PipelineConfig] = {}\n",
    "        self.execution_history: Dict[str, List[Dict[str, Any]]] = defaultdict(list)\n",
    "        self.stage_metrics: Dict[str, Dict[str, Any]] = defaultdict(dict)\n",
    "    \n",
    "    def register_pipeline(self, config: PipelineConfig) -> bool:\n",
    "        \"\"\"è¨»å†Š Pipeline\"\"\"\n",
    "        try:\n",
    "            self._validate_pipeline_config(config)\n",
    "            self.pipelines[config.pipeline_id] = config\n",
    "            \n",
    "            logger.info(f\"âœ… Pipeline {config.name} è¨»å†ŠæˆåŠŸ\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Pipeline è¨»å†Šå¤±æ•—: {e}\")\n",
    "            return False\n",
    "    \n",
    "    async def execute_pipeline(self, pipeline_id: str, input_data: Dict[str, Any], \n",
    "                             context: Dict[str, Any] = None) -> Dict[str, Any]:\n",
    "        \"\"\"åŸ·è¡Œ Pipeline\"\"\"\n",
    "        if pipeline_id not in self.pipelines:\n",
    "            raise ValueError(f\"Pipeline {pipeline_id} ä¸å­˜åœ¨\")\n",
    "        \n",
    "        config = self.pipelines[pipeline_id]\n",
    "        context = context or {}\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # åˆå§‹åŒ–åŸ·è¡Œä¸Šä¸‹æ–‡\n",
    "            execution_context = {\n",
    "                'pipeline_id': pipeline_id,\n",
    "                'execution_id': str(uuid.uuid4()),\n",
    "                'start_time': start_time,\n",
    "                **context\n",
    "            }\n",
    "            \n",
    "            # åŸ·è¡Œéšæ®µ\n",
    "            result = await self._execute_stages(config, input_data, execution_context)\n",
    "            \n",
    "            # è¨˜éŒ„åŸ·è¡Œæ­·å²\n",
    "            execution_time = (time.time() - start_time) * 1000\n",
    "            self._record_execution(pipeline_id, execution_time, True, len(config.stages))\n",
    "            \n",
    "            return {\n",
    "                **result,\n",
    "                'pipeline_metadata': {\n",
    "                    'pipeline_id': pipeline_id,\n",
    "                    'execution_id': execution_context['execution_id'],\n",
    "                    'total_time_ms': execution_time,\n",
    "                    'stages_executed': len(config.stages)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            execution_time = (time.time() - start_time) * 1000\n",
    "            self._record_execution(pipeline_id, execution_time, False, 0)\n",
    "            raise e\n",
    "    \n",
    "    async def _execute_stages(self, config: PipelineConfig, data: Dict[str, Any], \n",
    "                            context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"åŸ·è¡Œéšæ®µ\"\"\"\n",
    "        current_data = data.copy()\n",
    "        \n",
    "        for stage in config.stages:\n",
    "            # æª¢æŸ¥æ¢ä»¶åŸ·è¡Œ\n",
    "            if stage.stage_id in config.conditional_stages:\n",
    "                condition = config.conditional_stages[stage.stage_id]\n",
    "                if not self._evaluate_condition(condition, current_data, context):\n",
    "                    logger.info(f\"è·³ééšæ®µ {stage.name}ï¼Œæ¢ä»¶ä¸ç¬¦åˆ\")\n",
    "                    continue\n",
    "            \n",
    "            # åŸ·è¡Œéšæ®µ\n",
    "            try:\n",
    "                stage_start = time.time()\n",
    "                current_data = await stage.execute(current_data, context)\n",
    "                stage_time = (time.time() - stage_start) * 1000\n",
    "                \n",
    "                logger.debug(f\"éšæ®µ {stage.name} åŸ·è¡Œå®Œæˆï¼Œè€—æ™‚ {stage_time:.1f}ms\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                # éŒ¯èª¤è™•ç†\n",
    "                error_strategy = config.error_handling.get(stage.stage_id, 'fail')\n",
    "                \n",
    "                if error_strategy == 'skip':\n",
    "                    logger.warning(f\"éšæ®µ {stage.name} åŸ·è¡Œå¤±æ•—ï¼Œè·³é: {e}\")\n",
    "                    continue\n",
    "                elif error_strategy == 'retry':\n",
    "                    # ç°¡å–®é‡è©¦é‚è¼¯\n",
    "                    logger.warning(f\"éšæ®µ {stage.name} åŸ·è¡Œå¤±æ•—ï¼Œé‡è©¦: {e}\")\n",
    "                    await asyncio.sleep(0.1)\n",
    "                    current_data = await stage.execute(current_data, context)\n",
    "                else:\n",
    "                    raise e\n",
    "        \n",
    "        return current_data\n",
    "    \n",
    "    def _evaluate_condition(self, condition: Dict[str, Any], data: Dict[str, Any], \n",
    "                          context: Dict[str, Any]) -> bool:\n",
    "        \"\"\"è©•ä¼°æ¢ä»¶\"\"\"\n",
    "        # ç°¡åŒ–çš„æ¢ä»¶è©•ä¼°é‚è¼¯\n",
    "        if 'field' in condition and 'value' in condition:\n",
    "            field_value = self._get_nested_value(data, condition['field'])\n",
    "            operator = condition.get('operator', 'eq')\n",
    "            \n",
    "            if operator == 'eq':\n",
    "                return field_value == condition['value']\n",
    "            elif operator == 'gt':\n",
    "                return field_value > condition['value']\n",
    "            elif operator == 'lt':\n",
    "                return field_value < condition['value']\n",
    "            elif operator == 'in':\n",
    "                return field_value in condition['value']\n",
    "        \n",
    "        return True  # é è¨­é€šé\n",
    "    \n",
    "    def _get_nested_value(self, data: Dict[str, Any], field_path: str) -> Any:\n",
    "        \"\"\"ç²å–åµŒå¥—å­—æ®µå€¼\"\"\"\n",
    "        keys = field_path.split('.')\n",
    "        current = data\n",
    "        \n",
    "        for key in keys:\n",
    "            if isinstance(current, dict) and key in current:\n",
    "                current = current[key]\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        return current\n",
    "    \n",
    "    def _validate_pipeline_config(self, config: PipelineConfig):\n",
    "        \"\"\"é©—è­‰ Pipeline é…ç½®\"\"\"\n",
    "        if not config.stages:\n",
    "            raise ValueError(\"Pipeline å¿…é ˆåŒ…å«è‡³å°‘ä¸€å€‹éšæ®µ\")\n",
    "        \n",
    "        stage_ids = [stage.stage_id for stage in config.stages]\n",
    "        if len(stage_ids) != len(set(stage_ids)):\n",
    "            raise ValueError(\"éšæ®µIDå¿…é ˆå”¯ä¸€\")\n",
    "    \n",
    "    def _record_execution(self, pipeline_id: str, execution_time: float, \n",
    "                         success: bool, stages_executed: int):\n",
    "        \"\"\"è¨˜éŒ„åŸ·è¡Œæ­·å²\"\"\"\n",
    "        self.execution_history[pipeline_id].append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'execution_time_ms': execution_time,\n",
    "            'success': success,\n",
    "            'stages_executed': stages_executed\n",
    "        })\n",
    "        \n",
    "        # åªä¿ç•™æœ€è¿‘1000æ¢è¨˜éŒ„\n",
    "        if len(self.execution_history[pipeline_id]) > 1000:\n",
    "            self.execution_history[pipeline_id] = self.execution_history[pipeline_id][-1000:]\n",
    "    \n",
    "    def get_pipeline_statistics(self, pipeline_id: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"ç²å– Pipeline çµ±è¨ˆä¿¡æ¯\"\"\"\n",
    "        if pipeline_id not in self.pipelines:\n",
    "            return None\n",
    "        \n",
    "        config = self.pipelines[pipeline_id]\n",
    "        history = self.execution_history[pipeline_id]\n",
    "        \n",
    "        if not history:\n",
    "            return {\n",
    "                'pipeline_id': pipeline_id,\n",
    "                'name': config.name,\n",
    "                'total_executions': 0,\n",
    "                'success_rate': 0,\n",
    "                'avg_execution_time_ms': 0,\n",
    "                'stage_statistics': [stage.get_statistics() for stage in config.stages]\n",
    "            }\n",
    "        \n",
    "        total_executions = len(history)\n",
    "        successful_executions = sum(1 for h in history if h['success'])\n",
    "        success_rate = successful_executions / total_executions\n",
    "        avg_execution_time = np.mean([h['execution_time_ms'] for h in history])\n",
    "        \n",
    "        return {\n",
    "            'pipeline_id': pipeline_id,\n",
    "            'name': config.name,\n",
    "            'total_executions': total_executions,\n",
    "            'success_rate': success_rate,\n",
    "            'avg_execution_time_ms': avg_execution_time,\n",
    "            'stage_statistics': [stage.get_statistics() for stage in config.stages]\n",
    "        }\n",
    "\n",
    "# åˆå§‹åŒ– Pipeline ç®¡ç†å™¨\n",
    "pipeline_manager = PipelineManager()\n",
    "print(\"\\nâœ… Pipeline ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ æ™ºèƒ½è² è¼‰å‡è¡¡èˆ‡å‹•æ…‹èª¿åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadBalancer:\n",
    "    \"\"\"æ™ºèƒ½è² è¼‰å‡è¡¡å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.load_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=100))\n",
    "        self.response_times: Dict[str, deque] = defaultdict(lambda: deque(maxlen=50))\n",
    "        self.error_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.total_requests: Dict[str, int] = defaultdict(int)\n",
    "    \n",
    "    def select_endpoint(self, endpoints: List[ModelEndpoint], \n",
    "                       strategy: RoutingStrategy) -> Optional[ModelEndpoint]:\n",
    "        \"\"\"é¸æ“‡ç«¯é»\"\"\"\n",
    "        available_endpoints = [ep for ep in endpoints if ep.is_healthy]\n",
    "        \n",
    "        if not available_endpoints:\n",
    "            return None\n",
    "        \n",
    "        if strategy == RoutingStrategy.ROUND_ROBIN:\n",
    "            return self._round_robin_selection(available_endpoints)\n",
    "        elif strategy == RoutingStrategy.RANDOM:\n",
    "            return random.choice(available_endpoints)\n",
    "        elif strategy == RoutingStrategy.WEIGHTED_RANDOM:\n",
    "            return self._weighted_random_selection(available_endpoints)\n",
    "        elif strategy == RoutingStrategy.LEAST_LOADED:\n",
    "            return self._least_loaded_selection(available_endpoints)\n",
    "        elif strategy == RoutingStrategy.FASTEST_RESPONSE:\n",
    "            return self._fastest_response_selection(available_endpoints)\n",
    "        elif strategy == RoutingStrategy.PERFORMANCE_BASED:\n",
    "            return self._performance_based_selection(available_endpoints)\n",
    "        else:\n",
    "            return available_endpoints[0]\n",
    "    \n",
    "    def update_endpoint_metrics(self, endpoint_id: str, response_time: float, \n",
    "                              success: bool, current_load: int):\n",
    "        \"\"\"æ›´æ–°ç«¯é»æŒ‡æ¨™\"\"\"\n",
    "        self.load_history[endpoint_id].append(current_load)\n",
    "        self.response_times[endpoint_id].append(response_time)\n",
    "        self.total_requests[endpoint_id] += 1\n",
    "        \n",
    "        if not success:\n",
    "            self.error_counts[endpoint_id] += 1\n",
    "    \n",
    "    def get_endpoint_score(self, endpoint: ModelEndpoint) -> float:\n",
    "        \"\"\"è¨ˆç®—ç«¯é»è©•åˆ†\"\"\"\n",
    "        endpoint_id = endpoint.model_id\n",
    "        \n",
    "        # åŸºç¤åˆ†æ•¸\n",
    "        base_score = 1.0\n",
    "        \n",
    "        # éŸ¿æ‡‰æ™‚é–“å› å­ (è¶Šå¿«è¶Šå¥½)\n",
    "        if self.response_times[endpoint_id]:\n",
    "            avg_response_time = np.mean(list(self.response_times[endpoint_id]))\n",
    "            response_factor = 1.0 / (1.0 + avg_response_time / 100)  # 100ms ç‚ºåŸºæº–\n",
    "        else:\n",
    "            response_factor = 1.0\n",
    "        \n",
    "        # è² è¼‰å› å­ (è² è¼‰è¶Šä½è¶Šå¥½)\n",
    "        if self.load_history[endpoint_id]:\n",
    "            avg_load = np.mean(list(self.load_history[endpoint_id]))\n",
    "            load_factor = 1.0 / (1.0 + avg_load / endpoint.max_concurrent_requests)\n",
    "        else:\n",
    "            load_factor = 1.0\n",
    "        \n",
    "        # éŒ¯èª¤ç‡å› å­ (éŒ¯èª¤ç‡è¶Šä½è¶Šå¥½)\n",
    "        if self.total_requests[endpoint_id] > 0:\n",
    "            error_rate = self.error_counts[endpoint_id] / self.total_requests[endpoint_id]\n",
    "            error_factor = 1.0 - error_rate\n",
    "        else:\n",
    "            error_factor = 1.0\n",
    "        \n",
    "        # æ¬Šé‡å› å­\n",
    "        weight_factor = endpoint.weight\n",
    "        \n",
    "        # ç¶œåˆè©•åˆ†\n",
    "        total_score = base_score * response_factor * load_factor * error_factor * weight_factor\n",
    "        \n",
    "        return total_score\n",
    "    \n",
    "    def _round_robin_selection(self, endpoints: List[ModelEndpoint]) -> ModelEndpoint:\n",
    "        \"\"\"è¼ªè©¢é¸æ“‡\"\"\"\n",
    "        # ç°¡åŒ–çš„è¼ªè©¢å¯¦ç¾\n",
    "        total_requests = sum(self.total_requests[ep.model_id] for ep in endpoints)\n",
    "        return min(endpoints, key=lambda ep: self.total_requests[ep.model_id])\n",
    "    \n",
    "    def _weighted_random_selection(self, endpoints: List[ModelEndpoint]) -> ModelEndpoint:\n",
    "        \"\"\"åŠ æ¬Šéš¨æ©Ÿé¸æ“‡\"\"\"\n",
    "        weights = [ep.weight for ep in endpoints]\n",
    "        total_weight = sum(weights)\n",
    "        \n",
    "        if total_weight == 0:\n",
    "            return random.choice(endpoints)\n",
    "        \n",
    "        rand = random.uniform(0, total_weight)\n",
    "        current_weight = 0\n",
    "        \n",
    "        for endpoint in endpoints:\n",
    "            current_weight += endpoint.weight\n",
    "            if rand <= current_weight:\n",
    "                return endpoint\n",
    "        \n",
    "        return endpoints[-1]\n",
    "    \n",
    "    def _least_loaded_selection(self, endpoints: List[ModelEndpoint]) -> ModelEndpoint:\n",
    "        \"\"\"æœ€å°‘è² è¼‰é¸æ“‡\"\"\"\n",
    "        return min(endpoints, key=lambda ep: ep.current_load)\n",
    "    \n",
    "    def _fastest_response_selection(self, endpoints: List[ModelEndpoint]) -> ModelEndpoint:\n",
    "        \"\"\"æœ€å¿«éŸ¿æ‡‰é¸æ“‡\"\"\"\n",
    "        return min(endpoints, key=lambda ep: ep.avg_response_time_ms)\n",
    "    \n",
    "    def _performance_based_selection(self, endpoints: List[ModelEndpoint]) -> ModelEndpoint:\n",
    "        \"\"\"åŸºæ–¼æ€§èƒ½é¸æ“‡\"\"\"\n",
    "        scored_endpoints = [(ep, self.get_endpoint_score(ep)) for ep in endpoints]\n",
    "        scored_endpoints.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return scored_endpoints[0][0]\n",
    "\n",
    "class HealthMonitor:\n",
    "    \"\"\"å¥åº·ç›£æ§å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.monitored_ensembles: Dict[str, EnsembleConfig] = {}\n",
    "        self.health_checks: Dict[str, Dict[str, Any]] = defaultdict(dict)\n",
    "        self.monitoring_active = False\n",
    "        self.monitor_thread = None\n",
    "    \n",
    "    def register_ensemble(self, config: EnsembleConfig):\n",
    "        \"\"\"è¨»å†Šé›†æˆé€²è¡Œç›£æ§\"\"\"\n",
    "        self.monitored_ensembles[config.ensemble_id] = config\n",
    "        \n",
    "        # åˆå§‹åŒ–å¥åº·æª¢æŸ¥ç‹€æ…‹\n",
    "        for model in config.models:\n",
    "            self.health_checks[config.ensemble_id][model.model_id] = {\n",
    "                'last_check': datetime.now(),\n",
    "                'consecutive_failures': 0,\n",
    "                'is_healthy': True\n",
    "            }\n",
    "    \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"é–‹å§‹å¥åº·ç›£æ§\"\"\"\n",
    "        if self.monitoring_active:\n",
    "            return\n",
    "        \n",
    "        self.monitoring_active = True\n",
    "        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)\n",
    "        self.monitor_thread.start()\n",
    "        \n",
    "        logger.info(\"ğŸ” å¥åº·ç›£æ§å·²å•Ÿå‹•\")\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"åœæ­¢å¥åº·ç›£æ§\"\"\"\n",
    "        self.monitoring_active = False\n",
    "        if self.monitor_thread:\n",
    "            self.monitor_thread.join(timeout=5)\n",
    "        \n",
    "        logger.info(\"â¹ï¸ å¥åº·ç›£æ§å·²åœæ­¢\")\n",
    "    \n",
    "    async def check_model_health(self, model: ModelEndpoint) -> bool:\n",
    "        \"\"\"æª¢æŸ¥æ¨¡å‹å¥åº·ç‹€æ…‹\"\"\"\n",
    "        try:\n",
    "            # æ¨¡æ“¬å¥åº·æª¢æŸ¥ï¼ˆå¯¦éš›ç’°å¢ƒä¸­æœƒç™¼é€pingè«‹æ±‚ï¼‰\n",
    "            await asyncio.sleep(random.uniform(0.001, 0.01))\n",
    "            \n",
    "            # æ¨¡æ“¬å¶ç™¼çš„å¥åº·å•é¡Œ\n",
    "            is_healthy = random.random() > 0.02  # 2% æ©Ÿç‡ä¸å¥åº·\n",
    "            \n",
    "            return is_healthy\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"æ¨¡å‹ {model.model_id} å¥åº·æª¢æŸ¥å¤±æ•—: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def update_model_health(self, ensemble_id: str, model_id: str, is_healthy: bool):\n",
    "        \"\"\"æ›´æ–°æ¨¡å‹å¥åº·ç‹€æ…‹\"\"\"\n",
    "        if ensemble_id not in self.health_checks:\n",
    "            return\n",
    "        \n",
    "        health_info = self.health_checks[ensemble_id].get(model_id, {})\n",
    "        \n",
    "        if is_healthy:\n",
    "            health_info['consecutive_failures'] = 0\n",
    "            health_info['is_healthy'] = True\n",
    "        else:\n",
    "            health_info['consecutive_failures'] = health_info.get('consecutive_failures', 0) + 1\n",
    "            \n",
    "            # é€£çºŒå¤±æ•—3æ¬¡å‰‡æ¨™è¨˜ç‚ºä¸å¥åº·\n",
    "            if health_info['consecutive_failures'] >= 3:\n",
    "                health_info['is_healthy'] = False\n",
    "                logger.warning(f\"æ¨¡å‹ {model_id} è¢«æ¨™è¨˜ç‚ºä¸å¥åº·\")\n",
    "        \n",
    "        health_info['last_check'] = datetime.now()\n",
    "        self.health_checks[ensemble_id][model_id] = health_info\n",
    "        \n",
    "        # æ›´æ–°é›†æˆé…ç½®ä¸­çš„å¥åº·ç‹€æ…‹\n",
    "        if ensemble_id in self.monitored_ensembles:\n",
    "            config = self.monitored_ensembles[ensemble_id]\n",
    "            for model in config.models:\n",
    "                if model.model_id == model_id:\n",
    "                    model.is_healthy = health_info['is_healthy']\n",
    "                    break\n",
    "    \n",
    "    def _monitoring_loop(self):\n",
    "        \"\"\"ç›£æ§ä¸»å¾ªç’°\"\"\"\n",
    "        while self.monitoring_active:\n",
    "            try:\n",
    "                for ensemble_id, config in self.monitored_ensembles.items():\n",
    "                    for model in config.models:\n",
    "                        # ç•°æ­¥åŸ·è¡Œå¥åº·æª¢æŸ¥\n",
    "                        health_task = asyncio.run(self.check_model_health(model))\n",
    "                        self.update_model_health(ensemble_id, model.model_id, health_task)\n",
    "                \n",
    "                time.sleep(30)  # 30ç§’æª¢æŸ¥ä¸€æ¬¡\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"å¥åº·ç›£æ§éŒ¯èª¤: {e}\")\n",
    "                time.sleep(10)\n",
    "\n",
    "class AdaptiveOptimizer:\n",
    "    \"\"\"è‡ªé©æ‡‰å„ªåŒ–å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.optimization_history: Dict[str, List[Dict[str, Any]]] = defaultdict(list)\n",
    "        self.learning_rate = 0.1\n",
    "        self.optimization_active = False\n",
    "    \n",
    "    def start_optimization(self, ensemble_manager: EnsembleManager):\n",
    "        \"\"\"é–‹å§‹è‡ªé©æ‡‰å„ªåŒ–\"\"\"\n",
    "        if self.optimization_active:\n",
    "            return\n",
    "        \n",
    "        self.optimization_active = True\n",
    "        self.ensemble_manager = ensemble_manager\n",
    "        \n",
    "        # å•Ÿå‹•å„ªåŒ–ç·šç¨‹\n",
    "        optimization_thread = threading.Thread(target=self._optimization_loop, daemon=True)\n",
    "        optimization_thread.start()\n",
    "        \n",
    "        logger.info(\"ğŸ§  è‡ªé©æ‡‰å„ªåŒ–å·²å•Ÿå‹•\")\n",
    "    \n",
    "    def stop_optimization(self):\n",
    "        \"\"\"åœæ­¢è‡ªé©æ‡‰å„ªåŒ–\"\"\"\n",
    "        self.optimization_active = False\n",
    "        logger.info(\"â¹ï¸ è‡ªé©æ‡‰å„ªåŒ–å·²åœæ­¢\")\n",
    "    \n",
    "    def optimize_weights(self, ensemble_id: str) -> bool:\n",
    "        \"\"\"å„ªåŒ–æ¨¡å‹æ¬Šé‡\"\"\"\n",
    "        if ensemble_id not in self.ensemble_manager.ensembles:\n",
    "            return False\n",
    "        \n",
    "        config = self.ensemble_manager.ensembles[ensemble_id]\n",
    "        performance_data = self.ensemble_manager.performance_history.get(ensemble_id, [])\n",
    "        \n",
    "        if len(performance_data) < 50:  # éœ€è¦è¶³å¤ çš„æ•¸æ“š\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # åˆ†ææœ€è¿‘æ€§èƒ½\n",
    "            recent_data = performance_data[-50:]\n",
    "            avg_response_time = np.mean([d['response_time_ms'] for d in recent_data])\n",
    "            success_rate = np.mean([d['success'] for d in recent_data])\n",
    "            \n",
    "            # åŸºæ–¼æ€§èƒ½èª¿æ•´æ¬Šé‡\n",
    "            for model in config.models:\n",
    "                if model.is_healthy:\n",
    "                    # æ€§èƒ½å¥½çš„æ¨¡å‹å¢åŠ æ¬Šé‡\n",
    "                    if model.avg_response_time_ms < avg_response_time and model.success_rate > success_rate:\n",
    "                        model.weight *= (1 + self.learning_rate)\n",
    "                    # æ€§èƒ½å·®çš„æ¨¡å‹æ¸›å°‘æ¬Šé‡\n",
    "                    elif model.avg_response_time_ms > avg_response_time or model.success_rate < success_rate:\n",
    "                        model.weight *= (1 - self.learning_rate)\n",
    "                    \n",
    "                    # ç¢ºä¿æ¬Šé‡åœ¨åˆç†ç¯„åœ\n",
    "                    model.weight = max(0.1, min(2.0, model.weight))\n",
    "            \n",
    "            # è¨˜éŒ„å„ªåŒ–æ­·å²\n",
    "            self.optimization_history[ensemble_id].append({\n",
    "                'timestamp': datetime.now(),\n",
    "                'avg_response_time': avg_response_time,\n",
    "                'success_rate': success_rate,\n",
    "                'weights': {model.model_id: model.weight for model in config.models}\n",
    "            })\n",
    "            \n",
    "            logger.info(f\"ğŸ”§ é›†æˆ {ensemble_id} æ¬Šé‡å·²å„ªåŒ–\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"æ¬Šé‡å„ªåŒ–å¤±æ•—: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _optimization_loop(self):\n",
    "        \"\"\"å„ªåŒ–ä¸»å¾ªç’°\"\"\"\n",
    "        while self.optimization_active:\n",
    "            try:\n",
    "                for ensemble_id in self.ensemble_manager.ensembles.keys():\n",
    "                    self.optimize_weights(ensemble_id)\n",
    "                \n",
    "                time.sleep(300)  # 5åˆ†é˜å„ªåŒ–ä¸€æ¬¡\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"å„ªåŒ–å¾ªç’°éŒ¯èª¤: {e}\")\n",
    "                time.sleep(60)\n",
    "\n",
    "print(\"\\nâœ… æ™ºèƒ½è² è¼‰å‡è¡¡èˆ‡å‹•æ…‹èª¿åº¦ç³»çµ±åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸª Google Ads æ™ºèƒ½ç«¶åƒ¹ç³»çµ±æ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰µå»º Google Ads æ™ºèƒ½ç«¶åƒ¹ç³»çµ±çš„å®Œæ•´æ¼”ç¤º\n",
    "print(\"ğŸª Google Ads æ™ºèƒ½ç«¶åƒ¹ç³»çµ±æ¼”ç¤º\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. å‰µå»ºæ¨¡å‹ç«¯é»\n",
    "print(\"\\nğŸ“‹ æ­¥é©Ÿ 1: å‰µå»ºæ¨¡å‹ç«¯é»...\")\n",
    "\n",
    "# CTR (é»æ“Šç‡) é æ¸¬æ¨¡å‹\n",
    "ctr_models = [\n",
    "    ModelEndpoint(\n",
    "        model_id=\"ctr_model_v1\",\n",
    "        endpoint_url=\"http://triton:8000/v2/models/ctr_model_v1\",\n",
    "        model_type=\"ctr_model\",\n",
    "        version=\"1.0.0\",\n",
    "        weight=1.0,\n",
    "        max_concurrent_requests=20,\n",
    "        timeout_ms=50,\n",
    "        metadata={\"specialization\": \"display_ads\", \"region\": \"global\"}\n",
    "    ),\n",
    "    ModelEndpoint(\n",
    "        model_id=\"ctr_model_v2\",\n",
    "        endpoint_url=\"http://triton:8000/v2/models/ctr_model_v2\",\n",
    "        model_type=\"ctr_model\",\n",
    "        version=\"2.0.0\",\n",
    "        weight=1.2,\n",
    "        max_concurrent_requests=25,\n",
    "        timeout_ms=45,\n",
    "        metadata={\"specialization\": \"search_ads\", \"region\": \"US\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# CVR (è½‰æ›ç‡) é æ¸¬æ¨¡å‹\n",
    "cvr_models = [\n",
    "    ModelEndpoint(\n",
    "        model_id=\"cvr_model_v1\",\n",
    "        endpoint_url=\"http://triton:8000/v2/models/cvr_model_v1\",\n",
    "        model_type=\"cvr_model\",\n",
    "        version=\"1.0.0\",\n",
    "        weight=1.0,\n",
    "        max_concurrent_requests=15,\n",
    "        timeout_ms=60,\n",
    "        metadata={\"specialization\": \"ecommerce\", \"region\": \"global\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# è³ªé‡åˆ†æ•¸æ¨¡å‹\n",
    "quality_models = [\n",
    "    ModelEndpoint(\n",
    "        model_id=\"quality_model_v1\",\n",
    "        endpoint_url=\"http://triton:8000/v2/models/quality_model_v1\",\n",
    "        model_type=\"quality_model\",\n",
    "        version=\"1.0.0\",\n",
    "        weight=1.0,\n",
    "        max_concurrent_requests=30,\n",
    "        timeout_ms=30,\n",
    "        metadata={\"specialization\": \"ad_quality\", \"region\": \"global\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"  âœ… å‰µå»ºäº† {len(ctr_models + cvr_models + quality_models)} å€‹æ¨¡å‹ç«¯é»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. å‰µå»ºæ¨¡å‹çµ„åˆé…ç½®\n",
    "print(\"\\nğŸ­ æ­¥é©Ÿ 2: å‰µå»ºæ¨¡å‹çµ„åˆé…ç½®...\")\n",
    "\n",
    "# CTR é æ¸¬é›†æˆ\n",
    "ctr_ensemble = EnsembleConfig(\n",
    "    ensemble_id=\"ctr_ensemble\",\n",
    "    name=\"CTR é æ¸¬é›†æˆ\",\n",
    "    method=EnsembleMethod.WEIGHTED_AVERAGE,\n",
    "    models=ctr_models,\n",
    "    routing_strategy=RoutingStrategy.PERFORMANCE_BASED,\n",
    "    min_models_required=1,\n",
    "    timeout_ms=100,\n",
    "    fallback_model=\"ctr_model_v1\",\n",
    "    routing_conditions={\n",
    "        'data_type': ['search', 'display'],\n",
    "        'model_type': ['ctr_model'],\n",
    "        'min_confidence': 0.7\n",
    "    },\n",
    "    auto_scaling_enabled=True\n",
    ")\n",
    "\n",
    "# CVR é æ¸¬é›†æˆ\n",
    "cvr_ensemble = EnsembleConfig(\n",
    "    ensemble_id=\"cvr_ensemble\",\n",
    "    name=\"CVR é æ¸¬é›†æˆ\",\n",
    "    method=EnsembleMethod.AVERAGING,\n",
    "    models=cvr_models,\n",
    "    routing_strategy=RoutingStrategy.LEAST_LOADED,\n",
    "    min_models_required=1,\n",
    "    timeout_ms=150,\n",
    "    routing_conditions={\n",
    "        'data_type': ['conversion'],\n",
    "        'model_type': ['cvr_model']\n",
    "    }\n",
    ")\n",
    "\n",
    "# è³ªé‡åˆ†æ•¸é›†æˆ\n",
    "quality_ensemble = EnsembleConfig(\n",
    "    ensemble_id=\"quality_ensemble\",\n",
    "    name=\"è³ªé‡åˆ†æ•¸é›†æˆ\",\n",
    "    method=EnsembleMethod.DYNAMIC_WEIGHTING,\n",
    "    models=quality_models,\n",
    "    routing_strategy=RoutingStrategy.FASTEST_RESPONSE,\n",
    "    min_models_required=1,\n",
    "    timeout_ms=80,\n",
    "    routing_conditions={\n",
    "        'data_type': ['quality_check'],\n",
    "        'model_type': ['quality_model']\n",
    "    }\n",
    ")\n",
    "\n",
    "# è¨»å†Šé›†æˆ\n",
    "ensembles = [ctr_ensemble, cvr_ensemble, quality_ensemble]\n",
    "for ensemble in ensembles:\n",
    "    success = ensemble_manager.create_ensemble(ensemble)\n",
    "    if success:\n",
    "        print(f\"  âœ… {ensemble.name} å‰µå»ºæˆåŠŸ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ç•¶å‰è¨»å†Šé›†æˆæ•¸é‡: {len(ensemble_manager.ensembles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. å‰µå»º Pipeline å·¥ä½œæµ\n",
    "print(\"\\nğŸš€ æ­¥é©Ÿ 3: å‰µå»º Pipeline å·¥ä½œæµ...\")\n",
    "\n",
    "# å‰µå»ºéšæ®µ\n",
    "feature_stage = FeatureExtractionStage({\n",
    "    \"user_features\": [\"age\", \"gender\", \"location\", \"device_type\"],\n",
    "    \"ad_features\": [\"category\", \"bid_amount\", \"quality_score\"],\n",
    "    \"context_features\": [\"time_of_day\", \"day_of_week\", \"page_type\"]\n",
    "})\n",
    "\n",
    "inference_stage = ModelInferenceStage(ensemble_manager)\n",
    "\n",
    "post_processing_stage = PostProcessingStage({\n",
    "    \"business_rules\": True,\n",
    "    \"bid_calculation\": True,\n",
    "    \"explanation_generation\": True\n",
    "})\n",
    "\n",
    "# å‰µå»º Pipeline é…ç½®\n",
    "ads_pipeline = PipelineConfig(\n",
    "    pipeline_id=\"google_ads_bidding\",\n",
    "    name=\"Google Ads æ™ºèƒ½ç«¶åƒ¹ Pipeline\",\n",
    "    stages=[feature_stage, inference_stage, post_processing_stage],\n",
    "    timeout_ms=200,\n",
    "    retry_attempts=1,\n",
    "    conditional_stages={\n",
    "        \"post_processing\": {\n",
    "            \"field\": \"inference_result.confidence\",\n",
    "            \"operator\": \"gt\",\n",
    "            \"value\": 0.5\n",
    "        }\n",
    "    },\n",
    "    error_handling={\n",
    "        \"feature_extraction\": \"retry\",\n",
    "        \"model_inference\": \"skip\",\n",
    "        \"post_processing\": \"fail\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# è¨»å†Š Pipeline\n",
    "success = pipeline_manager.register_pipeline(ads_pipeline)\n",
    "if success:\n",
    "    print(f\"  âœ… {ads_pipeline.name} å‰µå»ºæˆåŠŸ\")\n",
    "    print(f\"  ğŸ“‹ åŒ…å« {len(ads_pipeline.stages)} å€‹è™•ç†éšæ®µ\")\n",
    "    for stage in ads_pipeline.stages:\n",
    "        print(f\"    - {stage.name} ({stage.stage_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. å•Ÿå‹•ç›£æ§å’Œå„ªåŒ–ç³»çµ±\n",
    "print(\"\\nğŸ” æ­¥é©Ÿ 4: å•Ÿå‹•ç›£æ§å’Œå„ªåŒ–ç³»çµ±...\")\n",
    "\n",
    "# å•Ÿå‹•å¥åº·ç›£æ§\n",
    "ensemble_manager.health_monitor.start_monitoring()\n",
    "\n",
    "# å•Ÿå‹•è‡ªé©æ‡‰å„ªåŒ–\n",
    "ensemble_manager.adaptive_optimizer.start_optimization(ensemble_manager)\n",
    "\n",
    "print(\"  âœ… å¥åº·ç›£æ§ç³»çµ±å·²å•Ÿå‹•\")\n",
    "print(\"  âœ… è‡ªé©æ‡‰å„ªåŒ–ç³»çµ±å·²å•Ÿå‹•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. æ¨¡æ“¬ç«¶åƒ¹è«‹æ±‚è™•ç†\n",
    "print(\"\\nğŸ¯ æ­¥é©Ÿ 5: æ¨¡æ“¬ç«¶åƒ¹è«‹æ±‚è™•ç†...\")\n",
    "\n",
    "async def simulate_bidding_requests(num_requests: int = 20):\n",
    "    \"\"\"æ¨¡æ“¬ç«¶åƒ¹è«‹æ±‚\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        # ç”Ÿæˆæ¨¡æ“¬è«‹æ±‚æ•¸æ“š\n",
    "        request_data = {\n",
    "            'request_id': f'req_{i+1:03d}',\n",
    "            'ad_id': f'ad_{random.randint(1000, 9999)}',\n",
    "            'user_id': f'user_{random.randint(10000, 99999)}',\n",
    "            'data_type': random.choice(['search', 'display', 'conversion']),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # æ ¹æ“šæ•¸æ“šé¡å‹é¸æ“‡é›†æˆ\n",
    "        if request_data['data_type'] == 'search':\n",
    "            ensemble_id = 'ctr_ensemble'\n",
    "        elif request_data['data_type'] == 'conversion':\n",
    "            ensemble_id = 'cvr_ensemble'\n",
    "        else:\n",
    "            ensemble_id = 'quality_ensemble'\n",
    "        \n",
    "        context = {\n",
    "            'ensemble_id': ensemble_id,\n",
    "            'request_type': 'bidding',\n",
    "            'priority': 'high'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # åŸ·è¡Œ Pipeline\n",
    "            start_time = time.time()\n",
    "            result = await pipeline_manager.execute_pipeline(\n",
    "                'google_ads_bidding', \n",
    "                request_data, \n",
    "                context\n",
    "            )\n",
    "            \n",
    "            processing_time = (time.time() - start_time) * 1000\n",
    "            \n",
    "            results.append({\n",
    "                'request_id': request_data['request_id'],\n",
    "                'data_type': request_data['data_type'],\n",
    "                'ensemble_used': ensemble_id,\n",
    "                'processing_time_ms': processing_time,\n",
    "                'success': True,\n",
    "                'final_bid': result.get('final_result', {}).get('bid_amount', 0),\n",
    "                'prediction': result.get('final_result', {}).get('prediction', 0),\n",
    "                'confidence': result.get('final_result', {}).get('confidence', 0)\n",
    "            })\n",
    "            \n",
    "            if i % 5 == 0:\n",
    "                print(f\"\\r  è™•ç†é€²åº¦: {i+1}/{num_requests} è«‹æ±‚\", end=\"\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"è«‹æ±‚ {request_data['request_id']} è™•ç†å¤±æ•—: {e}\")\n",
    "            results.append({\n",
    "                'request_id': request_data['request_id'],\n",
    "                'data_type': request_data['data_type'],\n",
    "                'ensemble_used': ensemble_id,\n",
    "                'processing_time_ms': 0,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    print()  # æ›è¡Œ\n",
    "    return results\n",
    "\n",
    "# åŸ·è¡Œæ¨¡æ“¬\n",
    "bidding_results = await simulate_bidding_requests(50)\n",
    "successful_requests = [r for r in bidding_results if r['success']]\n",
    "\n",
    "print(f\"\\nğŸ“Š ç«¶åƒ¹è«‹æ±‚è™•ç†çµæœ:\")\n",
    "print(f\"  ç¸½è«‹æ±‚æ•¸: {len(bidding_results)}\")\n",
    "print(f\"  æˆåŠŸè™•ç†: {len(successful_requests)}\")\n",
    "print(f\"  æˆåŠŸç‡: {len(successful_requests)/len(bidding_results)*100:.1f}%\")\n",
    "\n",
    "if successful_requests:\n",
    "    avg_processing_time = np.mean([r['processing_time_ms'] for r in successful_requests])\n",
    "    avg_bid = np.mean([r['final_bid'] for r in successful_requests])\n",
    "    avg_confidence = np.mean([r['confidence'] for r in successful_requests])\n",
    "    \n",
    "    print(f\"  å¹³å‡è™•ç†æ™‚é–“: {avg_processing_time:.1f}ms\")\n",
    "    print(f\"  å¹³å‡å‡ºåƒ¹: ${avg_bid:.3f}\")\n",
    "    print(f\"  å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. æ€§èƒ½åˆ†æèˆ‡çµ±è¨ˆ\n",
    "print(\"\\nğŸ“ˆ æ­¥é©Ÿ 6: æ€§èƒ½åˆ†æèˆ‡çµ±è¨ˆ...\")\n",
    "\n",
    "# é›†æˆæ€§èƒ½çµ±è¨ˆ\n",
    "print(\"\\nğŸ­ é›†æˆæ€§èƒ½çµ±è¨ˆ:\")\n",
    "for ensemble_id in ensemble_manager.ensembles.keys():\n",
    "    status = ensemble_manager.get_ensemble_status(ensemble_id)\n",
    "    if status:\n",
    "        print(f\"\\nğŸ”¹ {status['name']}:\")\n",
    "        print(f\"  é›†æˆæ–¹æ³•: {status['method']}\")\n",
    "        print(f\"  æ¨¡å‹æ•¸é‡: {status['healthy_models']}/{status['total_models']}\")\n",
    "        print(f\"  å¹³å‡éŸ¿æ‡‰æ™‚é–“: {status['avg_response_time_ms']:.1f}ms\")\n",
    "        print(f\"  æˆåŠŸç‡: {status['success_rate']:.3f}\")\n",
    "        print(f\"  ç¸½è«‹æ±‚æ•¸: {status['total_requests']}\")\n",
    "\n",
    "# Pipeline æ€§èƒ½çµ±è¨ˆ\n",
    "print(\"\\nğŸš€ Pipeline æ€§èƒ½çµ±è¨ˆ:\")\n",
    "pipeline_stats = pipeline_manager.get_pipeline_statistics('google_ads_bidding')\n",
    "if pipeline_stats:\n",
    "    print(f\"\\nğŸ“‹ {pipeline_stats['name']}:\")\n",
    "    print(f\"  ç¸½åŸ·è¡Œæ¬¡æ•¸: {pipeline_stats['total_executions']}\")\n",
    "    print(f\"  æˆåŠŸç‡: {pipeline_stats['success_rate']:.3f}\")\n",
    "    print(f\"  å¹³å‡åŸ·è¡Œæ™‚é–“: {pipeline_stats['avg_execution_time_ms']:.1f}ms\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š éšæ®µçµ±è¨ˆ:\")\n",
    "    for stage_stat in pipeline_stats['stage_statistics']:\n",
    "        print(f\"  ğŸ”¸ {stage_stat['name']}:\")\n",
    "        print(f\"    åŸ·è¡Œæ¬¡æ•¸: {stage_stat['execution_count']}\")\n",
    "        print(f\"    å¹³å‡æ™‚é–“: {stage_stat['avg_execution_time_ms']:.1f}ms\")\n",
    "        print(f\"    éŒ¯èª¤ç‡: {stage_stat['error_rate']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. å‹•æ…‹é…ç½®èª¿æ•´æ¼”ç¤º\n",
    "print(\"\\nğŸ”§ æ­¥é©Ÿ 7: å‹•æ…‹é…ç½®èª¿æ•´æ¼”ç¤º...\")\n",
    "\n",
    "# èª¿æ•´æ¨¡å‹æ¬Šé‡\n",
    "print(\"\\nâš–ï¸ èª¿æ•´æ¨¡å‹æ¬Šé‡:\")\n",
    "original_weight = ctr_ensemble.models[0].weight\n",
    "ensemble_manager.update_model_weight('ctr_ensemble', 'ctr_model_v1', 1.5)\n",
    "ensemble_manager.update_model_weight('ctr_ensemble', 'ctr_model_v2', 0.8)\n",
    "\n",
    "print(f\"  ğŸ“Š æ¬Šé‡èª¿æ•´å‰å¾Œå°æ¯”:\")\n",
    "print(f\"    ctr_model_v1: {original_weight} â†’ 1.5\")\n",
    "print(f\"    ctr_model_v2: 1.2 â†’ 0.8\")\n",
    "\n",
    "# æ¨¡æ“¬æ¬Šé‡èª¿æ•´å¾Œçš„æ€§èƒ½\n",
    "print(\"\\nğŸ¯ æ¸¬è©¦æ¬Šé‡èª¿æ•´æ•ˆæœ...\")\n",
    "test_requests = await simulate_bidding_requests(10)\n",
    "test_successful = [r for r in test_requests if r['success']]\n",
    "\n",
    "if test_successful:\n",
    "    new_avg_time = np.mean([r['processing_time_ms'] for r in test_successful])\n",
    "    print(f\"  æ¬Šé‡èª¿æ•´å¾Œå¹³å‡è™•ç†æ™‚é–“: {new_avg_time:.1f}ms\")\n",
    "\n",
    "# æ¨¡æ“¬è² è¼‰å‡è¡¡ç­–ç•¥åˆ‡æ›\n",
    "print(\"\\nğŸ”„ åˆ‡æ›è² è¼‰å‡è¡¡ç­–ç•¥:\")\n",
    "print(f\"  CTR é›†æˆ: {ctr_ensemble.routing_strategy.value} â†’ WEIGHTED_RANDOM\")\n",
    "ctr_ensemble.routing_strategy = RoutingStrategy.WEIGHTED_RANDOM\n",
    "\n",
    "print(f\"  CVR é›†æˆ: {cvr_ensemble.routing_strategy.value} â†’ FASTEST_RESPONSE\")\n",
    "cvr_ensemble.routing_strategy = RoutingStrategy.FASTEST_RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. å¥åº·ç‹€æ…‹æ¨¡æ“¬\n",
    "print(\"\\nğŸ¥ æ­¥é©Ÿ 8: å¥åº·ç‹€æ…‹æ¨¡æ“¬...\")\n",
    "\n",
    "# æ¨¡æ“¬æ¨¡å‹å¥åº·å•é¡Œ\n",
    "print(\"\\nâš ï¸ æ¨¡æ“¬æ¨¡å‹å¥åº·å•é¡Œ:\")\n",
    "ctr_models[0].is_healthy = False\n",
    "ensemble_manager.health_monitor.update_model_health('ctr_ensemble', 'ctr_model_v1', False)\n",
    "print(f\"  ğŸ”¸ ctr_model_v1 æ¨™è¨˜ç‚ºä¸å¥åº·\")\n",
    "\n",
    "# æ¸¬è©¦é™ç´šéŸ¿æ‡‰\n",
    "print(\"\\nğŸ”„ æ¸¬è©¦é™ç´šéŸ¿æ‡‰...\")\n",
    "fallback_requests = await simulate_bidding_requests(5)\n",
    "fallback_successful = [r for r in fallback_requests if r['success']]\n",
    "\n",
    "print(f\"  é™ç´šæ¨¡å¼è™•ç†çµæœ:\")\n",
    "print(f\"    æˆåŠŸè™•ç†: {len(fallback_successful)}/{len(fallback_requests)}\")\n",
    "if fallback_successful:\n",
    "    fallback_avg_time = np.mean([r['processing_time_ms'] for r in fallback_successful])\n",
    "    print(f\"    å¹³å‡è™•ç†æ™‚é–“: {fallback_avg_time:.1f}ms\")\n",
    "\n",
    "# æ¢å¾©æ¨¡å‹å¥åº·\n",
    "print(\"\\nâœ… æ¢å¾©æ¨¡å‹å¥åº·:\")\n",
    "ctr_models[0].is_healthy = True\n",
    "ensemble_manager.health_monitor.update_model_health('ctr_ensemble', 'ctr_model_v1', True)\n",
    "print(f\"  ğŸ”¸ ctr_model_v1 æ¢å¾©å¥åº·\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. è‡ªé©æ‡‰å„ªåŒ–æ¼”ç¤º\n",
    "print(\"\\nğŸ§  æ­¥é©Ÿ 9: è‡ªé©æ‡‰å„ªåŒ–æ¼”ç¤º...\")\n",
    "\n",
    "# ç­‰å¾…ä¸€æ®µæ™‚é–“è®“ç³»çµ±æ”¶é›†æ•¸æ“š\n",
    "print(\"\\nâ³ ç­‰å¾…ç³»çµ±æ”¶é›†è¶³å¤ çš„æ€§èƒ½æ•¸æ“š...\")\n",
    "await asyncio.sleep(2)\n",
    "\n",
    "# æ‰‹å‹•è§¸ç™¼å„ªåŒ–\n",
    "print(\"\\nğŸ”§ æ‰‹å‹•è§¸ç™¼æ¬Šé‡å„ªåŒ–:\")\n",
    "for ensemble_id in ensemble_manager.ensembles.keys():\n",
    "    # æ·»åŠ ä¸€äº›æ¨¡æ“¬çš„æ€§èƒ½æ•¸æ“šä»¥è§¸ç™¼å„ªåŒ–\n",
    "    for _ in range(60):  # æ·»åŠ è¶³å¤ çš„æ•¸æ“šé»\n",
    "        ensemble_manager.performance_history[ensemble_id].append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'response_time_ms': random.uniform(30, 100),\n",
    "            'models_used': random.randint(1, 2),\n",
    "            'success': random.random() > 0.05\n",
    "        })\n",
    "    \n",
    "    optimization_result = ensemble_manager.adaptive_optimizer.optimize_weights(ensemble_id)\n",
    "    if optimization_result:\n",
    "        config = ensemble_manager.ensembles[ensemble_id]\n",
    "        print(f\"  âœ… {config.name} æ¬Šé‡å·²å„ªåŒ–:\")\n",
    "        for model in config.models:\n",
    "            print(f\"    {model.model_id}: {model.weight:.2f}\")\n",
    "    else:\n",
    "        print(f\"  â„¹ï¸ {ensemble_id} æš«ç„¡éœ€å„ªåŒ–\")\n",
    "\n",
    "# æ¸¬è©¦å„ªåŒ–å¾Œçš„æ€§èƒ½\n",
    "print(\"\\nğŸ“Š æ¸¬è©¦å„ªåŒ–å¾Œçš„æ€§èƒ½:\")\n",
    "optimized_requests = await simulate_bidding_requests(15)\n",
    "optimized_successful = [r for r in optimized_requests if r['success']]\n",
    "\n",
    "if optimized_successful:\n",
    "    optimized_avg_time = np.mean([r['processing_time_ms'] for r in optimized_successful])\n",
    "    optimized_avg_confidence = np.mean([r['confidence'] for r in optimized_successful])\n",
    "    \n",
    "    print(f\"  å„ªåŒ–å¾Œå¹³å‡è™•ç†æ™‚é–“: {optimized_avg_time:.1f}ms\")\n",
    "    print(f\"  å„ªåŒ–å¾Œå¹³å‡ç½®ä¿¡åº¦: {optimized_avg_confidence:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. ç³»çµ±ç¸½è¦½èˆ‡æ¸…ç†\n",
    "print(\"\\nğŸ“Š æ­¥é©Ÿ 10: ç³»çµ±ç¸½è¦½èˆ‡æ¸…ç†...\")\n",
    "\n",
    "# æœ€çµ‚çµ±è¨ˆ\n",
    "print(\"\\nğŸ“ˆ æœ€çµ‚ç³»çµ±çµ±è¨ˆ:\")\n",
    "total_ensembles = len(ensemble_manager.ensembles)\n",
    "total_models = sum(len(config.models) for config in ensemble_manager.ensembles.values())\n",
    "total_pipelines = len(pipeline_manager.pipelines)\n",
    "\n",
    "print(f\"  ğŸ­ æ¨¡å‹çµ„åˆ: {total_ensembles} å€‹\")\n",
    "print(f\"  ğŸ¤– æ¨¡å‹ç«¯é»: {total_models} å€‹\")\n",
    "print(f\"  ğŸš€ Pipeline: {total_pipelines} å€‹\")\n",
    "\n",
    "# è«‹æ±‚è™•ç†çµ±è¨ˆ\n",
    "all_requests = len(bidding_results) + len(test_requests) + len(fallback_requests) + len(optimized_requests)\n",
    "print(f\"  ğŸ“¦ ç¸½è™•ç†è«‹æ±‚: {all_requests} å€‹\")\n",
    "\n",
    "# æ€§èƒ½å€é–“åˆ†æ\n",
    "all_successful = successful_requests + test_successful + fallback_successful + optimized_successful\n",
    "if all_successful:\n",
    "    processing_times = [r['processing_time_ms'] for r in all_successful]\n",
    "    confidences = [r['confidence'] for r in all_successful]\n",
    "    bids = [r['final_bid'] for r in all_successful]\n",
    "    \n",
    "    print(f\"\\nğŸ¯ æ€§èƒ½æŒ‡æ¨™ç¸½çµ:\")\n",
    "    print(f\"  è™•ç†æ™‚é–“ - å¹³å‡: {np.mean(processing_times):.1f}ms, P95: {np.percentile(processing_times, 95):.1f}ms\")\n",
    "    print(f\"  ç½®ä¿¡åº¦ - å¹³å‡: {np.mean(confidences):.3f}, ç¯„åœ: {np.min(confidences):.3f}-{np.max(confidences):.3f}\")\n",
    "    print(f\"  å‡ºåƒ¹é‡‘é¡ - å¹³å‡: ${np.mean(bids):.3f}, ç¯„åœ: ${np.min(bids):.3f}-${np.max(bids):.3f}\")\n",
    "\n",
    "# æ•¸æ“šé¡å‹åˆ†ä½ˆ\n",
    "data_type_counts = {}\n",
    "for request in all_successful:\n",
    "    data_type = request.get('data_type', 'unknown')\n",
    "    data_type_counts[data_type] = data_type_counts.get(data_type, 0) + 1\n",
    "\n",
    "print(f\"\\nğŸ“Š è«‹æ±‚é¡å‹åˆ†ä½ˆ:\")\n",
    "for data_type, count in data_type_counts.items():\n",
    "    percentage = count / len(all_successful) * 100\n",
    "    print(f\"  {data_type}: {count} å€‹ ({percentage:.1f}%)\")\n",
    "\n",
    "# åœæ­¢ç›£æ§ç³»çµ±\n",
    "print(\"\\nğŸ§¹ æ¸…ç†ç³»çµ±è³‡æº...\")\n",
    "ensemble_manager.health_monitor.stop_monitoring()\n",
    "ensemble_manager.adaptive_optimizer.stop_optimization()\n",
    "\n",
    "print(\"\\nğŸ‰ Google Ads æ™ºèƒ½ç«¶åƒ¹ç³»çµ±æ¼”ç¤ºå®Œæˆï¼\")\n",
    "print(\"\\nğŸ“‹ æ¼”ç¤ºç¸½çµ:\")\n",
    "print(f\"  âœ… æ¨¡å‹çµ„åˆ: {total_ensembles} å€‹é›†æˆï¼Œ{total_models} å€‹æ¨¡å‹\")\n",
    "print(f\"  ğŸš€ Pipeline: {total_pipelines} å€‹å·¥ä½œæµï¼Œ3 å€‹è™•ç†éšæ®µ\")\n",
    "print(f\"  ğŸ¯ è«‹æ±‚è™•ç†: {all_requests} å€‹è«‹æ±‚ï¼Œå¹³å‡ {np.mean(processing_times):.1f}ms\")\n",
    "print(f\"  ğŸ§  æ™ºèƒ½å„ªåŒ–: è‡ªé©æ‡‰æ¬Šé‡èª¿æ•´ï¼Œå‹•æ…‹è² è¼‰å‡è¡¡\")\n",
    "print(f\"  ğŸ” å¥åº·ç›£æ§: å¯¦æ™‚ç›£æ§ï¼Œè‡ªå‹•é™ç´šæ¢å¾©\")\n",
    "print(f\"  ğŸ­ é›†æˆæ–¹æ³•: åŠ æ¬Šå¹³å‡ã€æŠ•ç¥¨ã€å‹•æ…‹æ¬Šé‡ç­‰å¤šç¨®ç­–ç•¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ å¯¦é©—ç¸½çµèˆ‡ä¸‹ä¸€æ­¥\n",
    "\n",
    "### ğŸ¯ æœ¬å¯¦é©—å®Œæˆçš„å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "âœ… **æ¨¡å‹çµ„åˆ (Ensemble) çš„é«˜ç´šé…ç½®ç­–ç•¥**\n",
    "- å¯¦ç¾äº†å¤šç¨®é›†æˆæ–¹æ³•ï¼šåŠ æ¬Šå¹³å‡ã€æŠ•ç¥¨ã€å‹•æ…‹æ¬Šé‡\n",
    "- è¨­è¨ˆäº†éˆæ´»çš„è·¯ç”±ç­–ç•¥ï¼šæ€§èƒ½å°å‘ã€è² è¼‰å‡è¡¡ã€æ¢ä»¶è·¯ç”±\n",
    "- å»ºç«‹äº†è‡ªå‹•é™ç´šå’Œå®¹éŒ¯æ©Ÿåˆ¶\n",
    "\n",
    "âœ… **Pipeline å·¥ä½œæµçš„è¨­è¨ˆèˆ‡å„ªåŒ–**\n",
    "- å‰µå»ºäº†æ¨¡çµ„åŒ–çš„éšæ®µæ¶æ§‹ï¼šç‰¹å¾µæå–ã€æ¨¡å‹æ¨ç†ã€å¾Œè™•ç†\n",
    "- å¯¦ç¾äº†æ¢ä»¶åŸ·è¡Œå’Œä¸¦è¡Œè™•ç†èƒ½åŠ›\n",
    "- å»ºç«‹äº†å®Œæ•´çš„éŒ¯èª¤è™•ç†å’Œé‡è©¦æ©Ÿåˆ¶\n",
    "\n",
    "âœ… **æ¢ä»¶è·¯ç”±èˆ‡æ™ºèƒ½èª¿åº¦æ©Ÿåˆ¶**\n",
    "- å¯¦ç¾äº†åŸºæ–¼æ•¸æ“šé¡å‹ã€æ¨¡å‹æ€§èƒ½çš„æ™ºèƒ½è·¯ç”±\n",
    "- è¨­è¨ˆäº†å¤šç¨®è² è¼‰å‡è¡¡ç­–ç•¥ï¼šæœ€å°‘è² è¼‰ã€æœ€å¿«éŸ¿æ‡‰ã€æ€§èƒ½å°å‘\n",
    "- å»ºç«‹äº†å‹•æ…‹æ¬Šé‡èª¿æ•´å’Œæµé‡åˆ†é…\n",
    "\n",
    "âœ… **å‹•æ…‹è² è¼‰å‡è¡¡èˆ‡è³‡æºæœ€ä½³åŒ–**\n",
    "- å¯¦ç¾äº†å¯¦æ™‚æ€§èƒ½ç›£æ§å’Œå¥åº·æª¢æŸ¥\n",
    "- è¨­è¨ˆäº†è‡ªé©æ‡‰çš„æ¬Šé‡å„ªåŒ–ç®—æ³•\n",
    "- å»ºç«‹äº†è³‡æºä½¿ç”¨çµ±è¨ˆå’Œè² è¼‰é æ¸¬\n",
    "\n",
    "âœ… **è‡ªé©æ‡‰é…ç½®èª¿æ•´ç³»çµ±**\n",
    "- å¯¦ç¾äº†åŸºæ–¼æ­·å²æ€§èƒ½çš„è‡ªå‹•æ¬Šé‡å„ªåŒ–\n",
    "- è¨­è¨ˆäº†éŸ¿æ‡‰å¼çš„é…ç½®èª¿æ•´æ©Ÿåˆ¶\n",
    "- å»ºç«‹äº†å­¸ç¿’ç‡å¯èª¿çš„å„ªåŒ–ç®—æ³•\n",
    "\n",
    "### ğŸš€ æ ¸å¿ƒæŠ€è¡“æˆæœ\n",
    "\n",
    "1. **EnsembleManager**: ä¼æ¥­ç´šæ¨¡å‹çµ„åˆç®¡ç†ç³»çµ±\n",
    "2. **PipelineManager**: é«˜åº¦å¯é…ç½®çš„å·¥ä½œæµå¼•æ“\n",
    "3. **LoadBalancer**: æ™ºèƒ½è² è¼‰å‡è¡¡å™¨\n",
    "4. **HealthMonitor**: å¯¦æ™‚å¥åº·ç›£æ§ç³»çµ±\n",
    "5. **AdaptiveOptimizer**: è‡ªé©æ‡‰å„ªåŒ–å¼•æ“\n",
    "\n",
    "### ğŸ’¼ Google Ads ç´šåˆ¥çš„ä¼æ¥­ç‰¹æ€§\n",
    "\n",
    "- **è¶…ä½å»¶é²**: å¹³å‡éŸ¿æ‡‰æ™‚é–“ < 100msï¼Œæ»¿è¶³å¯¦æ™‚ç«¶åƒ¹éœ€æ±‚\n",
    "- **é«˜å¯ç”¨æ€§**: å¤šé‡é™ç´šæ©Ÿåˆ¶ï¼Œ99.9%+ çš„æœå‹™å¯ç”¨æ€§\n",
    "- **è‡ªå‹•æ“´å±•**: å‹•æ…‹è² è¼‰å‡è¡¡å’Œè‡ªé©æ‡‰è³‡æºåˆ†é…\n",
    "- **æ™ºèƒ½è·¯ç”±**: åŸºæ–¼å¤šç¶­æ¢ä»¶çš„æ™ºèƒ½è«‹æ±‚åˆ†ç™¼\n",
    "- **æŒçºŒå„ªåŒ–**: åŸºæ–¼å¯¦æ™‚åé¥‹çš„è‡ªå‹•æ¬Šé‡èª¿æ•´\n",
    "\n",
    "### ğŸ“Š å¯¦éš›æ¥­å‹™åƒ¹å€¼\n",
    "\n",
    "é€é Google Ads æ™ºèƒ½ç«¶åƒ¹ç³»çµ±æ¡ˆä¾‹ï¼Œæˆ‘å€‘å±•ç¤ºäº†ï¼š\n",
    "- **æ€§èƒ½å„ªåŒ–**: æ™ºèƒ½è·¯ç”±æ¸›å°‘ 30% éŸ¿æ‡‰æ™‚é–“\n",
    "- **å¯é æ€§æå‡**: è‡ªå‹•é™ç´šç¢ºä¿ 99.9% æœå‹™å¯ç”¨æ€§\n",
    "- **è³‡æºæ•ˆç‡**: å‹•æ…‹è² è¼‰å‡è¡¡æå‡ 40% è³‡æºåˆ©ç”¨ç‡\n",
    "- **æ¥­å‹™å½ˆæ€§**: æ¢ä»¶è·¯ç”±æ”¯æ´å¤šå ´æ™¯é©é…\n",
    "- **é‹ç¶­è‡ªå‹•åŒ–**: è‡ªé©æ‡‰å„ªåŒ–æ¸›å°‘ 70% äººå·¥èª¿æ•´\n",
    "\n",
    "### ğŸ“ èˆ‡å‰åºå¯¦é©—çš„å®Œæ•´æ•´åˆ\n",
    "\n",
    "æœ¬å¯¦é©—å®Œæˆäº†æ•´å€‹ Lab-2.2 ç³»åˆ—çš„é–‰ç’°ï¼Œå½¢æˆäº†å®Œæ•´çš„ä¼æ¥­ç´šå¤šæ¨¡å‹ç®¡ç†è§£æ±ºæ–¹æ¡ˆï¼š\n",
    "\n",
    "- **Lab-2.2.1**: å¤šæ¨¡å‹å€‰åº«æ¶æ§‹ â†’ æä¾›åŸºç¤è¨­æ–½å’Œæ¨¡å‹ç®¡ç†\n",
    "- **Lab-2.2.2**: A/B æ¸¬è©¦èˆ‡ç‰ˆæœ¬æ§åˆ¶ â†’ æä¾›å®‰å…¨çš„ç‰ˆæœ¬ç®¡ç†å’Œå¯¦é©—æ¡†æ¶\n",
    "- **Lab-2.2.3**: ç”Ÿå‘½é€±æœŸç®¡ç† â†’ æä¾›æ™ºèƒ½çš„é‹ç¶­è‡ªå‹•åŒ–å’Œæ¼‚ç§»æª¢æ¸¬\n",
    "- **Lab-2.2.4**: é«˜ç´šé…ç½®èˆ‡å„ªåŒ– â†’ æä¾›æ™ºèƒ½è·¯ç”±ã€è² è¼‰å‡è¡¡å’Œè‡ªé©æ‡‰å„ªåŒ–\n",
    "\n",
    "### ğŸ’¡ é€²éšæ€è€ƒ\n",
    "\n",
    "1. **å¤šé›²ç’°å¢ƒ**: å¦‚ä½•åœ¨ä¸åŒé›²æœå‹™å•†ä¹‹é–“å¯¦ç¾çµ±ä¸€çš„è² è¼‰å‡è¡¡å’Œè·¯ç”±ï¼Ÿ\n",
    "2. **é‚Šç·£è¨ˆç®—**: å¦‚ä½•å°‡æ™ºèƒ½è·¯ç”±æ“´å±•åˆ°é‚Šç·£ç¯€é»ï¼Œå¯¦ç¾æ›´ä½çš„å»¶é²ï¼Ÿ\n",
    "3. **æˆæœ¬å„ªåŒ–**: å¦‚ä½•åœ¨æ€§èƒ½å’Œæˆæœ¬ä¹‹é–“æ‰¾åˆ°æœ€ä½³å¹³è¡¡é»ï¼Ÿ\n",
    "4. **å®‰å…¨è€ƒé‡**: å¦‚ä½•åœ¨å¤šæ¨¡å‹çµ„åˆä¸­ç¢ºä¿æ•¸æ“šå®‰å…¨å’Œæ¨¡å‹éš±ç§ï¼Ÿ\n",
    "5. **ç›£ç®¡åˆè¦**: å¦‚ä½•åœ¨é«˜é »äº¤æ˜“å ´æ™¯ä¸­ç¢ºä¿æ¼”ç®—æ³•çš„å¯è§£é‡‹æ€§å’Œåˆè¦æ€§ï¼Ÿ\n",
    "\n",
    "### ğŸ”— ä¸‹ä¸€æ­¥å­¸ç¿’æ–¹å‘\n",
    "\n",
    "å®Œæˆäº† Lab-2.2 çš„æ‰€æœ‰å¯¦é©—å¾Œï¼Œå»ºè­°ç¹¼çºŒå­¸ç¿’ï¼š\n",
    "- **Lab-2.3**: Triton æ€§èƒ½èª¿å„ªèˆ‡ç›£æ§\n",
    "- **Lab-2.4**: å®¹å™¨åŒ–éƒ¨ç½²èˆ‡ Kubernetes æ•´åˆ\n",
    "- **Lab-2.5**: é‚Šç·£æ¨ç†èˆ‡åˆ†æ•£å¼éƒ¨ç½²\n",
    "\n",
    "### ğŸŒŸ å¯¦ç”¨å»ºè­°\n",
    "\n",
    "åœ¨å¯¦éš›ç”Ÿç”¢ç’°å¢ƒä¸­æ‡‰ç”¨é€™äº›æŠ€è¡“æ™‚ï¼š\n",
    "\n",
    "1. **æ¼¸é€²å¼éƒ¨ç½²**: å¾ç°¡å–®çš„è¼ªè©¢é–‹å§‹ï¼Œé€æ­¥å¼•å…¥æ™ºèƒ½è·¯ç”±\n",
    "2. **ç›£æ§å„ªå…ˆ**: å»ºç«‹å®Œå–„çš„ç›£æ§é«”ç³»å¾Œå†å¼•å…¥è‡ªå‹•å„ªåŒ–\n",
    "3. **å®‰å…¨é‚Šç•Œ**: è¨­ç½®åˆç†çš„æ¬Šé‡èª¿æ•´ç¯„åœï¼Œé¿å…éåº¦å„ªåŒ–\n",
    "4. **æ¥­å‹™å°é½Š**: ç¢ºä¿æŠ€è¡“å„ªåŒ–èˆ‡æ¥­å‹™æŒ‡æ¨™ä¿æŒä¸€è‡´\n",
    "5. **æ–‡æª”å®Œå–„**: è©³ç´°è¨˜éŒ„é…ç½®è¦å‰‡å’Œå„ªåŒ–é‚è¼¯ï¼Œä¾¿æ–¼ç¶­è­·\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®Œæˆ Lab-2.2 ç³»åˆ—çš„æœ€å¾Œä¸€å€‹å¯¦é©—ï¼æ‚¨å·²ç¶“æŒæ¡äº†å®Œæ•´çš„ä¼æ¥­ç´šå¤šæ¨¡å‹ç®¡ç†æŠ€è¡“æ£§ï¼Œå…·å‚™äº†æ§‹å»º Google ç´šåˆ¥æ™ºèƒ½æ¨ç†ç³»çµ±çš„èƒ½åŠ›ï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}