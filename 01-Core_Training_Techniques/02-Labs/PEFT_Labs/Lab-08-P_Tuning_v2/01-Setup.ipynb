{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 8: P-Tuning v2 - Deep Prompt Tuning for Diverse Tasks\n",
        "\n",
        "**Goal:** This lab explores **P-Tuning v2**, an advanced PEFT method that applies prompts to every layer of the transformer, making it comparable to full fine-tuning across various scales and tasks. Unlike P-Tuning v1, P-Tuning v2 provides deeper integration with the model architecture.\n",
        "\n",
        "**You will learn to:**\n",
        "-   Understand the evolution from P-Tuning to P-Tuning v2.\n",
        "-   Apply deep prompts to every transformer layer.\n",
        "-   Configure P-Tuning v2 for both understanding and generation tasks.\n",
        "-   Compare performance with other PEFT methods.\n",
        "-   Fine-tune models with extreme parameter efficiency.\n",
        "\n",
        "---\n",
        "## Notebook 1: Environment Setup\n",
        "\n",
        "This notebook will prepare your environment for the P-Tuning v2 lab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Check for GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Install Core Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q transformers peft datasets accelerate torch scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Verify Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import peft\n",
        "import datasets\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Transformers version: {transformers.__version__}\")\n",
        "print(f\"PEFT version: {peft.__version__}\")\n",
        "print(f\"Datasets version: {datasets.__version__}\")\n",
        "\n",
        "print(\"\\nâœ… Environment is set up correctly!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
