# å¤§æ¨¡å‹è¨“ç·´æŠ€è¡“ 1.3 è¨“ç·´å„ªåŒ–èˆ‡å°é½Š (Training Optimization & Alignment)

æœ¬æ•™å­¸æ¨¡çµ„æ·±å…¥æ¢è¨å¤§å‹èªè¨€æ¨¡å‹ (LLM) è¨“ç·´å„ªåŒ–èˆ‡å°é½ŠæŠ€è¡“ï¼Œæ¶µè“‹å¾æ•ˆç‡æå‡åˆ°æ¨¡å‹å°é½Šçš„å®Œæ•´çŸ¥è­˜é«”ç³»ã€‚

**ğŸš¨ é‡è¦é™åˆ¶**: æœ¬èª²ç¨‹å¼·èª¿ç†è«–æ•™å­¸èˆ‡æ¼”ç®—æ³•åˆ†æï¼Œé©åˆå–®GPUç’°å¢ƒå­¸ç¿’ã€‚

| å±¤æ¬¡ | æ™‚é–“ | å­¸ç¿’ç›®æ¨™ | æ ¸å¿ƒå…§å®¹ | ç”¢å‡º |
| :--- | :--- | :--- | :--- | :--- |
| **Fundamentals** | åŸºç¤ | æŒæ¡è¨“ç·´å„ªåŒ–åŸºæœ¬æŠ€è¡“èˆ‡å°é½ŠåŸç† | æ³¨æ„åŠ›å„ªåŒ–èˆ‡åŸºç¤å°é½Š | æŒæ¡åŸºæœ¬æ¦‚å¿µèˆ‡å¯¦ç¾åŸç† |
| **First Principles** | åŸç† | ç†è§£æ•¸å­¸åŸç†èˆ‡è¨ˆç®—è¤‡é›œåº¦åˆ†æ | é€šè¨Šè¤‡é›œåº¦èˆ‡å°é½Šç†è«– | ç†è§£åº•å±¤æ¼”ç®—æ³•è¨­è¨ˆåŸç† |
| **Body of Knowledge** | å¯¦å‹™ | å„ªåŒ– LLM è¨“ç·´èˆ‡å°é½Šç­–ç•¥ç²¾é€š | ä¸»æµæŠ€è¡“ FlashAttention & RLHF | å…·å‚™æ¼”ç®—æ³•å¯¦ç¾èˆ‡èª¿å„ªèƒ½åŠ› |

---

## 1. Fundamentals (åŸºç¤)

### 1.1 è¨“ç·´å„ªåŒ–å‹•æ©Ÿ

å¤§å‹èªè¨€æ¨¡å‹é¢è‡¨çš„é—œéµæŒ‘æˆ°ï¼š

1. **è¨˜æ†¶é«”ç“¶é ¸** Transformer æ¶æ§‹çš„æ³¨æ„åŠ›è¤‡é›œåº¦ $O(n^2)$ é€ æˆè¨˜æ†¶é«”ç“¶é ¸
2. **è¨ˆç®—æ•ˆç‡** æ¿€æ´»å€¼ã€å„ªåŒ–å™¨ç‹€æ…‹ä½”ç”¨å¤§é‡è¨˜æ†¶é«”
3. **æ”¶æ–‚é€Ÿåº¦** å¤§æ¨¡å‹è¨“ç·´éœ€è¦é«˜æ•ˆå­¸ç¿’ç‡èª¿åº¦
4. **æ¨¡å‹å°é½Š** ç¢ºä¿æ¨¡å‹è¼¸å‡ºç¬¦åˆäººé¡åƒ¹å€¼è§€èˆ‡é æœŸ

**è¨“ç·´å„ªåŒ–**æ˜¯è§£æ±ºLLMè¨“ç·´æ•ˆç‡å•é¡Œçš„æ ¸å¿ƒæŠ€è¡“ï¼ŒåŒ…å«è¨˜æ†¶é«”å„ªåŒ–ã€è¨ˆç®—åŠ é€Ÿå’Œæ”¶æ–‚æ”¹é€²ã€‚

**æ¨¡å‹å°é½Š**æ˜¯ç¢ºä¿æ¨¡å‹è¡Œç‚ºèˆ‡äººé¡æ„åœ–ä¸€è‡´çš„é‡è¦æŠ€è¡“ï¼ŒåŒ…å«åƒ¹å€¼å°é½Šå’Œè¡Œç‚ºå°é½Šã€‚

### 1.2 è¨“ç·´å„ªåŒ–æŠ€è¡“

#### 1.2.1 æ³¨æ„åŠ›å„ªåŒ–

##### FlashAttention: è¨˜æ†¶é«”é«˜æ•ˆæ³¨æ„åŠ›

**å•é¡Œåˆ†æ**ï¼šæ¨™æº–æ³¨æ„åŠ›éœ€è¦å„²å­˜ $n \times n$ çš„æ³¨æ„åŠ›çŸ©é™£ï¼Œç•¶ $n$ å¾ˆå¤§æ™‚æœƒå°è‡´è¨˜æ†¶é«”ç“¶é ¸ã€‚

**æ•¸å­¸åŸºç¤**
æ¨™æº–æ³¨æ„åŠ›ï¼š
$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

**FlashAttention æ ¸å¿ƒæ€æƒ³**
1. **åˆ†å¡Š (Tiling)** å°‡ $Q$ã€$K$ã€$V$ åˆ†å‰²æˆå°å¡Š
2. **åœ¨ç·šç®—æ³•** é€å¡Šè¨ˆç®—ä¸¦æ›´æ–°çµæœ
3. **è¨˜æ†¶é«”å±¤æ¬¡** å……åˆ†åˆ©ç”¨ GPU å¿«é€Ÿè¨˜æ†¶é«”

**ç®—æ³•æ¡†æ¶**
```python
# FlashAttention å½ä»£ç¢¼
def flash_attention(Q, K, V, block_size):
    N, d = Q.shape
    O = zeros_like(Q)
    l = zeros(N)  # æ­£è¦åŒ–å¸¸æ•¸
    m = full(-inf, N)  # æœ€å¤§å€¼

    for i in range(0, N, block_size):
        # è¼‰å…¥ Q å¡Šåˆ° SRAM
        Qi = Q[i:i+block_size]
        for j in range(0, N, block_size):
            # è¼‰å…¥ K, V å¡Šåˆ° SRAM
            Kj = K[j:j+block_size]
            Vj = V[j:j+block_size]

            # è¨ˆç®—åˆ†æ•¸
            Sij = Qi @ Kj.T / sqrt(d)

            # åœ¨ç·š softmax æ›´æ–°
            # ... (çœç•¥å…·é«”å¯¦ç¾)

    return O
```

**æ•ˆæœæå‡**
- è¨˜æ†¶é«”å¾ $O(n^2)$ é™è‡³ $O(n)$
- é€Ÿåº¦æå‡2-4å€
- æ”¯æ´é•·åºåˆ—è¨“ç·´

##### FlashAttention-2: é€²ä¸€æ­¥å„ªåŒ–

**ä¸»è¦æ”¹é€²**
1. **å·¥ä½œé‡åˆ†é…å„ªåŒ–** æ›´å¥½åˆ©ç”¨ GPU çš„å¹³è¡Œè¨ˆç®—å–®å…ƒ
2. **ä¸¦è¡Œç­–ç•¥æ”¹é€²** é‡å°ä¸åŒåºåˆ—é•·åº¦çš„ä¸¦è¡Œå„ªåŒ–
3. **backward pass å„ªåŒ–** åå‘å‚³æ’­çš„è¨˜æ†¶é«”èˆ‡è¨ˆç®—å„ªåŒ–

#### 1.2.2 æ··åˆç²¾åº¦è¨“ç·´

##### æ··åˆç²¾åº¦ (Mixed Precision Training)

**åŸºæœ¬æ¦‚å¿µ**ï¼šçµåˆ FP16 å’Œ FP32 ç²¾åº¦é€²è¡Œè¨“ç·´ï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡ç©©å®šæ€§ã€‚

**å¯¦ç¾æ–¹å¼**
```python
# PyTorch æ··åˆç²¾åº¦å¯¦ä¾‹
from torch.cuda.amp import autocast, GradScaler

model = MyModel().cuda()
optimizer = torch.optim.Adam(model.parameters())
scaler = GradScaler()

for data, target in dataloader:
    optimizer.zero_grad()

    # å‰å‘å‚³æ’­ä½¿ç”¨ FP16
    with autocast():
        output = model(data)
        loss = criterion(output, target)

    # æå¤±ç¸®æ”¾é˜²æ­¢æ¢¯åº¦ä¸‹æº¢
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

**æŠ€è¡“è¦é»**
- **å‹•æ…‹æå¤±ç¸®æ”¾** è‡ªå‹•èª¿æ•´ç¸®æ”¾å› å­é˜²æ­¢æ¢¯åº¦ä¸‹æº¢
- **é¸æ“‡æ€§ç²¾åº¦** é—œéµæ“ä½œä½¿ç”¨ FP32 ç²¾åº¦
- **è¨˜æ†¶é«”ç¯€çœ** æ¸›å°‘ç´„50%è¨˜æ†¶é«”ä½¿ç”¨ï¼ŒåŒæ™‚é¿å… inf/nan å•é¡Œ

##### æ¢¯åº¦ç´¯ç© (Gradient Accumulation)

**æ‡‰ç”¨å ´æ™¯** ç•¶GPUè¨˜æ†¶é«”ä¸è¶³ä»¥æ”¯æŒå¤§æ‰¹æ¬¡è¨“ç·´æ™‚

**å¯¦ç¾ç­–ç•¥**
```python
# æ¢¯åº¦ç´¯ç©ç¯„ä¾‹
accumulation_steps = 4
model.zero_grad()

for i, (data, target) in enumerate(dataloader):
    output = model(data)
    loss = criterion(output, target) / accumulation_steps
    loss.backward()

    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        model.zero_grad()
```

**æœ‰æ•ˆæ‰¹æ¬¡å¤§å°è¨ˆç®—**
$$ \text{batch\_size}_{\text{effective}} = \text{batch\_size}_{\text{micro}} \times \text{accumulation\_steps} $$

##### æ¢¯åº¦æª¢æŸ¥é» (Gradient Checkpointing)

**åŸºæœ¬åŸç†** åœ¨å‰å‘å‚³æ’­æ™‚ä¸å„²å­˜æ‰€æœ‰ä¸­é–“æ¿€æ´»å€¼ï¼Œåœ¨åå‘å‚³æ’­æ™‚é‡æ–°è¨ˆç®—ã€‚

**ç­–ç•¥æ¬Šè¡¡**
- **è¨˜æ†¶é«”ç¯€çœ** ä»¥æ™‚é–“æ›ç©ºé–“çš„ç¶“å…¸ç­–ç•¥
- **è¨ˆç®—é–‹éŠ·** éœ€è¦é‡æ–°è¨ˆç®—ä¸Ÿæ£„çš„ä¸­é–“æ¿€æ´»å€¼
- **å¯¦ç¾ç­–ç•¥** æ ¹æ“šå±¤æ•¸æ±ºå®šæª¢æŸ¥é»ä½ç½®

**ç†è«–åˆ†æ**
- è¨˜æ†¶é«”å¾ $O(L)$ é™è‡³ $O(\sqrt{L})$ï¼Œå…¶ä¸­ $L$ ç‚ºå±¤æ•¸
- å¢åŠ ç´„ 20-30% çš„è¨ˆç®—æ™‚é–“

#### 1.2.3 æ³¨æ„åŠ›æ”¹é€²

##### Multi-Query Attention (MQA)

**æ ¸å¿ƒæ€æƒ³** æ¸›å°‘ KV Cache è¨˜æ†¶é«”ä½¿ç”¨ï¼Œæå‡æ¨ç†æ•ˆç‡ã€‚

**æ¶æ§‹å°æ¯”**
```python
# æ¨™æº– Multi-Head Attention
class StandardMHA(nn.Module):
    def __init__(self, d_model, n_heads):
        self.n_heads = n_heads
        self.d_k = d_model // n_heads
        self.W_q = nn.Linear(d_model, d_model)  # n_heads å€‹ query
        self.W_k = nn.Linear(d_model, d_model)  # n_heads å€‹ key
        self.W_v = nn.Linear(d_model, d_model)  # n_heads å€‹ value

# Multi-Query Attention
class MQA(nn.Module):
    def __init__(self, d_model, n_heads):
        self.n_heads = n_heads
        self.d_k = d_model // n_heads
        self.W_q = nn.Linear(d_model, d_model)  # n_heads å€‹ query
        self.W_k = nn.Linear(d_model, self.d_k)  # 1 å€‹å…±äº« key
        self.W_v = nn.Linear(d_model, self.d_k)  # 1 å€‹å…±äº« value
```

**æ•ˆèƒ½æ”¹å–„**
- KV Cache æ¸›å°‘ $\frac{n_{\text{heads}} - 1}{n_{\text{heads}}}$
- æ¨ç†é€Ÿåº¦æå‡ 10-20%
- å°æ¨¡å‹å“è³ªå½±éŸ¿æœ€å°

##### Grouped-Query Attention (GQA)

**æ ¸å¿ƒæ€æƒ³** MQA èˆ‡ MHA çš„æŠ˜è¡·æ–¹æ¡ˆ

**æŠ€è¡“ç‰¹é»**
- æŸ¥è©¢é ­åˆ†çµ„è™•ç†
- æ¯çµ„å…±äº«ä¸€å€‹ Key å’Œ Value
- å¹³è¡¡è¨˜æ†¶é«”èˆ‡å“è³ª

**é…ç½®ç¯„ä¾‹**
```python
# GQA é…ç½®
n_heads = 32
n_kv_heads = 8  # 4 å€‹æŸ¥è©¢é ­å…±äº«ä¸€çµ„ KV
group_size = n_heads // n_kv_heads  # = 4
```

---

## 2. First Principles (åŸç†)

### 2.1 è¨ˆç®—è¤‡é›œåº¦åˆ†æ

#### æ³¨æ„åŠ›æ©Ÿåˆ¶è¨ˆç®—è¤‡é›œåº¦

**æ¨™æº–æ³¨æ„åŠ›è¤‡é›œåº¦**
- **æ™‚é–“è¤‡é›œåº¦** $O(n^2 d)$ï¼Œå…¶ä¸­ $n$ ç‚ºåºåˆ—é•·åº¦ï¼Œ$d$ ç‚ºéš±å‘é‡ç¶­åº¦
- **ç©ºé–“è¤‡é›œåº¦** $O(n^2 + nd)$
- **è¨˜æ†¶é«”ç“¶é ¸** ç•¶ $n \gg d$ æ™‚ï¼Œ$n^2$ é …ä¸»å°è¤‡é›œåº¦

**æ•¸å­¸åˆ†æ**
å°æ–¼è¼¸å…¥ $X \in \mathbb{R}^{n \times d}$ï¼š
1. è¨ˆç®— QKVï¼š$3nd^2$ æ¬¡æ“ä½œ
2. æ³¨æ„åŠ›åˆ†æ•¸ï¼š$n^2d$ æ¬¡æ“ä½œ
3. åŠ æ¬Šå¹³å‡ï¼š$n^2d$ æ¬¡æ“ä½œ

ç¸½è¨ˆç®—é‡ï¼š$O(3nd^2 + 2n^2d)$

**è¨˜æ†¶é«”ç“¶é ¸åˆ†æ**
ç•¶ $n = 8192, d = 4096$ æ™‚ï¼š
- æ³¨æ„åŠ›çŸ©é™£ï¼š$8192^2 \times 4 \text{bytes} = 268 \text{GB}$
- è¶…å‡ºå¸¸è¦‹ GPU è¨˜æ†¶é«”å®¹é‡

#### è¨˜æ†¶é«”å±¤æ¬¡å„ªåŒ–åŸç†

**GPU è¨˜æ†¶é«”å±¤æ¬¡**
1. **æš«å­˜å™¨** 1-2KBï¼Œ1 cycle å­˜å–
2. **å…±äº«è¨˜æ†¶é«”** 48-164KBï¼Œ1-32 cycles
3. **L2 å¿«å–** 40-80MBï¼Œ200-400 cycles
4. **å…¨åŸŸè¨˜æ†¶é«”** 16-80GBï¼Œ400-800 cycles

**æœ€ä½³åŒ–ç­–ç•¥**
- **è³‡æ–™é‡ç”¨** æœ€å¤§åŒ–æš«å­˜å™¨å’Œå…±äº«è¨˜æ†¶é«”çš„ä½¿ç”¨
- **åˆä½µå­˜å–** åˆ†å¡Šæ¼”ç®—æ³•å„ªåŒ–è¨˜æ†¶é«”å­˜å–æ¨¡å¼
- **è¨ˆç®—éš±è—** åˆ©ç”¨è¨˜æ†¶é«”å±¤æ¬¡éš±è—è¨ˆç®—å»¶é²

### 2.2 æ•¸å€¼ç²¾åº¦ç†è«–

#### æµ®é»æ•¸è¡¨ç¤ºåˆ†æ

**IEEE 754 æ¨™æº–**
- **FP32**ï¼š1 ç¬¦è™Ÿä½ + 8 æŒ‡æ•¸ä½ + 23 å°¾æ•¸ä½
- **FP16**ï¼š1 ç¬¦è™Ÿä½ + 5 æŒ‡æ•¸ä½ + 10 å°¾æ•¸ä½
- **BF16**ï¼š1 ç¬¦è™Ÿä½ + 8 æŒ‡æ•¸ä½ + 7 å°¾æ•¸ä½

**ç²¾åº¦æ¯”è¼ƒ**
| æ ¼å¼ | ç¯„åœ | ç²¾åº¦ | ç‰¹æ€§ |
|------|------|------|------|
| FP32 | $\pm 3.4 \times 10^{38}$ | ~7 ä½ | æ¨™æº–ç²¾åº¦ |
| FP16 | $\pm 6.5 \times 10^4$ | ~3 ä½ | é«˜é€Ÿæ¨ç† |
| BF16 | $\pm 3.4 \times 10^{38}$ | ~2 ä½ | è¨“ç·´å‹å¥½ |

#### æ¢¯åº¦ä¸‹æº¢å•é¡Œ

**å•é¡Œæè¿°** FP16 æœ€å°å¯è¡¨ç¤ºæ­£æ•¸ç´„ç‚º $6 \times 10^{-5}$ï¼Œå°æ–¼æ­¤å€¼çš„æ¢¯åº¦æœƒè¢«æˆªæ–·ç‚º 0

**è§£æ±ºæ–¹æ¡ˆ** æå¤±ç¸®æ”¾
$$L_{\text{scaled}} = \text{scale} \times L_{\text{original}}$$
$$\nabla_{\text{scaled}} = \text{scale} \times \nabla_{\text{original}}$$

**å‹•æ…‹ç¸®æ”¾æ¼”ç®—æ³•**
```python
def dynamic_loss_scaling(loss, scale, growth_factor=2.0,
                        backoff_factor=0.5, growth_interval=2000):
    # æª¢æ¸¬æ¢¯åº¦æ˜¯å¦åŒ…å« inf/nan
    if has_inf_or_nan(gradients):
        scale *= backoff_factor
        skip_update = True
    else:
        if steps_since_last_unscale > growth_interval:
            scale *= growth_factor
        skip_update = False

    return scale, skip_update
```

---

## 3. Body of Knowledge (å¯¦å‹™çŸ¥è­˜)

### 3.1 FlashAttention é€²éšå¯¦å‹™

#### 3.1.1 FlashAttention ç”Ÿç”¢ç’°å¢ƒå„ªåŒ–

##### å¯¦éš›éƒ¨ç½²è€ƒé‡

**ç¡¬é«”é©é…ç­–ç•¥**
```python
# FlashAttention ç¡¬é«”æª¢æ¸¬èˆ‡é…ç½®
import torch
import torch.nn.functional as F
from flash_attn import flash_attn_func, flash_attn_varlen_func

def configure_flash_attention(device_capability):
    """æ ¹æ“šGPUç®—åŠ›é…ç½®FlashAttentionåƒæ•¸"""
    if device_capability >= (8, 0):  # A100, H100
        return {
            'block_size_m': 128,
            'block_size_n': 128,
            'num_warps': 8,
            'num_stages': 2
        }
    elif device_capability >= (7, 5):  # RTX 20/30 series
        return {
            'block_size_m': 64,
            'block_size_n': 64,
            'num_warps': 4,
            'num_stages': 1
        }
    else:
        # å›é€€åˆ°æ¨™æº–æ³¨æ„åŠ›
        return None

class OptimizedFlashAttention(torch.nn.Module):
    def __init__(self, d_model, n_heads, dropout=0.0):
        super().__init__()
        self.d_model = d_model
        self.n_heads = n_heads
        self.head_dim = d_model // n_heads
        self.dropout = dropout

        # æª¢æ¸¬ç¡¬é«”èƒ½åŠ›
        device_cap = torch.cuda.get_device_capability()
        self.flash_config = configure_flash_attention(device_cap)

        self.qkv_proj = torch.nn.Linear(d_model, 3 * d_model, bias=False)
        self.out_proj = torch.nn.Linear(d_model, d_model)

    def forward(self, x, attention_mask=None):
        batch_size, seq_len, _ = x.shape

        # æŠ•å½±åˆ° QKV
        qkv = self.qkv_proj(x)
        q, k, v = qkv.chunk(3, dim=-1)

        # é‡å¡‘ç‚ºå¤šé ­æ ¼å¼
        q = q.view(batch_size, seq_len, self.n_heads, self.head_dim)
        k = k.view(batch_size, seq_len, self.n_heads, self.head_dim)
        v = v.view(batch_size, seq_len, self.n_heads, self.head_dim)

        if self.flash_config is not None:
            # ä½¿ç”¨ FlashAttention
            output = flash_attn_func(
                q, k, v,
                dropout_p=self.dropout if self.training else 0.0,
                softmax_scale=1.0 / (self.head_dim ** 0.5),
                causal=True
            )
        else:
            # å›é€€åˆ°æ¨™æº–æ³¨æ„åŠ›
            output = self._standard_attention(q, k, v, attention_mask)

        # é‡å¡‘è¼¸å‡º
        output = output.view(batch_size, seq_len, self.d_model)
        return self.out_proj(output)
```

##### è¨˜æ†¶é«”ä½¿ç”¨å„ªåŒ–

**å‹•æ…‹åºåˆ—é•·åº¦è™•ç†**
```python
class VariableLengthFlashAttention:
    """è™•ç†ä¸åŒåºåˆ—é•·åº¦çš„æ‰¹æ¬¡æ¨ç†"""

    def __init__(self, max_seq_len=4096):
        self.max_seq_len = max_seq_len

    def packed_attention(self, q, k, v, cu_seqlens):
        """
        ä½¿ç”¨ packed æ ¼å¼è™•ç†è®Šé•·åºåˆ—
        Args:
            q, k, v: (total_tokens, n_heads, head_dim)
            cu_seqlens: ç´¯ç©åºåˆ—é•·åº¦ [0, len1, len1+len2, ...]
        """
        return flash_attn_varlen_func(
            q, k, v, cu_seqlens, cu_seqlens,
            max_seqlen_q=self.max_seq_len,
            max_seqlen_k=self.max_seq_len,
            dropout_p=0.0,
            softmax_scale=1.0 / (q.shape[-1] ** 0.5),
            causal=True
        )

    def batch_inference(self, inputs):
        """æ‰¹æ¬¡æ¨ç†å„ªåŒ–"""
        # å°‡ä¸åŒé•·åº¦åºåˆ—æ‰“åŒ…
        packed_inputs, cu_seqlens = self._pack_sequences(inputs)

        # åŸ·è¡Œæ³¨æ„åŠ›è¨ˆç®—
        output = self.packed_attention(
            packed_inputs['q'],
            packed_inputs['k'],
            packed_inputs['v'],
            cu_seqlens
        )

        # è§£åŒ…å›åŸå§‹æ ¼å¼
        return self._unpack_sequences(output, cu_seqlens)
```

##### æ¨ç†æœå‹™æ•´åˆ

**èˆ‡ vLLM æ•´åˆ**
```python
# vLLM ä¸­çš„ FlashAttention é…ç½®
class FlashAttentionBackend:
    def __init__(self, model_config):
        self.model_config = model_config
        self.use_flash_attn = self._check_flash_support()

    def _check_flash_support(self):
        """æª¢æŸ¥ç’°å¢ƒæ˜¯å¦æ”¯æŒ FlashAttention"""
        try:
            import flash_attn
            device_cap = torch.cuda.get_device_capability()
            return device_cap >= (7, 5)
        except ImportError:
            return False

    def attention_forward(self, query, key, value, attention_mask):
        if self.use_flash_attn:
            return self._flash_attention_forward(query, key, value)
        else:
            return self._standard_attention_forward(
                query, key, value, attention_mask
            )
```

#### 3.1.2 FlashAttention æ€§èƒ½èª¿å„ª

##### æ¨¡å‹æ¶æ§‹é©é…

**é•·åºåˆ—å„ªåŒ–**
```python
class LongSequenceOptimizer:
    """é•·åºåˆ—å ´æ™¯çš„ç‰¹æ®Šå„ªåŒ–"""

    def __init__(self, window_size=2048, stride=1024):
        self.window_size = window_size
        self.stride = stride

    def sliding_window_attention(self, q, k, v, seq_len):
        """æ»‘å‹•çª—å£æ³¨æ„åŠ›"""
        if seq_len <= self.window_size:
            return flash_attn_func(q, k, v, causal=True)

        outputs = []
        for start in range(0, seq_len, self.stride):
            end = min(start + self.window_size, seq_len)

            # çª—å£å…§çš„æ³¨æ„åŠ›è¨ˆç®—
            window_q = q[:, start:end]
            window_k = k[:, :end]  # å¯ä»¥çœ‹åˆ°ä¹‹å‰çš„æ‰€æœ‰å…§å®¹
            window_v = v[:, :end]

            window_out = flash_attn_func(
                window_q, window_k, window_v, causal=True
            )
            outputs.append(window_out)

        return torch.cat(outputs, dim=1)
```

##### é‡åŒ–èˆ‡ç²¾åº¦å„ªåŒ–

**æ··åˆç²¾åº¦ FlashAttention**
```python
class MixedPrecisionFlashAttention:
    """æ··åˆç²¾åº¦å„ªåŒ–çš„ FlashAttention"""

    def __init__(self, dtype=torch.float16):
        self.compute_dtype = dtype
        self.storage_dtype = torch.float32

    def forward(self, q, k, v):
        # ç¢ºä¿è¨ˆç®—ç²¾åº¦
        q = q.to(self.compute_dtype)
        k = k.to(self.compute_dtype)
        v = v.to(self.compute_dtype)

        # FlashAttention è¨ˆç®—
        with torch.cuda.amp.autocast(dtype=self.compute_dtype):
            output = flash_attn_func(q, k, v, causal=True)

        # è½‰å›å„²å­˜ç²¾åº¦
        return output.to(self.storage_dtype)
```

##### æ€§èƒ½ç›£æ§èˆ‡èª¿è©¦

**æ€§èƒ½åˆ†æå·¥å…·**
```python
class FlashAttentionProfiler:
    """FlashAttention æ€§èƒ½åˆ†æ"""

    def __init__(self):
        self.metrics = {}

    def profile_attention(self, q, k, v, num_runs=100):
        """æ¯”è¼ƒ FlashAttention èˆ‡æ¨™æº–æ³¨æ„åŠ›æ€§èƒ½"""
        batch_size, seq_len, n_heads, head_dim = q.shape

        # FlashAttention æ€§èƒ½æ¸¬è©¦
        flash_times = []
        flash_memory = []

        for _ in range(num_runs):
            torch.cuda.empty_cache()
            torch.cuda.synchronize()

            start_memory = torch.cuda.memory_allocated()
            start_time = time.time()

            _ = flash_attn_func(q, k, v, causal=True)

            torch.cuda.synchronize()
            end_time = time.time()
            end_memory = torch.cuda.max_memory_allocated()

            flash_times.append(end_time - start_time)
            flash_memory.append(end_memory - start_memory)

        # æ¨™æº–æ³¨æ„åŠ›æ€§èƒ½æ¸¬è©¦
        standard_times = []
        standard_memory = []

        for _ in range(num_runs):
            torch.cuda.empty_cache()
            torch.cuda.synchronize()

            start_memory = torch.cuda.memory_allocated()
            start_time = time.time()

            _ = self._standard_attention(q, k, v)

            torch.cuda.synchronize()
            end_time = time.time()
            end_memory = torch.cuda.max_memory_allocated()

            standard_times.append(end_time - start_time)
            standard_memory.append(end_memory - start_memory)

        return {
            'flash_attn': {
                'avg_time': np.mean(flash_times),
                'avg_memory': np.mean(flash_memory)
            },
            'standard_attn': {
                'avg_time': np.mean(standard_times),
                'avg_memory': np.mean(standard_memory)
            },
            'speedup': np.mean(standard_times) / np.mean(flash_times),
            'memory_reduction': 1 - np.mean(flash_memory) / np.mean(standard_memory)
        }
```

### 3.2 æ¨¡å‹å°é½ŠæŠ€è¡“

#### 3.2.1 å¼·åŒ–å­¸ç¿’å°é½Š (RLHF)

##### è¿‘ç«¯ç­–ç•¥å„ªåŒ– (Proximal Policy Optimization, PPO) åœ¨ LLM å°é½Šä¸­çš„æ‡‰ç”¨

**PPO æ ¸å¿ƒæ€æƒ³**
PPO é€éé™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦ä¾†é¿å…ä¸ç©©å®šçš„å¤§å¹…ç­–ç•¥è®ŠåŒ–ï¼Œä¿æŒè¨“ç·´çš„ç©©å®šæ€§

**ç›®æ¨™å‡½æ•¸**
$$L^{\text{CLIP}}(\theta) = \mathbb{E}_t\left[\min\left(r_t(\theta)\hat{A}_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon)\hat{A}_t\right)\right]$$

å…¶ä¸­ï¼š
- $r_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{\text{old}}}(a_t|s_t)}$ ç‚ºé‡è¦æ€§æ¯”å€¼
- $\hat{A}_t$ ç‚ºå„ªå‹¢å‡½æ•¸ä¼°è¨ˆ
- $\epsilon$ ç‚ºè£åˆ‡åƒæ•¸ï¼ˆé€šå¸¸ç‚º 0.2ï¼‰

**RLHF ä¸‰éšæ®µæµç¨‹**

**éšæ®µ 1ï¼šç›£ç£å¾®èª¿ (SFT)**
```python
# ç›£ç£å¾®èª¿ç¯„ä¾‹
def sft_loss(model, batch):
    input_ids, labels = batch
    logits = model(input_ids).logits
    loss = cross_entropy(logits.view(-1, vocab_size),
                        labels.view(-1))
    return loss
```

**éšæ®µ 2ï¼šçå‹µæ¨¡å‹è¨“ç·´**
```python
# çå‹µæ¨¡å‹è¨“ç·´
def reward_model_loss(reward_model, chosen, rejected):
    reward_chosen = reward_model(chosen)
    reward_rejected = reward_model(rejected)

    # Bradley-Terry æ¨¡å‹
    loss = -log_sigmoid(reward_chosen - reward_rejected)
    return loss.mean()
```

**éšæ®µ 3ï¼šPPO (Proximal Policy Optimization) å¼·åŒ–å­¸ç¿’**
```python
# PPO è¨“ç·´ç¯„ä¾‹
def ppo_loss(policy_model, value_model, ref_model, batch):
    states, actions, old_log_probs, rewards, values = batch

    # è¨ˆç®—é‡è¦æ€§æ¯”å€¼
    new_log_probs = policy_model.log_prob(states, actions)
    ratio = torch.exp(new_log_probs - old_log_probs)

    # å„ªå‹¢ä¼°è¨ˆ
    advantages = rewards - values

    # PPO è£åˆ‡æå¤±
    surr1 = ratio * advantages
    surr2 = torch.clamp(ratio, 1-eps, 1+eps) * advantages
    policy_loss = -torch.min(surr1, surr2).mean()

    # åƒ¹å€¼å‡½æ•¸æå¤±
    value_loss = F.mse_loss(value_model(states), rewards)

    # KL æ•£åº¦æ­£å‰‡åŒ–é …
    kl_div = kl_divergence(policy_model(states), ref_model(states))

    total_loss = policy_loss + 0.5 * value_loss + 0.01 * kl_div
    return total_loss
```

##### RLHF çš„æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆ

**æ”¶æ–‚æ€§å•é¡Œ**
- **å•é¡Œ** ç­–ç•¥æ¢¯åº¦æ–¹æ³•å®¹æ˜“ç™¼æ•£
- **è§£æ±º** KL æ•£åº¦ç´„æŸé™åˆ¶ç­–ç•¥è®ŠåŒ–å¹…åº¦

**çå‹µå‡½æ•¸è¨­è¨ˆ**
- **å•é¡Œ** äººé¡æ¨™è¨»çš„çå‹µæ¨¡å‹å¯èƒ½ä¸æº–ç¢º
- **è§£æ±º** çå‹µæ¨¡å‹çš„é­¯æ£’æ€§è¨“ç·´

**è¨ˆç®—è¤‡é›œæ€§**
- **å•é¡Œ** éœ€è¦åŒæ™‚ç¶­è­·å¤šå€‹æ¨¡å‹
- **è§£æ±º** æ¨¡å‹ä¸¦è¡Œå’Œè¨˜æ†¶é«”å„ªåŒ–

#### 3.2.2 ç›´æ¥åå¥½å„ªåŒ–

##### ç›´æ¥åå¥½å„ªåŒ– (Direct Preference Optimization, DPO)

**æ ¸å¿ƒæ€æƒ³** ç¹éçå‹µæ¨¡å‹ï¼Œç›´æ¥å¾åå¥½è³‡æ–™é€²è¡Œå„ªåŒ–

**ç†è«–åŸºç¤**
æ ¹æ“š Bradley-Terry åå¥½æ¨¡å‹ï¼Œæœ€å„ªç­–ç•¥æ»¿è¶³ï¼š
$$\pi^*(y|x) = \frac{1}{Z(x)} \pi_{\text{ref}}(y|x) \exp\left(\frac{r(x,y)}{\beta}\right)$$

**DPO (Direct Preference Optimization) ç›®æ¨™å‡½æ•¸**
$$L_{\text{DPO}}(\pi_\theta) = -\mathbb{E}_{(x,y_w,y_l) \sim \mathcal{D}}\left[\log \sigma\left(\beta \log \frac{\pi_\theta(y_w|x)}{\pi_{\text{ref}}(y_w|x)} - \beta \log \frac{\pi_\theta(y_l|x)}{\pi_{\text{ref}}(y_l|x)}\right)\right]$$

å…¶ä¸­ï¼š
- $y_w$ ç‚ºåå¥½å›æ‡‰
- $y_l$ ç‚ºéåå¥½å›æ‡‰
- $\beta$ ç‚ºæº«åº¦åƒæ•¸

**å¯¦ç¾ä»£ç¢¼**
```python
def dpo_loss(model, ref_model, chosen, rejected, beta=0.1):
    # è¨ˆç®—ç­–ç•¥æ¨¡å‹å°æ•¸æ©Ÿç‡
    chosen_logprobs = model.log_prob(chosen)
    rejected_logprobs = model.log_prob(rejected)

    # è¨ˆç®—åƒè€ƒæ¨¡å‹å°æ•¸æ©Ÿç‡
    with torch.no_grad():
        chosen_ref_logprobs = ref_model.log_prob(chosen)
        rejected_ref_logprobs = ref_model.log_prob(rejected)

    # è¨ˆç®—æ¯”å€¼
    chosen_ratio = chosen_logprobs - chosen_ref_logprobs
    rejected_ratio = rejected_logprobs - rejected_ref_logprobs

    # DPO æå¤±
    loss = -F.logsigmoid(beta * (chosen_ratio - rejected_ratio))
    return loss.mean()
```

**DPO å„ªå‹¢**
- ç„¡éœ€ç¨ç«‹çš„çå‹µæ¨¡å‹
- è¨“ç·´æ›´åŠ ç©©å®šç°¡æ½”
- è¨ˆç®—è³‡æºéœ€æ±‚è¼ƒä½

##### Odds Ratio Preference Optimization (ORPO)

**åŸºæœ¬æ¦‚å¿µ** åœ¨ç›£ç£å¾®èª¿çš„åŒæ™‚é€²è¡Œåå¥½å„ªåŒ–

**ç›®æ¨™å‡½æ•¸**
$$L_{\text{ORPO}} = L_{\text{SFT}} + \lambda \cdot L_{\text{OR}}$$

å…¶ä¸­ Odds Ratio æå¤±ï¼š
$$L_{\text{OR}} = -\mathbb{E}\left[\log \sigma\left(\log \frac{\text{odds}_\theta(y_w|x)}{\text{odds}_\theta(y_l|x)}\right)\right]$$

**æŠ€è¡“å„ªå‹¢**
- å–®éšæ®µè¨“ç·´
- ç„¡éœ€çå‹µæ¨¡å‹
- æ›´é«˜çš„è¨“ç·´æ•ˆç‡

### 3.3 å„ªåŒ–å™¨é€²éšæŠ€è¡“

#### 3.3.1 ç¾ä»£å„ªåŒ–å™¨è¨­è¨ˆ

##### AdamW èˆ‡ Weight Decay

**æ ¸å¿ƒå•é¡Œ** å‚³çµ± Adam çš„L2æ­£å‰‡åŒ–æœƒèˆ‡è‡ªé©æ‡‰å­¸ç¿’ç‡ç”¢ç”Ÿäº¤äº’ä½œç”¨

**AdamW è§£æ±ºæ–¹æ¡ˆ**
å°‡æ¬Šé‡è¡°æ¸›èˆ‡æ¢¯åº¦æ›´æ–°åˆ†é›¢ï¼š
$$\theta_{t+1} = \theta_t - \alpha \cdot \left(\frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} + \lambda \theta_t\right)$$

**å¯¦ç¾å°æ¯”**
```python
# å‚³çµ± Adam + L2 (ä¸æ­£ç¢ºçš„åšæ³•)
loss = mse_loss + l2_reg * sum(p**2 for p in parameters)

# AdamW (æ­£ç¢ºçš„åšæ³•)
optimizer = torch.optim.AdamW(parameters, lr=1e-3, weight_decay=0.01)
```

##### Lion å„ªåŒ–å™¨

**æ ¸å¿ƒæ€æƒ³** ä½¿ç”¨ç¬¦è™Ÿå‡½æ•¸ç°¡åŒ–æ¢¯åº¦æ›´æ–°ï¼Œæé«˜è¨˜æ†¶é«”æ•ˆç‡

**æ›´æ–°è¦å‰‡**
$$\theta_{t+1} = \theta_t - \eta \cdot \text{sign}(\text{interp}(m_t, \nabla_t, \beta_1))$$
$$m_{t+1} = \beta_2 m_t + (1-\beta_2) \nabla_t$$

**å„ªå‹¢ç‰¹é»**
- è¨˜æ†¶é«”ä½¿ç”¨æ¯” Adam ç¯€çœ 50%
- å¤§å‹æ¨¡å‹è¨“ç·´æ•ˆæœæ›´ä½³
- è¨ˆç®—ç°¡æ½”é«˜æ•ˆ

#### 3.3.2 å­¸ç¿’ç‡èª¿åº¦ç­–ç•¥

##### Cosine Annealing with Warmup

**æœ€ä½³å¯¦è¸çµ„åˆ**
```python
class CosineAnnealingWarmup:
    def __init__(self, optimizer, warmup_steps, total_steps,
                 min_lr_ratio=0.1):
        self.optimizer = optimizer
        self.warmup_steps = warmup_steps
        self.total_steps = total_steps
        self.min_lr_ratio = min_lr_ratio
        self.base_lrs = [group['lr'] for group in optimizer.param_groups]

    def get_lr(self, step):
        if step < self.warmup_steps:
            # ç·šæ€§ warmup
            lr_scale = step / self.warmup_steps
        else:
            # Cosine annealing
            progress = (step - self.warmup_steps) / (self.total_steps - self.warmup_steps)
            lr_scale = self.min_lr_ratio + (1 - self.min_lr_ratio) * \
                      0.5 * (1 + math.cos(math.pi * progress))

        return [base_lr * lr_scale for base_lr in self.base_lrs]
```

---

## ç¸½çµ

è¨“ç·´å„ªåŒ–èˆ‡å°é½ŠæŠ€è¡“æ˜¯ LLM å¯¦ç”¨åŒ–çš„é—œéµæŠ€è¡“ç¾¤çµ„ï¼Œè§£æ±ºäº†å¤§æ¨¡å‹è¨“ç·´æ•ˆç‡å’Œå®‰å…¨æ€§çš„æ ¸å¿ƒå•é¡Œã€‚é€šéè¨˜æ†¶é«”å„ªåŒ–ã€è¨ˆç®—åŠ é€Ÿã€æ•¸å€¼ç©©å®šå’Œå°é½ŠæŠ€è¡“çš„ç³»çµ±æ€§æ‡‰ç”¨ï¼Œç¾ä»£LLMèƒ½å¤ é«˜æ•ˆä¸”å®‰å…¨åœ°ç‚ºå„ç¨®æ‡‰ç”¨å ´æ™¯æä¾›æœå‹™ã€‚

### æŠ€è¡“è¦é»ç¸½çµ

1. **è¨˜æ†¶é«”å„ªåŒ–** FlashAttentionç­‰æŠ€è¡“é¡¯è‘—é™ä½è¨˜æ†¶é«”éœ€æ±‚ï¼Œå¯¦ç¾é•·åºåˆ—è¨“ç·´
2. **è¨ˆç®—åŠ é€Ÿ** æ··åˆç²¾åº¦ã€æ¢¯åº¦ç´¯ç©ã€å‹•æ…‹æå¤±ç¸®æ”¾æœ‰æ•ˆæå‡è¨“ç·´æ•ˆç‡
3. **å°é½ŠæŠ€è¡“** å¾ RLHF åˆ° DPO çš„æ¼”é€²ï¼Œä½¿æ¨¡å‹æ›´å¥½åœ°ç¬¦åˆäººé¡åƒ¹å€¼è§€
4. **å„ªåŒ–å™¨å‰µæ–°** å¾é—œæ³¨æ”¶æ–‚é€Ÿåº¦åˆ°å¼·èª¿è¨˜æ†¶é«”æ•ˆç‡å’Œç©©å®šæ€§

### æœªä¾†ç™¼å±•æ–¹å‘

- **è¨˜æ†¶é«”æ•ˆç‡** æŒçºŒæ¢ç´¢æ›´é«˜æ•ˆçš„è¨˜æ†¶é«”å„ªåŒ–æŠ€è¡“
- **å°é½Šé­¯æ£’æ€§** é–‹ç™¼æ›´å¼·å¥çš„å°é½ŠæŠ€è¡“æ¡†æ¶
- **ç¡¬é«”é©é…** é‡å°æ–°ä¸€ä»£ç¡¬é«”çš„å„ªåŒ–æ¼”ç®—æ³•
- **å°é½Šå‰µæ–°** æ†²æ³•AIç­‰æ–°èˆˆå°é½ŠæŠ€è¡“çš„ç ”ç©¶å’Œæ‡‰ç”¨

**ğŸš¨ å–®GPUç’°å¢ƒé™åˆ¶èªªæ˜**
1. ç†è§£GPUè¨˜æ†¶é«”å„ªåŒ–çš„æ ¸å¿ƒæ¼”ç®—æ³•
2. æŒæ¡ FlashAttention ç­‰é—œéµæŠ€è¡“åŸç†
3. ç†è§£ DPO ç­‰å°é½ŠæŠ€è¡“çš„ç†è«–åŸºç¤
4. å»ºç«‹å„ªåŒ–æŠ€è¡“çš„å…¨åŸŸè¦–è§’
5. ç‚ºå¯¦éš›Constitution AIç­‰æ–°èˆˆæŠ€è¡“å¥ å®šåŸºç¤

é€éç³»çµ±æ€§çš„ç†è«–å­¸ç¿’ï¼Œæ‚¨å°‡æŒæ¡ LLM è¨“ç·´å„ªåŒ–çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œç‚ºé€²ä¸€æ­¥çš„å¯¦è¸æ‡‰ç”¨å’ŒæŠ€è¡“å‰µæ–°æ‰“ä¸‹å …å¯¦åŸºç¤ã€‚