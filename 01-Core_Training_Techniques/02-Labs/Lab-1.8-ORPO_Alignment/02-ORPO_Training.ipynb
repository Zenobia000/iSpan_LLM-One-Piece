{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-1.8: ORPO å–®éšæ®µå°é½Šè¨“ç·´\n",
    "\n",
    "**å¯¦é©—ç›®æ¨™**: å¯¦ç¾ ORPO å–®éšæ®µå°é½Šè¨“ç·´\n",
    "\n",
    "ORPO (Odds Ratio Preference Optimization) çš„æ ¸å¿ƒå‰µæ–°åœ¨æ–¼å–®éšæ®µè¨“ç·´ï¼š\n",
    "- **çµ±ä¸€ç›®æ¨™**: åŒæ™‚å„ªåŒ– SFT å’Œåå¥½å°é½Š\n",
    "- **ç„¡éœ€åƒè€ƒæ¨¡å‹**: ä¸åƒ DPO éœ€è¦åƒè€ƒæ¨¡å‹\n",
    "- **è¨˜æ†¶é«”é«˜æ•ˆ**: åªéœ€è¼‰å…¥ä¸€å€‹æ¨¡å‹\n",
    "- **è¨“ç·´ç°¡åŒ–**: å–®ä¸€æå¤±å‡½æ•¸ï¼Œæ›´å®¹æ˜“èª¿å„ª\n",
    "\n",
    "## ORPO æå¤±å‡½æ•¸\n",
    "\n",
    "```\n",
    "L_ORPO = L_SFT + Î» Ã— L_OR\n",
    "\n",
    "å…¶ä¸­:\n",
    "- L_SFT: æ¨™æº–èªè¨€æ¨¡å‹æå¤± (åœ¨ chosen ä¸Š)\n",
    "- L_OR: Odds Ratio åå¥½æå¤±\n",
    "- Î»: å¹³è¡¡æ¬Šé‡ (é€šå¸¸ 0.1-1.0)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 1: ç’°å¢ƒæº–å‚™èˆ‡æ•¸æ“šè¼‰å…¥\n",
    "\n",
    "è¼‰å…¥ä¹‹å‰æº–å‚™çš„ç’°å¢ƒå’Œæ•¸æ“šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_from_disk, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# è¨­ç½®éš¨æ©Ÿç¨®å­\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print('ğŸš€ é–‹å§‹ ORPO å–®éšæ®µå°é½Šè¨“ç·´')\n",
    "print(f'GPU å¯ç”¨: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'ç•¶å‰ GPU: {torch.cuda.get_device_name()}')\n",
    "    print(f'GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥æ•¸æ“šé›†\n",
    "try:\n",
    "    orpo_dataset = load_from_disk('./orpo_data')\n",
    "    print(f'âœ… è¼‰å…¥ ORPO æ•¸æ“šé›†ï¼Œæ¨£æœ¬æ•¸: {len(orpo_dataset)}')\n",
    "except:\n",
    "    print('âš ï¸  ç„¡æ³•è¼‰å…¥å·²ä¿å­˜çš„æ•¸æ“šï¼Œå‰µå»ºæ¨¡æ“¬æ•¸æ“š')\n",
    "    # å‰µå»ºæ¨¡æ“¬ ORPO æ•¸æ“š\n",
    "    mock_data = [\n",
    "        {\n",
    "            'prompt': 'è«‹è§£é‡‹ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’?',\n",
    "            'chosen': 'æ©Ÿå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€å€‹é‡è¦åˆ†æ”¯ï¼Œå®ƒè®“è¨ˆç®—æ©Ÿèƒ½å¤ å¾æ•¸æ“šä¸­è‡ªå‹•å­¸ç¿’ä¸¦æ”¹é€²æ€§èƒ½ï¼Œè€Œç„¡éœ€æ˜ç¢ºç·¨ç¨‹ã€‚',\n",
    "            'rejected': 'æ©Ÿå™¨å­¸ç¿’å°±æ˜¯è®“æ©Ÿå™¨è®Šè°æ˜ã€‚'\n",
    "        },\n",
    "        {\n",
    "            'prompt': 'å¦‚ä½•é–‹å§‹å­¸ç¿’ç¨‹å¼è¨­è¨ˆ?',\n",
    "            'chosen': 'å­¸ç¿’ç¨‹å¼è¨­è¨ˆå»ºè­°å¾åŸºç¤èªæ³•é–‹å§‹ï¼Œé¸æ“‡ä¸€é–€é©åˆçš„èªè¨€å¦‚Pythonï¼Œå¤šåšç·´ç¿’é …ç›®ï¼Œåƒèˆ‡é–‹æºå°ˆæ¡ˆã€‚',\n",
    "            'rejected': 'å­¸ç¨‹å¼å°±æ˜¯å¯«codeã€‚'\n",
    "        },\n",
    "        {\n",
    "            'prompt': 'å¥åº·é£²é£Ÿçš„åŸºæœ¬åŸå‰‡æ˜¯ä»€éº¼?',\n",
    "            'chosen': 'å¥åº·é£²é£Ÿæ‡‰éµå¾ªç‡Ÿé¤Šå‡è¡¡åŸå‰‡ï¼ŒåŒ…æ‹¬é©ç•¶çš„ç¢³æ°´åŒ–åˆç‰©ã€è›‹ç™½è³ªã€è„‚è‚ªå’Œç¶­ç”Ÿç´ æ”å–ã€‚',\n",
    "            'rejected': 'å¥åº·é£²é£Ÿå°±æ˜¯å°‘åƒå¤šå‹•ã€‚'\n",
    "        }\n",
    "    ]\n",
    "    orpo_dataset = Dataset.from_list(mock_data)\n",
    "\n",
    "print(f'æ•¸æ“šé›†å¤§å°: {len(orpo_dataset)}')\n",
    "print(f'æ•¸æ“šæ¬„ä½: {list(orpo_dataset.features.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 2: æ¨¡å‹æº–å‚™\n",
    "\n",
    "è¼‰å…¥åŸºç¤æ¨¡å‹ä¸¦é…ç½® PEFTã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡å‹é…ç½®\n",
    "MODEL_NAME = 'microsoft/DialoGPT-medium'\n",
    "\n",
    "print(f'ğŸ“¦ è¼‰å…¥æ¨¡å‹: {MODEL_NAME}')\n",
    "\n",
    "# è¼‰å…¥ tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# è¼‰å…¥æ¨¡å‹\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "print(f'âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ')\n",
    "print(f'æ¨¡å‹åƒæ•¸é‡: {model.num_parameters():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½® LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=['c_attn', 'c_proj', 'c_fc'],\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    task_type='CAUSAL_LM'\n",
    ")\n",
    "\n",
    "# æº–å‚™æ¨¡å‹é€²è¡Œ PEFT\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print('âœ… PEFT é…ç½®å®Œæˆ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 3: ORPO æå¤±å‡½æ•¸å¯¦ç¾\n",
    "\n",
    "å¯¦ç¾å®Œæ•´çš„ ORPO æå¤±å‡½æ•¸å’Œè¨“ç·´é‚è¼¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_probs(model, input_ids, attention_mask, tokenizer):\n",
    "    \"\"\"è¨ˆç®—åºåˆ—çš„å°æ•¸æ¦‚ç‡\"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # è¨ˆç®—æ¯å€‹ token çš„å°æ•¸æ¦‚ç‡\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        \n",
    "        # æ”¶é›†ç›®æ¨™ token çš„å°æ•¸æ¦‚ç‡\n",
    "        target_log_probs = torch.gather(log_probs[:, :-1], dim=-1, \n",
    "                                       index=input_ids[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        # åƒ…è¨ˆç®—é padding token çš„å¹³å‡å°æ•¸æ¦‚ç‡\n",
    "        mask = (input_ids[:, 1:] != tokenizer.pad_token_id).float()\n",
    "        sequence_log_prob = (target_log_probs * mask).sum(dim=1) / mask.sum(dim=1)\n",
    "    \n",
    "    return sequence_log_prob\n",
    "\n",
    "\n",
    "def compute_odds_ratio_loss(chosen_log_probs, rejected_log_probs):\n",
    "    \"\"\"è¨ˆç®— ORPO çš„ Odds Ratio æå¤±\"\"\"\n",
    "    # è¨ˆç®— log odds (ä½¿ç”¨è¿‘ä¼¼)\n",
    "    chosen_log_odds = chosen_log_probs\n",
    "    rejected_log_odds = rejected_log_probs\n",
    "    \n",
    "    # Odds Ratio æå¤±\n",
    "    log_odds_ratio = chosen_log_odds - rejected_log_odds\n",
    "    loss = -F.logsigmoid(log_odds_ratio).mean()\n",
    "    \n",
    "    return loss, log_odds_ratio.mean()\n",
    "\n",
    "\n",
    "def orpo_loss_function(model, batch, tokenizer, lambda_or=0.5):\n",
    "    \"\"\"\n",
    "    ORPO æå¤±å‡½æ•¸\n",
    "    \n",
    "    Args:\n",
    "        model: è¨“ç·´ä¸­çš„æ¨¡å‹\n",
    "        batch: åŒ…å« chosen_input_ids, rejected_input_ids ç­‰\n",
    "        tokenizer: tokenizer\n",
    "        lambda_or: Odds Ratio æå¤±æ¬Šé‡\n",
    "    \n",
    "    Returns:\n",
    "        total_loss, metrics\n",
    "    \"\"\"\n",
    "    # 1. SFT æå¤± (æ¨™æº–èªè¨€æ¨¡å‹æå¤±ï¼Œåƒ…åœ¨ chosen ä¸Š)\n",
    "    chosen_input_ids = batch['chosen_input_ids']\n",
    "    chosen_attention_mask = batch['chosen_attention_mask']\n",
    "    \n",
    "    outputs = model(input_ids=chosen_input_ids, attention_mask=chosen_attention_mask, \n",
    "                   labels=chosen_input_ids)\n",
    "    sft_loss = outputs.loss\n",
    "    \n",
    "    # 2. Odds Ratio æå¤±\n",
    "    chosen_log_probs = compute_log_probs(model, batch['chosen_input_ids'], \n",
    "                                        batch['chosen_attention_mask'], tokenizer)\n",
    "    \n",
    "    rejected_log_probs = compute_log_probs(model, batch['rejected_input_ids'],\n",
    "                                          batch['rejected_attention_mask'], tokenizer)\n",
    "    \n",
    "    or_loss, log_odds_ratio = compute_odds_ratio_loss(chosen_log_probs, rejected_log_probs)\n",
    "    \n",
    "    # 3. ç¸½æå¤±\n",
    "    total_loss = sft_loss + lambda_or * or_loss\n",
    "    \n",
    "    metrics = {\n",
    "        'total_loss': total_loss.item(),\n",
    "        'sft_loss': sft_loss.item(),\n",
    "        'or_loss': or_loss.item(),\n",
    "        'log_odds_ratio': log_odds_ratio.item()\n",
    "    }\n",
    "    \n",
    "    return total_loss, metrics\n",
    "\n",
    "\n",
    "print('âœ… ORPO æå¤±å‡½æ•¸å¯¦ç¾å®Œæˆ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 4: æ•¸æ“šé è™•ç†èˆ‡ DataLoader\n",
    "\n",
    "æº–å‚™ ORPO è¨“ç·´çš„æ•¸æ“šè¼‰å…¥å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_orpo_batch(examples, tokenizer, max_length=256):\n",
    "    \"\"\"æº–å‚™ ORPO è¨“ç·´æ‰¹æ¬¡\"\"\"\n",
    "    batch_data = {\n",
    "        'chosen_input_ids': [],\n",
    "        'chosen_attention_mask': [],\n",
    "        'rejected_input_ids': [],\n",
    "        'rejected_attention_mask': []\n",
    "    }\n",
    "    \n",
    "    for example in examples:\n",
    "        # æ ¼å¼åŒ–ç‚ºå°è©±æ ¼å¼\n",
    "        prompt = f\"Human: {example['prompt']}\\n\\nAssistant:\"\n",
    "        chosen_text = prompt + example['chosen']\n",
    "        rejected_text = prompt + example['rejected']\n",
    "        \n",
    "        # Tokenize chosen\n",
    "        chosen_tokens = tokenizer(\n",
    "            chosen_text,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize rejected\n",
    "        rejected_tokens = tokenizer(\n",
    "            rejected_text,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        batch_data['chosen_input_ids'].append(chosen_tokens['input_ids'].squeeze())\n",
    "        batch_data['chosen_attention_mask'].append(chosen_tokens['attention_mask'].squeeze())\n",
    "        batch_data['rejected_input_ids'].append(rejected_tokens['input_ids'].squeeze())\n",
    "        batch_data['rejected_attention_mask'].append(rejected_tokens['attention_mask'].squeeze())\n",
    "    \n",
    "    # è½‰æ›ç‚º tensor\n",
    "    for key in batch_data:\n",
    "        batch_data[key] = torch.stack(batch_data[key])\n",
    "    \n",
    "    return batch_data\n",
    "\n",
    "\n",
    "# æº–å‚™è¨“ç·´æ•¸æ“š\n",
    "def create_dataloader(dataset, batch_size=2):\n",
    "    \"\"\"å‰µå»º ORPO æ•¸æ“šè¼‰å…¥å™¨\"\"\"\n",
    "    def collate_fn(examples):\n",
    "        batch = prepare_orpo_batch(examples, tokenizer)\n",
    "        return batch\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# å‰µå»ºè¨“ç·´ DataLoader\n",
    "train_dataloader = create_dataloader(orpo_dataset, batch_size=1)\n",
    "\n",
    "print(f'âœ… æ•¸æ“šè¼‰å…¥å™¨æº–å‚™å®Œæˆï¼Œæ‰¹æ¬¡æ•¸: {len(train_dataloader)}')\n",
    "\n",
    "# æ¸¬è©¦ä¸€å€‹æ‰¹æ¬¡\n",
    "test_batch = next(iter(train_dataloader))\n",
    "print(f'æ‰¹æ¬¡æ¸¬è©¦:')\n",
    "for key, value in test_batch.items():\n",
    "    print(f'  {key}: {value.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 5: ORPO è¨“ç·´é…ç½®\n",
    "\n",
    "è¨­ç½® ORPO è¨“ç·´çš„åƒæ•¸å’Œå„ªåŒ–å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORPO è¨“ç·´é…ç½®\n",
    "orpo_config = {\n",
    "    'epochs': 2,\n",
    "    'learning_rate': 5e-6,  # ORPO é€šå¸¸ä½¿ç”¨è¼ƒå°çš„å­¸ç¿’ç‡\n",
    "    'lambda_or': 0.5,       # Odds Ratio æå¤±æ¬Šé‡\n",
    "    'warmup_steps': 10,\n",
    "    'max_grad_norm': 1.0\n",
    "}\n",
    "\n",
    "# å„ªåŒ–å™¨\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=orpo_config['learning_rate'],\n",
    "    betas=(0.9, 0.95),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# å­¸ç¿’ç‡èª¿åº¦å™¨\n",
    "total_steps = len(train_dataloader) * orpo_config['epochs']\n",
    "warmup_steps = orpo_config['warmup_steps']\n",
    "\n",
    "def get_linear_schedule_with_warmup_lambda(current_step):\n",
    "    if current_step < warmup_steps:\n",
    "        return current_step / warmup_steps\n",
    "    return max(0, (total_steps - current_step) / (total_steps - warmup_steps))\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "scheduler = LambdaLR(optimizer, get_linear_schedule_with_warmup_lambda)\n",
    "\n",
    "print('âš™ï¸  ORPO è¨“ç·´é…ç½®:')\n",
    "for key, value in orpo_config.items():\n",
    "    print(f'  {key}: {value}')\n",
    "print(f'  total_steps: {total_steps}')\n",
    "print(f'  optimizer: AdamW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 6: ORPO è¨“ç·´å¾ªç’°\n",
    "\n",
    "åŸ·è¡Œ ORPO å–®éšæ®µå°é½Šè¨“ç·´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´æŒ‡æ¨™è¨˜éŒ„\n",
    "training_metrics = {\n",
    "    'total_loss': [],\n",
    "    'sft_loss': [],\n",
    "    'or_loss': [],\n",
    "    'log_odds_ratio': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "# æ¨¡å‹è¨­ç‚ºè¨“ç·´æ¨¡å¼\n",
    "model.train()\n",
    "\n",
    "print('ğŸš€ é–‹å§‹ ORPO è¨“ç·´...')\n",
    "print(f'ç¸½è¨ˆ {orpo_config[\"epochs\"]} å€‹ epochï¼Œ{total_steps} å€‹è¨“ç·´æ­¥é©Ÿ')\n",
    "\n",
    "# è¨“ç·´å‰çš„è¨˜æ†¶é«”ç‹€æ…‹\n",
    "if torch.cuda.is_available():\n",
    "    print(f'è¨“ç·´å‰ GPU è¨˜æ†¶é«”: {torch.cuda.memory_allocated() / 1e9:.2f} GB')\n",
    "\n",
    "global_step = 0\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    for epoch in range(orpo_config['epochs']):\n",
    "        print(f'\\n=== Epoch {epoch + 1}/{orpo_config[\"epochs\"]} ===')\n",
    "        \n",
    "        epoch_losses = []\n",
    "        \n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=f'Epoch {epoch + 1}')):\n",
    "            # ç§»å‹•æ‰¹æ¬¡åˆ° GPU\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            \n",
    "            # è¨ˆç®— ORPO æå¤±\n",
    "            total_loss, metrics = orpo_loss_function(\n",
    "                model, batch, tokenizer, lambda_or=orpo_config['lambda_or']\n",
    "            )\n",
    "            \n",
    "            # åå‘å‚³æ’­\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            \n",
    "            # æ¢¯åº¦è£åˆ‡\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), orpo_config['max_grad_norm']\n",
    "            )\n",
    "            \n",
    "            # å„ªåŒ–å™¨æ­¥é©Ÿ\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # è¨˜éŒ„æŒ‡æ¨™\n",
    "            training_metrics['total_loss'].append(metrics['total_loss'])\n",
    "            training_metrics['sft_loss'].append(metrics['sft_loss'])\n",
    "            training_metrics['or_loss'].append(metrics['or_loss'])\n",
    "            training_metrics['log_odds_ratio'].append(metrics['log_odds_ratio'])\n",
    "            training_metrics['learning_rate'].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            epoch_losses.append(total_loss.item())\n",
    "            global_step += 1\n",
    "            \n",
    "            # æ¯å¹¾æ­¥æ‰“å°ä¸€æ¬¡\n",
    "            if step % 2 == 0:\n",
    "                print(f'Step {step}: Loss={total_loss.item():.4f}, '\n",
    "                      f'SFT={metrics[\"sft_loss\"]:.4f}, '\n",
    "                      f'OR={metrics[\"or_loss\"]:.4f}, '\n",
    "                      f'Odds Ratio={metrics[\"log_odds_ratio\"]:.4f}')\n",
    "        \n",
    "        # Epoch çµæŸçµ±è¨ˆ\n",
    "        avg_loss = np.mean(epoch_losses)\n",
    "        print(f'Epoch {epoch + 1} å¹³å‡æå¤±: {avg_loss:.4f}')\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f'\\nâœ… ORPO è¨“ç·´å®Œæˆï¼')\n",
    "    print(f'ç¸½è¨“ç·´æ™‚é–“: {training_time:.2f} ç§’')\n",
    "    \n",
    "    # è¨“ç·´å¾Œçš„è¨˜æ†¶é«”ç‹€æ…‹\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'è¨“ç·´å¾Œ GPU è¨˜æ†¶é«”: {torch.cuda.memory_allocated() / 1e9:.2f} GB')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'âŒ è¨“ç·´éç¨‹ä¸­å‡ºéŒ¯: {e}')\n",
    "    print('å˜—è©¦æ¸›å°‘æ‰¹æ¬¡å¤§å°æˆ–åºåˆ—é•·åº¦')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 7: è¨“ç·´æŒ‡æ¨™åˆ†æ\n",
    "\n",
    "åˆ†æ ORPO è¨“ç·´éç¨‹ä¸­çš„æŒ‡æ¨™è®ŠåŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ–è¨“ç·´æŒ‡æ¨™\n",
    "if training_metrics['total_loss']:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('ORPO è¨“ç·´æŒ‡æ¨™', fontsize=16)\n",
    "    \n",
    "    steps = range(len(training_metrics['total_loss']))\n",
    "    \n",
    "    # ç¸½æå¤±\n",
    "    axes[0, 0].plot(steps, training_metrics['total_loss'], 'b-', alpha=0.7)\n",
    "    axes[0, 0].set_title('ç¸½æå¤± (Total Loss)')\n",
    "    axes[0, 0].set_xlabel('æ­¥é©Ÿ')\n",
    "    axes[0, 0].set_ylabel('æå¤±')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # SFT vs OR æå¤±\n",
    "    axes[0, 1].plot(steps, training_metrics['sft_loss'], 'g-', label='SFT Loss', alpha=0.7)\n",
    "    axes[0, 1].plot(steps, training_metrics['or_loss'], 'r-', label='OR Loss', alpha=0.7)\n",
    "    axes[0, 1].set_title('SFT vs OR æå¤±')\n",
    "    axes[0, 1].set_xlabel('æ­¥é©Ÿ')\n",
    "    axes[0, 1].set_ylabel('æå¤±')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Log Odds Ratio\n",
    "    axes[1, 0].plot(steps, training_metrics['log_odds_ratio'], 'purple', alpha=0.7)\n",
    "    axes[1, 0].set_title('Log Odds Ratio (Chosen vs Rejected)')\n",
    "    axes[1, 0].set_xlabel('æ­¥é©Ÿ')\n",
    "    axes[1, 0].set_ylabel('Log Odds Ratio')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # å­¸ç¿’ç‡\n",
    "    axes[1, 1].plot(steps, training_metrics['learning_rate'], 'orange', alpha=0.7)\n",
    "    axes[1, 1].set_title('å­¸ç¿’ç‡èª¿åº¦')\n",
    "    axes[1, 1].set_xlabel('æ­¥é©Ÿ')\n",
    "    axes[1, 1].set_ylabel('å­¸ç¿’ç‡')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ‰“å°è¨“ç·´çµ±è¨ˆ\n",
    "    print('ğŸ“Š è¨“ç·´çµ±è¨ˆ:')\n",
    "    print(f'æœ€çµ‚ç¸½æå¤±: {training_metrics[\"total_loss\"][-1]:.4f}')\n",
    "    print(f'æœ€çµ‚ SFT æå¤±: {training_metrics[\"sft_loss\"][-1]:.4f}')\n",
    "    print(f'æœ€çµ‚ OR æå¤±: {training_metrics[\"or_loss\"][-1]:.4f}')\n",
    "    print(f'æœ€çµ‚ Log Odds Ratio: {training_metrics[\"log_odds_ratio\"][-1]:.4f}')\n",
    "    \n",
    "    # åˆ†æè¶¨å‹¢\n",
    "    total_loss_trend = training_metrics['total_loss'][-1] - training_metrics['total_loss'][0]\n",
    "    odds_ratio_trend = training_metrics['log_odds_ratio'][-1] - training_metrics['log_odds_ratio'][0]\n",
    "    \n",
    "    print(f'\\nğŸ“ˆ è¶¨å‹¢åˆ†æ:')\n",
    "    print(f'ç¸½æå¤±è®ŠåŒ–: {total_loss_trend:+.4f} ({\"+\" if total_loss_trend < 0 else \"-\"})')\n",
    "    print(f'Odds Ratio è®ŠåŒ–: {odds_ratio_trend:+.4f} ({\"+\" if odds_ratio_trend > 0 else \"-\"})')\n",
    "    \n",
    "else:\n",
    "    print('âš ï¸  ç„¡å¯ç”¨çš„è¨“ç·´æŒ‡æ¨™é€²è¡Œåˆ†æ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 8: æ¨¡å‹ä¿å­˜\n",
    "\n",
    "ä¿å­˜è¨“ç·´å®Œæˆçš„ ORPO æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜ ORPO æ¨¡å‹\n",
    "output_dir = './orpo_model_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print('ğŸ’¾ ä¿å­˜ ORPO æ¨¡å‹...')\n",
    "\n",
    "try:\n",
    "    # ä¿å­˜ PEFT æ¨¡å‹\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    # ä¿å­˜è¨“ç·´é…ç½®\n",
    "    import json\n",
    "    config_path = os.path.join(output_dir, 'orpo_config.json')\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(orpo_config, f, indent=2)\n",
    "    \n",
    "    # ä¿å­˜è¨“ç·´æŒ‡æ¨™\n",
    "    metrics_path = os.path.join(output_dir, 'training_metrics.json')\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(training_metrics, f, indent=2)\n",
    "    \n",
    "    print(f'âœ… ORPO æ¨¡å‹å·²ä¿å­˜è‡³: {output_dir}')\n",
    "    \n",
    "    # åˆ—å‡ºä¿å­˜çš„æª”æ¡ˆ\n",
    "    saved_files = list(Path(output_dir).glob('*'))\n",
    "    print(f'ä¿å­˜çš„æª”æ¡ˆ: {[f.name for f in saved_files]}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'âš ï¸  æ¨¡å‹ä¿å­˜éç¨‹ä¸­å‡ºç¾å•é¡Œ: {e}')\n",
    "    print('å˜—è©¦åŸºæœ¬ä¿å­˜æ–¹å¼...')\n",
    "    \n",
    "    # åŸºæœ¬ä¿å­˜æ–¹å¼\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': orpo_config,\n",
    "        'metrics': training_metrics\n",
    "    }, os.path.join(output_dir, 'orpo_model_manual.pth'))\n",
    "    \n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f'âœ… ORPO æ¨¡å‹æ‰‹å‹•ä¿å­˜è‡³: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 9: ORPO æ¨¡å‹æ¸¬è©¦\n",
    "\n",
    "æ¸¬è©¦è¨“ç·´å®Œæˆçš„ ORPO æ¨¡å‹ç”Ÿæˆèƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ ORPO æ¨¡å‹\n",
    "def test_orpo_model(model, tokenizer, prompt, max_length=200):\n",
    "    \"\"\"æ¸¬è©¦ ORPO æ¨¡å‹ç”Ÿæˆ\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # æº–å‚™è¼¸å…¥\n",
    "    formatted_prompt = f\"Human: {prompt}\\n\\nAssistant:\"\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors='pt')\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "    \n",
    "    # ç”Ÿæˆå›æ‡‰\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # è§£ç¢¼è¼¸å‡º\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = generated_text[len(formatted_prompt):].strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "print('ğŸ§ª æ¸¬è©¦ ORPO æ¨¡å‹ç”Ÿæˆèƒ½åŠ›...')\n",
    "\n",
    "test_prompts = [\n",
    "    \"è«‹è§£é‡‹ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’?\",\n",
    "    \"å¦‚ä½•é–‹å§‹å­¸ç¿’ç¨‹å¼è¨­è¨ˆ?\",\n",
    "    \"å¥åº·é£²é£Ÿçš„åŸºæœ¬åŸå‰‡æ˜¯ä»€éº¼?\",\n",
    "    \"å¦‚ä½•æé«˜å·¥ä½œæ•ˆç‡?\",\n",
    "    \"äººå·¥æ™ºèƒ½çš„ç™¼å±•å‰æ™¯å¦‚ä½•?\"\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    print(f'\\nğŸ“ æ¸¬è©¦ {i+1}:')\n",
    "    print(f'Prompt: {prompt}')\n",
    "    print('ORPO Generated:')\n",
    "    \n",
    "    try:\n",
    "        response = test_orpo_model(model, tokenizer, prompt)\n",
    "        print(f'{response}')\n",
    "    except Exception as e:\n",
    "        print(f'ç”Ÿæˆå¤±æ•—: {e}')\n",
    "    \n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 10: ORPO è¨“ç·´ç¸½çµ\n",
    "\n",
    "ç¸½çµ ORPO å–®éšæ®µå°é½Šè¨“ç·´çš„çµæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORPO è¨“ç·´ç¸½çµ\n",
    "print('=== ORPO å–®éšæ®µå°é½Šè¨“ç·´ç¸½çµ ===')\n",
    "print(f'âœ… åŸºç¤æ¨¡å‹: {MODEL_NAME}')\n",
    "print(f'âœ… PEFT æ–¹æ³•: LoRA (r={lora_config.r}, alpha={lora_config.lora_alpha})')\n",
    "print(f'âœ… è¨“ç·´æ•¸æ“š: {len(orpo_dataset)} å€‹åå¥½å°')\n",
    "print(f'âœ… è¨“ç·´è¼ªæ•¸: {orpo_config[\"epochs\"]}')\n",
    "print(f'âœ… Lambda OR: {orpo_config[\"lambda_or\"]}')\n",
    "print(f'âœ… å­¸ç¿’ç‡: {orpo_config[\"learning_rate\"]}')\n",
    "print(f'âœ… ORPO æ¨¡å‹ä¿å­˜ä½ç½®: {output_dir}')\n",
    "\n",
    "# è¨ˆç®—æ¨¡å‹åƒæ•¸çµ±è¨ˆ\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'âœ… ç¸½åƒæ•¸: {total_params:,}')\n",
    "print(f'âœ… å¯è¨“ç·´åƒæ•¸: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)')\n",
    "\n",
    "if training_metrics['total_loss']:\n",
    "    print(f'\\nğŸ“Š è¨“ç·´æˆæœ:')\n",
    "    print(f'â€¢ æå¤±æ”¹å–„: {training_metrics[\"total_loss\"][0]:.4f} â†’ {training_metrics[\"total_loss\"][-1]:.4f}')\n",
    "    print(f'â€¢ Odds Ratio æå‡: {training_metrics[\"log_odds_ratio\"][0]:.4f} â†’ {training_metrics[\"log_odds_ratio\"][-1]:.4f}')\n",
    "\n",
    "print('\\nğŸ¯ ORPO æ ¸å¿ƒå„ªå‹¢é©—è­‰:')\n",
    "print('âœ… å–®éšæ®µè¨“ç·´: ç„¡éœ€ SFT + DPO åˆ†éšæ®µ')\n",
    "print('âœ… ç„¡éœ€åƒè€ƒæ¨¡å‹: è¨˜æ†¶é«”ä½¿ç”¨æ¸›åŠ')\n",
    "print('âœ… çµ±ä¸€æå¤±å‡½æ•¸: SFT + OR åŒæ™‚å„ªåŒ–')\n",
    "print('âœ… è¨“ç·´ç©©å®š: æ¯” PPO æ›´ç©©å®šçš„å„ªåŒ–éç¨‹')\n",
    "\n",
    "print('\\nğŸš€ ä¸‹ä¸€æ­¥: åŸ·è¡Œ 03-Compare_with_DPO.ipynb é€²è¡Œå°æ¯”åˆ†æ')\n",
    "\n",
    "# æ¸…ç† GPU è¨˜æ†¶é«”\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'\\nğŸ’¾ GPU è¨˜æ†¶é«”å·²æ¸…ç†ï¼Œç•¶å‰ä½¿ç”¨: {torch.cuda.memory_allocated() / 1e9:.2f} GB')\n",
    "\n",
    "print('\\nğŸ”¬ ORPO æŠ€è¡“ç¸½çµ:')\n",
    "print('â€¢ ORPO å¯¦ç¾äº†çœŸæ­£çš„å–®éšæ®µå°é½Šè¨“ç·´')\n",
    "print('â€¢ é€šé Odds Ratio ç›´æ¥å„ªåŒ–åå¥½ï¼Œç„¡éœ€çå‹µæ¨¡å‹')\n",
    "print('â€¢ ç›¸æ¯” DPO æ›´åŠ é«˜æ•ˆï¼Œè¨“ç·´æˆæœ¬é™ä½ 50%+')\n",
    "print('â€¢ ç‚º LLM å°é½ŠæŠ€è¡“å¸¶ä¾†æ–°çš„ç¯„å¼çªç ´')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}