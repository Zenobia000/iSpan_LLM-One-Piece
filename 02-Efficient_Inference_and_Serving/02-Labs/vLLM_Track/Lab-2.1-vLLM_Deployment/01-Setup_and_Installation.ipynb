{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-2.1 Part 1: vLLM Setup and Installation\n",
    "\n",
    "## Objectives\n",
    "- Verify environment (CUDA, GPU)\n",
    "- Install vLLM\n",
    "- Run basic inference test\n",
    "- Understand PagedAttention basics\n",
    "\n",
    "## Estimated Time: 30-60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.12 (main, Aug 15 2025, 14:32:43) [GCC 11.4.0]\n",
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "Number of GPUs: 1\n",
      "\n",
      "GPU 0: NVIDIA RTX 2000 Ada Generation\n",
      "  Memory: 16.71 GB\n",
      "  Compute Capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"  Compute Capability: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ WARNING: No CUDA GPU detected!\")\n",
    "    print(\"vLLM requires a CUDA-compatible GPU to run efficiently.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0:\n",
      "  Allocated: 0.00 GB\n",
      "  Reserved:  0.00 GB\n",
      "  Free:      16.71 GB\n",
      "  Total:     16.71 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed GPU memory check\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1e9\n",
    "        reserved = torch.cuda.memory_reserved(i) / 1e9\n",
    "        total = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "        \n",
    "        print(f\"GPU {i}:\")\n",
    "        print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "        print(f\"  Reserved:  {reserved:.2f} GB\")\n",
    "        print(f\"  Free:      {total - reserved:.2f} GB\")\n",
    "        print(f\"  Total:     {total:.2f} GB\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Install vLLM\n",
    "\n",
    "vLLM can be installed via pip. For CUDA 12.1+:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ vLLM is already installed: v0.11.0\n"
     ]
    }
   ],
   "source": [
    "# Check if vLLM is already installed\n",
    "try:\n",
    "    import vllm\n",
    "    print(f\"✅ vLLM is already installed: v{vllm.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"❌ vLLM is not installed.\")\n",
    "    print(\"\\nTo fix this, please run the following commands in your terminal inside the poetry shell (`poetry shell`)\")\n",
    "    print(\"in the `00-Course_Setup` directory, and then restart the Jupyter kernel.\")\n",
    "    print(\"\\n---\")\n",
    "    print('pip install \"torch==2.3.0\" \"torchvision==0.18.0\" \"torchaudio==2.3.0\" --index-url https://download.pytorch.org/whl/cu121')\n",
    "    print('pip install \"vllm==0.4.1\"')\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Command\n",
    "\n",
    "If vLLM is not installed, run in terminal:\n",
    "\n",
    "```bash\n",
    "# Basic installation\n",
    "pip install vllm\n",
    "\n",
    "# Or specify CUDA version\n",
    "pip install vllm --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Basic Inference Test\n",
    "\n",
    "Let's test vLLM with a small model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-23 18:37:09 [__init__.py:216] Automatically detected platform cuda.\n",
      "✅ vLLM imported successfully!\n",
      "Version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "# Import vLLM\n",
    "from vllm import LLM, SamplingParams\n",
    "import time\n",
    "\n",
    "print(\"✅ vLLM imported successfully!\")\n",
    "print(f\"Version: {vllm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Small Model\n",
    "\n",
    "We'll use GPT-2 for quick testing (124M parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-2 model...\n",
      "INFO 10-23 18:37:46 [utils.py:233] non-default args: {'max_model_len': 512, 'disable_log_stats': True, 'model': 'gpt2'}\n",
      "INFO 10-23 18:37:47 [model.py:547] Resolved architecture: GPT2LMHeadModel\n",
      "INFO 10-23 18:37:47 [model.py:1730] Downcasting torch.float32 to torch.bfloat16.\n",
      "INFO 10-23 18:37:47 [model.py:1510] Using max model len 512\n",
      "INFO 10-23 18:37:47 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 10-23 18:37:51 [__init__.py:216] Automatically detected platform cuda.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m INFO 10-23 18:37:51 [core.py:644] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m INFO 10-23 18:37:51 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='gpt2', speculative_config=None, tokenizer='gpt2', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=512, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=gpt2, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\",\"vllm.sparse_attn_indexer\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":[2,1],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"use_inductor_graph_partition\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m INFO 10-23 18:37:53 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708] EngineCore failed to start.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708] Traceback (most recent call last):\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py\", line 699, in run_engine_core\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]     engine_core = EngineCoreProc(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py\", line 498, in __init__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]     super().__init__(vllm_config, executor_class, log_stats,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py\", line 83, in __init__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]     self.model_executor = executor_class(vllm_config)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/executor/executor_base.py\", line 54, in __init__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]     self._init_executor()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py\", line 54, in _init_executor\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]     self.collective_rpc(\"init_device\")\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py\", line 83, in collective_rpc\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/utils/__init__.py\", line 3122, in run_method\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]     return func(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/worker/worker_base.py\", line 259, in init_device\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]     self.worker.init_device()  # type: ignore\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py\", line 187, in init_device\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708]     raise ValueError(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ERROR 10-23 18:37:53 [core.py:708] ValueError: Free memory on device (7.55/15.57 GiB) on startup is less than desired GPU memory utilization (0.9, 14.01 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m Process EngineCore_DP0:\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m Traceback (most recent call last):\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     self.run()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     self._target(*self._args, **self._kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py\", line 712, in run_engine_core\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     raise e\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py\", line 699, in run_engine_core\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     engine_core = EngineCoreProc(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py\", line 498, in __init__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     super().__init__(vllm_config, executor_class, log_stats,\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py\", line 83, in __init__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     self.model_executor = executor_class(vllm_config)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/executor/executor_base.py\", line 54, in __init__\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     self._init_executor()\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py\", line 54, in _init_executor\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     self.collective_rpc(\"init_device\")\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py\", line 83, in collective_rpc\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/utils/__init__.py\", line 3122, in run_method\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     return func(*args, **kwargs)\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/worker/worker_base.py\", line 259, in init_device\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     self.worker.init_device()  # type: ignore\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m   File \"/home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py\", line 187, in init_device\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m     raise ValueError(\n",
      "\u001b[1;36m(EngineCore_DP0 pid=498799)\u001b[0;0m ValueError: Free memory on device (7.55/15.57 GiB) on startup is less than desired GPU memory utilization (0.9, 14.01 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.\n",
      "[rank0]:[W1023 18:37:53.193294059 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Engine core initialization failed. See root cause above. Failed core proc(s): {}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading GPT-2 model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# gpu_memory_utilization=0.3,  # Use 30% GPU memory for testing\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_model_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Limit context length\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m load_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Model loaded in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mload_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/entrypoints/llm.py:297\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, runner, convert, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, allowed_media_domains, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, disable_custom_all_reduce, hf_token, hf_overrides, mm_processor_kwargs, pooler_config, override_pooler_config, structured_outputs_config, kv_cache_memory_bytes, compilation_config, logits_processors, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m log_non_default_args(engine_args)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/v1/engine/llm_engine.py:177\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers, enable_multiprocessing)\u001b[0m\n\u001b[1;32m    174\u001b[0m     enable_multiprocessing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Create the LLMEngine.\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m           \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/v1/engine/llm_engine.py:114\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, mm_registry, use_cached_outputs, multiprocess_mode)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_processor\u001b[38;5;241m.\u001b[39mtracer \u001b[38;5;241m=\u001b[39m tracer\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# EngineCore (gets EngineCoreRequests and gives EngineCoreOutputs)\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_core \u001b[38;5;241m=\u001b[39m \u001b[43mEngineCoreClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger_manager: Optional[StatLoggerManager] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_stats:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/v1/engine/core_client.py:80\u001b[0m, in \u001b[0;36mEngineCoreClient.make_client\u001b[0;34m(multiprocess_mode, asyncio_mode, vllm_config, executor_class, log_stats)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EngineCoreClient\u001b[38;5;241m.\u001b[39mmake_async_mp_client(\n\u001b[1;32m     77\u001b[0m         vllm_config, executor_class, log_stats)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multiprocess_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio_mode:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSyncMPClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m InprocClient(vllm_config, executor_class, log_stats)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/v1/engine/core_client.py:602\u001b[0m, in \u001b[0;36mSyncMPClient.__init__\u001b[0;34m(self, vllm_config, executor_class, log_stats)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vllm_config: VllmConfig, executor_class: \u001b[38;5;28mtype\u001b[39m[Executor],\n\u001b[1;32m    601\u001b[0m              log_stats: \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_dp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvllm_config\u001b[38;5;241m.\u001b[39mparallel_config\u001b[38;5;241m.\u001b[39mdata_parallel_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_queue \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39mQueue[Union[EngineCoreOutputs, \u001b[38;5;167;01mException\u001b[39;00m]]()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/v1/engine/core_client.py:448\u001b[0m, in \u001b[0;36mMPClient.__init__\u001b[0;34m(self, asyncio_mode, vllm_config, executor_class, log_stats, client_addresses)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats_update_address \u001b[38;5;241m=\u001b[39m client_addresses\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats_update_address\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# Engines are managed by this client.\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m launch_core_engines(vllm_config, executor_class,\n\u001b[1;32m    449\u001b[0m                              log_stats) \u001b[38;5;28;01mas\u001b[39;00m (engine_manager,\n\u001b[1;32m    450\u001b[0m                                             coordinator,\n\u001b[1;32m    451\u001b[0m                                             addresses):\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresources\u001b[38;5;241m.\u001b[39mcoordinator \u001b[38;5;241m=\u001b[39m coordinator\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresources\u001b[38;5;241m.\u001b[39mengine_manager \u001b[38;5;241m=\u001b[39m engine_manager\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:142\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/v1/engine/utils.py:732\u001b[0m, in \u001b[0;36mlaunch_core_engines\u001b[0;34m(vllm_config, executor_class, log_stats, num_api_servers)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m local_engine_manager, coordinator, addresses\n\u001b[1;32m    731\u001b[0m \u001b[38;5;66;03m# Now wait for engines to start.\u001b[39;00m\n\u001b[0;32m--> 732\u001b[0m \u001b[43mwait_for_engine_startup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandshake_socket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddresses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengines_to_handshake\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_engine_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vllm/v1/engine/utils.py:785\u001b[0m, in \u001b[0;36mwait_for_engine_startup\u001b[0;34m(handshake_socket, addresses, core_engines, parallel_config, cache_config, proc_manager, coord_process)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coord_process \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m coord_process\u001b[38;5;241m.\u001b[39mexitcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    784\u001b[0m         finished[coord_process\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m coord_process\u001b[38;5;241m.\u001b[39mexitcode\n\u001b[0;32m--> 785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine core initialization failed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    786\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee root cause above. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    787\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed core proc(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinished\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Receive HELLO and READY messages from the input socket.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m eng_identity, ready_msg_bytes \u001b[38;5;241m=\u001b[39m handshake_socket\u001b[38;5;241m.\u001b[39mrecv_multipart()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Engine core initialization failed. See root cause above. Failed core proc(s): {}"
     ]
    }
   ],
   "source": [
    "# Initialize vLLM with GPT-2\n",
    "print(\"Loading GPT-2 model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"gpt2\",\n",
    "    # gpu_memory_utilization=0.3,  # Use 30% GPU memory for testing\n",
    "    max_model_len=512,           # Limit context length\n",
    ")\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f\"✅ Model loaded in {load_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating text...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(prompts, sampling_params)\n\u001b[1;32m     20\u001b[0m generation_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "# Define sampling parameters\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    max_tokens=50,\n",
    ")\n",
    "\n",
    "# Test prompts\n",
    "prompts = [\n",
    "    \"Once upon a time in a distant land,\",\n",
    "    \"The future of artificial intelligence is\",\n",
    "    \"Python is a programming language that\",\n",
    "]\n",
    "\n",
    "print(\"Generating text...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "generation_time = time.time() - start_time\n",
    "\n",
    "# Display results\n",
    "for i, output in enumerate(outputs):\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt {i+1}: {prompt}\")\n",
    "    print(f\"Generated: {generated_text}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n⏱️  Total generation time: {generation_time:.2f} seconds\")\n",
    "print(f\"⏱️  Average time per prompt: {generation_time/len(prompts):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. PagedAttention Overview\n",
    "\n",
    "PagedAttention is vLLM's key innovation for efficient KV cache management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional KV Cache Problem\n",
    "\n",
    "Traditional approach allocates contiguous memory:\n",
    "\n",
    "```\n",
    "Request 1 (len=1024): ████████░░░░░░░░ (allocated 2048, used 1024)\n",
    "Request 2 (len=512):  ████░░░░░░░░░░░░ (allocated 2048, used 512)\n",
    "\n",
    "Memory waste: ~60%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PagedAttention Solution\n",
    "\n",
    "PagedAttention uses paging (like virtual memory):\n",
    "\n",
    "```\n",
    "Physical blocks: [P0][P1][P2][P3][P4][P5]...\n",
    "\n",
    "Request 1: P0 → P1 → P2 → P3 (1024 tokens, 4 blocks)\n",
    "Request 2: P4 → P5           (512 tokens, 2 blocks)\n",
    "\n",
    "Memory waste: ~0%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Noto Sans CJK TC\\naxes.unicode_minus : False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 PagedAttention improves memory utilization from 40% to 95%!\n"
     ]
    }
   ],
   "source": [
    "# Visualize memory efficiency\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated data\n",
    "approaches = ['Traditional', 'PagedAttention']\n",
    "memory_used = [40, 95]  # Percentage\n",
    "memory_wasted = [60, 5]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Memory utilization\n",
    "ax1.bar(approaches, memory_used, color=['#ff6b6b', '#51cf66'])\n",
    "ax1.set_ylabel('Memory Utilization (%)')\n",
    "ax1.set_title('Memory Utilization Comparison')\n",
    "ax1.set_ylim(0, 100)\n",
    "for i, v in enumerate(memory_used):\n",
    "    ax1.text(i, v + 2, f\"{v}%\", ha='center', fontweight='bold')\n",
    "\n",
    "# Memory waste\n",
    "ax2.bar(approaches, memory_wasted, color=['#ff6b6b', '#51cf66'])\n",
    "ax2.set_ylabel('Memory Waste (%)')\n",
    "ax2.set_title('Memory Waste Comparison')\n",
    "ax2.set_ylim(0, 100)\n",
    "for i, v in enumerate(memory_wasted):\n",
    "    ax2.text(i, v + 2, f\"{v}%\", ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 PagedAttention improves memory utilization from 40% to 95%!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Compare with HuggingFace\n",
    "\n",
    "Let's compare vLLM with standard HuggingFace inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HuggingFace GPT-2...\n",
      "✅ HuggingFace model loaded\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace baseline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "print(\"Loading HuggingFace GPT-2...\")\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(\"cuda\")\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "hf_tokenizer.pad_token = hf_tokenizer.eos_token\n",
    "\n",
    "print(\"✅ HuggingFace model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HuggingFace...\n",
      "HuggingFace output: The future of artificial intelligence is in its infancy. While artificial intelligence could eventually reach an advanced state of automation, that's not really a reason to invest much time in AI. The potential uses for AI in healthcare could be greatly expanded in the near future. AI could be a major\n",
      "Time: 0.467s\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace generation\n",
    "test_prompt = \"The future of artificial intelligence is\"\n",
    "\n",
    "print(\"Testing HuggingFace...\")\n",
    "inputs = hf_tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    hf_outputs = hf_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        temperature=0.8,\n",
    "        top_p=0.95,\n",
    "        do_sample=True,\n",
    "    )\n",
    "hf_time = time.time() - start_time\n",
    "\n",
    "hf_text = hf_tokenizer.decode(hf_outputs[0], skip_special_tokens=True)\n",
    "print(f\"HuggingFace output: {hf_text}\")\n",
    "print(f\"Time: {hf_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing vLLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b432cddf4f9948c291cd8c19fd347f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c0f31a4b1747b083747999319d79d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM output: The future of artificial intelligence is now more complicated than ever.\n",
      "\n",
      "The smartest people are smarter than the average person. They are smarter than the average person in some ways. But, for the average person, the human mind is a vast, vast machine. They are the best\n",
      "Time: 0.117s\n"
     ]
    }
   ],
   "source": [
    "# vLLM generation (same prompt)\n",
    "print(\"\\nTesting vLLM...\")\n",
    "start_time = time.time()\n",
    "vllm_outputs = llm.generate([test_prompt], sampling_params)\n",
    "vllm_time = time.time() - start_time\n",
    "\n",
    "vllm_text = vllm_outputs[0].outputs[0].text\n",
    "print(f\"vLLM output: {test_prompt}{vllm_text}\")\n",
    "print(f\"Time: {vllm_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERFORMANCE COMPARISON\n",
      "================================================================================\n",
      "HuggingFace:  0.467s\n",
      "vLLM:         0.117s\n",
      "Speedup:      3.98x faster ⚡\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Performance comparison\n",
    "speedup = hf_time / vllm_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"HuggingFace:  {hf_time:.3f}s\")\n",
    "print(f\"vLLM:         {vllm_time:.3f}s\")\n",
    "print(f\"Speedup:      {speedup:.2f}x faster ⚡\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Check vLLM Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM Engine Configuration:\n",
      "  Model: gpt2\n",
      "  Max model length: 512\n",
      "  GPU memory utilization: 0.9\n",
      "  Block size: 16\n"
     ]
    }
   ],
   "source": [
    "# Inspect vLLM engine configuration\n",
    "print(\"vLLM Engine Configuration:\")\n",
    "print(f\"  Model: {llm.llm_engine.model_config.model}\")\n",
    "print(f\"  Max model length: {llm.llm_engine.model_config.max_model_len}\")\n",
    "print(f\"  GPU memory utilization: {llm.llm_engine.cache_config.gpu_memory_utilization}\")\n",
    "print(f\"  Block size: {llm.llm_engine.cache_config.block_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "✅ **Completed**:\n",
    "1. Verified CUDA and GPU environment\n",
    "2. Installed vLLM\n",
    "3. Ran basic inference test\n",
    "4. Understood PagedAttention benefits\n",
    "5. Compared vLLM vs HuggingFace\n",
    "\n",
    "📊 **Key Findings**:\n",
    "- vLLM provides significant speedup over HuggingFace\n",
    "- PagedAttention improves memory utilization from ~40% to ~95%\n",
    "- Simple API similar to HuggingFace\n",
    "\n",
    "➡️ **Next**: In `02-Basic_Inference.ipynb`, we'll explore:\n",
    "- Batch inference\n",
    "- Advanced sampling strategies\n",
    "- Memory profiling\n",
    "- Throughput optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises\n",
    "\n",
    "1. **Try different models**: Replace GPT-2 with other models (e.g., `facebook/opt-125m`)\n",
    "2. **Adjust parameters**: Experiment with `gpu_memory_utilization` and `max_model_len`\n",
    "3. **Measure memory**: Use `nvidia-smi` to monitor GPU memory usage\n",
    "4. **Batch size**: Test with different numbers of prompts (1, 4, 8, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W1021 21:20:53.293578239 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned up GPU memory\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "import gc\n",
    "\n",
    "del llm\n",
    "del hf_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"✅ Cleaned up GPU memory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Engineering Course (Poetry)",
   "language": "python",
   "name": "llm-engineering-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
