{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 2: Adapter Layers - Fine-Tuning a BERT Model for Classification\n",
        "\n",
        "**Goal:** This lab explores one of the original PEFT methods, **Adapter Layers**. You will learn how to inject small, trainable \"adapter\" modules into a pre-trained model to adapt it for a new task. For this lab, we will fine-tune a **BERT** model for a text classification task.\n",
        "\n",
        "**You will learn to:**\n",
        "-   Load a pre-trained BERT model and a classification dataset (GLUE MRPC).\n",
        "-   Understand and configure `AdapterConfig` from the `peft` library.\n",
        "-   Add adapter modules to the base model using `peft`.\n",
        "-   Fine-tune the model by training *only* the adapter layers.\n",
        "-   Perform inference using the trained adapters.\n",
        "\n",
        "---\n",
        "## Notebook 1: Environment Setup\n",
        "\n",
        "This notebook will prepare your environment for the Adapter Layers lab. We will install all the necessary libraries. Note that for this lab, since we are using a smaller model (BERT) and not using 4-bit quantization, the `bitsandbytes` library is not strictly required.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Check for GPU\n",
        "\n",
        "While BERT is much smaller than Llama-2, a GPU is still highly recommended to make the training process fast and efficient.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Install Core Libraries\n",
        "\n",
        "We will now install the necessary libraries. The set of packages is very similar to the previous lab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q transformers peft datasets accelerate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Verify Installation\n",
        "\n",
        "Let's import the main libraries and print their versions to confirm that everything was installed correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import peft\n",
        "import datasets\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Transformers version: {transformers.__version__}\")\n",
        "print(f\"PEFT version: {peft.__version__}\")\n",
        "print(f\"Datasets version: {datasets.__version__}\")\n",
        "\n",
        "print(\"\\nâœ… Environment is set up correctly!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
