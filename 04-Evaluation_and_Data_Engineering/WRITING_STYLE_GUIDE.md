# ğŸ“˜ è©•ä¼°èˆ‡æ•¸æ“šå·¥ç¨‹ç« ç¯€æ’°æ–‡é¢¨æ ¼è¦ç¯„

**é©ç”¨ç¯„åœ**: `04-Evaluation_and_Data_Engineering` ç›®éŒ„ä¸‹æ‰€æœ‰æ–‡æª”èˆ‡å¯¦é©—å®¤
**åƒè€ƒä¾†æº**: `01-Core_Training_Techniques` å’Œ `03-Model_Compression` å·²é©—è­‰çš„æ’°æ–‡æ¨¡å¼
**æœ€å¾Œæ›´æ–°**: 2025-10-17

---

## ğŸ¯ æ ¸å¿ƒåŸå‰‡

### 1. ä¸€è‡´æ€§å„ªå…ˆ
- èˆ‡ `01-Core_Training_Techniques` å’Œ `03-Model_Compression` ä¿æŒé«˜åº¦ä¸€è‡´çš„çµæ§‹å’Œé¢¨æ ¼
- å­¸ç¿’è€…æ‡‰èƒ½ç„¡ç¸«åˆ‡æ›ç« ç¯€è€Œä¸æ„Ÿåˆ°å›°æƒ‘

### 2. è©•ä¼°æ€ç¶­å„ªå…ˆ
- å¼·èª¿ã€Œå¦‚ä½•è©•ä¼°ã€è€Œéã€Œå¦‚ä½•è¨“ç·´ã€
- é—œæ³¨æ•¸æ“šè³ªé‡å°æ¨¡å‹æ€§èƒ½çš„å½±éŸ¿
- åŸ¹é¤Šå®¢è§€è©•ä¼°èˆ‡æ•¸æ“šé©…å‹•æ±ºç­–æ€ç¶­

### 3. å·¥ç¨‹å°å‘
- ä¸åƒ…è¬›ã€Œå¦‚ä½•è©•ä¼°ã€,æ›´è¬›ã€Œå¦‚ä½•è§£è®€çµæœã€
- åŒ…å«ç”Ÿç”¢ç’°å¢ƒè©•ä¼°ç®¡ç·šèˆ‡æ•¸æ“šè™•ç†æœ€ä½³å¯¦è¸
- å¼·èª¿è‡ªå‹•åŒ–èˆ‡å¯é‡ç¾æ€§

---

## ğŸ“‚ ç›®éŒ„çµæ§‹è¦ç¯„

```
04-Evaluation_and_Data_Engineering/
â”œâ”€â”€ 01-Theory/
â”‚   â”œâ”€â”€ 4.1-Evaluation_Benchmarks.md      # è©•ä¼°åŸºæº–ç†è«–
â”‚   â””â”€â”€ 4.2-Data_Engineering.md           # æ•¸æ“šå·¥ç¨‹ç†è«–
â”œâ”€â”€ 02-Labs/
â”‚   â”œâ”€â”€ Lab-4.1-Evaluate_with_OpenCompass/
â”‚   â”‚   â”œâ”€â”€ README.md                     # å¯¦é©—èªªæ˜æ–‡æª”
â”‚   â”‚   â”œâ”€â”€ 01-Setup.ipynb
â”‚   â”‚   â”œâ”€â”€ 02-Evaluate.ipynb
â”‚   â”‚   â”œâ”€â”€ 03-Analyze.ipynb
â”‚   â”‚   â””â”€â”€ 04-Visualize_and_Report.ipynb
â”‚   â””â”€â”€ Lab-4.2-Efficient_Data_Filtering/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ 01-Setup.ipynb
â”‚       â”œâ”€â”€ 02-Filter.ipynb
â”‚       â”œâ”€â”€ 03-Validate.ipynb
â”‚       â””â”€â”€ 04-Pipeline.ipynb
â””â”€â”€ WRITING_STYLE_GUIDE.md                # æœ¬æ–‡æª”
```

---

## ğŸ“„ README.md æ’°æ–‡æ¨¡æ¿

### çµæ§‹å¤§ç¶± (11å€‹å¿…è¦ç« ç¯€)

```markdown
# Lab 4.X: [æŠ€è¡“åç¨±] - [ç°¡çŸ­æè¿°]

## æ¦‚è¿°
**[æ ¸å¿ƒæŠ€è¡“]** æ˜¯... [æŠ€è¡“èƒŒæ™¯ 1-2æ®µ]
æœ¬å¯¦é©—å°‡... [å¯¦é©—ç›®æ¨™è²æ˜]

![æŠ€è¡“ç¤ºæ„åœ–](url_or_local_path)

---

## 1. æŠ€è¡“èƒŒæ™¯èˆ‡å‹•æ©Ÿ

### 1.1 ç‚ºä½•éœ€è¦è©•ä¼°/æ•¸æ“šå·¥ç¨‹?
- **è©•ä¼°å¿…è¦æ€§**: å®¢è§€è¡¡é‡æ¨¡å‹èƒ½åŠ›,è­˜åˆ¥å„ªå‹¢èˆ‡ä¸è¶³
- **æ•¸æ“šé‡è¦æ€§**: é«˜è³ªé‡æ•¸æ“šæ˜¯æ¨¡å‹æ€§èƒ½çš„åŸºçŸ³
- **å·¥ç¨‹åŒ–éœ€æ±‚**: è‡ªå‹•åŒ–è©•ä¼°ç®¡ç·šæå‡ç ”ç™¼æ•ˆç‡

### 1.2 è©•ä¼°/æ•¸æ“šå·¥ç¨‹æŠ€è¡“åˆ†é¡
[æ©«å‘æ¯”è¼ƒ: èƒ½åŠ›è©•ä¼° vs æ€§èƒ½è©•ä¼° vs æ•¸æ“šè³ªé‡è©•ä¼°]

---

## 2. [æŠ€è¡“åç¨±] æ ¸å¿ƒåŸç†

### 2.1 ç†è«–åŸºç¤
[æ•¸å­¸åŸç†ã€æ¼”ç®—æ³•åŸºç¤]

### 2.2 æŠ€è¡“å¯¦ç¾
[å…·é«”å¯¦ç¾æ–¹å¼ã€é—œéµæ­¥é©Ÿ]

### 2.3 ä¸»æµæ–¹æ³•å°æ¯”
[OpenCompass vs LM-Eval-Harness / IFD vs DEITA vs LESS]

---

## 3. å¯¦ç¾åŸç†èˆ‡æ­¥é©Ÿ

### 3.1 é—œéµé…ç½®
\```python
# é…ç½®ç¯„ä¾‹ (å¸¶è©³ç´°è¨»è§£)
config = EvaluationConfig(
    datasets=['ceval', 'cmmlu'],  # è©•ä¼°åŸºæº–
    batch_size=16,                # æ‰¹æ¬¡å¤§å°
    num_fewshot=5,                # Few-shot æ¨£æœ¬æ•¸
    ...
)
\```

### 3.2 é—œéµåƒæ•¸èªªæ˜
| åƒæ•¸åç¨± | å«ç¾© | æ¨è–¦å€¼ | å½±éŸ¿ |
|:---|:---|:---|:---|
| `batch_size` | æ‰¹æ¬¡å¤§å° | 16/32 | è©•ä¼°é€Ÿåº¦ vs è¨˜æ†¶é«” |
| `num_fewshot` | Few-shot æ•¸é‡ | 0/5 | æ¸¬è©¦é›£åº¦èˆ‡çœŸå¯¦æ€§ |

### 3.3 å·¥ä½œæµç¨‹
1. æ­¥é©Ÿ1: [è©³ç´°èªªæ˜]
2. æ­¥é©Ÿ2: [è©³ç´°èªªæ˜]
...

---

## 4. æ€§èƒ½è¡¨ç¾èˆ‡å°æ¯”

### 4.1 è©•ä¼°åŸºæº–çµæœ

| æ¨¡å‹ | C-Eval | CMMLU | MMLU | ç¶œåˆå¾—åˆ† |
|:---|:---|:---|:---|:---|
| **Llama-2-7B** | 45.3% | 42.1% | 46.8% | 44.7% |
| **Qwen-7B** | 59.7% | 58.2% | 56.4% | 58.1% |
| **å·®ç•°** | **+14.4%** | **+16.1%** | **+9.6%** | **+13.4%** |

### 4.2 æ•¸æ“šç¯©é¸æ•ˆæœ

| æ•¸æ“šé›† | æ¨£æœ¬æ•¸ | è¨“ç·´æ™‚é–“ | C-Eval æº–ç¢ºç‡ | æ•ˆç‡æå‡ |
|:---|:---|:---|:---|:---|
| **åŸå§‹æ•¸æ“š** | 52K | 12h | 45.3% | - |
| **ç¯©é¸å¾Œ** | 15.6K | 3.5h | 47.1% | **3.4x** |

---

## 5. æŠ€è¡“å„ªå‹¢

| å„ªå‹¢é …ç›® | èªªæ˜ |
|:---|:---|
| **å®¢è§€æ€§** | åŸºæ–¼æ¨™æº–åŸºæº–,é¿å…ä¸»è§€åè¦‹ |
| **å…¨é¢æ€§** | å¤šç¶­åº¦è©•ä¼°,æ¶µè“‹èƒ½åŠ›èˆ‡æ€§èƒ½ |
| **å¯é‡ç¾** | å›ºå®šè©•ä¼°å”è­°,çµæœå¯é©—è­‰ |
| **è‡ªå‹•åŒ–** | å®Œæ•´ç®¡ç·š,é«˜æ•ˆæ‰¹é‡è©•ä¼° |

---

## 6. å¯¦é©—è¨­è¨ˆèˆ‡å¯¦ä½œ

### 6.1 å¯¦é©—ç’°å¢ƒ
- **è©•ä¼°æ¡†æ¶**: OpenCompass / IFD+DEITA
- **æ¨¡å‹**: Llama-2-7B, Qwen-7B
- **åŸºæº–**: C-Eval, CMMLU, MMLU
- **æ•¸æ“šé›†**: Alpaca, Dolly, Self-Instruct

### 6.2 å¯¦é©—æµç¨‹
1. **ç’°å¢ƒæº–å‚™** (`01-Setup.ipynb`)
   - å®‰è£è©•ä¼°æ¡†æ¶
   - ä¸‹è¼‰åŸºæº–æ•¸æ“šé›†
   - é©—è­‰æ¨¡å‹è¼‰å…¥

2. **åŸ·è¡Œè©•ä¼°/ç¯©é¸** (`02-[æ“ä½œ].ipynb`)
   - é…ç½®è©•ä¼°ä»»å‹™
   - åŸ·è¡Œè©•ä¼°/ç¯©é¸
   - æ”¶é›†çµæœ

3. **çµæœåˆ†æ** (`03-Analyze.ipynb` / `03-Validate.ipynb`)
   - è§£æè©•ä¼°çµæœ
   - è­˜åˆ¥å„ªåŠ£å‹¢é ˜åŸŸ
   - é©—è­‰ç¯©é¸æ•ˆæœ

4. **å¯è¦–åŒ–èˆ‡å ±å‘Š** (`04-Visualize.ipynb` / `04-Pipeline.ipynb`)
   - ç”Ÿæˆå¯è¦–åŒ–åœ–è¡¨
   - è‡ªå‹•ç”Ÿæˆå ±å‘Š
   - å»ºç«‹è‡ªå‹•åŒ–ç®¡ç·š

---

## 7. å¯¦æˆ°åƒæ•¸èª¿å„ªç­–ç•¥ (2024 å¹´è¡Œæ¥­æœ€ä½³å¯¦è¸)

### 7.1 è©•ä¼°é…ç½®å„ªåŒ–

| å ´æ™¯ | Few-shot | Batch Size | è©•ä¼°æ¨¡å¼ | é æœŸæ™‚é–“ |
|:---|:---|:---|:---|:---|
| **å¿«é€Ÿé©—è­‰** | 0 | 32 | ç”Ÿæˆå¼ | 30min |
| **æ¨™æº–è©•ä¼°** | 5 | 16 | ç”Ÿæˆå¼ | 2-3h |
| **ç²¾ç¢ºè©•ä¼°** | 5 | 8 | å¤šæ¨£æœ¬ | 4-6h |

### 7.2 æ•¸æ“šç¯©é¸ç­–ç•¥

#### é«˜è³ªé‡æ•¸æ“šå„ªå…ˆ
\```python
# IFD + DEITA èåˆè©•åˆ†
def calculate_data_score(sample):
    ifd_score = calculate_ifd(sample)        # å›°é›£åº¦
    complexity = analyze_complexity(sample)  # è¤‡é›œåº¦
    diversity = calculate_diversity(sample)  # å¤šæ¨£æ€§

    # åŠ æ¬Šèåˆ
    final_score = (
        0.4 * ifd_score +
        0.3 * complexity +
        0.3 * diversity
    )
    return final_score
\```

#### å¤šæ¨£æ€§ä¿æŒ
\```python
# K-means èšé¡ç¢ºä¿è¦†è“‹
from sklearn.cluster import KMeans

embeddings = embed_instructions(dataset)
clusters = KMeans(n_clusters=20).fit(embeddings)

# å¾æ¯å€‹èšé¡é¸æ“‡ Top-K
filtered_data = select_top_k_per_cluster(
    dataset, clusters, k=10
)
\```

### 7.3 è©•ä¼°çµæœè§£è®€æŒ‡å—

| åˆ†æ•¸ç¯„åœ | èƒ½åŠ›ç­‰ç´š | é©ç”¨å ´æ™¯ | æ”¹é€²å»ºè­° |
|:---|:---|:---|:---|
| **<40%** | åŸºç¤ç´š | ç°¡å–®å°è©±ã€åŸºç¤åˆ†é¡ | å¢åŠ è¨“ç·´æ•¸æ“šã€å»¶é•·è¨“ç·´æ™‚é–“ |
| **40-60%** | ä¸­ç´š | é€šç”¨åŠ©æ‰‹ã€ä¿¡æ¯æª¢ç´¢ | å„ªåŒ–æ•¸æ“šè³ªé‡ã€èª¿æ•´è¶…åƒæ•¸ |
| **60-80%** | é«˜ç´š | å°ˆæ¥­é ˜åŸŸã€è¤‡é›œæ¨ç† | é ˜åŸŸå¾®èª¿ã€å°ˆå®¶æ•¸æ“š |
| **>80%** | å°ˆå®¶ç´š | é—œéµä»»å‹™ã€é«˜é¢¨éšªå ´æ™¯ | æŒçºŒç›£æ§ã€æ•¸æ“šè¿­ä»£ |

### 7.4 æ•…éšœè¨ºæ–·æŒ‡å—

| å•é¡Œç¾è±¡ | å¯èƒ½åŸå›  | è§£æ±ºæ–¹æ¡ˆ |
|:---|:---|:---|
| è©•ä¼°åˆ†æ•¸ç•°å¸¸ä½ | æ¨¡å‹æœªæ­£ç¢ºè¼‰å…¥ / Few-shot æ¨£æœ¬éŒ¯èª¤ | æª¢æŸ¥æ¨¡å‹é…ç½®ã€é©—è­‰æ¨£æœ¬æ ¼å¼ |
| è©•ä¼°é€Ÿåº¦æ¥µæ…¢ | Batch size éå° / GPU æœªä½¿ç”¨ | å¢å¤§ batch sizeã€å•Ÿç”¨ GPU |
| çµæœä¸å¯é‡ç¾ | éš¨æ©Ÿç¨®å­æœªå›ºå®š / è©•ä¼°å”è­°ä¸ä¸€è‡´ | å›ºå®šç¨®å­ã€çµ±ä¸€è©•ä¼°é…ç½® |
| æ•¸æ“šç¯©é¸å¾Œæ€§èƒ½ä¸‹é™ | ç¯©é¸éåº¦ / å¤šæ¨£æ€§æå¤± | é™ä½ç¯©é¸æ¯”ä¾‹ã€å¢åŠ å¤šæ¨£æ€§æ¬Šé‡ |

---

## 8. è©•ä¼°ç®¡ç·šèˆ‡ç”Ÿç”¢ç’°å¢ƒæœ€ä½³å¯¦è¸

### 8.1 è©•ä¼°æ¡†æ¶é¸æ“‡

| è©•ä¼°æ¡†æ¶ | é©ç”¨å ´æ™¯ | å„ªå‹¢ | é™åˆ¶ |
|:---|:---|:---|:---|
| **OpenCompass** | ä¸­æ–‡æ¨¡å‹è©•ä¼° | ä¸­æ–‡åŸºæº–è±å¯Œã€æ˜“æ–¼é…ç½® | è‹±æ–‡åŸºæº–è¼ƒå°‘ |
| **LM-Eval-Harness** | è‹±æ–‡æ¨¡å‹è©•ä¼° | åœ‹éš›æ¨™æº–ã€åŸºæº–æœ€å…¨ | ä¸­æ–‡æ”¯æŒæœ‰é™ |
| **è‡ªå»ºè©•ä¼°ç³»çµ±** | å®šåˆ¶åŒ–éœ€æ±‚ | éˆæ´»å¯æ§ | é–‹ç™¼æˆæœ¬é«˜ |

### 8.2 è©•ä¼° CI/CD ç®¡ç·š

```python
# è‡ªå‹•åŒ–è©•ä¼°ç®¡ç·šç¯„ä¾‹
class EvaluationPipeline:
    def __init__(self, config):
        self.config = config
        self.evaluator = load_evaluator(config)

    def run(self, model_path, datasets):
        """åŸ·è¡Œå®Œæ•´è©•ä¼°æµç¨‹"""
        # 1. è¼‰å…¥æ¨¡å‹
        model = self.load_model(model_path)

        # 2. åŸ·è¡Œè©•ä¼°
        results = {}
        for dataset in datasets:
            score = self.evaluator.evaluate(model, dataset)
            results[dataset] = score

        # 3. ç”Ÿæˆå ±å‘Š
        report = self.generate_report(results)
        self.save_report(report)

        # 4. è§¸ç™¼å‘Šè­¦ (å¦‚æ€§èƒ½ä¸‹é™)
        if self.check_regression(results):
            self.send_alert(results)

        return results
```

### 8.3 æ•¸æ“šè³ªé‡ç›£æ§

```python
# æ•¸æ“šè³ªé‡å„€è¡¨æ¿
class DataQualityMonitor:
    def __init__(self):
        self.metrics = {
            'avg_ifd_score': [],
            'avg_complexity': [],
            'diversity_score': [],
            'data_size': []
        }

    def track(self, data_batch):
        """è¿½è¹¤æ•¸æ“šè³ªé‡æŒ‡æ¨™"""
        self.metrics['avg_ifd_score'].append(
            np.mean([calc_ifd(s) for s in data_batch])
        )
        self.metrics['avg_complexity'].append(
            np.mean([analyze_complexity(s) for s in data_batch])
        )
        # ... å…¶ä»–æŒ‡æ¨™

    def visualize(self):
        """ç”Ÿæˆå¯è¦–åŒ–å„€è¡¨æ¿"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))

        # ç¹ªè£½è¶¨å‹¢åœ–
        axes[0, 0].plot(self.metrics['avg_ifd_score'])
        axes[0, 0].set_title('IFD Score Trend')
        # ... å…¶ä»–åœ–è¡¨

        plt.tight_layout()
        plt.show()
```

---

## 9. çµè«–èˆ‡å­¸ç¿’æˆæœ

é€šéæœ¬å¯¦é©—,æ‚¨å°‡ç²å¾—:

1. **è©•ä¼°é«”ç³»ç†è§£** æŒæ¡ä¸»æµè©•ä¼°åŸºæº–èˆ‡æŒ‡æ¨™é«”ç³»
2. **å¯¦æˆ°ç¶“é©—** ä½¿ç”¨æ¥­ç•Œæ¨™æº–å·¥å…·è©•ä¼°çœŸå¯¦æ¨¡å‹
3. **åˆ†æèƒ½åŠ›** è§£è®€è©•ä¼°çµæœ,è­˜åˆ¥æ¨¡å‹å„ªåŠ£å‹¢
4. **æ•¸æ“šå·¥ç¨‹** å¯¦æ–½é«˜æ•ˆæ•¸æ“šç¯©é¸èˆ‡è³ªé‡å„ªåŒ–
5. **å·¥ç¨‹å¯¦è¸** å»ºç«‹è‡ªå‹•åŒ–è©•ä¼°èˆ‡æ•¸æ“šç®¡ç·š

---

## 10. æŠ€è¡“é™åˆ¶èˆ‡æ”¹é€²æ–¹å‘

### 10.1 ç•¶å‰é™åˆ¶åˆ†æ

| é™åˆ¶é …ç›® | å…·é«”è¡¨ç¾ | å½±éŸ¿ | ç·©è§£æ–¹æ¡ˆ |
|:---|:---|:---|:---|
| **åŸºæº–è¦†è“‹** | ç¾æœ‰åŸºæº–ç„¡æ³•æ¶µè“‹æ‰€æœ‰èƒ½åŠ› | è©•ä¼°ç‰‡é¢æ€§ | å¤šåŸºæº–çµ„åˆè©•ä¼° |
| **ä¸»è§€ä»»å‹™è©•ä¼°** | å‰µæ„å¯«ä½œã€å°è©±è³ªé‡é›£ä»¥è‡ªå‹•åŒ– | éœ€è¦äººå·¥è©•ä¼° | ä½¿ç”¨ GPT-4 ä½œç‚ºè©•åˆ¤ |
| **æ•¸æ“šåè¦‹** | ç¯©é¸å¯èƒ½å¼•å…¥é ˜åŸŸåè¦‹ | æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸‹é™ | ä¿æŒå¤šæ¨£æ€§ã€åˆ†å±¤æ¡æ¨£ |
| **è©•ä¼°æˆæœ¬** | å¤§è¦æ¨¡è©•ä¼°è€—æ™‚é•·ã€æˆæœ¬é«˜ | é–‹ç™¼è¿­ä»£é€Ÿåº¦æ…¢ | ä½¿ç”¨å­é›†å¿«é€Ÿé©—è­‰ |

### 10.2 æœªä¾†ç ”ç©¶æ–¹å‘

- **å‹•æ…‹è©•ä¼°**: æ ¹æ“šæ¨¡å‹èƒ½åŠ›å‹•æ…‹èª¿æ•´è©•ä¼°é›£åº¦
- **å°æŠ—è©•ä¼°**: æ¸¬è©¦æ¨¡å‹å°å°æŠ—æ¨£æœ¬çš„é­¯æ£’æ€§
- **å¤šæ¨¡æ…‹è©•ä¼°**: æ“´å±•åˆ°åœ–åƒã€è¦–é »ã€éŸ³é »
- **åœ¨ç·šè©•ä¼°**: å¯¦æ™‚ç›£æ§ç”Ÿç”¢ç’°å¢ƒæ¨¡å‹æ€§èƒ½

### 10.3 è©•ä¼°èˆ‡è¨“ç·´é–‰ç’°

```
è©•ä¼° â†’ ç™¼ç¾ä¸è¶³ â†’ æ•¸æ“šç¯©é¸ â†’ è¨“ç·´å„ªåŒ– â†’ å†è©•ä¼°
  â†‘                                        â†“
  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æŒçºŒè¿­ä»£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

---

## 11. åƒè€ƒè³‡æ–™

### æ ¸å¿ƒè«–æ–‡

**è©•ä¼°åŸºæº–**:
- **C-Eval**: "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models" (arXiv:2305.08322)
- **CMMLU**: "CMMLU: Measuring Massive Multitask Language Understanding in Chinese" (arXiv:2306.09212)
- **MMLU**: "Measuring Massive Multitask Language Understanding" (arXiv:2009.03300)

**æ•¸æ“šå·¥ç¨‹**:
- **DEITA**: "What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning" (arXiv:2312.15685)
- **IFD**: "From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning" (arXiv:2308.12032)
- **LIMA**: "LIMA: Less Is More for Alignment" (arXiv:2305.11206)

### å·¥å…·èˆ‡å¯¦ç¾

**è©•ä¼°æ¡†æ¶**:
- **OpenCompass**: https://github.com/open-compass/opencompass
- **LM-Eval-Harness**: https://github.com/EleutherAI/lm-evaluation-harness

**æ•¸æ“šå·¥ç¨‹å·¥å…·**:
- **Sentence-BERT**: https://www.sbert.net/
- **DVC (Data Version Control)**: https://dvc.org/

### å»¶ä¼¸é–±è®€
- **Phi-1.5 Technical Report**: https://arxiv.org/abs/2309.05463
- **OpenAI Evals**: https://github.com/openai/evals

---

## ğŸ“š é€Ÿè¨˜å¿ƒæ³•èˆ‡å£è¨£

### ğŸ¯ è©•ä¼°å››æ­¥æ³•
```
è©•ä¼°æµç¨‹:
1. é¸åŸºæº– - æ ¹æ“šç›®æ¨™é¸æ“‡åˆé©åŸºæº–
2. è·‘è©•ä¼° - åŸ·è¡Œæ¨™æº–è©•ä¼°å”è­°
3. æçµæœ - å¤šç¶­åº¦åˆ†æè©•ä¼°çµæœ
4. å®šæ–¹å‘ - åŸºæ–¼çµæœåˆ¶å®šå„ªåŒ–ç­–ç•¥

å£è¨£: ã€Œé¸è·‘æå®š,ç’°ç’°ç›¸æ‰£ã€
```

### âš¡ æ•¸æ“šç¯©é¸ä¸‰åŸå‰‡
```
ç¯©é¸åŸå‰‡:
è³ª - é«˜è³ªé‡å„ªå…ˆ (IFD + DEITA)
å¤š - ä¿æŒå¤šæ¨£æ€§ (èšé¡è¦†è“‹)
é©— - é©—è­‰æ•ˆæœ (A/B æ¸¬è©¦)

ã€Œè³ªå¤šé©—,ç¼ºä¸€ä¸å¯ã€
```

### ğŸ“Š çµæœè§£è®€ä¸‰å±¤æ¬¡
```
è§£è®€å±¤æ¬¡:
1. æ•´é«”åˆ†æ•¸ - å®è§€èƒ½åŠ›æ°´å¹³
2. å­¸ç§‘åˆ†ä½ˆ - å„ªåŠ£å‹¢è­˜åˆ¥
3. éŒ¯èª¤åˆ†æ - å…·é«”å•é¡Œå®šä½

ã€Œç¸½åˆ†çœ‹æ°´å¹³,åˆ†ç§‘æ‰¾å•é¡Œ,éŒ¯ä¾‹å®šæ–¹å‘ã€
```

---

**ç‹€æ…‹**: âœ… å·²å®Œæˆ / â¸ï¸ é–‹ç™¼ä¸­ / ğŸ“ è¦åŠƒä¸­
**æœ€å¾Œæ›´æ–°**: YYYY-MM-DD
**ç¶­è­·è€…**: [ç¶­è­·è€…åç¨±]
```

---

## ğŸ““ Jupyter Notebook æ’°æ–‡è¦ç¯„

### Notebook å‘½åèˆ‡çµæ§‹

#### Lab-4.1: OpenCompass è©•ä¼°

**01-Setup.ipynb**
```markdown
# Lab 4.1: OpenCompass Model Evaluation - Environment Setup

**Goal:** Prepare OpenCompass evaluation environment

**You will learn to:**
- Install OpenCompass framework
- Download and prepare evaluation datasets (C-Eval, CMMLU)
- Load models for evaluation
- Verify configuration

---

## Step 1: Install OpenCompass

OpenCompass is a comprehensive evaluation platform for foundation models...
```

**02-Evaluate.ipynb**
```markdown
# Lab 4.1: OpenCompass Model Evaluation - Execute Evaluation

**Goal:** Run evaluation on multiple benchmarks

**Key concepts:**
- Few-shot evaluation
- Batch inference optimization
- Result collection

---

## Step 1: Configure Evaluation Tasks

Before evaluation, we need to configure...
```

**03-Analyze.ipynb**
```markdown
# Lab 4.1: OpenCompass Model Evaluation - Result Analysis

**Goal:** Analyze evaluation results in depth

**Analysis dimensions:**
- Overall accuracy by benchmark
- Performance by subject category
- Model comparison
- Error case analysis

---

## Step 1: Load Evaluation Results

We'll load and parse the evaluation outputs...
```

**04-Visualize_and_Report.ipynb**
```markdown
# Lab 4.1: OpenCompass Model Evaluation - Visualization and Reporting

**Goal:** Generate visualizations and automated reports

**Deliverables:**
- Radar charts (multi-dimensional capability)
- Heatmaps (subject performance matrix)
- Comparison bar charts
- Automated evaluation report

---

## Step 1: Prepare Data for Visualization

First, we aggregate results across models and benchmarks...
```

#### Lab-4.2: é«˜æ•ˆæ•¸æ“šç¯©é¸

**01-Setup.ipynb**
```markdown
# Lab 4.2: Efficient Data Filtering - Data Preparation

**Goal:** Load and analyze instruction datasets

**You will learn to:**
- Load instruction datasets (Alpaca, Dolly)
- Analyze data distribution
- Prepare quality evaluation models
- Set filtering goals

---

## Step 1: Load Instruction Datasets

We'll work with popular instruction datasets...
```

**02-Filter.ipynb**
```markdown
# Lab 4.2: Efficient Data Filtering - Apply Filtering

**Goal:** Implement IFD and DEITA filtering methods

**Key algorithms:**
- IFD (Instruction Following Difficulty)
- DEITA complexity scoring
- Multi-objective optimization

---

## Step 1: Calculate IFD Scores

IFD measures instruction difficulty by semantic similarity...
```

**03-Validate.ipynb**
```markdown
# Lab 4.2: Efficient Data Filtering - Validation Experiments

**Goal:** Validate filtering effectiveness through training

**Experiments:**
- Baseline: Full dataset training
- Experiment: Filtered dataset training
- Comparison: Performance and efficiency

---

## Step 1: Prepare Training Configurations

We'll conduct controlled experiments...
```

**04-Pipeline.ipynb**
```markdown
# Lab 4.2: Efficient Data Filtering - Automated Pipeline

**Goal:** Build end-to-end data processing pipeline

**Pipeline components:**
- Data ingestion
- Quality scoring
- Filtering logic
- Incremental processing
- Quality monitoring dashboard

---

## Step 1: Define Pipeline Architecture

An automated data pipeline consists of...
```

---

### Code Cell è¦ç¯„

#### 1. è©•ä¼°çµæœè§£æ
```python
# è§£æ OpenCompass è©•ä¼°çµæœ
import json
import pandas as pd

def parse_evaluation_results(result_file):
    """è§£æè©•ä¼°çµæœæ–‡ä»¶"""
    with open(result_file, 'r') as f:
        results = json.load(f)

    # æå–é—œéµæŒ‡æ¨™
    metrics = {
        'model': results['model_name'],
        'c_eval': results['c_eval']['accuracy'],
        'cmmlu': results['cmmlu']['accuracy'],
        'mmlu': results['mmlu']['accuracy']
    }

    return metrics

# ä½¿ç”¨ç¯„ä¾‹
results = parse_evaluation_results('outputs/results.json')
print(f"âœ… Evaluation results loaded: {results}")
```

#### 2. IFD è¨ˆç®—å¯¦ç¾
```python
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# è¼‰å…¥åµŒå…¥æ¨¡å‹
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

def calculate_ifd(instruction, response):
    """è¨ˆç®—æŒ‡ä»¤è·Ÿéš¨é›£åº¦"""
    # ç”Ÿæˆèªç¾©åµŒå…¥
    instr_emb = model.encode([instruction])
    resp_emb = model.encode([response])

    # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
    similarity = cosine_similarity(instr_emb, resp_emb)[0][0]

    # IFD = 1 - similarity (ä½ç›¸ä¼¼åº¦ = é«˜é›£åº¦)
    ifd = 1 - similarity

    return ifd

# æ¸¬è©¦ç¯„ä¾‹
sample_instr = "Analyze the causes of the French Revolution"
sample_resp = "The French Revolution was caused by..."
ifd_score = calculate_ifd(sample_instr, sample_resp)
print(f"âœ… IFD Score: {ifd_score:.4f}")
```

#### 3. å¯è¦–åŒ–è©•ä¼°çµæœ
```python
import matplotlib.pyplot as plt
import numpy as np

# æº–å‚™æ•¸æ“š
models = ['Llama-2-7B', 'Qwen-7B', 'ChatGLM-6B']
subjects = ['STEM', 'Social Science', 'Humanities', 'Others']

scores = np.array([
    [42.1, 48.7, 44.9, 43.2],  # Llama-2-7B
    [56.2, 62.4, 60.1, 58.7],  # Qwen-7B
    [51.3, 55.8, 53.4, 52.1]   # ChatGLM-6B
])

# ç¹ªè£½é›·é”åœ–
fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection='polar'))

angles = np.linspace(0, 2 * np.pi, len(subjects), endpoint=False).tolist()
angles += angles[:1]  # é–‰åˆåœ–å½¢

for i, model in enumerate(models):
    values = scores[i].tolist()
    values += values[:1]
    ax.plot(angles, values, 'o-', linewidth=2, label=model)
    ax.fill(angles, values, alpha=0.15)

ax.set_theta_offset(np.pi / 2)
ax.set_theta_direction(-1)
ax.set_thetagrids(np.degrees(angles[:-1]), subjects)
ax.set_ylim(0, 100)
ax.set_yticks([20, 40, 60, 80, 100])
ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
ax.set_title('Model Performance by Subject Category', pad=20, fontsize=14, fontweight='bold')
ax.grid(True)

plt.tight_layout()
plt.show()

print("âœ… Radar chart generated")
```

---

## ğŸ¨ è¦–è¦ºå…ƒç´ è¦ç¯„

### Emoji ä½¿ç”¨æŒ‡å—

```markdown
## ğŸ“Š è©•ä¼°çµæœåˆ†æ        # æ•¸æ“šåˆ†æ
## ğŸ“ˆ æ€§èƒ½è¶¨å‹¢            # è¶¨å‹¢åœ–è¡¨
## ğŸ¯ è©•ä¼°ç›®æ¨™            # ç›®æ¨™è²æ˜
## ğŸ” æ·±åº¦åˆ†æ            # è©³ç´°åˆ†æ
## ğŸ“‹ è©•ä¼°æ¸…å–®            # æª¢æŸ¥æ¸…å–®
## ğŸ† æ¨¡å‹æ’å            # æ’è¡Œæ¦œ
## ğŸ“‰ æ€§èƒ½ä¸‹é™            # è² é¢è¶¨å‹¢
## ğŸ”§ æ•¸æ“šè™•ç†            # æ•¸æ“šå·¥ç¨‹
## âš¡ æ•ˆç‡å„ªåŒ–            # æ€§èƒ½æå‡
## ğŸ’¡ è©•ä¼°æ´å¯Ÿ            # é—œéµç™¼ç¾
## âš ï¸  é™åˆ¶èˆ‡æ³¨æ„         # è­¦å‘Š
## âœ… é©—è­‰é€šé            # æˆåŠŸ
## âŒ è©•ä¼°å¤±æ•—            # éŒ¯èª¤
## ğŸ”¬ å¯¦é©—è¨­è¨ˆ            # å¯¦é©—
## ğŸ“ å ±å‘Šç”Ÿæˆ            # æ–‡æª”
```

### è¡¨æ ¼è¦–è¦ºåŒ–

#### è©•ä¼°çµæœè¡¨æ ¼
```markdown
| æ¨¡å‹ | C-Eval | CMMLU | MMLU | ç¶œåˆ | æ’å |
|:---|---:|---:|---:|---:|:---:|
| **Qwen-7B** | **59.7%** | **58.2%** | **56.4%** | **58.1%** | ğŸ¥‡ |
| ChatGLM-6B | 51.7% | 50.3% | 48.9% | 50.3% | ğŸ¥ˆ |
| Llama-2-7B | 45.3% | 42.1% | 46.8% | 44.7% | ğŸ¥‰ |
```

#### æ•¸æ“šç¯©é¸æ•ˆæœè¡¨æ ¼
```markdown
| æ–¹æ³• | æ•¸æ“šé‡ | è¨“ç·´æ™‚é–“ | C-Eval | æ•ˆç‡ |
|:---|---:|---:|---:|---:|
| **DEITA** | **15.6K** | **3.5h** | **47.1%** | **3.4x** |
| IFD only | 18.2K | 4.1h | 46.3% | 2.9x |
| Random | 52K | 12h | 45.3% | 1.0x |
```

---

## âœï¸ æ–‡å­—é¢¨æ ¼è¦ç¯„

### èªè¨€ç‰¹å¾µ

1. **å®¢è§€ä¸­æ€§**
   - âœ… "åœ¨ C-Eval åŸºæº–ä¸Š,Qwen-7B å¾—åˆ† 59.7%,è¶…é Llama-2-7B 14.4%"
   - âŒ "Qwen-7B é é è¶…é Llama-2-7B"

2. **æ•¸æ“šé©…å‹•**
   - âœ… "ç¯©é¸å¾Œæ•¸æ“šè¨“ç·´çš„æ¨¡å‹åœ¨ C-Eval ä¸Šæå‡ 1.8%,åŒæ™‚è¨“ç·´æ™‚é–“æ¸›å°‘ 70%"
   - âŒ "ç¯©é¸å¾Œçš„æ•¸æ“šæ•ˆæœæ›´å¥½"

3. **çµè«–æ˜ç¢º**
   - âœ… "åŸºæ–¼è©•ä¼°çµæœ,Qwen-7B åœ¨ä¸­æ–‡ç†è§£ä»»å‹™ä¸Šå…·æœ‰é¡¯è‘—å„ªå‹¢"
   - âŒ "Qwen-7B ä¼¼ä¹è¡¨ç¾é‚„ä¸éŒ¯"

4. **å› æœåˆ†æ**
   - âœ… "ç”±æ–¼ Qwen-7B ä½¿ç”¨äº†æ›´å¤šä¸­æ–‡èªæ–™,å…¶åœ¨ C-Eval ä¸Šè¡¨ç¾æ›´å„ª"
   - âŒ "Qwen-7B æ¯”è¼ƒå¥½"

### è¡“èªä¸€è‡´æ€§

#### è©•ä¼°å°ˆç”¨è¡“èª
```
è©•ä¼°åŸºæº– (Benchmark)
  - C-Eval (Chinese Evaluation)
  - CMMLU (Chinese Massive Multitask Language Understanding)
  - MMLU (Massive Multitask Language Understanding)
  - HumanEval (ä»£ç¢¼ç”Ÿæˆè©•ä¼°)

è©•ä¼°æŒ‡æ¨™ (Metrics)
  - æº–ç¢ºç‡ (Accuracy)
  - F1 åˆ†æ•¸ (F1-Score)
  - å›°æƒ‘åº¦ (Perplexity)
  - é€šéç‡ (Pass@K)

è©•ä¼°æ¨¡å¼ (Evaluation Mode)
  - Zero-shot (é›¶æ¨£æœ¬)
  - Few-shot (å°‘æ¨£æœ¬)
  - Chain-of-Thought (æ€ç¶­éˆ)
```

#### æ•¸æ“šå·¥ç¨‹è¡“èª
```
æ•¸æ“šè³ªé‡ (Data Quality)
  - IFD (Instruction Following Difficulty)
  - è¤‡é›œåº¦ (Complexity)
  - å¤šæ¨£æ€§ (Diversity)
  - ä¸€è‡´æ€§ (Consistency)

ç¯©é¸æ–¹æ³• (Filtering Methods)
  - DEITA
  - LESS (Low-Effort Score Sampling)
  - MoDS (Mixture of Data Selection)
  - CaR (Context-aware Reweighting)

æ•¸æ“šè™•ç† (Data Processing)
  - æ¸…æ´— (Cleaning)
  - å»é‡ (Deduplication)
  - æ¡æ¨£ (Sampling)
  - å¢å¼· (Augmentation)
```

---

## ğŸ” å“è³ªæª¢æŸ¥æ¸…å–®

### README.md æª¢æŸ¥
- [ ] åŒ…å«æ‰€æœ‰ 11 å€‹æ ¸å¿ƒç« ç¯€
- [ ] è©•ä¼°åŸºæº–ä»‹ç´¹æ¸…æ™°æº–ç¢º
- [ ] æ•¸æ“šå·¥ç¨‹æ–¹æ³•è«–å®Œæ•´
- [ ] æä¾›ä»£ç¢¼ç¯„ä¾‹ (å¸¶è©³ç´°è¨»è§£)
- [ ] åŒ…å«è©•ä¼°çµæœå°æ¯”è¡¨æ ¼
- [ ] åˆ—å‡ºå¯¦æˆ°èª¿å„ªç­–ç•¥
- [ ] æœ‰çµæœè§£è®€æŒ‡å—
- [ ] åŒ…å«å®Œæ•´åƒè€ƒè³‡æ–™
- [ ] ä½¿ç”¨ä¸€è‡´çš„ emoji æ¨™è¨˜
- [ ] å°ˆæ¥­è¡“èªç¿»è­¯ä¸€è‡´

### Notebook æª¢æŸ¥
- [ ] æ¯å€‹ code cell å‰æœ‰ markdown èªªæ˜
- [ ] è©•ä¼°çµæœè§£ææ¸…æ™°
- [ ] å¯è¦–åŒ–åœ–è¡¨ç¾è§€æ˜“æ‡‚
- [ ] åŒ…å«çµ±è¨ˆé¡¯è‘—æ€§æª¢é©—
- [ ] æ•¸æ“šç¯©é¸é‚è¼¯æ­£ç¢º
- [ ] é©—è­‰å¯¦é©—å°æ¯”å…¬å¹³
- [ ] è¨»è§£æ¸…æ™° (è‹±æ–‡)
- [ ] è®Šæ•¸å‘½åè¦ç¯„
- [ ] å¯é‡ç¾åŸ·è¡Œ (å›ºå®šéš¨æ©Ÿç¨®å­)

### è©•ä¼°å¯¦é©—ç‰¹å®šæª¢æŸ¥
- [ ] è©•ä¼°å”è­°çµ±ä¸€ (Few-shot, æº«åº¦ç­‰)
- [ ] çµæœå¯é‡ç¾ (å›ºå®šç¨®å­)
- [ ] éŒ¯èª¤æ¡ˆä¾‹åˆ†ææ·±å…¥
- [ ] å¤šç¶­åº¦çµæœå±•ç¤º
- [ ] çµ±è¨ˆé¡¯è‘—æ€§é©—è­‰

### æ•¸æ“šå¯¦é©—ç‰¹å®šæª¢æŸ¥
- [ ] ç¯©é¸å‰å¾Œæ•¸æ“šå°æ¯”
- [ ] å¤šæ¨£æ€§ä¿ç•™é©—è­‰
- [ ] A/B æ¸¬è©¦æ§åˆ¶è®Šé‡
- [ ] è¨“ç·´æ›²ç·šå¯è¦–åŒ–
- [ ] æ•ˆç‡æå‡é‡åŒ–

### æ•´é«”ä¸€è‡´æ€§
- [ ] README èˆ‡ notebook å…§å®¹å°æ‡‰
- [ ] èˆ‡ç†è«–æ–‡æª”ä¿æŒä¸€è‡´
- [ ] èˆ‡å…¶ä»– Lab é¢¨æ ¼çµ±ä¸€
- [ ] åœ–ç‰‡å’Œè¡¨æ ¼æ­£ç¢ºé¡¯ç¤º
- [ ] è¶…é€£çµæœ‰æ•ˆ

---

## ğŸ“– ç¯„ä¾‹åƒè€ƒ

### å®Œæ•´ README ç¯„ä¾‹
åƒè€ƒ: `03-Model_Compression/02-Labs/Lab-3.1-Post_Training_Quantization_GPTQ/README.md`

### å®Œæ•´ Notebook ç¯„ä¾‹
åƒè€ƒ: `03-Model_Compression/02-Labs/Lab-3.1-Post_Training_Quantization_GPTQ/01-Setup.ipynb`

---

## ğŸ› ï¸ å·¥å…·èˆ‡è³‡æº

### è©•ä¼°å·¥å…·
- **OpenCompass**: https://opencompass.org.cn/
- **LM-Eval-Harness**: https://github.com/EleutherAI/lm-evaluation-harness

### æ•¸æ“šå·¥ç¨‹å·¥å…·
- **Sentence-BERT**: https://www.sbert.net/
- **scikit-learn**: https://scikit-learn.org/

### å¯è¦–åŒ–å·¥å…·
- **Matplotlib**: https://matplotlib.org/
- **Seaborn**: https://seaborn.pydata.org/
- **Plotly**: https://plotly.com/python/

### Markdown ç·¨è¼¯å™¨
- **VS Code**: Markdown Preview Enhanced æ’ä»¶
- **Typora**: æ‰€è¦‹å³æ‰€å¾—ç·¨è¼¯å™¨
- **åœ¨ç·šå·¥å…·**: StackEdit, Dillinger

### è¡¨æ ¼ç”Ÿæˆå™¨
- [Tables Generator](https://www.tablesgenerator.com/markdown_tables)
- [Markdown Tables](https://tabletomarkdown.com/)

---

## ğŸ¯ è©•ä¼°å¯¦é©—ç‰¹æ®Šæ³¨æ„äº‹é …

### 1. è©•ä¼°å”è­°çµ±ä¸€æ€§
```python
# å›ºå®šè©•ä¼°é…ç½®
EVAL_CONFIG = {
    'num_fewshot': 5,
    'temperature': 0.0,      # è©•ä¼°æ™‚ä½¿ç”¨è²ªå©ªè§£ç¢¼
    'max_length': 2048,
    'batch_size': 16,
    'seed': 42
}
```

### 2. çµæœå¯é‡ç¾æ€§
```python
# å›ºå®šæ‰€æœ‰éš¨æ©Ÿæº
import random
import numpy as np
import torch

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
```

### 3. çµ±è¨ˆé¡¯è‘—æ€§æª¢é©—
```python
from scipy import stats

# ä½¿ç”¨ t-test æ¯”è¼ƒå…©å€‹æ¨¡å‹
def compare_models(scores_a, scores_b, alpha=0.05):
    """æ¯”è¼ƒå…©å€‹æ¨¡å‹æ€§èƒ½å·®ç•°çš„é¡¯è‘—æ€§"""
    t_stat, p_value = stats.ttest_ind(scores_a, scores_b)

    if p_value < alpha:
        print(f"âœ… Significant difference (p={p_value:.4f})")
    else:
        print(f"âš ï¸  No significant difference (p={p_value:.4f})")

    return p_value
```

---

## ğŸ”„ æ•¸æ“šå¯¦é©—ç‰¹æ®Šæ³¨æ„äº‹é …

### 1. æ•¸æ“šç‰ˆæœ¬ç®¡ç†
```python
# è¨˜éŒ„æ•¸æ“šç‰ˆæœ¬èˆ‡ç¯©é¸åƒæ•¸
DATA_VERSION = {
    'source': 'alpaca_52k',
    'filtering_method': 'DEITA',
    'ifd_threshold': 0.4,
    'complexity_threshold': 3.0,
    'final_size': 15600,
    'timestamp': '2025-10-17'
}

# ä¿å­˜æ•¸æ“šç‰ˆæœ¬ä¿¡æ¯
with open('data_version.json', 'w') as f:
    json.dump(DATA_VERSION, f, indent=2)
```

### 2. A/B æ¸¬è©¦å…¬å¹³æ€§
```python
# ç¢ºä¿å°æ¯”å¯¦é©—çš„å…¬å¹³æ€§
TRAINING_CONFIG = {
    'model': 'Llama-2-7B',
    'learning_rate': 2e-5,
    'num_epochs': 3,
    'batch_size': 16,
    'seed': 42,
    'optimizer': 'AdamW',
    'scheduler': 'linear'
}

# åƒ…æ”¹è®Šæ•¸æ“šé›†,å…¶ä»–åƒæ•¸ä¿æŒä¸€è‡´
experiments = {
    'baseline': {'data': 'full_dataset', **TRAINING_CONFIG},
    'filtered': {'data': 'filtered_dataset', **TRAINING_CONFIG}
}
```

---

**ç¶­è­·è€…**: Claude Code
**æœ€å¾Œæ›´æ–°**: 2025-10-17
**ç‰ˆæœ¬**: 1.0

---

**ä½¿ç”¨å»ºè­°**:
1. é–‹ç™¼æ–° Lab å‰,å…ˆé–±è®€æœ¬è¦ç¯„
2. åƒè€ƒå·²æœ‰ Lab çš„çµæ§‹å’Œé¢¨æ ¼
3. ä¿æŒèˆ‡å…¶ä»–ç« ç¯€ä¸€è‡´
4. é‡è¦–è©•ä¼°çµæœçš„å®¢è§€æ€§èˆ‡å¯é‡ç¾æ€§
5. å¼·èª¿æ•¸æ“šè³ªé‡å°æ¨¡å‹æ€§èƒ½çš„é—œéµå½±éŸ¿
6. å®šæœŸæ›´æ–°æœ€ä½³å¯¦è¸

**å•é¡Œåé¥‹**:
å¦‚ç™¼ç¾è¦ç¯„ä¸æ¸…æ¥šæˆ–éœ€è¦è£œå……,è«‹åœ¨å°ˆæ¡ˆä¸­æå‡º issueã€‚
