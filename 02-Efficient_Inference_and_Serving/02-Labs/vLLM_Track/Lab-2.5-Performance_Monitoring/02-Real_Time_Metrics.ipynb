{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.5-02: å¯¦æ™‚æŒ‡æ¨™æ”¶é›†èˆ‡ç›£æ§\n",
    "\n",
    "## å¯¦é©—ç›®æ¨™\n",
    "\n",
    "æœ¬ç¯€å°‡æ·±å…¥æ¢è¨ vLLM çš„å¯¦æ™‚æ€§èƒ½æŒ‡æ¨™æ”¶é›†ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- vLLM å…§å»ºæŒ‡æ¨™çš„è©³ç´°åˆ†æ\n",
    "- é«˜é »ç‡å¯¦æ™‚æ•¸æ“šæµå»ºç«‹\n",
    "- å…ˆé€²çš„æŒ‡æ¨™èšåˆèˆ‡è¨ˆç®—\n",
    "- å‹•æ…‹ç›£æ§å„€è¡¨æ¿é–‹ç™¼\n",
    "\n",
    "## æ ¸å¿ƒç›£æ§æŒ‡æ¨™é«”ç³»\n",
    "\n",
    "### 1. è«‹æ±‚ç´šæŒ‡æ¨™ (Request-level Metrics)\n",
    "- **TTFT (Time to First Token)**: å¾è«‹æ±‚åˆ°é¦–å€‹ token çš„æ™‚é–“\n",
    "- **TPOT (Time Per Output Token)**: æ¯å€‹è¼¸å‡º token çš„å¹³å‡æ™‚é–“\n",
    "- **Request Duration**: å®Œæ•´è«‹æ±‚çš„ç¸½æ™‚é–“\n",
    "- **Queue Time**: è«‹æ±‚åœ¨ä½‡åˆ—ä¸­çš„ç­‰å¾…æ™‚é–“\n",
    "\n",
    "### 2. ååé‡æŒ‡æ¨™ (Throughput Metrics)\n",
    "- **Requests per Second (RPS)**: æ¯ç§’è™•ç†çš„è«‹æ±‚æ•¸\n",
    "- **Tokens per Second (TPS)**: æ¯ç§’ç”Ÿæˆçš„ token æ•¸\n",
    "- **Concurrent Requests**: ä¸¦ç™¼è«‹æ±‚æ•¸é‡\n",
    "- **Batch Size Distribution**: æ‰¹æ¬¡å¤§å°åˆ†ä½ˆ\n",
    "\n",
    "### 3. è³‡æºä½¿ç”¨æŒ‡æ¨™ (Resource Utilization)\n",
    "- **GPU Memory Usage**: GPU è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³\n",
    "- **KV Cache Utilization**: KV å¿«å–ä½¿ç”¨æ•ˆç‡\n",
    "- **Model Loading Time**: æ¨¡å‹è¼‰å…¥æ™‚é–“\n",
    "- **Attention Computation Time**: æ³¨æ„åŠ›è¨ˆç®—æ™‚é–“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒåˆå§‹åŒ–èˆ‡ä¾è³´å°å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "import threading\n",
    "import logging\n",
    "import statistics\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, deque\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "# æ•¸æ“šè™•ç†èˆ‡åˆ†æ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# è¦–è¦ºåŒ–\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "\n",
    "# HTTP å®¢æˆ¶ç«¯\n",
    "import requests\n",
    "import aiohttp\n",
    "\n",
    "# Prometheus æŒ‡æ¨™\n",
    "from prometheus_client import (\n",
    "    Gauge, Counter, Histogram, Summary, \n",
    "    CollectorRegistry, start_http_server\n",
    ")\n",
    "from prometheus_client.parser import text_string_to_metric_families\n",
    "\n",
    "# ç³»çµ±ç›£æ§\n",
    "import psutil\n",
    "try:\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    NVIDIA_GPU_AVAILABLE = True\n",
    "except (ImportError, Exception):\n",
    "    NVIDIA_GPU_AVAILABLE = False\n",
    "\n",
    "# è¨­ç½®æ—¥èªŒ\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# å•Ÿç”¨ Plotly é›¢ç·šæ¨¡å¼\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "print(\"âœ… å¯¦æ™‚ç›£æ§ç’°å¢ƒåˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. vLLM Metrics è§£æå™¨èˆ‡æ”¶é›†å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLLMMetricsParser:\n",
    "    \"\"\"vLLM Prometheus æŒ‡æ¨™è§£æå™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, metrics_url: str = \"http://127.0.0.1:8001/metrics\"):\n",
    "        self.metrics_url = metrics_url\n",
    "        self.last_scrape_time = None\n",
    "        self.metrics_cache = {}\n",
    "    \n",
    "    def fetch_raw_metrics(self) -> Optional[str]:\n",
    "        \"\"\"ç²å–åŸå§‹ metrics æ–‡æœ¬\"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.metrics_url, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                self.last_scrape_time = datetime.now()\n",
    "                return response.text\n",
    "            else:\n",
    "                logger.warning(f\"Metrics endpoint returned {response.status_code}\")\n",
    "                return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Failed to fetch metrics: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def parse_metrics(self, raw_metrics: str) -> Dict[str, Any]:\n",
    "        \"\"\"è§£æ Prometheus æ ¼å¼çš„ metrics\"\"\"\n",
    "        parsed_metrics = {}\n",
    "        \n",
    "        try:\n",
    "            for family in text_string_to_metric_families(raw_metrics):\n",
    "                metric_name = family.name\n",
    "                metric_type = family.type\n",
    "                \n",
    "                if metric_type == 'counter':\n",
    "                    for sample in family.samples:\n",
    "                        parsed_metrics[sample.name] = {\n",
    "                            'value': sample.value,\n",
    "                            'labels': sample.labels,\n",
    "                            'type': 'counter'\n",
    "                        }\n",
    "                \n",
    "                elif metric_type == 'gauge':\n",
    "                    for sample in family.samples:\n",
    "                        parsed_metrics[sample.name] = {\n",
    "                            'value': sample.value,\n",
    "                            'labels': sample.labels,\n",
    "                            'type': 'gauge'\n",
    "                        }\n",
    "                \n",
    "                elif metric_type == 'histogram':\n",
    "                    histogram_data = defaultdict(dict)\n",
    "                    for sample in family.samples:\n",
    "                        key = sample.name.replace(f'{metric_name}_', '')\n",
    "                        labels_key = str(sorted(sample.labels.items()))\n",
    "                        histogram_data[labels_key][key] = sample.value\n",
    "                    \n",
    "                    parsed_metrics[metric_name] = {\n",
    "                        'type': 'histogram',\n",
    "                        'data': dict(histogram_data)\n",
    "                    }\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing metrics: {e}\")\n",
    "        \n",
    "        return parsed_metrics\n",
    "    \n",
    "    def get_specific_metrics(self, metric_patterns: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"ç²å–ç‰¹å®šæ¨¡å¼çš„æŒ‡æ¨™\"\"\"\n",
    "        raw_metrics = self.fetch_raw_metrics()\n",
    "        if not raw_metrics:\n",
    "            return {}\n",
    "        \n",
    "        all_metrics = self.parse_metrics(raw_metrics)\n",
    "        filtered_metrics = {}\n",
    "        \n",
    "        for pattern in metric_patterns:\n",
    "            for metric_name, metric_data in all_metrics.items():\n",
    "                if pattern in metric_name:\n",
    "                    filtered_metrics[metric_name] = metric_data\n",
    "        \n",
    "        return filtered_metrics\n",
    "\n",
    "# åˆå§‹åŒ– metrics è§£æå™¨\n",
    "metrics_parser = VLLMMetricsParser()\n",
    "print(\"âœ… vLLM Metrics è§£æå™¨å·²åˆå§‹åŒ–\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeMetricsCollector:\n",
    "    \"\"\"å¯¦æ™‚æŒ‡æ¨™æ”¶é›†å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_interval: float = 1.0, max_data_points: int = 1000):\n",
    "        self.collection_interval = collection_interval\n",
    "        self.max_data_points = max_data_points\n",
    "        self.running = False\n",
    "        \n",
    "        # æ™‚é–“åºåˆ—æ•¸æ“šå„²å­˜\n",
    "        self.time_series_data = defaultdict(lambda: deque(maxlen=max_data_points))\n",
    "        self.timestamps = deque(maxlen=max_data_points)\n",
    "        \n",
    "        # èšåˆçµ±è¨ˆ\n",
    "        self.aggregated_stats = defaultdict(dict)\n",
    "        \n",
    "        # æŒ‡æ¨™å®šç¾©\n",
    "        self.key_metrics = [\n",
    "            'vllm_request_success_total',\n",
    "            'vllm_request_failure_total',\n",
    "            'vllm_time_to_first_token_seconds',\n",
    "            'vllm_time_per_output_token_seconds',\n",
    "            'vllm_request_duration_seconds',\n",
    "            'vllm_num_requests_running',\n",
    "            'vllm_num_requests_waiting',\n",
    "            'vllm_gpu_cache_usage_perc'\n",
    "        ]\n",
    "        \n",
    "        # ç³»çµ±æŒ‡æ¨™\n",
    "        self.system_metrics = {\n",
    "            'cpu_percent': deque(maxlen=max_data_points),\n",
    "            'memory_percent': deque(maxlen=max_data_points),\n",
    "            'gpu_memory_used': deque(maxlen=max_data_points),\n",
    "            'gpu_utilization': deque(maxlen=max_data_points)\n",
    "        }\n",
    "    \n",
    "    def collect_system_metrics(self) -> Dict[str, float]:\n",
    "        \"\"\"æ”¶é›†ç³»çµ±ç´šæŒ‡æ¨™\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # CPU å’Œè¨˜æ†¶é«”\n",
    "        metrics['cpu_percent'] = psutil.cpu_percent(interval=None)\n",
    "        metrics['memory_percent'] = psutil.virtual_memory().percent\n",
    "        \n",
    "        # GPU æŒ‡æ¨™\n",
    "        if NVIDIA_GPU_AVAILABLE:\n",
    "            try:\n",
    "                handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "                mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                util_info = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "                \n",
    "                metrics['gpu_memory_used'] = (mem_info.used / mem_info.total) * 100\n",
    "                metrics['gpu_utilization'] = util_info.gpu\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"GPU metrics collection failed: {e}\")\n",
    "                metrics['gpu_memory_used'] = 0\n",
    "                metrics['gpu_utilization'] = 0\n",
    "        else:\n",
    "            metrics['gpu_memory_used'] = 0\n",
    "            metrics['gpu_utilization'] = 0\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def collect_vllm_metrics(self) -> Dict[str, float]:\n",
    "        \"\"\"æ”¶é›† vLLM ç‰¹å®šæŒ‡æ¨™\"\"\"\n",
    "        vllm_metrics = metrics_parser.get_specific_metrics(self.key_metrics)\n",
    "        \n",
    "        # ç°¡åŒ–æŒ‡æ¨™æå–\n",
    "        simplified_metrics = {}\n",
    "        \n",
    "        for metric_name, metric_data in vllm_metrics.items():\n",
    "            if metric_data['type'] in ['counter', 'gauge']:\n",
    "                simplified_metrics[metric_name] = metric_data['value']\n",
    "            elif metric_data['type'] == 'histogram':\n",
    "                # å°æ–¼ histogramï¼Œæå–é—œéµçµ±è¨ˆå€¼\n",
    "                for labels_key, hist_data in metric_data['data'].items():\n",
    "                    if 'count' in hist_data:\n",
    "                        simplified_metrics[f\"{metric_name}_count\"] = hist_data['count']\n",
    "                    if 'sum' in hist_data:\n",
    "                        simplified_metrics[f\"{metric_name}_sum\"] = hist_data['sum']\n",
    "        \n",
    "        return simplified_metrics\n",
    "    \n",
    "    def collect_single_round(self):\n",
    "        \"\"\"åŸ·è¡Œå–®æ¬¡æŒ‡æ¨™æ”¶é›†\"\"\"\n",
    "        timestamp = datetime.now()\n",
    "        \n",
    "        # æ”¶é›†ç³»çµ±æŒ‡æ¨™\n",
    "        system_data = self.collect_system_metrics()\n",
    "        for key, value in system_data.items():\n",
    "            self.system_metrics[key].append(value)\n",
    "        \n",
    "        # æ”¶é›† vLLM æŒ‡æ¨™\n",
    "        vllm_data = self.collect_vllm_metrics()\n",
    "        for key, value in vllm_data.items():\n",
    "            self.time_series_data[key].append(value)\n",
    "        \n",
    "        # è¨˜éŒ„æ™‚é–“æˆ³\n",
    "        self.timestamps.append(timestamp)\n",
    "        \n",
    "        # è¨ˆç®—èšåˆçµ±è¨ˆ\n",
    "        self.update_aggregated_stats()\n",
    "    \n",
    "    def update_aggregated_stats(self):\n",
    "        \"\"\"æ›´æ–°èšåˆçµ±è¨ˆæ•¸æ“š\"\"\"\n",
    "        # ç³»çµ±æŒ‡æ¨™çµ±è¨ˆ\n",
    "        for metric_name, values in self.system_metrics.items():\n",
    "            if len(values) > 0:\n",
    "                self.aggregated_stats[metric_name] = {\n",
    "                    'current': values[-1],\n",
    "                    'avg_5m': np.mean(list(values)[-300:]) if len(values) >= 300 else np.mean(list(values)),\n",
    "                    'max_5m': np.max(list(values)[-300:]) if len(values) >= 300 else np.max(list(values)),\n",
    "                    'min_5m': np.min(list(values)[-300:]) if len(values) >= 300 else np.min(list(values))\n",
    "                }\n",
    "        \n",
    "        # vLLM æŒ‡æ¨™çµ±è¨ˆ\n",
    "        for metric_name, values in self.time_series_data.items():\n",
    "            if len(values) > 0:\n",
    "                self.aggregated_stats[metric_name] = {\n",
    "                    'current': values[-1],\n",
    "                    'avg_5m': np.mean(list(values)[-300:]) if len(values) >= 300 else np.mean(list(values)),\n",
    "                    'max_5m': np.max(list(values)[-300:]) if len(values) >= 300 else np.max(list(values)),\n",
    "                    'min_5m': np.min(list(values)[-300:]) if len(values) >= 300 else np.min(list(values))\n",
    "                }\n",
    "    \n",
    "    def start_collection(self):\n",
    "        \"\"\"é–‹å§‹å¯¦æ™‚æ”¶é›†\"\"\"\n",
    "        self.running = True\n",
    "        \n",
    "        def collection_loop():\n",
    "            while self.running:\n",
    "                try:\n",
    "                    self.collect_single_round()\n",
    "                    time.sleep(self.collection_interval)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Collection error: {e}\")\n",
    "                    time.sleep(self.collection_interval)\n",
    "        \n",
    "        # åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­é‹è¡Œ\n",
    "        self.collection_thread = threading.Thread(target=collection_loop, daemon=True)\n",
    "        self.collection_thread.start()\n",
    "        \n",
    "        logger.info(f\"Started real-time metrics collection (interval: {self.collection_interval}s)\")\n",
    "    \n",
    "    def stop_collection(self):\n",
    "        \"\"\"åœæ­¢å¯¦æ™‚æ”¶é›†\"\"\"\n",
    "        self.running = False\n",
    "        logger.info(\"Stopped real-time metrics collection\")\n",
    "    \n",
    "    def get_latest_data(self, metric_name: str, num_points: int = 60) -> tuple:\n",
    "        \"\"\"ç²å–æœ€æ–°çš„æ™‚é–“åºåˆ—æ•¸æ“š\"\"\"\n",
    "        if metric_name in self.system_metrics:\n",
    "            values = list(self.system_metrics[metric_name])[-num_points:]\n",
    "        elif metric_name in self.time_series_data:\n",
    "            values = list(self.time_series_data[metric_name])[-num_points:]\n",
    "        else:\n",
    "            return [], []\n",
    "        \n",
    "        timestamps = list(self.timestamps)[-len(values):]\n",
    "        return timestamps, values\n",
    "    \n",
    "    def get_summary_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"ç²å–æ‘˜è¦çµ±è¨ˆ\"\"\"\n",
    "        return dict(self.aggregated_stats)\n",
    "\n",
    "# åˆå§‹åŒ–å¯¦æ™‚æ”¶é›†å™¨\n",
    "collector = RealTimeMetricsCollector(collection_interval=2.0)\n",
    "print(\"âœ… å¯¦æ™‚æŒ‡æ¨™æ”¶é›†å™¨å·²åˆå§‹åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å‹•æ…‹è¦–è¦ºåŒ–å„€è¡¨æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeDashboard:\n",
    "    \"\"\"å¯¦æ™‚ç›£æ§å„€è¡¨æ¿\"\"\"\n",
    "    \n",
    "    def __init__(self, collector: RealTimeMetricsCollector):\n",
    "        self.collector = collector\n",
    "        self.fig = None\n",
    "        self.animation = None\n",
    "        \n",
    "        # è¨­ç½® matplotlib é¢¨æ ¼\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "        \n",
    "        # é¡è‰²é…ç½®\n",
    "        self.colors = {\n",
    "            'cpu': '#FF6B6B',\n",
    "            'memory': '#4ECDC4',\n",
    "            'gpu_memory': '#45B7D1',\n",
    "            'gpu_util': '#96CEB4',\n",
    "            'requests': '#FFEAA7',\n",
    "            'latency': '#DDA0DD'\n",
    "        }\n",
    "    \n",
    "    def create_static_dashboard(self):\n",
    "        \"\"\"å‰µå»ºéœæ…‹å„€è¡¨æ¿å¿«ç…§\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('vLLM å¯¦æ™‚æ€§èƒ½ç›£æ§å„€è¡¨æ¿', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # ç³»çµ±è³‡æºç›£æ§\n",
    "        self._plot_system_metrics(axes[0, 0], 'cpu_percent', 'CPU ä½¿ç”¨ç‡ (%)', self.colors['cpu'])\n",
    "        self._plot_system_metrics(axes[0, 1], 'memory_percent', 'è¨˜æ†¶é«”ä½¿ç”¨ç‡ (%)', self.colors['memory'])\n",
    "        self._plot_system_metrics(axes[0, 2], 'gpu_memory_used', 'GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡ (%)', self.colors['gpu_memory'])\n",
    "        \n",
    "        # vLLM ç‰¹å®šæŒ‡æ¨™\n",
    "        self._plot_vllm_requests(axes[1, 0])\n",
    "        self._plot_vllm_latency(axes[1, 1])\n",
    "        self._plot_summary_stats(axes[1, 2])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_system_metrics(self, ax, metric_name, title, color):\n",
    "        \"\"\"ç¹ªè£½ç³»çµ±æŒ‡æ¨™\"\"\"\n",
    "        timestamps, values = self.collector.get_latest_data(metric_name, 60)\n",
    "        \n",
    "        if len(values) > 0:\n",
    "            ax.plot(timestamps, values, color=color, linewidth=2)\n",
    "            ax.fill_between(timestamps, values, alpha=0.3, color=color)\n",
    "            \n",
    "            # æ·»åŠ ç•¶å‰å€¼æ¨™è¨»\n",
    "            current_value = values[-1] if values else 0\n",
    "            ax.text(0.02, 0.98, f'ç•¶å‰: {current_value:.1f}%', \n",
    "                   transform=ax.transAxes, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        ax.set_title(title, fontweight='bold')\n",
    "        ax.set_ylabel('ä½¿ç”¨ç‡ (%)')\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # æ ¼å¼åŒ– x è»¸æ™‚é–“é¡¯ç¤º\n",
    "        if len(timestamps) > 0:\n",
    "            ax.set_xlim(timestamps[0], timestamps[-1])\n",
    "    \n",
    "    def _plot_vllm_requests(self, ax):\n",
    "        \"\"\"ç¹ªè£½ vLLM è«‹æ±‚æŒ‡æ¨™\"\"\"\n",
    "        # é‹è¡Œä¸­çš„è«‹æ±‚\n",
    "        timestamps, running = self.collector.get_latest_data('vllm_num_requests_running', 60)\n",
    "        timestamps_waiting, waiting = self.collector.get_latest_data('vllm_num_requests_waiting', 60)\n",
    "        \n",
    "        if len(running) > 0:\n",
    "            ax.plot(timestamps, running, label='é‹è¡Œä¸­', color=self.colors['requests'], linewidth=2)\n",
    "        \n",
    "        if len(waiting) > 0:\n",
    "            ax.plot(timestamps_waiting, waiting, label='ç­‰å¾…ä¸­', color='orange', linewidth=2)\n",
    "        \n",
    "        ax.set_title('vLLM è«‹æ±‚ç‹€æ…‹', fontweight='bold')\n",
    "        ax.set_ylabel('è«‹æ±‚æ•¸é‡')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _plot_vllm_latency(self, ax):\n",
    "        \"\"\"ç¹ªè£½å»¶é²æŒ‡æ¨™\"\"\"\n",
    "        # å˜—è©¦ç²å– TTFT æ•¸æ“š\n",
    "        timestamps, ttft_count = self.collector.get_latest_data('vllm_time_to_first_token_seconds_count', 60)\n",
    "        timestamps_sum, ttft_sum = self.collector.get_latest_data('vllm_time_to_first_token_seconds_sum', 60)\n",
    "        \n",
    "        if len(ttft_count) > 0 and len(ttft_sum) > 0:\n",
    "            # è¨ˆç®—å¹³å‡ TTFT\n",
    "            avg_ttft = [s/c if c > 0 else 0 for s, c in zip(ttft_sum, ttft_count)]\n",
    "            ax.plot(timestamps, avg_ttft, label='TTFT å¹³å‡', color=self.colors['latency'], linewidth=2)\n",
    "        \n",
    "        ax.set_title('å»¶é²æŒ‡æ¨™', fontweight='bold')\n",
    "        ax.set_ylabel('æ™‚é–“ (ç§’)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _plot_summary_stats(self, ax):\n",
    "        \"\"\"ç¹ªè£½æ‘˜è¦çµ±è¨ˆ\"\"\"\n",
    "        stats = self.collector.get_summary_stats()\n",
    "        \n",
    "        # é¸æ“‡é—œéµæŒ‡æ¨™é¡¯ç¤º\n",
    "        key_stats = {\n",
    "            'CPU': stats.get('cpu_percent', {}).get('current', 0),\n",
    "            'Memory': stats.get('memory_percent', {}).get('current', 0),\n",
    "            'GPU Mem': stats.get('gpu_memory_used', {}).get('current', 0),\n",
    "            'GPU Util': stats.get('gpu_utilization', {}).get('current', 0)\n",
    "        }\n",
    "        \n",
    "        labels = list(key_stats.keys())\n",
    "        values = list(key_stats.values())\n",
    "        \n",
    "        bars = ax.bar(labels, values, \n",
    "                     color=[self.colors['cpu'], self.colors['memory'], \n",
    "                           self.colors['gpu_memory'], self.colors['gpu_util']])\n",
    "        \n",
    "        # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{value:.1f}%', ha='center', va='bottom')\n",
    "        \n",
    "        ax.set_title('ç•¶å‰ç³»çµ±ç‹€æ…‹', fontweight='bold')\n",
    "        ax.set_ylabel('ä½¿ç”¨ç‡ (%)')\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def create_interactive_dashboard(self):\n",
    "        \"\"\"å‰µå»ºäº’å‹•å¼ Plotly å„€è¡¨æ¿\"\"\"\n",
    "        # å‰µå»ºå­åœ–\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=3,\n",
    "            subplot_titles=['CPU ä½¿ç”¨ç‡', 'è¨˜æ†¶é«”ä½¿ç”¨ç‡', 'GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡',\n",
    "                          'vLLM è«‹æ±‚ç‹€æ…‹', 'å»¶é²æŒ‡æ¨™', 'ç³»çµ±æ‘˜è¦'],\n",
    "            specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n",
    "                   [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    "        )\n",
    "        \n",
    "        # æ·»åŠ  CPU ä½¿ç”¨ç‡\n",
    "        timestamps, cpu_values = self.collector.get_latest_data('cpu_percent', 100)\n",
    "        if len(cpu_values) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=cpu_values, \n",
    "                          mode='lines+markers', name='CPU',\n",
    "                          line=dict(color='#FF6B6B', width=2)),\n",
    "                row=1, col=1\n",
    "            )\n",
    "        \n",
    "        # æ·»åŠ è¨˜æ†¶é«”ä½¿ç”¨ç‡\n",
    "        timestamps, mem_values = self.collector.get_latest_data('memory_percent', 100)\n",
    "        if len(mem_values) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=mem_values,\n",
    "                          mode='lines+markers', name='Memory',\n",
    "                          line=dict(color='#4ECDC4', width=2)),\n",
    "                row=1, col=2\n",
    "            )\n",
    "        \n",
    "        # æ·»åŠ  GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡\n",
    "        timestamps, gpu_mem_values = self.collector.get_latest_data('gpu_memory_used', 100)\n",
    "        if len(gpu_mem_values) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=gpu_mem_values,\n",
    "                          mode='lines+markers', name='GPU Memory',\n",
    "                          line=dict(color='#45B7D1', width=2)),\n",
    "                row=1, col=3\n",
    "            )\n",
    "        \n",
    "        # æ·»åŠ  vLLM è«‹æ±‚ç‹€æ…‹\n",
    "        timestamps, running = self.collector.get_latest_data('vllm_num_requests_running', 100)\n",
    "        if len(running) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=running,\n",
    "                          mode='lines+markers', name='Running Requests',\n",
    "                          line=dict(color='#FFEAA7', width=2)),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        # æ›´æ–°ä½ˆå±€\n",
    "        fig.update_layout(\n",
    "            title='vLLM å¯¦æ™‚æ€§èƒ½ç›£æ§å„€è¡¨æ¿',\n",
    "            height=800,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        # é¡¯ç¤ºåœ–è¡¨\n",
    "        pyo.iplot(fig)\n",
    "\n",
    "# åˆå§‹åŒ–å„€è¡¨æ¿\n",
    "dashboard = RealTimeDashboard(collector)\n",
    "print(\"âœ… å¯¦æ™‚å„€è¡¨æ¿å·²åˆå§‹åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. é–‹å§‹å¯¦æ™‚ç›£æ§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–‹å§‹å¯¦æ™‚æŒ‡æ¨™æ”¶é›†\n",
    "collector.start_collection()\n",
    "\n",
    "print(\"ğŸš€ å¯¦æ™‚ç›£æ§å·²å•Ÿå‹•\")\n",
    "print(\"   æ”¶é›†é–“éš”: 2 ç§’\")\n",
    "print(\"   æœ€å¤§æ•¸æ“šé»: 1000\")\n",
    "print(\"   ç›£æ§æŒ‡æ¨™åŒ…æ‹¬:\")\n",
    "print(\"   - ç³»çµ±è³‡æº (CPU, è¨˜æ†¶é«”, GPU)\")\n",
    "print(\"   - vLLM è«‹æ±‚æŒ‡æ¨™\")\n",
    "print(\"   - å»¶é²å’Œååé‡æŒ‡æ¨™\")\n",
    "print(\"\\nâ³ ç­‰å¾… 30 ç§’æ”¶é›†åˆå§‹æ•¸æ“š...\")\n",
    "\n",
    "# ç­‰å¾…æ”¶é›†ä¸€äº›åˆå§‹æ•¸æ“š\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ¨¡æ“¬ vLLM å·¥ä½œè² è¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLLMWorkloadSimulator:\n",
    "    \"\"\"vLLM å·¥ä½œè² è¼‰æ¨¡æ“¬å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, api_base: str = \"http://127.0.0.1:8000\"):\n",
    "        self.api_base = api_base\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # æ¸¬è©¦æç¤ºè©é›†åˆ\n",
    "        self.test_prompts = [\n",
    "            \"What is the capital of France?\",\n",
    "            \"Explain quantum computing in simple terms.\",\n",
    "            \"Write a short story about a robot.\",\n",
    "            \"How do neural networks work?\",\n",
    "            \"Describe the process of photosynthesis.\",\n",
    "            \"What are the benefits of renewable energy?\",\n",
    "            \"Explain the theory of relativity.\",\n",
    "            \"Write a poem about the ocean.\"\n",
    "        ]\n",
    "    \n",
    "    def check_vllm_availability(self) -> bool:\n",
    "        \"\"\"æª¢æŸ¥ vLLM æœå‹™æ˜¯å¦å¯ç”¨\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f\"{self.api_base}/v1/models\", timeout=5)\n",
    "            return response.status_code == 200\n",
    "        except requests.exceptions.RequestException:\n",
    "            return False\n",
    "    \n",
    "    def send_completion_request(self, prompt: str, max_tokens: int = 100) -> Dict[str, Any]:\n",
    "        \"\"\"ç™¼é€å®Œæˆè«‹æ±‚\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"microsoft/DialoGPT-medium\",  # ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.7,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = self.session.post(\n",
    "                f\"{self.api_base}/v1/completions\",\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            result = {\n",
    "                'success': response.status_code == 200,\n",
    "                'duration': duration,\n",
    "                'status_code': response.status_code,\n",
    "                'prompt_length': len(prompt),\n",
    "                'response_length': 0\n",
    "            }\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if 'choices' in data and len(data['choices']) > 0:\n",
    "                    result['response_length'] = len(data['choices'][0].get('text', ''))\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'duration': time.time() - start_time,\n",
    "                'error': str(e),\n",
    "                'prompt_length': len(prompt),\n",
    "                'response_length': 0\n",
    "            }\n",
    "    \n",
    "    async def simulate_concurrent_load(self, num_requests: int = 10, delay_range: tuple = (1, 5)):\n",
    "        \"\"\"æ¨¡æ“¬ä¸¦ç™¼è² è¼‰\"\"\"\n",
    "        print(f\"ğŸ”„ é–‹å§‹æ¨¡æ“¬ {num_requests} å€‹ä¸¦ç™¼è«‹æ±‚...\")\n",
    "        \n",
    "        async def single_request(request_id: int):\n",
    "            prompt = np.random.choice(self.test_prompts)\n",
    "            max_tokens = np.random.randint(50, 150)\n",
    "            \n",
    "            # æ¨¡æ“¬è«‹æ±‚é–“éš”\n",
    "            await asyncio.sleep(np.random.uniform(*delay_range))\n",
    "            \n",
    "            # åŒæ­¥è«‹æ±‚ (åœ¨å¯¦éš›ç’°å¢ƒä¸­æ‡‰ä½¿ç”¨ aiohttp)\n",
    "            result = self.send_completion_request(prompt, max_tokens)\n",
    "            result['request_id'] = request_id\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        # å‰µå»ºä¸¦ç™¼ä»»å‹™\n",
    "        tasks = [single_request(i) for i in range(num_requests)]\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        # åˆ†æçµæœ\n",
    "        successful_requests = [r for r in results if isinstance(r, dict) and r.get('success', False)]\n",
    "        failed_requests = [r for r in results if not (isinstance(r, dict) and r.get('success', False))]\n",
    "        \n",
    "        print(f\"âœ… æ¨¡æ“¬å®Œæˆ: {len(successful_requests)} æˆåŠŸ, {len(failed_requests)} å¤±æ•—\")\n",
    "        \n",
    "        if successful_requests:\n",
    "            durations = [r['duration'] for r in successful_requests]\n",
    "            print(f\"   å¹³å‡å»¶é²: {np.mean(durations):.2f}s\")\n",
    "            print(f\"   P95 å»¶é²: {np.percentile(durations, 95):.2f}s\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def simulate_steady_load(self, duration_minutes: int = 5, requests_per_minute: int = 12):\n",
    "        \"\"\"æ¨¡æ“¬ç©©å®šè² è¼‰\"\"\"\n",
    "        print(f\"ğŸ”„ é–‹å§‹æ¨¡æ“¬ {duration_minutes} åˆ†é˜çš„ç©©å®šè² è¼‰ ({requests_per_minute} è«‹æ±‚/åˆ†é˜)...\")\n",
    "        \n",
    "        end_time = time.time() + duration_minutes * 60\n",
    "        request_interval = 60.0 / requests_per_minute\n",
    "        request_count = 0\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        while time.time() < end_time:\n",
    "            prompt = np.random.choice(self.test_prompts)\n",
    "            max_tokens = np.random.randint(50, 150)\n",
    "            \n",
    "            result = self.send_completion_request(prompt, max_tokens)\n",
    "            result['request_id'] = request_count\n",
    "            result['timestamp'] = datetime.now()\n",
    "            \n",
    "            results.append(result)\n",
    "            request_count += 1\n",
    "            \n",
    "            if request_count % 10 == 0:\n",
    "                successful = len([r for r in results[-10:] if r.get('success', False)])\n",
    "                print(f\"   å·²ç™¼é€ {request_count} è«‹æ±‚ (æœ€è¿‘ 10 å€‹: {successful}/10 æˆåŠŸ)\")\n",
    "            \n",
    "            # ç­‰å¾…ä¸‹ä¸€å€‹è«‹æ±‚\n",
    "            time.sleep(request_interval + np.random.uniform(-0.5, 0.5))\n",
    "        \n",
    "        print(f\"âœ… ç©©å®šè² è¼‰æ¨¡æ“¬å®Œæˆ: ç¸½å…± {request_count} è«‹æ±‚\")\n",
    "        return results\n",
    "\n",
    "# åˆå§‹åŒ–å·¥ä½œè² è¼‰æ¨¡æ“¬å™¨\n",
    "simulator = VLLMWorkloadSimulator()\n",
    "\n",
    "# æª¢æŸ¥ vLLM æœå‹™å¯ç”¨æ€§\n",
    "if simulator.check_vllm_availability():\n",
    "    print(\"âœ… vLLM æœå‹™å·²å¯ç”¨ï¼Œå¯ä»¥é–‹å§‹è² è¼‰æ¸¬è©¦\")\n",
    "    vllm_available = True\n",
    "else:\n",
    "    print(\"âš ï¸  vLLM æœå‹™ä¸å¯ç”¨ï¼Œå°‡è·³éè² è¼‰æ¸¬è©¦\")\n",
    "    print(\"   è«‹ç¢ºä¿ vLLM æœå‹™æ­£åœ¨é‹è¡Œ: bash start_vllm_with_metrics.sh\")\n",
    "    vllm_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœ vLLM å¯ç”¨ï¼Œé–‹å§‹è² è¼‰æ¸¬è©¦\n",
    "if vllm_available:\n",
    "    print(\"ğŸš€ é–‹å§‹æ¨¡æ“¬å·¥ä½œè² è¼‰...\")\n",
    "    \n",
    "    # æ¨¡æ“¬ 2 åˆ†é˜çš„ç©©å®šè² è¼‰\n",
    "    load_results = simulator.simulate_steady_load(duration_minutes=2, requests_per_minute=6)\n",
    "    \n",
    "    print(\"\\nğŸ“Š è² è¼‰æ¸¬è©¦çµæœåˆ†æ:\")\n",
    "    successful_results = [r for r in load_results if r.get('success', False)]\n",
    "    \n",
    "    if successful_results:\n",
    "        durations = [r['duration'] for r in successful_results]\n",
    "        print(f\"   æˆåŠŸè«‹æ±‚: {len(successful_results)}/{len(load_results)}\")\n",
    "        print(f\"   å¹³å‡å»¶é²: {np.mean(durations):.2f}s\")\n",
    "        print(f\"   ä¸­ä½æ•¸å»¶é²: {np.median(durations):.2f}s\")\n",
    "        print(f\"   P95 å»¶é²: {np.percentile(durations, 95):.2f}s\")\n",
    "        print(f\"   æœ€å¤§å»¶é²: {np.max(durations):.2f}s\")\n",
    "else:\n",
    "    print(\"â­ï¸  è·³éè² è¼‰æ¸¬è©¦ï¼Œç¹¼çºŒé€²è¡Œç›£æ§æ•¸æ“šåˆ†æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. å¯¦æ™‚ç›£æ§å„€è¡¨æ¿å±•ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆéœæ…‹å„€è¡¨æ¿\n",
    "print(\"ğŸ“Š ç”Ÿæˆå¯¦æ™‚ç›£æ§å„€è¡¨æ¿...\")\n",
    "dashboard.create_static_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¡¯ç¤ºè©³ç´°çš„çµ±è¨ˆæ‘˜è¦\n",
    "def display_detailed_stats():\n",
    "    stats = collector.get_summary_stats()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“ˆ è©³ç´°ç›£æ§çµ±è¨ˆæ‘˜è¦\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ç³»çµ±è³‡æºçµ±è¨ˆ\n",
    "    print(\"\\nğŸ–¥ï¸  ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³:\")\n",
    "    system_metrics = ['cpu_percent', 'memory_percent', 'gpu_memory_used', 'gpu_utilization']\n",
    "    \n",
    "    for metric in system_metrics:\n",
    "        if metric in stats:\n",
    "            data = stats[metric]\n",
    "            print(f\"   {metric:20}: ç•¶å‰ {data.get('current', 0):6.1f}% | \"\n",
    "                  f\"5åˆ†é˜å¹³å‡ {data.get('avg_5m', 0):6.1f}% | \"\n",
    "                  f\"æœ€å¤§ {data.get('max_5m', 0):6.1f}%\")\n",
    "    \n",
    "    # vLLM æŒ‡æ¨™çµ±è¨ˆ\n",
    "    print(\"\\nğŸ¤– vLLM æœå‹™æŒ‡æ¨™:\")\n",
    "    vllm_metrics = [k for k in stats.keys() if k.startswith('vllm_')]\n",
    "    \n",
    "    if vllm_metrics:\n",
    "        for metric in sorted(vllm_metrics)[:10]:  # é¡¯ç¤ºå‰ 10 å€‹æŒ‡æ¨™\n",
    "            data = stats[metric]\n",
    "            print(f\"   {metric:35}: {data.get('current', 0):8.2f} | \"\n",
    "                  f\"å¹³å‡ {data.get('avg_5m', 0):8.2f}\")\n",
    "    else:\n",
    "        print(\"   æš«ç„¡ vLLM æŒ‡æ¨™æ•¸æ“š (æœå‹™å¯èƒ½æœªé‹è¡Œ)\")\n",
    "    \n",
    "    # æ•¸æ“šæ”¶é›†çµ±è¨ˆ\n",
    "    print(\"\\nğŸ“Š æ•¸æ“šæ”¶é›†çµ±è¨ˆ:\")\n",
    "    print(f\"   æ”¶é›†æ™‚é–“é»: {len(collector.timestamps)}\")\n",
    "    print(f\"   æ”¶é›†é–“éš”: {collector.collection_interval} ç§’\")\n",
    "    print(f\"   é‹è¡Œç‹€æ…‹: {'æ´»èº' if collector.running else 'å·²åœæ­¢'}\")\n",
    "    \n",
    "    if len(collector.timestamps) >= 2:\n",
    "        duration = (collector.timestamps[-1] - collector.timestamps[0]).total_seconds()\n",
    "        print(f\"   ç›£æ§æ™‚é•·: {duration:.0f} ç§’ ({duration/60:.1f} åˆ†é˜)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "display_detailed_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. é€²éšæŒ‡æ¨™åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedMetricsAnalyzer:\n",
    "    \"\"\"é€²éšæŒ‡æ¨™åˆ†æå™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, collector: RealTimeMetricsCollector):\n",
    "        self.collector = collector\n",
    "    \n",
    "    def analyze_resource_correlation(self):\n",
    "        \"\"\"åˆ†æè³‡æºä½¿ç”¨ç›¸é—œæ€§\"\"\"\n",
    "        print(\"ğŸ” åˆ†æç³»çµ±è³‡æºä½¿ç”¨ç›¸é—œæ€§...\")\n",
    "        \n",
    "        # ç²å–ç³»çµ±æŒ‡æ¨™æ•¸æ“š\n",
    "        _, cpu_data = self.collector.get_latest_data('cpu_percent', 1000)\n",
    "        _, memory_data = self.collector.get_latest_data('memory_percent', 1000)\n",
    "        _, gpu_memory_data = self.collector.get_latest_data('gpu_memory_used', 1000)\n",
    "        _, gpu_util_data = self.collector.get_latest_data('gpu_utilization', 1000)\n",
    "        \n",
    "        if len(cpu_data) < 10:\n",
    "            print(\"   æ•¸æ“šé»ä¸è¶³ï¼Œç„¡æ³•é€²è¡Œç›¸é—œæ€§åˆ†æ\")\n",
    "            return\n",
    "        \n",
    "        # å‰µå»º DataFrame\n",
    "        min_len = min(len(cpu_data), len(memory_data), len(gpu_memory_data), len(gpu_util_data))\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'CPU': cpu_data[-min_len:],\n",
    "            'Memory': memory_data[-min_len:],\n",
    "            'GPU_Memory': gpu_memory_data[-min_len:],\n",
    "            'GPU_Util': gpu_util_data[-min_len:]\n",
    "        })\n",
    "        \n",
    "        # è¨ˆç®—ç›¸é—œæ€§çŸ©é™£\n",
    "        correlation_matrix = df.corr()\n",
    "        \n",
    "        # è¦–è¦ºåŒ–ç›¸é—œæ€§\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # ç›¸é—œæ€§ç†±åŠ›åœ–\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                   square=True, linewidths=0.5)\n",
    "        plt.title('ç³»çµ±è³‡æºä½¿ç”¨ç›¸é—œæ€§')\n",
    "        \n",
    "        # æ•£é»åœ–çŸ©é™£\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.scatter(df['CPU'], df['Memory'], alpha=0.6, color='blue')\n",
    "        plt.xlabel('CPU ä½¿ç”¨ç‡ (%)')\n",
    "        plt.ylabel('è¨˜æ†¶é«”ä½¿ç”¨ç‡ (%)')\n",
    "        plt.title('CPU vs Memory')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.scatter(df['GPU_Memory'], df['GPU_Util'], alpha=0.6, color='green')\n",
    "        plt.xlabel('GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡ (%)')\n",
    "        plt.ylabel('GPU ä½¿ç”¨ç‡ (%)')\n",
    "        plt.title('GPU Memory vs GPU Utilization')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # æ™‚é–“åºåˆ—è¶¨å‹¢\n",
    "        plt.subplot(2, 2, 4)\n",
    "        timestamps = list(range(len(df)))\n",
    "        plt.plot(timestamps, df['CPU'], label='CPU', alpha=0.7)\n",
    "        plt.plot(timestamps, df['Memory'], label='Memory', alpha=0.7)\n",
    "        plt.plot(timestamps, df['GPU_Memory'], label='GPU Mem', alpha=0.7)\n",
    "        plt.xlabel('æ™‚é–“é»')\n",
    "        plt.ylabel('ä½¿ç”¨ç‡ (%)')\n",
    "        plt.title('è³‡æºä½¿ç”¨è¶¨å‹¢')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return correlation_matrix\n",
    "    \n",
    "    def detect_anomalies(self, metric_name: str, threshold_std: float = 2.0):\n",
    "        \"\"\"æª¢æ¸¬æŒ‡æ¨™ç•°å¸¸å€¼\"\"\"\n",
    "        timestamps, values = self.collector.get_latest_data(metric_name, 1000)\n",
    "        \n",
    "        if len(values) < 20:\n",
    "            print(f\"   {metric_name}: æ•¸æ“šé»ä¸è¶³ï¼Œç„¡æ³•æª¢æ¸¬ç•°å¸¸\")\n",
    "            return []\n",
    "        \n",
    "        # ä½¿ç”¨æ»‘å‹•å¹³å‡å’Œæ¨™æº–å·®æª¢æ¸¬ç•°å¸¸\n",
    "        window_size = min(20, len(values) // 4)\n",
    "        \n",
    "        anomalies = []\n",
    "        \n",
    "        for i in range(window_size, len(values)):\n",
    "            window_data = values[i-window_size:i]\n",
    "            mean_val = np.mean(window_data)\n",
    "            std_val = np.std(window_data)\n",
    "            \n",
    "            current_val = values[i]\n",
    "            \n",
    "            if abs(current_val - mean_val) > threshold_std * std_val:\n",
    "                anomalies.append({\n",
    "                    'timestamp': timestamps[i],\n",
    "                    'value': current_val,\n",
    "                    'expected_range': (mean_val - threshold_std * std_val,\n",
    "                                     mean_val + threshold_std * std_val),\n",
    "                    'deviation': abs(current_val - mean_val) / std_val if std_val > 0 else 0\n",
    "                })\n",
    "        \n",
    "        return anomalies\n",
    "    \n",
    "    def generate_performance_report(self):\n",
    "        \"\"\"ç”Ÿæˆæ€§èƒ½å ±å‘Š\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“‹ vLLM æ€§èƒ½åˆ†æå ±å‘Š\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # ç³»çµ±è³‡æºåˆ†æ\n",
    "        print(\"\\nğŸ” ç•°å¸¸æª¢æ¸¬çµæœ:\")\n",
    "        \n",
    "        metrics_to_check = ['cpu_percent', 'memory_percent', 'gpu_memory_used', 'gpu_utilization']\n",
    "        \n",
    "        total_anomalies = 0\n",
    "        for metric in metrics_to_check:\n",
    "            anomalies = self.detect_anomalies(metric, threshold_std=2.0)\n",
    "            total_anomalies += len(anomalies)\n",
    "            \n",
    "            if anomalies:\n",
    "                print(f\"   {metric}: ç™¼ç¾ {len(anomalies)} å€‹ç•°å¸¸é»\")\n",
    "                # é¡¯ç¤ºæœ€åš´é‡çš„ç•°å¸¸\n",
    "                worst_anomaly = max(anomalies, key=lambda x: x['deviation'])\n",
    "                print(f\"     æœ€åš´é‡ç•°å¸¸: {worst_anomaly['value']:.1f} (åå·® {worst_anomaly['deviation']:.1f}Ïƒ)\")\n",
    "            else:\n",
    "                print(f\"   {metric}: ç„¡ç•°å¸¸æª¢æ¸¬\")\n",
    "        \n",
    "        if total_anomalies == 0:\n",
    "            print(\"   âœ… ç³»çµ±é‹è¡Œç©©å®šï¼Œæœªæª¢æ¸¬åˆ°é¡¯è‘—ç•°å¸¸\")\n",
    "        \n",
    "        # æ€§èƒ½æ‘˜è¦\n",
    "        stats = self.collector.get_summary_stats()\n",
    "        \n",
    "        print(\"\\nğŸ“Š æ€§èƒ½æ‘˜è¦:\")\n",
    "        \n",
    "        # è³‡æºä½¿ç”¨æ•ˆç‡è©•ä¼°\n",
    "        cpu_avg = stats.get('cpu_percent', {}).get('avg_5m', 0)\n",
    "        memory_avg = stats.get('memory_percent', {}).get('avg_5m', 0)\n",
    "        gpu_memory_avg = stats.get('gpu_memory_used', {}).get('avg_5m', 0)\n",
    "        \n",
    "        print(f\"   å¹³å‡ CPU ä½¿ç”¨ç‡: {cpu_avg:.1f}%\")\n",
    "        print(f\"   å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨ç‡: {memory_avg:.1f}%\")\n",
    "        print(f\"   å¹³å‡ GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡: {gpu_memory_avg:.1f}%\")\n",
    "        \n",
    "        # æ•ˆç‡è©•ä¼°\n",
    "        if cpu_avg < 20:\n",
    "            print(\"   ğŸ’¡ CPU ä½¿ç”¨ç‡è¼ƒä½ï¼Œå¯è€ƒæ…®å¢åŠ è² è¼‰\")\n",
    "        elif cpu_avg > 80:\n",
    "            print(\"   âš ï¸  CPU ä½¿ç”¨ç‡éé«˜ï¼Œå»ºè­°å„ªåŒ–æˆ–æ“´å®¹\")\n",
    "        \n",
    "        if gpu_memory_avg < 30 and NVIDIA_GPU_AVAILABLE:\n",
    "            print(\"   ğŸ’¡ GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡è¼ƒä½ï¼Œå¯è€ƒæ…®å¢åŠ æ‰¹æ¬¡å¤§å°\")\n",
    "        elif gpu_memory_avg > 90:\n",
    "            print(\"   âš ï¸  GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜ï¼Œå»ºè­°æ¸›å°‘æ‰¹æ¬¡å¤§å°\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# å‰µå»ºé€²éšåˆ†æå™¨\n",
    "analyzer = AdvancedMetricsAnalyzer(collector)\n",
    "\n",
    "# åŸ·è¡Œåˆ†æ\n",
    "print(\"ğŸ”¬ åŸ·è¡Œé€²éšæŒ‡æ¨™åˆ†æ...\")\n",
    "correlation_matrix = analyzer.analyze_resource_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæ€§èƒ½å ±å‘Š\n",
    "analyzer.generate_performance_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç›£æ§æ•¸æ“šå°å‡ºèˆ‡å„²å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_monitoring_data():\n",
    "    \"\"\"å°å‡ºç›£æ§æ•¸æ“š\"\"\"\n",
    "    print(\"ğŸ’¾ å°å‡ºç›£æ§æ•¸æ“š...\")\n",
    "    \n",
    "    # æº–å‚™å°å‡ºæ•¸æ“š\n",
    "    export_data = {\n",
    "        'metadata': {\n",
    "            'export_time': datetime.now().isoformat(),\n",
    "            'collection_interval': collector.collection_interval,\n",
    "            'total_data_points': len(collector.timestamps),\n",
    "            'monitoring_duration_seconds': (collector.timestamps[-1] - collector.timestamps[0]).total_seconds() if len(collector.timestamps) >= 2 else 0\n",
    "        },\n",
    "        'timestamps': [ts.isoformat() for ts in collector.timestamps],\n",
    "        'system_metrics': {},\n",
    "        'vllm_metrics': {},\n",
    "        'aggregated_stats': dict(collector.aggregated_stats)\n",
    "    }\n",
    "    \n",
    "    # å°å‡ºç³»çµ±æŒ‡æ¨™\n",
    "    for metric_name, values in collector.system_metrics.items():\n",
    "        export_data['system_metrics'][metric_name] = list(values)\n",
    "    \n",
    "    # å°å‡º vLLM æŒ‡æ¨™\n",
    "    for metric_name, values in collector.time_series_data.items():\n",
    "        export_data['vllm_metrics'][metric_name] = list(values)\n",
    "    \n",
    "    # å„²å­˜ç‚º JSON æª”æ¡ˆ\n",
    "    filename = f\"vllm_monitoring_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… ç›£æ§æ•¸æ“šå·²å°å‡ºåˆ°: {filename}\")\n",
    "    \n",
    "    # åŒæ™‚å°å‡ºç‚º CSV æ ¼å¼ (ä¾¿æ–¼åˆ†æ)\n",
    "    if len(collector.timestamps) > 0:\n",
    "        # å‰µå»º DataFrame\n",
    "        df_data = {'timestamp': [ts.isoformat() for ts in collector.timestamps]}\n",
    "        \n",
    "        # æ·»åŠ ç³»çµ±æŒ‡æ¨™\n",
    "        for metric_name, values in collector.system_metrics.items():\n",
    "            # ç¢ºä¿é•·åº¦ä¸€è‡´\n",
    "            padded_values = list(values) + [None] * (len(collector.timestamps) - len(values))\n",
    "            df_data[metric_name] = padded_values[:len(collector.timestamps)]\n",
    "        \n",
    "        # æ·»åŠ éƒ¨åˆ† vLLM æŒ‡æ¨™\n",
    "        for metric_name, values in list(collector.time_series_data.items())[:10]:  # é™åˆ¶æ•¸é‡\n",
    "            padded_values = list(values) + [None] * (len(collector.timestamps) - len(values))\n",
    "            df_data[metric_name] = padded_values[:len(collector.timestamps)]\n",
    "        \n",
    "        df = pd.DataFrame(df_data)\n",
    "        csv_filename = filename.replace('.json', '.csv')\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"âœ… CSV æ ¼å¼æ•¸æ“šå·²å°å‡ºåˆ°: {csv_filename}\")\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# å°å‡ºæ•¸æ“š\n",
    "export_filename = export_monitoring_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. æ¸…ç†èˆ‡åœæ­¢ç›£æ§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœæ­¢ç›£æ§æ”¶é›†\n",
    "print(\"ğŸ›‘ åœæ­¢å¯¦æ™‚ç›£æ§æ”¶é›†...\")\n",
    "collector.stop_collection()\n",
    "\n",
    "# æœ€çµ‚çµ±è¨ˆ\n",
    "final_stats = collector.get_summary_stats()\n",
    "print(f\"\\nğŸ“Š æœ€çµ‚ç›£æ§çµ±è¨ˆ:\")\n",
    "print(f\"   ç¸½ç›£æ§æ™‚é–“: {len(collector.timestamps)} å€‹æ•¸æ“šé»\")\n",
    "print(f\"   ç³»çµ±æŒ‡æ¨™é¡å‹: {len(collector.system_metrics)}\")\n",
    "print(f\"   vLLM æŒ‡æ¨™é¡å‹: {len(collector.time_series_data)}\")\n",
    "\n",
    "if len(collector.timestamps) >= 2:\n",
    "    duration = (collector.timestamps[-1] - collector.timestamps[0]).total_seconds()\n",
    "    print(f\"   ç›£æ§æŒçºŒæ™‚é–“: {duration:.0f} ç§’ ({duration/60:.1f} åˆ†é˜)\")\n",
    "\n",
    "print(\"\\nâœ… å¯¦æ™‚ç›£æ§å¯¦é©—å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¯¦é©—ç¸½çµ\n",
    "\n",
    "æœ¬å¯¦é©—æˆåŠŸå»ºç«‹äº†å®Œæ•´çš„ vLLM å¯¦æ™‚ç›£æ§ç³»çµ±ï¼Œæ¶µè“‹ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š\n",
    "\n",
    "### âœ… å®Œæˆé …ç›®\n",
    "\n",
    "1. **å¯¦æ™‚æŒ‡æ¨™æ”¶é›†**\n",
    "   - vLLM åŸç”Ÿ Prometheus æŒ‡æ¨™è§£æ\n",
    "   - ç³»çµ±è³‡æºç›£æ§ (CPU, è¨˜æ†¶é«”, GPU)\n",
    "   - é«˜é »ç‡æ•¸æ“šæ”¶é›† (2ç§’é–“éš”)\n",
    "\n",
    "2. **å‹•æ…‹ç›£æ§è¦–è¦ºåŒ–**\n",
    "   - å¤šé¢æ¿å¯¦æ™‚å„€è¡¨æ¿\n",
    "   - ç³»çµ±è³‡æºä½¿ç”¨è¶¨å‹¢åœ–\n",
    "   - vLLM æœå‹™ç‹€æ…‹ç›£æ§\n",
    "\n",
    "3. **é€²éšåˆ†æåŠŸèƒ½**\n",
    "   - è³‡æºä½¿ç”¨ç›¸é—œæ€§åˆ†æ\n",
    "   - ç•°å¸¸æª¢æ¸¬ç®—æ³•\n",
    "   - æ€§èƒ½è©•ä¼°å ±å‘Š\n",
    "\n",
    "4. **å·¥ä½œè² è¼‰æ¨¡æ“¬**\n",
    "   - ä¸¦ç™¼è«‹æ±‚æ¨¡æ“¬\n",
    "   - ç©©å®šè² è¼‰æ¸¬è©¦\n",
    "   - å»¶é²æ€§èƒ½åˆ†æ\n",
    "\n",
    "5. **æ•¸æ“šç®¡ç†**\n",
    "   - æ™‚é–“åºåˆ—æ•¸æ“šå„²å­˜\n",
    "   - JSON/CSV æ ¼å¼å°å‡º\n",
    "   - èšåˆçµ±è¨ˆè¨ˆç®—\n",
    "\n",
    "### ğŸ¯ æ ¸å¿ƒæˆæœ\n",
    "\n",
    "- **å¯¦æ™‚ç›£æ§æ¶æ§‹**: å»ºç«‹äº†å¯æ“´å±•çš„ç›£æ§æ•¸æ“šæ”¶é›†æ¶æ§‹\n",
    "- **æŒ‡æ¨™è§£æå¼•æ“**: é–‹ç™¼äº† Prometheus æ ¼å¼æŒ‡æ¨™çš„è§£æå™¨\n",
    "- **ç•°å¸¸æª¢æ¸¬**: å¯¦ç¾äº†åŸºæ–¼çµ±è¨ˆçš„ç•°å¸¸æª¢æ¸¬æ©Ÿåˆ¶\n",
    "- **æ€§èƒ½åˆ†æ**: æä¾›äº†å…¨é¢çš„æ€§èƒ½è©•ä¼°å’Œå„ªåŒ–å»ºè­°\n",
    "\n",
    "### ğŸ“ˆ ç›£æ§æŒ‡æ¨™è¦†è“‹\n",
    "\n",
    "- **ç³»çµ±å±¤**: CPU, è¨˜æ†¶é«”, GPU ä½¿ç”¨ç‡\n",
    "- **æ‡‰ç”¨å±¤**: vLLM è«‹æ±‚ç‹€æ…‹, å»¶é²æŒ‡æ¨™\n",
    "- **æ¥­å‹™å±¤**: ååé‡, éŒ¯èª¤ç‡, ä½µç™¼æ•¸\n",
    "\n",
    "### ğŸ”§ æŠ€è¡“ç‰¹é»\n",
    "\n",
    "- **éé˜»å¡æ”¶é›†**: ä½¿ç”¨å¤šåŸ·è¡Œç·’å¯¦ç¾èƒŒæ™¯æ•¸æ“šæ”¶é›†\n",
    "- **è¨˜æ†¶é«”æ•ˆç‡**: æ»‘å‹•è¦–çª—é™åˆ¶æ•¸æ“šé»æ•¸é‡\n",
    "- **å®¹éŒ¯è¨­è¨ˆ**: ç¶²è·¯ç•°å¸¸å’Œæœå‹™ä¸å¯ç”¨çš„è™•ç†\n",
    "- **æ¨™æº–åŒ–è¼¸å‡º**: æ”¯æ´å¤šç¨®æ•¸æ“šæ ¼å¼å°å‡º\n",
    "\n",
    "### ğŸ“‹ ä¸‹ä¸€æ­¥\n",
    "\n",
    "ç¹¼çºŒé€²è¡Œ **03-Performance_Analysis.ipynb**ï¼Œå­¸ç¿’æ·±åº¦æ€§èƒ½åˆ†æå’Œç“¶é ¸è¨ºæ–·æŠ€è¡“ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "**æ³¨æ„äº‹é …**:\n",
    "- ç”Ÿç”¢ç’°å¢ƒå»ºè­°èª¿æ•´æ”¶é›†é »ç‡ä»¥ç¯€çœè³‡æº\n",
    "- é•·æœŸç›£æ§éœ€è¦é…ç½®æ•¸æ“šä¿ç•™ç­–ç•¥\n",
    "- ç•°å¸¸æª¢æ¸¬é–¾å€¼éœ€è¦æ ¹æ“šå¯¦éš›æ¥­å‹™èª¿æ•´\n",
    "- å»ºè­°çµåˆ Grafana å¯¦ç¾æ›´è±å¯Œçš„è¦–è¦ºåŒ–æ•ˆæœ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}