# 大模型（LLM）工程化高階速成課綱

## 課程介紹

本課程旨在為具備一定技術背景的學員（如軟體工程師、AI 研究員）提供一個基於麥肯錫金字塔原理的結構化學習路徑。學員將透過四大核心模組，系統性地掌握從 **模型訓練、高效推理、全面優化** 到 **評估驗證** 的完整生命週期，最終具備獨立完成 LLM 從原型到部署的工程化能力。

### 課程總目標 (Top-Level Idea)

建立一套完整且互斥（MECE）的 LLM 工程化知識框架，使學員能迅速、高效地掌握 LLM 工程化的核心知識體系。

### 目標學員
- 希望轉向 LLM 領域的軟體工程師與後端開發者。
- 專注於模型研究，期望補強工程化實踐能力的 AI 研究員。
- 負責 AI 產品開發的技術經理與架構師。

### 先備知識
- 熟悉 Python 程式設計。
- 具備深度學習與神經網路基礎知識。
- 了解 Linux 環境與 Shell 操作。

---

## 課程結構

**學習路徑說明：**
本課程的結構設計遵循「先理論，後實踐」的原則。
- **第零章** 旨在建立一個全面的 LLM 工程化知識地圖，宏觀介紹各核心模組的「是什麼」(What) 與「為什麼」(Why)。
- **後續章節（第一至四章）** 則深入每個垂直領域，詳細講解「如何做」(How)，聚焦於具體的工程技術、框架與最佳實踐。
這種由淺入深的設計確保了學習路徑的平滑與知識體系的完整性，使理論與實踐緊密結合。

#### 內容對應

| **第零章：理論基礎 (From `00-LLM_Fundamentals`)** | **後續章節：深入實踐** | **關係說明** |
| :--- | :--- | :--- |
| **0.1 LLM 生命週期全景** | **第一章：核心訓練技術** | 第零章建立生命週期的宏觀認知（做什麼），第一章深入訓練與微調的工程實踐（如何做）。 |
| **0.5 模型參數量與計算複雜度估算** | **第二章：高效推理部署** | 第零章分析性能瓶頸（FLOPs、記憶體），第二章提供具體的推理優化方案（如 KV Cache）。 |
| **0.4 量化技術全景圖** | **第三章：模型壓縮技術** | 第零章提供量化技術的理論地圖，第三章深入 GPTQ、AWQ 等具體壓縮算法的實現。 |
| **0.2 核心評估指標體系** & **0.3 數據集類型與特性分析** | **第四章：評估與數據工程** | 第零章建立評估維度與數據分類的認知，第四章介紹 C-Eval、數據篩選等具體工具與技術。 |

### 第零章：LLM 基礎知識體系 (LLM Fundamentals)
**模組目標：** 建立完整的LLM工程化先備知識，為後續深度學習提供堅實基礎。本章涵蓋LLM生命週期、評估體系、數據工程、量化技術和資源估算等核心概念。

#### 0.1 LLM 生命週期全景
- **0.1.1 Pre-training（預訓練）階段**
  - **自監督學習範式：** 下一個token預測、大規模並行訓練
  - **技術組件：** 數據處理管線、模型架構設計、訓練基礎設施
  - **代表案例：** GPT系列、LLaMA系列演進路徑
- **0.1.2 Fine-tuning（微調）階段**
  - **技術分類：** 全參數微調、參數高效微調、混合微調策略
  - **核心挑戰：** 災難性遺忘、過擬合控制、領域適應
- **0.1.3 Post-training（後訓練）階段**
  - **指令跟隨訓練：** Self-Instruct、多任務指令泛化
  - **對話能力訓練：** 多輪對話建模、人格一致性
- **0.1.4 RLHF（人類反饋強化學習）階段**
  - **三階段管線：** SFT、獎勵模型訓練、策略優化
  - **替代技術：** DPO、ORPO、Constitutional AI

#### 0.2 LLM 核心評估指標體系
- **0.2.1 訓練過程評估指標**
  - **Loss函數體系：** Cross-entropy、Perplexity、對比學習損失
  - **訓練動態指標：** 學習曲線分析、梯度統計、優化效率
- **0.2.2 能力評估指標體系**
  - **語言理解：** GLUE、SuperGLUE、CLUE、C-Eval
  - **推理能力：** HellaSwag、CommonsenseQA、數學推理
  - **專業領域：** 代碼生成(HumanEval)、知識密集型任務(MMLU)
- **0.2.3 性能評估指標**
  - **推理效率：** TPS、QPS、TTFT、ITL
  - **資源效率：** 記憶體使用、GPU利用率、能耗分析
- **0.2.4 安全性與倫理評估**
  - **安全性指標：** 有害內容檢測、對抗攻擊抵抗力
  - **評估方法：** RealToxicityPrompts、BOLD、WinoBias

#### 0.3 數據集類型與特性分析
- **0.3.1 預訓練數據集體系**
  - **大規模通用語料：** Common Crawl、OpenWebText、RefinedWeb
  - **代碼語料庫：** The Stack、CodeParrot、StarCoder數據集
  - **數據質量評估：** 語言質量、內容質量、安全性檢查
- **0.3.2 微調階段數據集**
  - **指令微調數據：** Super-NaturalInstructions、Alpaca、Self-Instruct
  - **對話系統數據：** Persona-Chat、MultiWOZ、EmpatheticDialogues
- **0.3.3 對齊與安全數據集**
  - **人類偏好數據：** Anthropic HH-RLHF、OpenAI WebGPT、SHP
  - **安全評估數據：** RealToxicityPrompts、CrowS-Pairs
- **0.3.4 數據倫理與合規**
  - **版權與知識產權：** 開源許可證、公平使用原則
  - **隱私保護：** 個人信息識別、去標識化處理
  - **內容安全：** 有害內容識別、偏見防範

#### 0.4 量化技術全景圖
- **0.4.1 數值表示基礎**
  - **浮點標準：** FP32、FP16、BF16、FP8、NF4
  - **量化原理：** 線性量化、非線性量化、量化誤差分析
- **0.4.2 訓練後量化（PTQ）**
  - **基礎方法：** Min-Max、百分位數、熵校準量化
  - **高級技術：** GPTQ、AWQ、SmoothQuant、SpQR
- **0.4.3 量化感知訓練（QAT）**
  - **核心概念：** 偽量化機制、直通估計器、量化參數學習
  - **高級技術：** 混合精度QAT、知識蒸餾結合、對抗量化訓練
- **0.4.4 極低精度量化**
  - **4位量化：** INT4、FP4、NF4技術突破
  - **二值量化：** BNN、三值量化、極限壓縮技術

#### 0.5 模型參數量與計算複雜度估算
- **0.5.1 Transformer架構參數計算**
  - **精確計算公式：** Embedding、Attention、FFN各組件參數量
  - **架構變體差異：** MHA、MQA、GQA、MoE的參數影響
- **0.5.2 計算複雜度分析**
  - **訓練FLOPs：** 前向傳播、反向傳播、優化器更新
  - **推理FLOPs：** 預填充階段、解碼階段、KV Cache影響
- **0.5.3 記憶體需求估算**
  - **訓練記憶體：** 模型參數、優化器狀態、梯度、激活值
  - **推理記憶體：** 參數記憶體、KV Cache、激活值
  - **優化策略：** ZeRO、梯度檢查點、模型並行
- **0.5.4 縮放法則與性能預測**
  - **經典縮放法則：** Kaplan、Chinchilla、PaLM縮放法則
  - **最優資源分配：** 參數量與數據量的平衡
  - **成本估算：** 訓練成本、推理成本、部署資源規劃

---

### 第一章：LLM 核心訓練技術 (Model Training)
**模組目標：** 掌握 LLM 的生命週期起點——如何從無到有地訓練及微調一個強大的基礎模型。本章聚焦於核心演算法、分散式架構與前沿優化技術。

#### 1.1 參數高效微調 (Parameter-Efficient Fine-Tuning, PEFT)
- **1.1.1 理論基礎：**
  - **核心思想：** BitFit, Prefix Tuning, Prompt Tuning, P-Tuning v1/v2
  - **主流框架：** Adapter Tuning, LoRA, AdaLoRA, QLoRA
  - **高階變體：** MAM Adapter, UniPELT
- **1.1.2 PEFT 框架實戰 (HuggingFace PEFT)：**
  - Prompt Tuning / P-Tuning / Prefix Tuning
  - LoRA / IA3
  - INT8/FP4/NF4 低精度微調
  - 多模態模型微調

#### 1.2 分散式訓練 (Distributed Training)
- **1.2.1 並行技術原理：**
  - **數據與模型並行：** 數據並行、流水線並行、張量並行
  - **進階並行策略：** 序列並行、多維混合並行、自動並行
  - **專家混合模型：** MOE 並行
- **1.2.2 主流分散式框架：**
  - **PyTorch DDP**
  - **Megatron-LM**
  - **DeepSpeed**
  - **Megatron-DeepSpeed**

#### 1.3 訓練優化與對齊 (Training Optimization & Alignment)
- **1.3.1 訓練優化技術：**
  - **注意力機制優化：** FlashAttention V1/V2
  - **記憶體與計算優化：** 混合精度訓練、重計算、梯度累積
  - **架構優化：** MQA/GQA
- **1.3.2 對齊技術：**
  - **強化學習對齊：** PPO
  - **無獎勵函數對齊：** DPO, ORPO

#### 1.4 經典模型訓練案例分析
- **從 0 到 1 完整復現：** 斯坦福 Alpaca, BELLE, Chinese-LLaMA-Alpaca
- **高效微調與推理：** Alpaca-LoRA, ChatGLM, Vicuna, LLaMA
- **前沿模型探索：** OPT (RLHF), MiniGPT-4 (多模態)

---

### 第二章：LLM 高效推理部署 (Efficient Inference & Serving)
**模組目標：** 學習如何將訓練好的模型部署為高效、穩定且可擴展的線上服務。本章重點在於推理引擎、服務框架與性能優化。

#### 2.1 推理引擎核心
- **2.1.1 框架與引擎概覽**
- **2.1.2 NVIDIA 生態系統：** FasterTransformer, TensorRT-LLM
- **2.1.3 熱門開源引擎：** vLLM, SGLang, LightLLM, MNN-LLM

#### 2.2 模型推理服務
- **2.2.1 服務工具概覽**
- **2.2.2 Triton 推理伺服器：** 架構解析與開發實踐

#### 2.3 推理性能優化
- **2.3.1 核心優化技術概覽**
- **2.3.2 記憶體優化：** KV Cache, PagedAttention, Offload
- **2.3.3 解碼與吞吐量優化：** Continuous Batching, Speculative Decoding
- **2.3.4 特殊場景優化：** 結構化文本生成

---

### 第三章：LLM 模型壓縮技術 (Model Compression)
**模組目標：** 掌握縮小模型體積、降低部署成本的核心技術。本章涵蓋量化、稀疏化、蒸餾等關鍵方法。

#### 3.1 模型量化 (Quantization)
- **3.1.1 量化技術概覽**
- **3.1.2 訓練後量化 (PTQ)：** GPTQ, SmoothQuant, AWQ, SpQR
- **3.1.3 量化感知訓練 (QAT)：** QLoRA, PEQA
- **3.1.4 前沿量化技術：** FP8, FP6, FP4

#### 3.2 模型稀疏化/剪枝 (Sparsification/Pruning)
- **3.2.1 稀疏化技術概覽**
- **3.2.2 結構化剪枝：** LLM-Pruner, SliceGPT
- **3.2.3 非結構化剪枝：** SparseGPT, Wanda

#### 3.3 知識蒸餾 (Knowledge Distillation)
- **3.3.1 蒸餾技術概覽**
- **3.3.2 標準蒸餾：** MINILLM, GKD
- **3.3.3 基於湧現能力的蒸餾 (EA-based KD)**

#### 3.4 低秩分解 (Low-Rank Decomposition)
- **3.4.1 核心思想與應用**
- **3.4.2 混合壓縮技術：** 低秩+量化, 低秩+剪枝

---

### 第四章：LLM 評估與數據工程 (Evaluation & Data Engineering)
**模組目標：** 建立模型與數據的品質保證體系。本章涵蓋如何客觀評估模型效果，以及如何高效處理與篩選數據。

#### 4.1 模型效果評估
- **4.1.1 主流評估基準：** C-Eval, CMMLU, SuperCLUE, OpenCompass

#### 4.2 模型性能評估
- **4.2.1 推理性能指標：** GenAI-Perf (吞吐量, 延遲), TTFT, ITL

#### 4.3 LLM 數據工程
- **4.3.1 預訓練語料處理**
- **4.3.2 高效微調數據篩選技術：** DEITA, MoDS, IFD, CaR, LESS

---

## 課程總結與展望
- **回顧 LLM 工程化全景圖：** 整合四大模組，形成從數據到產品的閉環思維。
- **未來趨勢：** 探討多模態、端側 LLM、AI Agent 等前沿方向的工程挑戰。
- **期末專案：** 設計一個動手實踐專案，要求學員選擇一個場景，完整實踐模型微調、壓縮、部署與評估的全過程。
