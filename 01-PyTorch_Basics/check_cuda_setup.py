#!/usr/bin/env python3
"""
CUDA è¨­å®šæª¢æŸ¥è…³æœ¬
Check CUDA setup and PyTorch installation compatibility
"""

import sys
import subprocess
import platform

def check_system_info():
    """æª¢æŸ¥ç³»çµ±è³‡è¨Š"""
    print("=== ç³»çµ±è³‡è¨Š ===")
    print(f"ä½œæ¥­ç³»çµ±: {platform.system()} {platform.release()}")
    print(f"Python ç‰ˆæœ¬: {sys.version}")
    print()

def check_cuda_driver():
    """æª¢æŸ¥ CUDA Driver"""
    print("=== CUDA Driver æª¢æŸ¥ ===")
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA Driver æ­£å¸¸é‹ä½œ")
            # æå– CUDA ç‰ˆæœ¬
            lines = result.stdout.split('\n')
            for line in lines:
                if 'CUDA Version:' in line:
                    cuda_version = line.split('CUDA Version:')[1].strip().split()[0]
                    print(f"Driver æ”¯æ´çš„ CUDA ç‰ˆæœ¬: {cuda_version}")
            print()
        else:
            print("âŒ NVIDIA Driver æœªæ­£ç¢ºå®‰è£æˆ–é‹ä½œ")
            return False
    except FileNotFoundError:
        print("âŒ nvidia-smi å‘½ä»¤æœªæ‰¾åˆ°ï¼Œè«‹æª¢æŸ¥ NVIDIA Driver å®‰è£")
        return False

    return True

def check_cuda_toolkit():
    """æª¢æŸ¥ CUDA Toolkit"""
    print("=== CUDA Toolkit æª¢æŸ¥ ===")
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… CUDA Toolkit å·²å®‰è£")
            # æå– CUDA ç‰ˆæœ¬
            lines = result.stdout.split('\n')
            for line in lines:
                if 'release' in line:
                    version = line.split('release')[1].split(',')[0].strip()
                    print(f"CUDA Toolkit ç‰ˆæœ¬: {version}")
            print()
            return True
        else:
            print("âŒ CUDA Toolkit æœªæ­£ç¢ºå®‰è£")
            return False
    except FileNotFoundError:
        print("âŒ nvcc å‘½ä»¤æœªæ‰¾åˆ°ï¼Œè«‹æª¢æŸ¥ CUDA Toolkit å®‰è£")
        return False

def check_pytorch():
    """æª¢æŸ¥ PyTorch å®‰è£"""
    print("=== PyTorch æª¢æŸ¥ ===")
    try:
        import torch
        print(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")

        # æª¢æŸ¥ CUDA å¯ç”¨æ€§
        if torch.cuda.is_available():
            print(f"âœ… CUDA åœ¨ PyTorch ä¸­å¯ç”¨")
            print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
            print(f"CuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}")
            print(f"GPU æ•¸é‡: {torch.cuda.device_count()}")

            # åˆ—å‡ºæ‰€æœ‰ GPU
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
        else:
            print("âŒ CUDA åœ¨ PyTorch ä¸­ä¸å¯ç”¨")
            return False

        print()
        return True

    except ImportError:
        print("âŒ PyTorch æœªå®‰è£")
        return False

def check_other_libraries():
    """æª¢æŸ¥å…¶ä»–é‡è¦å¥—ä»¶"""
    print("=== å…¶ä»–å¥—ä»¶æª¢æŸ¥ ===")

    libraries = [
        'transformers',
        'datasets',
        'accelerate',
        'peft',
        'bitsandbytes',
        'flash_attn'
    ]

    results = {}

    for lib in libraries:
        try:
            if lib == 'flash_attn':
                import flash_attn
                version = flash_attn.__version__
            else:
                module = __import__(lib)
                version = getattr(module, '__version__', 'Unknown')

            print(f"âœ… {lib}: {version}")
            results[lib] = True
        except ImportError:
            print(f"âŒ {lib}: æœªå®‰è£")
            results[lib] = False

    print()
    return results

def test_cuda_operations():
    """æ¸¬è©¦ CUDA æ“ä½œ"""
    print("=== CUDA æ“ä½œæ¸¬è©¦ ===")

    try:
        import torch

        if not torch.cuda.is_available():
            print("âŒ CUDA ä¸å¯ç”¨ï¼Œè·³éæ¸¬è©¦")
            return False

        # åŸºæœ¬å¼µé‡æ“ä½œ
        device = torch.device('cuda')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")

        # å‰µå»ºå¼µé‡ä¸¦ç§»åˆ° GPU
        x = torch.randn(1000, 1000).to(device)
        y = torch.randn(1000, 1000).to(device)

        # çŸ©é™£ä¹˜æ³•
        import time
        start_time = time.time()
        z = torch.mm(x, y)
        torch.cuda.synchronize()  # ç­‰å¾… GPU å®Œæˆ
        end_time = time.time()

        print(f"âœ… GPU çŸ©é™£ä¹˜æ³•æˆåŠŸ")
        print(f"è¨ˆç®—æ™‚é–“: {end_time - start_time:.4f} ç§’")

        # è¨˜æ†¶é«”è³‡è¨Š
        memory_allocated = torch.cuda.memory_allocated() / 1024**2
        memory_reserved = torch.cuda.memory_reserved() / 1024**2
        print(f"GPU è¨˜æ†¶é«”ä½¿ç”¨: {memory_allocated:.1f} MB å·²åˆ†é…, {memory_reserved:.1f} MB å·²ä¿ç•™")

        print()
        return True

    except Exception as e:
        print(f"âŒ CUDA æ“ä½œæ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»å‡½å¼"""
    print("CUDA ç’°å¢ƒæª¢æŸ¥å·¥å…·")
    print("=" * 50)

    # æª¢æŸ¥å„é …ç›®
    system_ok = True
    cuda_driver_ok = check_cuda_driver()
    cuda_toolkit_ok = check_cuda_toolkit()
    pytorch_ok = check_pytorch()
    libraries = check_other_libraries()
    cuda_ops_ok = test_cuda_operations()

    # ç¸½çµ
    print("=== æª¢æŸ¥ç¸½çµ ===")

    if cuda_driver_ok and cuda_toolkit_ok and pytorch_ok and cuda_ops_ok:
        print("ğŸ‰ æ‰€æœ‰æª¢æŸ¥é€šéï¼CUDA ç’°å¢ƒè¨­å®šæ­£ç¢º")

        # æä¾›å»ºè­°
        print("\n=== å»ºè­° ===")
        if not libraries.get('flash_attn', False):
            print("ğŸ’¡ å»ºè­°å®‰è£ Flash Attention ä»¥æå‡è¨“ç·´æ•ˆç‡ï¼š")
            print("   pip install flash-attn --no-build-isolation")

        if not libraries.get('bitsandbytes', False):
            print("ğŸ’¡ å»ºè­°å®‰è£ BitsAndBytes ä»¥æ”¯æ´é‡åŒ–ï¼š")
            print("   pip install bitsandbytes")

    else:
        print("âŒ éƒ¨åˆ†æª¢æŸ¥æœªé€šéï¼Œè«‹æª¢æŸ¥ä¸Šè¿°å•é¡Œ")

        if not cuda_driver_ok:
            print("ğŸ”§ è«‹å®‰è£æˆ–æ›´æ–° NVIDIA GPU Driver")

        if not cuda_toolkit_ok:
            print("ğŸ”§ è«‹å®‰è£ CUDA Toolkit 11.5")

        if not pytorch_ok:
            print("ğŸ”§ è«‹å®‰è£æ”¯æ´ CUDA 11.5 çš„ PyTorchï¼š")
            print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu115")

if __name__ == "__main__":
    check_system_info()
    main()