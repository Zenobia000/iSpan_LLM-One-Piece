{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-2.2.2: A/B æ¸¬è©¦èˆ‡æ™ºèƒ½ç‰ˆæœ¬æ§åˆ¶\n",
    "\n",
    "## ğŸ¯ å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "- å¯¦ç¾ä¼æ¥­ç´šæ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ç­–ç•¥\n",
    "- æŒæ¡ A/B æ¸¬è©¦æµé‡åˆ†é…æ©Ÿåˆ¶\n",
    "- å»ºç«‹çµ±è¨ˆé¡¯è‘—æ€§æ¸¬è©¦æ¡†æ¶\n",
    "- å¯¦ç¾æ¼¸é€²å¼éƒ¨ç½² (Canary/Blue-Green)\n",
    "\n",
    "## ğŸ¢ ä¼æ¥­æ¡ˆä¾‹: PayPal é¢¨æ§æ¨¡å‹ A/B æ¸¬è©¦\n",
    "\n",
    "PayPal åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­åŒæ™‚é‹è¡Œå¤šå€‹é¢¨æ§æ¨¡å‹ç‰ˆæœ¬ï¼š\n",
    "- **ä¿å®ˆæ¨¡å‹ v2.1**: é«˜ç²¾ç¢ºåº¦ï¼Œä½å¬å›ç‡ (70% æµé‡)\n",
    "- **æ¿€é€²æ¨¡å‹ v2.2**: é«˜å¬å›ç‡ï¼Œå¯èƒ½èª¤æ®º (20% æµé‡)\n",
    "- **å¯¦é©—æ¨¡å‹ v3.0**: æ–°ç®—æ³•é©—è­‰ (10% æµé‡)\n",
    "\n",
    "é€šéæŒçºŒ A/B æ¸¬è©¦ï¼Œå„ªåŒ–æ¨¡å‹æ€§èƒ½ä¸¦ç¢ºä¿é¢¨éšªæ§åˆ¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import logging\n",
    "\n",
    "# è¨­å®šæ—¥èªŒ\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"ğŸš€ A/B æ¸¬è©¦èˆ‡æ™ºèƒ½ç‰ˆæœ¬æ§åˆ¶ - ç’°å¢ƒæª¢æŸ¥\")\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"å·¥ä½œç›®éŒ„: {os.getcwd()}\")\n",
    "\n",
    "# æª¢æŸ¥å¿…è¦çš„ä¾è³´\n",
    "required_packages = ['numpy', 'pandas', 'scipy']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"âœ… {package}: å·²å®‰è£\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package}: æœªå®‰è£\")\n",
    "\n",
    "print(\"\\nâœ… ç’°å¢ƒæª¢æŸ¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ä¼æ¥­ç´šæ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "class ModelStatus(Enum):\n",
    "    \"\"\"æ¨¡å‹ç‹€æ…‹æšèˆ‰\"\"\"\n",
    "    DEVELOPMENT = \"development\"\n",
    "    TESTING = \"testing\"\n",
    "    STAGING = \"staging\"\n",
    "    CANARY = \"canary\"\n",
    "    PRODUCTION = \"production\"\n",
    "    DEPRECATED = \"deprecated\"\n",
    "    RETIRED = \"retired\"\n",
    "\n",
    "class TrafficSplitStrategy(Enum):\n",
    "    \"\"\"æµé‡åˆ†é…ç­–ç•¥\"\"\"\n",
    "    PERCENTAGE = \"percentage\"\n",
    "    USER_ID_HASH = \"user_id_hash\"\n",
    "    GEOGRAPHIC = \"geographic\"\n",
    "    FEATURE_FLAG = \"feature_flag\"\n",
    "    TIME_BASED = \"time_based\"\n",
    "    GRADUAL_ROLLOUT = \"gradual_rollout\"\n",
    "\n",
    "@dataclass\n",
    "class ModelVersion:\n",
    "    \"\"\"æ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯\"\"\"\n",
    "    model_id: str\n",
    "    version: str\n",
    "    name: str\n",
    "    description: str\n",
    "    created_at: datetime\n",
    "    created_by: str\n",
    "    status: ModelStatus\n",
    "    config_path: str\n",
    "    model_path: str\n",
    "    performance_baseline: Dict[str, float]\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    dependencies: List[str] = field(default_factory=list)\n",
    "    traffic_allocation: float = 0.0\n",
    "    deployment_config: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "class ModelVersionControl:\n",
    "    \"\"\"æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ç³»çµ±\"\"\"\n",
    "    \n",
    "    def __init__(self, storage_path: str = \"./model_versions\"):\n",
    "        self.storage_path = Path(storage_path)\n",
    "        self.storage_path.mkdir(exist_ok=True)\n",
    "        self.versions: Dict[str, ModelVersion] = {}\n",
    "        self.version_history: Dict[str, List[str]] = {}  # model_name -> [versions]\n",
    "        self._load_versions()\n",
    "    \n",
    "    def register_version(self, version: ModelVersion) -> bool:\n",
    "        \"\"\"è¨»å†Šæ–°ç‰ˆæœ¬\"\"\"\n",
    "        try:\n",
    "            version_key = f\"{version.model_id}:{version.version}\"\n",
    "            \n",
    "            # æª¢æŸ¥ç‰ˆæœ¬æ˜¯å¦å·²å­˜åœ¨\n",
    "            if version_key in self.versions:\n",
    "                logger.warning(f\"ç‰ˆæœ¬ {version_key} å·²å­˜åœ¨\")\n",
    "                return False\n",
    "            \n",
    "            # é©—è­‰ç‰ˆæœ¬ä¿¡æ¯\n",
    "            self._validate_version(version)\n",
    "            \n",
    "            # è¨»å†Šç‰ˆæœ¬\n",
    "            self.versions[version_key] = version\n",
    "            \n",
    "            # æ›´æ–°ç‰ˆæœ¬æ­·å²\n",
    "            if version.model_id not in self.version_history:\n",
    "                self.version_history[version.model_id] = []\n",
    "            self.version_history[version.model_id].append(version.version)\n",
    "            \n",
    "            # ä¿å­˜åˆ°å­˜å„²\n",
    "            self._save_versions()\n",
    "            \n",
    "            logger.info(f\"âœ… ç‰ˆæœ¬ {version_key} è¨»å†ŠæˆåŠŸ\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ ç‰ˆæœ¬è¨»å†Šå¤±æ•—: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def promote_version(self, model_id: str, version: str, target_status: ModelStatus) -> bool:\n",
    "        \"\"\"å‡ç´šç‰ˆæœ¬ç‹€æ…‹\"\"\"\n",
    "        version_key = f\"{model_id}:{version}\"\n",
    "        \n",
    "        if version_key not in self.versions:\n",
    "            logger.error(f\"ç‰ˆæœ¬ {version_key} ä¸å­˜åœ¨\")\n",
    "            return False\n",
    "        \n",
    "        current_version = self.versions[version_key]\n",
    "        old_status = current_version.status\n",
    "        \n",
    "        # æª¢æŸ¥ç‹€æ…‹è½‰æ›æ˜¯å¦åˆæ³•\n",
    "        if not self._is_valid_status_transition(old_status, target_status):\n",
    "            logger.error(f\"éæ³•çš„ç‹€æ…‹è½‰æ›: {old_status.value} -> {target_status.value}\")\n",
    "            return False\n",
    "        \n",
    "        # æ›´æ–°ç‹€æ…‹\n",
    "        current_version.status = target_status\n",
    "        \n",
    "        # å¦‚æœå‡ç´šåˆ°ç”Ÿç”¢ç’°å¢ƒï¼Œé™ç´šå…¶ä»–ç‰ˆæœ¬\n",
    "        if target_status == ModelStatus.PRODUCTION:\n",
    "            self._demote_other_production_versions(model_id, version)\n",
    "        \n",
    "        self._save_versions()\n",
    "        \n",
    "        logger.info(f\"ğŸ”„ ç‰ˆæœ¬ {version_key} ç‹€æ…‹æ›´æ–°: {old_status.value} -> {target_status.value}\")\n",
    "        return True\n",
    "    \n",
    "    def get_versions_by_status(self, model_id: str, status: ModelStatus) -> List[ModelVersion]:\n",
    "        \"\"\"æŒ‰ç‹€æ…‹ç²å–ç‰ˆæœ¬\"\"\"\n",
    "        return [v for k, v in self.versions.items() \n",
    "                if v.model_id == model_id and v.status == status]\n",
    "    \n",
    "    def get_latest_version(self, model_id: str, status: Optional[ModelStatus] = None) -> Optional[ModelVersion]:\n",
    "        \"\"\"ç²å–æœ€æ–°ç‰ˆæœ¬\"\"\"\n",
    "        versions = [v for k, v in self.versions.items() if v.model_id == model_id]\n",
    "        \n",
    "        if status:\n",
    "            versions = [v for v in versions if v.status == status]\n",
    "        \n",
    "        if not versions:\n",
    "            return None\n",
    "        \n",
    "        return max(versions, key=lambda v: v.created_at)\n",
    "    \n",
    "    def compare_versions(self, model_id: str, version1: str, version2: str) -> Dict[str, Any]:\n",
    "        \"\"\"æ¯”è¼ƒå…©å€‹ç‰ˆæœ¬\"\"\"\n",
    "        v1_key = f\"{model_id}:{version1}\"\n",
    "        v2_key = f\"{model_id}:{version2}\"\n",
    "        \n",
    "        if v1_key not in self.versions or v2_key not in self.versions:\n",
    "            return {\"error\": \"ç‰ˆæœ¬ä¸å­˜åœ¨\"}\n",
    "        \n",
    "        v1 = self.versions[v1_key]\n",
    "        v2 = self.versions[v2_key]\n",
    "        \n",
    "        comparison = {\n",
    "            \"version1\": {\n",
    "                \"version\": v1.version,\n",
    "                \"status\": v1.status.value,\n",
    "                \"created_at\": v1.created_at.isoformat(),\n",
    "                \"performance\": v1.performance_baseline,\n",
    "                \"traffic_allocation\": v1.traffic_allocation\n",
    "            },\n",
    "            \"version2\": {\n",
    "                \"version\": v2.version,\n",
    "                \"status\": v2.status.value,\n",
    "                \"created_at\": v2.created_at.isoformat(),\n",
    "                \"performance\": v2.performance_baseline,\n",
    "                \"traffic_allocation\": v2.traffic_allocation\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # æ€§èƒ½æ¯”è¼ƒ\n",
    "        performance_diff = {}\n",
    "        for metric in set(v1.performance_baseline.keys()) & set(v2.performance_baseline.keys()):\n",
    "            diff = v2.performance_baseline[metric] - v1.performance_baseline[metric]\n",
    "            performance_diff[metric] = {\n",
    "                \"absolute_diff\": diff,\n",
    "                \"relative_diff\": diff / v1.performance_baseline[metric] if v1.performance_baseline[metric] != 0 else 0\n",
    "            }\n",
    "        \n",
    "        comparison[\"performance_diff\"] = performance_diff\n",
    "        \n",
    "        return comparison\n",
    "    \n",
    "    def _validate_version(self, version: ModelVersion):\n",
    "        \"\"\"é©—è­‰ç‰ˆæœ¬ä¿¡æ¯\"\"\"\n",
    "        if not version.model_id or not version.version:\n",
    "            raise ValueError(\"æ¨¡å‹IDå’Œç‰ˆæœ¬è™Ÿä¸èƒ½ç‚ºç©º\")\n",
    "        \n",
    "        if not version.config_path or not version.model_path:\n",
    "            raise ValueError(\"é…ç½®è·¯å¾‘å’Œæ¨¡å‹è·¯å¾‘ä¸èƒ½ç‚ºç©º\")\n",
    "    \n",
    "    def _is_valid_status_transition(self, from_status: ModelStatus, to_status: ModelStatus) -> bool:\n",
    "        \"\"\"æª¢æŸ¥ç‹€æ…‹è½‰æ›æ˜¯å¦åˆæ³•\"\"\"\n",
    "        valid_transitions = {\n",
    "            ModelStatus.DEVELOPMENT: [ModelStatus.TESTING, ModelStatus.DEPRECATED],\n",
    "            ModelStatus.TESTING: [ModelStatus.STAGING, ModelStatus.DEVELOPMENT, ModelStatus.DEPRECATED],\n",
    "            ModelStatus.STAGING: [ModelStatus.CANARY, ModelStatus.TESTING, ModelStatus.DEPRECATED],\n",
    "            ModelStatus.CANARY: [ModelStatus.PRODUCTION, ModelStatus.STAGING, ModelStatus.DEPRECATED],\n",
    "            ModelStatus.PRODUCTION: [ModelStatus.DEPRECATED],\n",
    "            ModelStatus.DEPRECATED: [ModelStatus.RETIRED],\n",
    "            ModelStatus.RETIRED: []\n",
    "        }\n",
    "        \n",
    "        return to_status in valid_transitions.get(from_status, [])\n",
    "    \n",
    "    def _demote_other_production_versions(self, model_id: str, exclude_version: str):\n",
    "        \"\"\"é™ç´šå…¶ä»–ç”Ÿç”¢ç‰ˆæœ¬\"\"\"\n",
    "        for key, version in self.versions.items():\n",
    "            if (version.model_id == model_id and \n",
    "                version.version != exclude_version and \n",
    "                version.status == ModelStatus.PRODUCTION):\n",
    "                version.status = ModelStatus.DEPRECATED\n",
    "                logger.info(f\"ğŸ”½ ç‰ˆæœ¬ {key} è‡ªå‹•é™ç´šç‚º DEPRECATED\")\n",
    "    \n",
    "    def _save_versions(self):\n",
    "        \"\"\"ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯åˆ°æ–‡ä»¶\"\"\"\n",
    "        versions_file = self.storage_path / \"versions.json\"\n",
    "        \n",
    "        data = {}\n",
    "        for key, version in self.versions.items():\n",
    "            data[key] = {\n",
    "                \"model_id\": version.model_id,\n",
    "                \"version\": version.version,\n",
    "                \"name\": version.name,\n",
    "                \"description\": version.description,\n",
    "                \"created_at\": version.created_at.isoformat(),\n",
    "                \"created_by\": version.created_by,\n",
    "                \"status\": version.status.value,\n",
    "                \"config_path\": version.config_path,\n",
    "                \"model_path\": version.model_path,\n",
    "                \"performance_baseline\": version.performance_baseline,\n",
    "                \"metadata\": version.metadata,\n",
    "                \"dependencies\": version.dependencies,\n",
    "                \"traffic_allocation\": version.traffic_allocation,\n",
    "                \"deployment_config\": version.deployment_config\n",
    "            }\n",
    "        \n",
    "        with open(versions_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    def _load_versions(self):\n",
    "        \"\"\"å¾æ–‡ä»¶è¼‰å…¥ç‰ˆæœ¬ä¿¡æ¯\"\"\"\n",
    "        versions_file = self.storage_path / \"versions.json\"\n",
    "        \n",
    "        if not versions_file.exists():\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            with open(versions_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            for key, version_data in data.items():\n",
    "                version = ModelVersion(\n",
    "                    model_id=version_data['model_id'],\n",
    "                    version=version_data['version'],\n",
    "                    name=version_data['name'],\n",
    "                    description=version_data['description'],\n",
    "                    created_at=datetime.fromisoformat(version_data['created_at']),\n",
    "                    created_by=version_data['created_by'],\n",
    "                    status=ModelStatus(version_data['status']),\n",
    "                    config_path=version_data['config_path'],\n",
    "                    model_path=version_data['model_path'],\n",
    "                    performance_baseline=version_data['performance_baseline'],\n",
    "                    metadata=version_data.get('metadata', {}),\n",
    "                    dependencies=version_data.get('dependencies', []),\n",
    "                    traffic_allocation=version_data.get('traffic_allocation', 0.0),\n",
    "                    deployment_config=version_data.get('deployment_config', {})\n",
    "                )\n",
    "                \n",
    "                self.versions[key] = version\n",
    "                \n",
    "                # é‡å»ºç‰ˆæœ¬æ­·å²\n",
    "                if version.model_id not in self.version_history:\n",
    "                    self.version_history[version.model_id] = []\n",
    "                self.version_history[version.model_id].append(version.version)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"è¼‰å…¥ç‰ˆæœ¬ä¿¡æ¯å¤±æ•—: {e}\")\n",
    "\n",
    "# åˆå§‹åŒ–ç‰ˆæœ¬æ§åˆ¶ç³»çµ±\n",
    "version_control = ModelVersionControl()\n",
    "print(\"\\nâœ… æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ç³»çµ±åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª A/B æ¸¬è©¦æ¡†æ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A/B æ¸¬è©¦ç›¸é—œæ•¸æ“šçµæ§‹\n",
    "@dataclass\n",
    "class ABTestConfig:\n",
    "    \"\"\"A/B æ¸¬è©¦é…ç½®\"\"\"\n",
    "    test_id: str\n",
    "    name: str\n",
    "    description: str\n",
    "    control_version: str\n",
    "    treatment_versions: List[str]\n",
    "    traffic_split: Dict[str, float]\n",
    "    split_strategy: TrafficSplitStrategy\n",
    "    start_time: datetime\n",
    "    end_time: Optional[datetime]\n",
    "    success_metrics: List[str]\n",
    "    minimum_sample_size: int\n",
    "    significance_level: float = 0.05\n",
    "    statistical_power: float = 0.8\n",
    "    early_stopping_enabled: bool = True\n",
    "    status: str = \"active\"\n",
    "    created_by: str = \"\"\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class ExperimentResult:\n",
    "    \"\"\"å¯¦é©—çµæœ\"\"\"\n",
    "    version: str\n",
    "    sample_size: int\n",
    "    metrics: Dict[str, float]\n",
    "    confidence_intervals: Dict[str, Tuple[float, float]]\n",
    "    timestamp: datetime\n",
    "\n",
    "print(\"\\nâœ… A/B æ¸¬è©¦æ•¸æ“šçµæ§‹å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš¦ æµé‡è·¯ç”±èˆ‡åˆ†é…ç­–ç•¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficRouter:\n",
    "    \"\"\"æµé‡è·¯ç”±å™¨\"\"\"\n",
    "    \n",
    "    def route(self, config: ABTestConfig, request_context: Dict[str, Any]) -> str:\n",
    "        \"\"\"æ ¹æ“šç­–ç•¥è·¯ç”±æµé‡\"\"\"\n",
    "        if config.split_strategy == TrafficSplitStrategy.PERCENTAGE:\n",
    "            return self._percentage_split(config, request_context)\n",
    "        elif config.split_strategy == TrafficSplitStrategy.USER_ID_HASH:\n",
    "            return self._user_id_hash_split(config, request_context)\n",
    "        elif config.split_strategy == TrafficSplitStrategy.GEOGRAPHIC:\n",
    "            return self._geographic_split(config, request_context)\n",
    "        elif config.split_strategy == TrafficSplitStrategy.FEATURE_FLAG:\n",
    "            return self._feature_flag_split(config, request_context)\n",
    "        elif config.split_strategy == TrafficSplitStrategy.TIME_BASED:\n",
    "            return self._time_based_split(config, request_context)\n",
    "        elif config.split_strategy == TrafficSplitStrategy.GRADUAL_ROLLOUT:\n",
    "            return self._gradual_rollout_split(config, request_context)\n",
    "        else:\n",
    "            return self._percentage_split(config, request_context)\n",
    "    \n",
    "    def _percentage_split(self, config: ABTestConfig, request_context: Dict[str, Any]) -> str:\n",
    "        \"\"\"åŸºæ–¼ç™¾åˆ†æ¯”çš„æµé‡åˆ†é…\"\"\"\n",
    "        rand = random.random()\n",
    "        cumulative = 0.0\n",
    "        \n",
    "        for version, traffic in config.traffic_split.items():\n",
    "            cumulative += traffic\n",
    "            if rand <= cumulative:\n",
    "                return version\n",
    "        \n",
    "        # å¦‚æœç”±æ–¼æµ®é»ç²¾åº¦å•é¡Œæ²’æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›æœ€å¾Œä¸€å€‹ç‰ˆæœ¬\n",
    "        return list(config.traffic_split.keys())[-1]\n",
    "    \n",
    "    def _user_id_hash_split(self, config: ABTestConfig, request_context: Dict[str, Any]) -> str:\n",
    "        \"\"\"åŸºæ–¼ç”¨æˆ¶IDå“ˆå¸Œçš„æµé‡åˆ†é…\"\"\"\n",
    "        user_id = request_context.get('user_id')\n",
    "        if not user_id:\n",
    "            return self._percentage_split(config, request_context)\n",
    "        \n",
    "        # ä½¿ç”¨å“ˆå¸Œç¢ºä¿åŒä¸€ç”¨æˆ¶ç¸½æ˜¯åˆ†é…åˆ°åŒä¸€ç‰ˆæœ¬\n",
    "        hash_value = int(hashlib.md5(f\"{user_id}:{config.test_id}\".encode()).hexdigest(), 16)\n",
    "        hash_ratio = (hash_value % 10000) / 10000.0\n",
    "        \n",
    "        cumulative = 0.0\n",
    "        for version, traffic in config.traffic_split.items():\n",
    "            cumulative += traffic\n",
    "            if hash_ratio <= cumulative:\n",
    "                return version\n",
    "        \n",
    "        return list(config.traffic_split.keys())[-1]\n",
    "    \n",
    "    def _geographic_split(self, config: ABTestConfig, request_context: Dict[str, Any]) -> str:\n",
    "        \"\"\"åŸºæ–¼åœ°ç†ä½ç½®çš„æµé‡åˆ†é…\"\"\"\n",
    "        region = request_context.get('region', 'default')\n",
    "        \n",
    "        # åœ°ç†ä½ç½®æ˜ å°„è¦å‰‡ï¼ˆå¯é…ç½®ï¼‰\n",
    "        region_mapping = {\n",
    "            'US': config.treatment_versions[0] if config.treatment_versions else config.control_version,\n",
    "            'EU': config.treatment_versions[1] if len(config.treatment_versions) > 1 else config.control_version,\n",
    "            'ASIA': config.control_version\n",
    "        }\n",
    "        \n",
    "        return region_mapping.get(region, config.control_version)\n",
    "    \n",
    "    def _feature_flag_split(self, config: ABTestConfig, request_context: Dict[str, Any]) -> str:\n",
    "        \"\"\"åŸºæ–¼ç‰¹å¾µæ¨™èªŒçš„æµé‡åˆ†é…\"\"\"\n",
    "        feature_flags = request_context.get('feature_flags', {})\n",
    "        \n",
    "        # æª¢æŸ¥ç‰¹å®šçš„ç‰¹å¾µæ¨™èªŒ\n",
    "        if feature_flags.get('use_experimental_model', False):\n",
    "            return config.treatment_versions[0] if config.treatment_versions else config.control_version\n",
    "        \n",
    "        if feature_flags.get('is_premium_user', False):\n",
    "            return config.treatment_versions[-1] if config.treatment_versions else config.control_version\n",
    "        \n",
    "        return config.control_version\n",
    "    \n",
    "    def _time_based_split(self, config: ABTestConfig, request_context: Dict[str, Any]) -> str:\n",
    "        \"\"\"åŸºæ–¼æ™‚é–“çš„æµé‡åˆ†é…\"\"\"\n",
    "        current_hour = datetime.now().hour\n",
    "        \n",
    "        # å·¥ä½œæ™‚é–“ä½¿ç”¨å¯¦é©—ç‰ˆæœ¬\n",
    "        if 9 <= current_hour <= 17:\n",
    "            return config.treatment_versions[0] if config.treatment_versions else config.control_version\n",
    "        else:\n",
    "            return config.control_version\n",
    "    \n",
    "    def _gradual_rollout_split(self, config: ABTestConfig, request_context: Dict[str, Any]) -> str:\n",
    "        \"\"\"æ¼¸é€²å¼æ¨å‡ºæµé‡åˆ†é…\"\"\"\n",
    "        # æ ¹æ“šæ¸¬è©¦é–‹å§‹æ™‚é–“è¨ˆç®—ç•¶å‰æ‡‰è©²çš„æµé‡æ¯”ä¾‹\n",
    "        elapsed_hours = (datetime.now() - config.start_time).total_seconds() / 3600\n",
    "        rollout_duration_hours = 24  # 24å°æ™‚å…§å®Œæˆå…¨é‡æ¨å‡º\n",
    "        \n",
    "        # è¨ˆç®—ç•¶å‰å¯¦é©—ç‰ˆæœ¬æ‡‰è©²å¾—åˆ°çš„æµé‡æ¯”ä¾‹\n",
    "        target_traffic = min(elapsed_hours / rollout_duration_hours, 1.0)\n",
    "        \n",
    "        # èª¿æ•´æµé‡åˆ†é…\n",
    "        adjusted_split = {}\n",
    "        control_traffic = 1.0 - target_traffic\n",
    "        \n",
    "        adjusted_split[config.control_version] = control_traffic\n",
    "        \n",
    "        # å¯¦é©—ç‰ˆæœ¬æŒ‰åŸæ¯”ä¾‹åˆ†é…å‰©é¤˜æµé‡\n",
    "        treatment_total = sum(config.traffic_split[v] for v in config.treatment_versions)\n",
    "        for version in config.treatment_versions:\n",
    "            if treatment_total > 0:\n",
    "                version_ratio = config.traffic_split[version] / treatment_total\n",
    "                adjusted_split[version] = target_traffic * version_ratio\n",
    "            else:\n",
    "                adjusted_split[version] = 0\n",
    "        \n",
    "        # ä½¿ç”¨èª¿æ•´å¾Œçš„åˆ†é…é€²è¡Œè·¯ç”±\n",
    "        temp_config = ABTestConfig(\n",
    "            test_id=config.test_id,\n",
    "            name=config.name,\n",
    "            description=config.description,\n",
    "            control_version=config.control_version,\n",
    "            treatment_versions=config.treatment_versions,\n",
    "            traffic_split=adjusted_split,\n",
    "            split_strategy=TrafficSplitStrategy.PERCENTAGE,\n",
    "            start_time=config.start_time,\n",
    "            success_metrics=config.success_metrics,\n",
    "            minimum_sample_size=config.minimum_sample_size\n",
    "        )\n",
    "        \n",
    "        return self._percentage_split(temp_config, request_context)\n",
    "\n",
    "print(\"\\nâœ… æµé‡è·¯ç”±å™¨åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ çµ±è¨ˆåˆ†æå¼•æ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "class StatisticsEngine:\n",
    "    \"\"\"çµ±è¨ˆåˆ†æå¼•æ“\"\"\"\n",
    "    \n",
    "    def analyze_versions(self, version_data: Dict[str, List[float]], \n",
    "                        control_version: str, significance_level: float = 0.05) -> Dict[str, Any]:\n",
    "        \"\"\"åˆ†æç‰ˆæœ¬é–“çš„çµ±è¨ˆå·®ç•°\"\"\"\n",
    "        \n",
    "        if control_version not in version_data:\n",
    "            return {\"error\": f\"æ§åˆ¶ç‰ˆæœ¬ {control_version} ç„¡æ•¸æ“š\"}\n",
    "        \n",
    "        control_data = np.array(version_data[control_version])\n",
    "        \n",
    "        if len(control_data) == 0:\n",
    "            return {\"error\": \"æ§åˆ¶ç‰ˆæœ¬ç„¡æ•¸æ“š\"}\n",
    "        \n",
    "        analysis = {\n",
    "            \"control_version\": control_version,\n",
    "            \"significance_level\": significance_level,\n",
    "            \"version_stats\": {},\n",
    "            \"comparisons\": []\n",
    "        }\n",
    "        \n",
    "        # è¨ˆç®—å„ç‰ˆæœ¬çš„çµ±è¨ˆä¿¡æ¯\n",
    "        for version, data in version_data.items():\n",
    "            data_array = np.array(data)\n",
    "            \n",
    "            if len(data_array) == 0:\n",
    "                continue\n",
    "            \n",
    "            stats_info = {\n",
    "                \"sample_size\": len(data_array),\n",
    "                \"mean\": float(np.mean(data_array)),\n",
    "                \"std\": float(np.std(data_array, ddof=1)),\n",
    "                \"median\": float(np.median(data_array)),\n",
    "                \"min\": float(np.min(data_array)),\n",
    "                \"max\": float(np.max(data_array)),\n",
    "                \"confidence_interval\": self._calculate_confidence_interval(\n",
    "                    data_array, significance_level\n",
    "                )\n",
    "            }\n",
    "            \n",
    "            analysis[\"version_stats\"][version] = stats_info\n",
    "        \n",
    "        # é€²è¡Œçµ±è¨ˆæ¯”è¼ƒ\n",
    "        for version, data in version_data.items():\n",
    "            if version == control_version:\n",
    "                continue\n",
    "            \n",
    "            treatment_data = np.array(data)\n",
    "            \n",
    "            if len(treatment_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            comparison = self._compare_versions(\n",
    "                control_data, treatment_data, \n",
    "                control_version, version, \n",
    "                significance_level\n",
    "            )\n",
    "            \n",
    "            analysis[\"comparisons\"].append(comparison)\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _calculate_confidence_interval(self, data: np.ndarray, \n",
    "                                     significance_level: float) -> Tuple[float, float]:\n",
    "        \"\"\"è¨ˆç®—ç½®ä¿¡å€é–“\"\"\"\n",
    "        if len(data) < 2:\n",
    "            return (float(data[0]), float(data[0])) if len(data) == 1 else (0.0, 0.0)\n",
    "        \n",
    "        confidence_level = 1 - significance_level\n",
    "        \n",
    "        mean = np.mean(data)\n",
    "        sem = stats.sem(data)  # æ¨™æº–èª¤å·®\n",
    "        \n",
    "        # ä½¿ç”¨ t åˆ†ä½ˆè¨ˆç®—ç½®ä¿¡å€é–“\n",
    "        t_critical = stats.t.ppf((1 + confidence_level) / 2, len(data) - 1)\n",
    "        margin_error = t_critical * sem\n",
    "        \n",
    "        return (float(mean - margin_error), float(mean + margin_error))\n",
    "    \n",
    "    def _compare_versions(self, control_data: np.ndarray, treatment_data: np.ndarray,\n",
    "                         control_version: str, treatment_version: str,\n",
    "                         significance_level: float) -> Dict[str, Any]:\n",
    "        \"\"\"æ¯”è¼ƒå…©å€‹ç‰ˆæœ¬çš„çµ±è¨ˆå·®ç•°\"\"\"\n",
    "        \n",
    "        # åŸ·è¡Œé›™æ¨£æœ¬ t æª¢å®š\n",
    "        t_stat, p_value = stats.ttest_ind(treatment_data, control_data, equal_var=False)\n",
    "        \n",
    "        # è¨ˆç®—æ•ˆæ‡‰å¤§å° (Cohen's d)\n",
    "        cohens_d = self._calculate_cohens_d(control_data, treatment_data)\n",
    "        \n",
    "        # è¨ˆç®—ç›¸å°æå‡\n",
    "        control_mean = np.mean(control_data)\n",
    "        treatment_mean = np.mean(treatment_data)\n",
    "        \n",
    "        if control_mean != 0:\n",
    "            relative_improvement = (treatment_mean - control_mean) / control_mean\n",
    "        else:\n",
    "            relative_improvement = 0\n",
    "        \n",
    "        # è¨ˆç®—çµ±è¨ˆåŠŸæ•ˆ\n",
    "        statistical_power = self._calculate_statistical_power(\n",
    "            control_data, treatment_data, significance_level\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"control_version\": control_version,\n",
    "            \"treatment_version\": treatment_version,\n",
    "            \"control_mean\": float(control_mean),\n",
    "            \"treatment_mean\": float(treatment_mean),\n",
    "            \"absolute_difference\": float(treatment_mean - control_mean),\n",
    "            \"relative_improvement\": float(relative_improvement),\n",
    "            \"t_statistic\": float(t_stat),\n",
    "            \"p_value\": float(p_value),\n",
    "            \"is_significant\": p_value < significance_level,\n",
    "            \"cohens_d\": float(cohens_d),\n",
    "            \"effect_size_interpretation\": self._interpret_effect_size(cohens_d),\n",
    "            \"statistical_power\": float(statistical_power),\n",
    "            \"confidence_level\": float(1 - significance_level)\n",
    "        }\n",
    "    \n",
    "    def _calculate_cohens_d(self, control_data: np.ndarray, treatment_data: np.ndarray) -> float:\n",
    "        \"\"\"è¨ˆç®— Cohen's d æ•ˆæ‡‰å¤§å°\"\"\"\n",
    "        control_mean = np.mean(control_data)\n",
    "        treatment_mean = np.mean(treatment_data)\n",
    "        \n",
    "        # åˆä½µæ¨™æº–å·®\n",
    "        n1, n2 = len(control_data), len(treatment_data)\n",
    "        \n",
    "        if n1 < 2 or n2 < 2:\n",
    "            return 0.0\n",
    "        \n",
    "        s1, s2 = np.std(control_data, ddof=1), np.std(treatment_data, ddof=1)\n",
    "        pooled_std = np.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))\n",
    "        \n",
    "        if pooled_std == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return (treatment_mean - control_mean) / pooled_std\n",
    "    \n",
    "    def _interpret_effect_size(self, cohens_d: float) -> str:\n",
    "        \"\"\"è§£é‡‹æ•ˆæ‡‰å¤§å°\"\"\"\n",
    "        abs_d = abs(cohens_d)\n",
    "        \n",
    "        if abs_d < 0.2:\n",
    "            return \"negligible\"\n",
    "        elif abs_d < 0.5:\n",
    "            return \"small\"\n",
    "        elif abs_d < 0.8:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"large\"\n",
    "    \n",
    "    def _calculate_statistical_power(self, control_data: np.ndarray, \n",
    "                                   treatment_data: np.ndarray, \n",
    "                                   significance_level: float) -> float:\n",
    "        \"\"\"è¨ˆç®—çµ±è¨ˆåŠŸæ•ˆ\"\"\"\n",
    "        # ç°¡åŒ–çš„åŠŸæ•ˆè¨ˆç®—\n",
    "        effect_size = abs(self._calculate_cohens_d(control_data, treatment_data))\n",
    "        n = min(len(control_data), len(treatment_data))\n",
    "        \n",
    "        # ä½¿ç”¨è¿‘ä¼¼å…¬å¼è¨ˆç®—åŠŸæ•ˆ\n",
    "        if n < 2 or effect_size == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # é€™æ˜¯ä¸€å€‹ç°¡åŒ–çš„è¨ˆç®—ï¼Œå¯¦éš›æ‡‰è©²ä½¿ç”¨æ›´ç²¾ç¢ºçš„æ–¹æ³•\n",
    "        z_alpha = stats.norm.ppf(1 - significance_level / 2)\n",
    "        z_beta = effect_size * np.sqrt(n / 2) - z_alpha\n",
    "        power = stats.norm.cdf(z_beta)\n",
    "        \n",
    "        return max(0.0, min(1.0, power))\n",
    "\n",
    "# åˆå§‹åŒ–çµ±è¨ˆåˆ†æå¼•æ“\n",
    "statistics_engine = StatisticsEngine()\n",
    "print(\"\\nâœ… çµ±è¨ˆåˆ†æå¼•æ“åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª å®Œæ•´çš„ A/B æ¸¬è©¦æ¡†æ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABTestFramework:\n",
    "    \"\"\"A/B æ¸¬è©¦æ¡†æ¶\"\"\"\n",
    "    \n",
    "    def __init__(self, version_control: ModelVersionControl):\n",
    "        self.version_control = version_control\n",
    "        self.active_tests: Dict[str, ABTestConfig] = {}\n",
    "        self.test_results: Dict[str, List[ExperimentResult]] = defaultdict(list)\n",
    "        self.traffic_router = TrafficRouter()\n",
    "        self.statistics_engine = StatisticsEngine()\n",
    "    \n",
    "    def create_ab_test(self, config: ABTestConfig) -> bool:\n",
    "        \"\"\"å‰µå»º A/B æ¸¬è©¦\"\"\"\n",
    "        try:\n",
    "            # é©—è­‰é…ç½®\n",
    "            self._validate_ab_test_config(config)\n",
    "            \n",
    "            # æª¢æŸ¥æµé‡åˆ†é…ç¸½å’Œ\n",
    "            total_traffic = sum(config.traffic_split.values())\n",
    "            if abs(total_traffic - 1.0) > 0.001:\n",
    "                raise ValueError(f\"æµé‡åˆ†é…ç¸½å’Œå¿…é ˆç‚º1.0ï¼Œç•¶å‰ç‚º {total_traffic}\")\n",
    "            \n",
    "            # æ›´æ–°ç‰ˆæœ¬çš„æµé‡åˆ†é…\n",
    "            for version, traffic in config.traffic_split.items():\n",
    "                model_version = self._get_model_version(version)\n",
    "                if model_version:\n",
    "                    model_version.traffic_allocation = traffic\n",
    "            \n",
    "            # è¨»å†Šæ¸¬è©¦\n",
    "            self.active_tests[config.test_id] = config\n",
    "            \n",
    "            logger.info(f\"âœ… A/B æ¸¬è©¦ {config.name} å‰µå»ºæˆåŠŸ\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ A/B æ¸¬è©¦å‰µå»ºå¤±æ•—: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def route_traffic(self, test_id: str, request_context: Dict[str, Any]) -> str:\n",
    "        \"\"\"è·¯ç”±æµé‡åˆ°æŒ‡å®šç‰ˆæœ¬\"\"\"\n",
    "        if test_id not in self.active_tests:\n",
    "            raise ValueError(f\"A/B æ¸¬è©¦ {test_id} ä¸å­˜åœ¨\")\n",
    "        \n",
    "        config = self.active_tests[test_id]\n",
    "        \n",
    "        return self.traffic_router.route(config, request_context)\n",
    "    \n",
    "    def record_result(self, test_id: str, version: str, metrics: Dict[str, float]):\n",
    "        \"\"\"è¨˜éŒ„å¯¦é©—çµæœ\"\"\"\n",
    "        if test_id not in self.active_tests:\n",
    "            logger.warning(f\"A/B æ¸¬è©¦ {test_id} ä¸å­˜åœ¨\")\n",
    "            return\n",
    "        \n",
    "        result = ExperimentResult(\n",
    "            version=version,\n",
    "            sample_size=1,  # å–®æ¬¡è¨˜éŒ„\n",
    "            metrics=metrics,\n",
    "            confidence_intervals={},  # ç¨å¾Œè¨ˆç®—\n",
    "            timestamp=datetime.now()\n",
    "        )\n",
    "        \n",
    "        self.test_results[test_id].append(result)\n",
    "    \n",
    "    def analyze_test_results(self, test_id: str, metric_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"åˆ†ææ¸¬è©¦çµæœ\"\"\"\n",
    "        if test_id not in self.active_tests:\n",
    "            return {\"error\": \"æ¸¬è©¦ä¸å­˜åœ¨\"}\n",
    "        \n",
    "        config = self.active_tests[test_id]\n",
    "        results = self.test_results[test_id]\n",
    "        \n",
    "        if not results:\n",
    "            return {\"error\": \"ç„¡æ¸¬è©¦çµæœ\"}\n",
    "        \n",
    "        # æŒ‰ç‰ˆæœ¬èšåˆçµæœ\n",
    "        version_results = defaultdict(list)\n",
    "        for result in results:\n",
    "            if metric_name in result.metrics:\n",
    "                version_results[result.version].append(result.metrics[metric_name])\n",
    "        \n",
    "        # çµ±è¨ˆåˆ†æ\n",
    "        analysis = self.statistics_engine.analyze_versions(\n",
    "            version_results, \n",
    "            config.control_version,\n",
    "            config.significance_level\n",
    "        )\n",
    "        \n",
    "        # æ·»åŠ å¯¦é©—é…ç½®ä¿¡æ¯\n",
    "        analysis['test_config'] = {\n",
    "            'test_id': test_id,\n",
    "            'name': config.name,\n",
    "            'control_version': config.control_version,\n",
    "            'treatment_versions': config.treatment_versions,\n",
    "            'significance_level': config.significance_level,\n",
    "            'minimum_sample_size': config.minimum_sample_size\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def check_early_stopping(self, test_id: str, metric_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"æª¢æŸ¥æ˜¯å¦æ»¿è¶³æ—©æœŸåœæ­¢æ¢ä»¶\"\"\"\n",
    "        if test_id not in self.active_tests:\n",
    "            return {\"should_stop\": False, \"reason\": \"æ¸¬è©¦ä¸å­˜åœ¨\"}\n",
    "        \n",
    "        config = self.active_tests[test_id]\n",
    "        \n",
    "        if not config.early_stopping_enabled:\n",
    "            return {\"should_stop\": False, \"reason\": \"æœªå•Ÿç”¨æ—©æœŸåœæ­¢\"}\n",
    "        \n",
    "        analysis = self.analyze_test_results(test_id, metric_name)\n",
    "        \n",
    "        if \"error\" in analysis:\n",
    "            return {\"should_stop\": False, \"reason\": analysis[\"error\"]}\n",
    "        \n",
    "        # æª¢æŸ¥æ¨£æœ¬é‡æ˜¯å¦è¶³å¤ \n",
    "        for version, stats in analysis['version_stats'].items():\n",
    "            if stats['sample_size'] < config.minimum_sample_size:\n",
    "                return {\n",
    "                    \"should_stop\": False, \n",
    "                    \"reason\": f\"æ¨£æœ¬é‡ä¸è¶³: {version} åƒ…æœ‰ {stats['sample_size']} æ¨£æœ¬\"\n",
    "                }\n",
    "        \n",
    "        # æª¢æŸ¥çµ±è¨ˆé¡¯è‘—æ€§\n",
    "        has_significant_result = False\n",
    "        for comparison in analysis['comparisons']:\n",
    "            if comparison['is_significant']:\n",
    "                has_significant_result = True\n",
    "                break\n",
    "        \n",
    "        if has_significant_result:\n",
    "            return {\n",
    "                \"should_stop\": True,\n",
    "                \"reason\": \"æª¢æ¸¬åˆ°çµ±è¨ˆé¡¯è‘—æ€§å·®ç•°\",\n",
    "                \"analysis\": analysis\n",
    "            }\n",
    "        \n",
    "        return {\"should_stop\": False, \"reason\": \"å°šæœªé”åˆ°åœæ­¢æ¢ä»¶\"}\n",
    "    \n",
    "    def get_test_summary(self, test_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"ç²å–æ¸¬è©¦æ‘˜è¦\"\"\"\n",
    "        if test_id not in self.active_tests:\n",
    "            return {\"error\": \"æ¸¬è©¦ä¸å­˜åœ¨\"}\n",
    "        \n",
    "        config = self.active_tests[test_id]\n",
    "        results = self.test_results[test_id]\n",
    "        \n",
    "        # çµ±è¨ˆåŸºæœ¬ä¿¡æ¯\n",
    "        version_counts = defaultdict(int)\n",
    "        for result in results:\n",
    "            version_counts[result.version] += 1\n",
    "        \n",
    "        duration = None\n",
    "        if config.end_time:\n",
    "            duration = (config.end_time - config.start_time).total_seconds() / 3600  # å°æ™‚\n",
    "        else:\n",
    "            duration = (datetime.now() - config.start_time).total_seconds() / 3600\n",
    "        \n",
    "        return {\n",
    "            \"test_id\": test_id,\n",
    "            \"name\": config.name,\n",
    "            \"status\": config.status,\n",
    "            \"duration_hours\": round(duration, 2),\n",
    "            \"total_samples\": len(results),\n",
    "            \"version_samples\": dict(version_counts),\n",
    "            \"traffic_split\": config.traffic_split,\n",
    "            \"success_metrics\": config.success_metrics,\n",
    "            \"created_by\": config.created_by\n",
    "        }\n",
    "    \n",
    "    def _validate_ab_test_config(self, config: ABTestConfig):\n",
    "        \"\"\"é©—è­‰ A/B æ¸¬è©¦é…ç½®\"\"\"\n",
    "        # æª¢æŸ¥å¿…è¦å­—æ®µ\n",
    "        if not config.test_id or not config.name:\n",
    "            raise ValueError(\"æ¸¬è©¦IDå’Œåç¨±ä¸èƒ½ç‚ºç©º\")\n",
    "        \n",
    "        # æª¢æŸ¥ç‰ˆæœ¬æ˜¯å¦å­˜åœ¨\n",
    "        all_versions = [config.control_version] + config.treatment_versions\n",
    "        for version in all_versions:\n",
    "            if not self._get_model_version(version):\n",
    "                raise ValueError(f\"ç‰ˆæœ¬ {version} ä¸å­˜åœ¨\")\n",
    "        \n",
    "        # æª¢æŸ¥æµé‡åˆ†é…\n",
    "        if set(config.traffic_split.keys()) != set(all_versions):\n",
    "            raise ValueError(\"æµé‡åˆ†é…å¿…é ˆåŒ…å«æ‰€æœ‰ç‰ˆæœ¬\")\n",
    "    \n",
    "    def _get_model_version(self, version_key: str) -> Optional[ModelVersion]:\n",
    "        \"\"\"ç²å–æ¨¡å‹ç‰ˆæœ¬\"\"\"\n",
    "        return self.version_control.versions.get(version_key)\n",
    "\n",
    "print(\"\\nâœ… A/B æ¸¬è©¦æ¡†æ¶åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¦ PayPal é¢¨æ§æ¨¡å‹ A/B æ¸¬è©¦æ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰µå»º PayPal é¢¨æ§æ¨¡å‹ A/B æ¸¬è©¦çš„å®Œæ•´æ¼”ç¤º\n",
    "print(\"ğŸ¦ PayPal é¢¨æ§æ¨¡å‹ A/B æ¸¬è©¦æ¼”ç¤º\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. è¨»å†Šæ¨¡å‹ç‰ˆæœ¬\n",
    "print(\"\\nğŸ“‹ æ­¥é©Ÿ 1: è¨»å†Šé¢¨æ§æ¨¡å‹ç‰ˆæœ¬...\")\n",
    "\n",
    "# PayPal é¢¨æ§æ¨¡å‹ç‰ˆæœ¬\n",
    "fraud_models = [\n",
    "    {\n",
    "        \"model_id\": \"fraud_detection\",\n",
    "        \"version\": \"v2.1\",\n",
    "        \"name\": \"ä¿å®ˆé¢¨æ§æ¨¡å‹\",\n",
    "        \"description\": \"é«˜ç²¾ç¢ºåº¦ï¼Œä½å¬å›ç‡çš„é¢¨æ§æ¨¡å‹ï¼Œé©åˆä¿å®ˆç­–ç•¥\",\n",
    "        \"performance\": {\"precision\": 0.95, \"recall\": 0.75, \"f1_score\": 0.84, \"auc\": 0.92}\n",
    "    },\n",
    "    {\n",
    "        \"model_id\": \"fraud_detection\",\n",
    "        \"version\": \"v2.2\",\n",
    "        \"name\": \"æ¿€é€²é¢¨æ§æ¨¡å‹\",\n",
    "        \"description\": \"é«˜å¬å›ç‡çš„é¢¨æ§æ¨¡å‹ï¼Œå¯èƒ½æœ‰èª¤æ®ºä½†èƒ½æ•ç²æ›´å¤šæ¬ºè©\",\n",
    "        \"performance\": {\"precision\": 0.85, \"recall\": 0.92, \"f1_score\": 0.88, \"auc\": 0.94}\n",
    "    },\n",
    "    {\n",
    "        \"model_id\": \"fraud_detection\",\n",
    "        \"version\": \"v3.0\",\n",
    "        \"name\": \"å¯¦é©—é¢¨æ§æ¨¡å‹\",\n",
    "        \"description\": \"åŸºæ–¼æ·±åº¦å­¸ç¿’çš„æ–°ç®—æ³•ï¼Œæ­£åœ¨é©—è­‰æ•ˆæœ\",\n",
    "        \"performance\": {\"precision\": 0.90, \"recall\": 0.88, \"f1_score\": 0.89, \"auc\": 0.96}\n",
    "    }\n",
    "]\n",
    "\n",
    "for model_info in fraud_models:\n",
    "    version = ModelVersion(\n",
    "        model_id=model_info[\"model_id\"],\n",
    "        version=model_info[\"version\"],\n",
    "        name=model_info[\"name\"],\n",
    "        description=model_info[\"description\"],\n",
    "        created_at=datetime.now() - timedelta(days=random.randint(1, 30)),\n",
    "        created_by=\"paypal_ml_team\",\n",
    "        status=ModelStatus.STAGING,\n",
    "        config_path=f\"/models/{model_info['model_id']}/{model_info['version']}/config.json\",\n",
    "        model_path=f\"/models/{model_info['model_id']}/{model_info['version']}/model.pth\",\n",
    "        performance_baseline=model_info[\"performance\"],\n",
    "        metadata={\n",
    "            \"training_data\": \"paypal_fraud_2024_q1\",\n",
    "            \"feature_count\": random.randint(50, 100),\n",
    "            \"model_size_mb\": random.randint(10, 50)\n",
    "        },\n",
    "        deployment_config={\n",
    "            \"max_batch_size\": 32,\n",
    "            \"timeout_ms\": 100,\n",
    "            \"memory_limit_mb\": 2048\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    success = version_control.register_version(version)\n",
    "    if success:\n",
    "        print(f\"  âœ… {model_info['name']} {model_info['version']} è¨»å†ŠæˆåŠŸ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ç•¶å‰è¨»å†Šç‰ˆæœ¬æ•¸é‡: {len(version_control.versions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. å‡ç´šç‰ˆæœ¬ç‹€æ…‹åˆ°ç”Ÿç”¢ç’°å¢ƒ\n",
    "print(\"\\nğŸš€ æ­¥é©Ÿ 2: å‡ç´šæ¨¡å‹ç‰ˆæœ¬åˆ°ç”Ÿç”¢ç’°å¢ƒ...\")\n",
    "\n",
    "# å‡ç´š v2.1 åˆ°ç”Ÿç”¢ç’°å¢ƒï¼ˆç•¶å‰ä¸»åŠ›æ¨¡å‹ï¼‰\n",
    "success = version_control.promote_version(\"fraud_detection\", \"v2.1\", ModelStatus.PRODUCTION)\n",
    "if success:\n",
    "    print(\"  âœ… v2.1 (ä¿å®ˆæ¨¡å‹) å‡ç´šåˆ°ç”Ÿç”¢ç’°å¢ƒ\")\n",
    "\n",
    "# å‡ç´š v2.2 åˆ° Canary ç’°å¢ƒæº–å‚™æ¸¬è©¦\n",
    "success = version_control.promote_version(\"fraud_detection\", \"v2.2\", ModelStatus.CANARY)\n",
    "if success:\n",
    "    print(\"  âœ… v2.2 (æ¿€é€²æ¨¡å‹) å‡ç´šåˆ° Canary ç’°å¢ƒ\")\n",
    "\n",
    "# v3.0 ä¿æŒåœ¨ Staging ç’°å¢ƒ\n",
    "print(\"  â„¹ï¸ v3.0 (å¯¦é©—æ¨¡å‹) ä¿æŒåœ¨ Staging ç’°å¢ƒ\")\n",
    "\n",
    "# æª¢æŸ¥ç•¶å‰å„ç‹€æ…‹çš„ç‰ˆæœ¬\n",
    "production_versions = version_control.get_versions_by_status(\"fraud_detection\", ModelStatus.PRODUCTION)\n",
    "canary_versions = version_control.get_versions_by_status(\"fraud_detection\", ModelStatus.CANARY)\n",
    "staging_versions = version_control.get_versions_by_status(\"fraud_detection\", ModelStatus.STAGING)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ç‰ˆæœ¬ç‹€æ…‹åˆ†ä½ˆ:\")\n",
    "print(f\"  ç”Ÿç”¢ç’°å¢ƒ: {len(production_versions)} å€‹ç‰ˆæœ¬\")\n",
    "print(f\"  Canary ç’°å¢ƒ: {len(canary_versions)} å€‹ç‰ˆæœ¬\")\n",
    "print(f\"  Staging ç’°å¢ƒ: {len(staging_versions)} å€‹ç‰ˆæœ¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. å‰µå»º A/B æ¸¬è©¦é…ç½®\n",
    "print(\"\\nğŸ§ª æ­¥é©Ÿ 3: å‰µå»º A/B æ¸¬è©¦é…ç½®...\")\n",
    "\n",
    "# åˆå§‹åŒ– A/B æ¸¬è©¦æ¡†æ¶\n",
    "ab_test_framework = ABTestFramework(version_control)\n",
    "\n",
    "# å‰µå»ºä¸»è¦ A/B æ¸¬è©¦ï¼šä¿å®ˆ vs æ¿€é€²æ¨¡å‹\n",
    "main_ab_test = ABTestConfig(\n",
    "    test_id=\"paypal_fraud_conservative_vs_aggressive\",\n",
    "    name=\"PayPal é¢¨æ§æ¨¡å‹ï¼šä¿å®ˆ vs æ¿€é€²ç­–ç•¥\",\n",
    "    description=\"æ¯”è¼ƒä¿å®ˆæ¨¡å‹ï¼ˆé«˜ç²¾ç¢ºåº¦ï¼‰å’Œæ¿€é€²æ¨¡å‹ï¼ˆé«˜å¬å›ç‡ï¼‰åœ¨å¯¦éš›äº¤æ˜“ä¸­çš„è¡¨ç¾\",\n",
    "    control_version=\"fraud_detection:v2.1\",\n",
    "    treatment_versions=[\"fraud_detection:v2.2\"],\n",
    "    traffic_split={\n",
    "        \"fraud_detection:v2.1\": 0.7,  # ä¿å®ˆæ¨¡å‹ 70% æµé‡\n",
    "        \"fraud_detection:v2.2\": 0.3   # æ¿€é€²æ¨¡å‹ 30% æµé‡\n",
    "    },\n",
    "    split_strategy=TrafficSplitStrategy.USER_ID_HASH,\n",
    "    start_time=datetime.now(),\n",
    "    success_metrics=[\"fraud_detection_rate\", \"false_positive_rate\", \"processing_time\"],\n",
    "    minimum_sample_size=1000,\n",
    "    significance_level=0.05,\n",
    "    statistical_power=0.8,\n",
    "    early_stopping_enabled=True,\n",
    "    created_by=\"paypal_fraud_team\",\n",
    "    metadata={\n",
    "        \"business_goal\": \"å¹³è¡¡æ¬ºè©æª¢æ¸¬ç‡å’Œç”¨æˆ¶é«”é©—\",\n",
    "        \"risk_tolerance\": \"medium\",\n",
    "        \"expected_duration_days\": 14\n",
    "    }\n",
    ")\n",
    "\n",
    "# è¨»å†Š A/B æ¸¬è©¦\n",
    "success = ab_test_framework.create_ab_test(main_ab_test)\n",
    "if success:\n",
    "    print(f\"  âœ… {main_ab_test.name} å‰µå»ºæˆåŠŸ\")\n",
    "    print(f\"    æ¸¬è©¦ID: {main_ab_test.test_id}\")\n",
    "    print(f\"    æµé‡åˆ†é…: {main_ab_test.traffic_split}\")\n",
    "    print(f\"    åˆ†é…ç­–ç•¥: {main_ab_test.split_strategy.value}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ç•¶å‰æ´»èº A/B æ¸¬è©¦: {len(ab_test_framework.active_tests)} å€‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. æ¨¡æ“¬äº¤æ˜“æµé‡å’Œæ¨¡å‹é æ¸¬\n",
    "print(\"\\nğŸ’³ æ­¥é©Ÿ 4: æ¨¡æ“¬ PayPal äº¤æ˜“æµé‡...\")\n",
    "\n",
    "def simulate_fraud_detection(model_version: str, transaction_data: Dict[str, Any]) -> Dict[str, float]:\n",
    "    \"\"\"æ¨¡æ“¬é¢¨æ§æ¨¡å‹é æ¸¬\"\"\"\n",
    "    \n",
    "    # æ¨¡æ“¬ä¸åŒæ¨¡å‹çš„ç‰¹æ€§\n",
    "    if \"v2.1\" in model_version:  # ä¿å®ˆæ¨¡å‹\n",
    "        base_fraud_rate = 0.02  # 2% æ¬ºè©æª¢å‡ºç‡\n",
    "        false_positive_rate = 0.01  # 1% èª¤æ®ºç‡\n",
    "        processing_time = random.uniform(80, 120)  # 80-120ms\n",
    "    elif \"v2.2\" in model_version:  # æ¿€é€²æ¨¡å‹\n",
    "        base_fraud_rate = 0.035  # 3.5% æ¬ºè©æª¢å‡ºç‡\n",
    "        false_positive_rate = 0.025  # 2.5% èª¤æ®ºç‡\n",
    "        processing_time = random.uniform(90, 130)  # 90-130ms\n",
    "    else:\n",
    "        base_fraud_rate = 0.02\n",
    "        false_positive_rate = 0.01\n",
    "        processing_time = random.uniform(80, 120)\n",
    "    \n",
    "    # åŸºæ–¼äº¤æ˜“ç‰¹å¾µèª¿æ•´æª¢æ¸¬ç‡\n",
    "    risk_factor = 1.0\n",
    "    \n",
    "    # é«˜é¢¨éšªåœ°å€\n",
    "    if transaction_data.get('region') in ['HIGH_RISK_REGION']:\n",
    "        risk_factor *= 2.0\n",
    "    \n",
    "    # é«˜é¡äº¤æ˜“\n",
    "    amount = transaction_data.get('amount', 100)\n",
    "    if amount > 1000:\n",
    "        risk_factor *= 1.5\n",
    "    \n",
    "    # æ–°ç”¨æˆ¶\n",
    "    if transaction_data.get('user_age_days', 365) < 30:\n",
    "        risk_factor *= 1.3\n",
    "    \n",
    "    # è¨ˆç®—æœ€çµ‚æŒ‡æ¨™\n",
    "    final_fraud_rate = min(base_fraud_rate * risk_factor, 0.1)  # æœ€é«˜10%\n",
    "    \n",
    "    # å¯¦éš›æª¢æ¸¬çµæœï¼ˆ0æˆ–1ï¼‰\n",
    "    is_flagged = 1 if random.random() < final_fraud_rate else 0\n",
    "    \n",
    "    # å¦‚æœæ²’æœ‰æª¢æ¸¬åˆ°æ¬ºè©ï¼Œå¯èƒ½æ˜¯èª¤æ®º\n",
    "    if is_flagged == 0 and random.random() < false_positive_rate:\n",
    "        is_flagged = 1  # èª¤æ®º\n",
    "    \n",
    "    return {\n",
    "        \"fraud_detection_rate\": float(is_flagged),\n",
    "        \"false_positive_rate\": float(1 if is_flagged and random.random() < 0.3 else 0),  # 30% çš„æª¢æ¸¬æ˜¯èª¤æ®º\n",
    "        \"processing_time\": processing_time\n",
    "    }\n",
    "\n",
    "# æ¨¡æ“¬å¤§é‡äº¤æ˜“\n",
    "print(\"\\nğŸ”„ ç”Ÿæˆæ¨¡æ“¬äº¤æ˜“æ•¸æ“š...\")\n",
    "\n",
    "transaction_count = 3000\n",
    "results_collected = 0\n",
    "\n",
    "for i in range(transaction_count):\n",
    "    # ç”Ÿæˆéš¨æ©Ÿäº¤æ˜“æ•¸æ“š\n",
    "    transaction = {\n",
    "        \"transaction_id\": f\"txn_{i+1:06d}\",\n",
    "        \"user_id\": f\"user_{random.randint(1000, 50000)}\",\n",
    "        \"amount\": random.uniform(10, 5000),\n",
    "        \"region\": random.choice([\"US\", \"EU\", \"ASIA\", \"HIGH_RISK_REGION\"]),\n",
    "        \"user_age_days\": random.randint(1, 1000),\n",
    "        \"payment_method\": random.choice([\"credit_card\", \"bank_transfer\", \"digital_wallet\"]),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # ç‚ºä¸»è¦ A/B æ¸¬è©¦è·¯ç”±æµé‡\n",
    "    try:\n",
    "        assigned_version = ab_test_framework.route_traffic(\n",
    "            \"paypal_fraud_conservative_vs_aggressive\", \n",
    "            transaction\n",
    "        )\n",
    "        \n",
    "        # åŸ·è¡Œæ¨¡å‹é æ¸¬\n",
    "        prediction_results = simulate_fraud_detection(assigned_version, transaction)\n",
    "        \n",
    "        # è¨˜éŒ„çµæœåˆ° A/B æ¸¬è©¦\n",
    "        ab_test_framework.record_result(\n",
    "            \"paypal_fraud_conservative_vs_aggressive\",\n",
    "            assigned_version,\n",
    "            prediction_results\n",
    "        )\n",
    "        \n",
    "        results_collected += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"äº¤æ˜“ {transaction['transaction_id']} è™•ç†å¤±æ•—: {e}\")\n",
    "    \n",
    "    # é¡¯ç¤ºé€²åº¦\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f\"\\r  è™•ç†é€²åº¦: {i+1}/{transaction_count} äº¤æ˜“\", end=\"\")\n",
    "\n",
    "print(f\"\\n\\nâœ… äº¤æ˜“æ¨¡æ“¬å®Œæˆ\")\n",
    "print(f\"  ç¸½äº¤æ˜“æ•¸: {transaction_count}\")\n",
    "print(f\"  æˆåŠŸè™•ç†: {results_collected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. åˆ†æ A/B æ¸¬è©¦çµæœ\n",
    "print(\"\\nğŸ“Š æ­¥é©Ÿ 5: åˆ†æ A/B æ¸¬è©¦çµæœ...\")\n",
    "\n",
    "# åˆ†æä¸»è¦ A/B æ¸¬è©¦\n",
    "print(\"\\nğŸ¯ ä¸»è¦ A/B æ¸¬è©¦çµæœåˆ†æ (ä¿å®ˆ vs æ¿€é€²æ¨¡å‹):\")\n",
    "\n",
    "main_test_metrics = [\"fraud_detection_rate\", \"false_positive_rate\", \"processing_time\"]\n",
    "\n",
    "for metric in main_test_metrics:\n",
    "    print(f\"\\nğŸ“ˆ æŒ‡æ¨™: {metric}\")\n",
    "    \n",
    "    analysis = ab_test_framework.analyze_test_results(\n",
    "        \"paypal_fraud_conservative_vs_aggressive\", \n",
    "        metric\n",
    "    )\n",
    "    \n",
    "    if \"error\" in analysis:\n",
    "        print(f\"  âŒ åˆ†æå¤±æ•—: {analysis['error']}\")\n",
    "        continue\n",
    "    \n",
    "    # é¡¯ç¤ºç‰ˆæœ¬çµ±è¨ˆ\n",
    "    print(f\"  ğŸ“Š ç‰ˆæœ¬çµ±è¨ˆ:\")\n",
    "    for version, stats in analysis[\"version_stats\"].items():\n",
    "        version_name = \"ä¿å®ˆæ¨¡å‹ v2.1\" if \"v2.1\" in version else \"æ¿€é€²æ¨¡å‹ v2.2\"\n",
    "        print(f\"    ğŸ”¹ {version_name}:\")\n",
    "        print(f\"      æ¨£æœ¬æ•¸: {stats['sample_size']}\")\n",
    "        print(f\"      å¹³å‡å€¼: {stats['mean']:.4f}\")\n",
    "        print(f\"      æ¨™æº–å·®: {stats['std']:.4f}\")\n",
    "        print(f\"      ç½®ä¿¡å€é–“: [{stats['confidence_interval'][0]:.4f}, {stats['confidence_interval'][1]:.4f}]\")\n",
    "    \n",
    "    # é¡¯ç¤ºçµ±è¨ˆæ¯”è¼ƒ\n",
    "    if analysis[\"comparisons\"]:\n",
    "        comparison = analysis[\"comparisons\"][0]  # åªæœ‰ä¸€å€‹æ¯”è¼ƒ\n",
    "        \n",
    "        print(f\"  ğŸ”¬ çµ±è¨ˆæ¯”è¼ƒçµæœ:\")\n",
    "        print(f\"    çµ•å°å·®ç•°: {comparison['absolute_difference']:.4f}\")\n",
    "        print(f\"    ç›¸å°æå‡: {comparison['relative_improvement']:.2%}\")\n",
    "        print(f\"    p-value: {comparison['p_value']:.6f}\")\n",
    "        print(f\"    çµ±è¨ˆé¡¯è‘—æ€§: {'æ˜¯' if comparison['is_significant'] else 'å¦'}\")\n",
    "        print(f\"    æ•ˆæ‡‰å¤§å°: {comparison['cohens_d']:.4f} ({comparison['effect_size_interpretation']})\")\n",
    "        print(f\"    çµ±è¨ˆåŠŸæ•ˆ: {comparison['statistical_power']:.3f}\")\n",
    "        \n",
    "        # æ¥­å‹™è§£é‡‹\n",
    "        if metric == \"fraud_detection_rate\":\n",
    "            if comparison['is_significant'] and comparison['relative_improvement'] > 0:\n",
    "                print(f\"  ğŸ’¡ æ¥­å‹™æ´å¯Ÿ: æ¿€é€²æ¨¡å‹çš„æ¬ºè©æª¢å‡ºç‡é¡¯è‘—é«˜æ–¼ä¿å®ˆæ¨¡å‹\")\n",
    "            elif comparison['is_significant'] and comparison['relative_improvement'] < 0:\n",
    "                print(f\"  ğŸ’¡ æ¥­å‹™æ´å¯Ÿ: ä¿å®ˆæ¨¡å‹çš„æ¬ºè©æª¢å‡ºç‡é¡¯è‘—é«˜æ–¼æ¿€é€²æ¨¡å‹\")\n",
    "        elif metric == \"false_positive_rate\":\n",
    "            if comparison['is_significant'] and comparison['relative_improvement'] > 0:\n",
    "                print(f\"  âš ï¸ æ¥­å‹™é¢¨éšª: æ¿€é€²æ¨¡å‹çš„èª¤æ®ºç‡é¡¯è‘—é«˜æ–¼ä¿å®ˆæ¨¡å‹\")\n",
    "            elif comparison['is_significant'] and comparison['relative_improvement'] < 0:\n",
    "                print(f\"  âœ… æ¥­å‹™å„ªå‹¢: æ¿€é€²æ¨¡å‹çš„èª¤æ®ºç‡é¡¯è‘—ä½æ–¼ä¿å®ˆæ¨¡å‹\")\n",
    "        elif metric == \"processing_time\":\n",
    "            if comparison['is_significant'] and comparison['relative_improvement'] > 0:\n",
    "                print(f\"  ğŸŒ æ€§èƒ½å•é¡Œ: æ¿€é€²æ¨¡å‹è™•ç†æ™‚é–“é¡¯è‘—é•·æ–¼ä¿å®ˆæ¨¡å‹\")\n",
    "            elif comparison['is_significant'] and comparison['relative_improvement'] < 0:\n",
    "                print(f\"  ğŸš€ æ€§èƒ½å„ªå‹¢: æ¿€é€²æ¨¡å‹è™•ç†æ™‚é–“é¡¯è‘—çŸ­æ–¼ä¿å®ˆæ¨¡å‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. æª¢æŸ¥æ—©æœŸåœæ­¢æ¢ä»¶\n",
    "print(\"\\nâ° æ­¥é©Ÿ 6: æª¢æŸ¥æ—©æœŸåœæ­¢æ¢ä»¶...\")\n",
    "\n",
    "# æª¢æŸ¥ä¸»è¦æ¸¬è©¦æ˜¯å¦æ»¿è¶³æ—©æœŸåœæ­¢æ¢ä»¶\n",
    "for metric in main_test_metrics:\n",
    "    early_stop_result = ab_test_framework.check_early_stopping(\n",
    "        \"paypal_fraud_conservative_vs_aggressive\", \n",
    "        metric\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ” æŒ‡æ¨™ {metric} æ—©æœŸåœæ­¢æª¢æŸ¥:\")\n",
    "    print(f\"  æ˜¯å¦æ‡‰è©²åœæ­¢: {early_stop_result['should_stop']}\")\n",
    "    print(f\"  åŸå› : {early_stop_result['reason']}\")\n",
    "    \n",
    "    if early_stop_result['should_stop'] and 'analysis' in early_stop_result:\n",
    "        print(f\"  ğŸ¯ å»ºè­°: åŸºæ–¼ {metric} æŒ‡æ¨™ï¼Œæ¸¬è©¦å·²é”åˆ°çµ±è¨ˆé¡¯è‘—æ€§ï¼Œå¯ä»¥æå‰çµæŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. æ¸¬è©¦æ‘˜è¦å’Œç‰ˆæœ¬æ¯”è¼ƒ\n",
    "print(\"\\nğŸ“‹ æ­¥é©Ÿ 7: æ¸¬è©¦æ‘˜è¦å’Œç‰ˆæœ¬æ¯”è¼ƒ...\")\n",
    "\n",
    "# ç²å–æ¸¬è©¦æ‘˜è¦\n",
    "print(\"\\nğŸ“Š A/B æ¸¬è©¦æ‘˜è¦:\")\n",
    "\n",
    "summary = ab_test_framework.get_test_summary(\"paypal_fraud_conservative_vs_aggressive\")\n",
    "\n",
    "if \"error\" not in summary:\n",
    "    print(f\"\\nğŸ§ª {summary['name']}:\")\n",
    "    print(f\"  æ¸¬è©¦ç‹€æ…‹: {summary['status']}\")\n",
    "    print(f\"  é‹è¡Œæ™‚é•·: {summary['duration_hours']:.2f} å°æ™‚\")\n",
    "    print(f\"  ç¸½æ¨£æœ¬æ•¸: {summary['total_samples']}\")\n",
    "    print(f\"  ç‰ˆæœ¬æ¨£æœ¬åˆ†ä½ˆ:\")\n",
    "    for version, count in summary['version_samples'].items():\n",
    "        version_name = \"ä¿å®ˆæ¨¡å‹ v2.1\" if \"v2.1\" in version else \"æ¿€é€²æ¨¡å‹ v2.2\"\n",
    "        percentage = count / summary['total_samples'] * 100 if summary['total_samples'] > 0 else 0\n",
    "        print(f\"    {version_name}: {count} ({percentage:.1f}%)\")\n",
    "    print(f\"  ç›®æ¨™æµé‡åˆ†é…: {summary['traffic_split']}\")\n",
    "    print(f\"  å‰µå»ºè€…: {summary['created_by']}\")\n",
    "\n",
    "# ç‰ˆæœ¬æ€§èƒ½æ¯”è¼ƒ\n",
    "print(\"\\nğŸ† æ¨¡å‹ç‰ˆæœ¬æ€§èƒ½æ¯”è¼ƒ:\")\n",
    "\n",
    "comparison_result = version_control.compare_versions(\"fraud_detection\", \"v2.1\", \"v2.2\")\n",
    "\n",
    "if \"error\" not in comparison_result:\n",
    "    print(f\"\\nğŸ“ˆ ä¿å®ˆæ¨¡å‹ v2.1 vs æ¿€é€²æ¨¡å‹ v2.2:\")\n",
    "    \n",
    "    v1_info = comparison_result[\"version1\"]\n",
    "    v2_info = comparison_result[\"version2\"]\n",
    "    \n",
    "    print(f\"  ç‰ˆæœ¬1 ({v1_info['version']}): ç‹€æ…‹ {v1_info['status']}, æµé‡ {v1_info['traffic_allocation']:.1%}\")\n",
    "    print(f\"  ç‰ˆæœ¬2 ({v2_info['version']}): ç‹€æ…‹ {v2_info['status']}, æµé‡ {v2_info['traffic_allocation']:.1%}\")\n",
    "    \n",
    "    if \"performance_diff\" in comparison_result:\n",
    "        print(f\"  ğŸ¯ æ€§èƒ½å·®ç•°:\")\n",
    "        for metric, diff in comparison_result[\"performance_diff\"].items():\n",
    "            direction = \"æå‡\" if diff[\"relative_diff\"] > 0 else \"ä¸‹é™\"\n",
    "            print(f\"    {metric}: {direction} {abs(diff['relative_diff']):.2%} (çµ•å°å·®ç•°: {diff['absolute_diff']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. æ¥­å‹™æ±ºç­–å»ºè­°\n",
    "print(\"\\nğŸ’¼ æ­¥é©Ÿ 8: æ¥­å‹™æ±ºç­–å»ºè­°...\")\n",
    "\n",
    "# åŸºæ–¼æ¸¬è©¦çµæœç”Ÿæˆæ¥­å‹™å»ºè­°\n",
    "def generate_business_recommendations(test_id: str, metric: str) -> List[str]:\n",
    "    \"\"\"åŸºæ–¼æ¸¬è©¦çµæœç”Ÿæˆæ¥­å‹™å»ºè­°\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    analysis = ab_test_framework.analyze_test_results(test_id, metric)\n",
    "    \n",
    "    if \"error\" in analysis or not analysis[\"comparisons\"]:\n",
    "        return [\"æ•¸æ“šä¸è¶³ï¼Œå»ºè­°ç¹¼çºŒæ”¶é›†æ›´å¤šæ¨£æœ¬\"]\n",
    "    \n",
    "    comparison = analysis[\"comparisons\"][0]\n",
    "    \n",
    "    # åŸºæ–¼ä¸åŒæŒ‡æ¨™çš„å»ºè­°\n",
    "    if metric == \"fraud_detection_rate\":\n",
    "        if comparison[\"is_significant\"]:\n",
    "            if comparison[\"relative_improvement\"] > 0.1:  # 10% ä»¥ä¸Šæå‡\n",
    "                recommendations.append(\"ğŸš€ å¼·çƒˆå»ºè­°ï¼šæ¿€é€²æ¨¡å‹åœ¨æ¬ºè©æª¢å‡ºç‡ä¸Šæœ‰é¡¯è‘—æå‡ï¼Œå»ºè­°å¢åŠ å…¶æµé‡åˆ†é…\")\n",
    "            elif comparison[\"relative_improvement\"] > 0.05:  # 5-10% æå‡\n",
    "                recommendations.append(\"âœ… å»ºè­°ï¼šæ¿€é€²æ¨¡å‹è¡¨ç¾æ›´å¥½ï¼Œå¯è€ƒæ…®é€æ­¥å¢åŠ æµé‡\")\n",
    "            elif comparison[\"relative_improvement\"] < -0.05:  # ä¸‹é™5%ä»¥ä¸Š\n",
    "                recommendations.append(\"âš ï¸ è­¦å‘Šï¼šæ¿€é€²æ¨¡å‹æª¢å‡ºç‡ä¸‹é™ï¼Œå»ºè­°é™ä½æµé‡æˆ–å›é€€åˆ°ä¿å®ˆæ¨¡å‹\")\n",
    "        else:\n",
    "            recommendations.append(\"â„¹ï¸ è§€å¯Ÿï¼šå…©å€‹æ¨¡å‹åœ¨æ¬ºè©æª¢å‡ºç‡ä¸Šç„¡é¡¯è‘—å·®ç•°ï¼Œå¯è€ƒæ…®å…¶ä»–æŒ‡æ¨™\")\n",
    "    \n",
    "    elif metric == \"false_positive_rate\":\n",
    "        if comparison[\"is_significant\"]:\n",
    "            if comparison[\"relative_improvement\"] > 0.2:  # èª¤æ®ºç‡å¢åŠ 20%ä»¥ä¸Š\n",
    "                recommendations.append(\"ğŸš¨ é«˜é¢¨éšªï¼šæ¿€é€²æ¨¡å‹èª¤æ®ºç‡éé«˜ï¼Œå¯èƒ½å½±éŸ¿ç”¨æˆ¶é«”é©—\")\n",
    "            elif comparison[\"relative_improvement\"] < -0.1:  # èª¤æ®ºç‡é™ä½10%ä»¥ä¸Š\n",
    "                recommendations.append(\"ğŸ‰ å„ªå‹¢ï¼šæ¿€é€²æ¨¡å‹èª¤æ®ºç‡æ›´ä½ï¼Œç”¨æˆ¶é«”é©—æ›´å¥½\")\n",
    "    \n",
    "    elif metric == \"processing_time\":\n",
    "        if comparison[\"is_significant\"]:\n",
    "            if comparison[\"relative_improvement\"] > 0.2:  # è™•ç†æ™‚é–“å¢åŠ 20%ä»¥ä¸Š\n",
    "                recommendations.append(\"â±ï¸ æ€§èƒ½å•é¡Œï¼šæ¿€é€²æ¨¡å‹è™•ç†æ™‚é–“éé•·ï¼Œå¯èƒ½å½±éŸ¿ç³»çµ±ååé‡\")\n",
    "            elif comparison[\"relative_improvement\"] < -0.1:  # è™•ç†æ™‚é–“æ¸›å°‘10%ä»¥ä¸Š\n",
    "                recommendations.append(\"ğŸš€ æ€§èƒ½å„ªå‹¢ï¼šæ¿€é€²æ¨¡å‹è™•ç†é€Ÿåº¦æ›´å¿«\")\n",
    "    \n",
    "    # çµ±è¨ˆåŠŸæ•ˆå»ºè­°\n",
    "    if comparison[\"statistical_power\"] < 0.8:\n",
    "        recommendations.append(f\"ğŸ“Š çµ±è¨ˆå»ºè­°ï¼šç•¶å‰çµ±è¨ˆåŠŸæ•ˆ {comparison['statistical_power']:.2f} åä½ï¼Œå»ºè­°æ”¶é›†æ›´å¤šæ¨£æœ¬\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "print(\"\\nğŸ¯ åŸºæ–¼ä¸»è¦ A/B æ¸¬è©¦çš„æ¥­å‹™å»ºè­°:\")\n",
    "\n",
    "all_recommendations = []\n",
    "\n",
    "for metric in main_test_metrics:\n",
    "    recommendations = generate_business_recommendations(\n",
    "        \"paypal_fraud_conservative_vs_aggressive\", \n",
    "        metric\n",
    "    )\n",
    "    \n",
    "    if recommendations:\n",
    "        print(f\"\\nğŸ“ˆ åŸºæ–¼ {metric} æŒ‡æ¨™:\")\n",
    "        for rec in recommendations:\n",
    "            print(f\"  {rec}\")\n",
    "            all_recommendations.append(rec)\n",
    "\n",
    "# ç¶œåˆå»ºè­°\n",
    "print(\"\\nğŸ† ç¶œåˆæ¥­å‹™æ±ºç­–å»ºè­°:\")\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦æœ‰ä¸€è‡´çš„çµè«–\n",
    "positive_signals = sum(1 for rec in all_recommendations if \"å¼·çƒˆå»ºè­°\" in rec or \"å»ºè­°\" in rec)\n",
    "negative_signals = sum(1 for rec in all_recommendations if \"è­¦å‘Š\" in rec or \"é«˜é¢¨éšª\" in rec)\n",
    "neutral_signals = sum(1 for rec in all_recommendations if \"è§€å¯Ÿ\" in rec or \"çµ±è¨ˆå»ºè­°\" in rec)\n",
    "\n",
    "if positive_signals > negative_signals:\n",
    "    print(\"  âœ… æ•´é«”å»ºè­°ï¼šæ¿€é€²æ¨¡å‹ v2.2 è¡¨ç¾è‰¯å¥½ï¼Œå»ºè­°é€æ­¥å¢åŠ æµé‡åˆ†é…è‡³ 50%\")\n",
    "    print(\"  ğŸ“‹ è¡Œå‹•è¨ˆåŠƒï¼š\")\n",
    "    print(\"    1. å°‡æ¿€é€²æ¨¡å‹æµé‡å¾ 30% æå‡è‡³ 40%\")\n",
    "    print(\"    2. ç›£æ§é—œéµæŒ‡æ¨™ 48 å°æ™‚\")\n",
    "    print(\"    3. å¦‚ç„¡ç•°å¸¸ï¼Œé€²ä¸€æ­¥æå‡è‡³ 50%\")\n",
    "    print(\"    4. æº–å‚™æ¿€é€²æ¨¡å‹ v2.2 çš„å…¨é‡éƒ¨ç½²è¨ˆåŠƒ\")\n",
    "elif negative_signals > positive_signals:\n",
    "    print(\"  âš ï¸ æ•´é«”å»ºè­°ï¼šæ¿€é€²æ¨¡å‹å­˜åœ¨é¢¨éšªï¼Œå»ºè­°é™ä½æµé‡åˆ†é…æˆ–å›é€€\")\n",
    "    print(\"  ğŸ“‹ è¡Œå‹•è¨ˆåŠƒï¼š\")\n",
    "    print(\"    1. å°‡æ¿€é€²æ¨¡å‹æµé‡å¾ 30% é™ä½è‡³ 10%\")\n",
    "    print(\"    2. æ·±å…¥åˆ†æå•é¡Œæ ¹å› \")\n",
    "    print(\"    3. å„ªåŒ–æ¿€é€²æ¨¡å‹é…ç½®\")\n",
    "    print(\"    4. è€ƒæ…®å•Ÿå‹•å¯¦é©—æ¨¡å‹ v3.0 çš„æ›´å¤§è¦æ¨¡æ¸¬è©¦\")\n",
    "else:\n",
    "    print(\"  ğŸ¤” æ•´é«”å»ºè­°ï¼šæ¸¬è©¦çµæœæ··åˆï¼Œéœ€è¦æ›´å¤šæ•¸æ“šå’Œåˆ†æ\")\n",
    "    print(\"  ğŸ“‹ è¡Œå‹•è¨ˆåŠƒï¼š\")\n",
    "    print(\"    1. ç¶­æŒç•¶å‰æµé‡åˆ†é…æ¯”ä¾‹\")\n",
    "    print(\"    2. å»¶é•·æ¸¬è©¦æ™‚é–“è‡³ 14 å¤©\")\n",
    "    print(\"    3. å¢åŠ æ¥­å‹™æŒ‡æ¨™ç›£æ§\")\n",
    "    print(\"    4. æº–å‚™ v3.0 å¯¦é©—æ¨¡å‹çš„ä¸¦è¡Œæ¸¬è©¦\")\n",
    "\n",
    "print(\"\\nâœ… PayPal é¢¨æ§æ¨¡å‹ A/B æ¸¬è©¦æ¼”ç¤ºå®Œæˆï¼\")\n",
    "print(\"\\nğŸ“‹ æ¼”ç¤ºç¸½çµ:\")\n",
    "print(f\"  ğŸ­ è¨»å†Šç‰ˆæœ¬: {len(version_control.versions)} å€‹\")\n",
    "print(f\"  ğŸ§ª A/B æ¸¬è©¦: {len(ab_test_framework.active_tests)} å€‹\")\n",
    "print(f\"  ğŸ’³ æ¨¡æ“¬äº¤æ˜“: {transaction_count} ç­†\")\n",
    "print(f\"  ğŸ“Š åˆ†ææŒ‡æ¨™: {len(main_test_metrics)} å€‹\")\n",
    "print(f\"  ğŸ’¡ æ¥­å‹™å»ºè­°: {len(all_recommendations)} æ¢\")\n",
    "print(f\"  ğŸš€ ç‰ˆæœ¬æ§åˆ¶ã€æµé‡åˆ†é…ã€çµ±è¨ˆåˆ†æã€æ¥­å‹™æ±ºç­–å…¨æµç¨‹æ¼”ç¤º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ å¯¦é©—ç¸½çµèˆ‡ä¸‹ä¸€æ­¥\n",
    "\n",
    "### ğŸ¯ æœ¬å¯¦é©—å®Œæˆçš„å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "âœ… **ä¼æ¥­ç´šæ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ç­–ç•¥**\n",
    "- å»ºç«‹äº†å®Œæ•´çš„ç‰ˆæœ¬ç‹€æ…‹ç®¡ç†ï¼ˆDevelopment â†’ Testing â†’ Staging â†’ Canary â†’ Productionï¼‰\n",
    "- å¯¦ç¾äº†ç‰ˆæœ¬å‡ç´šå’Œé™ç´šçš„å®‰å…¨æ©Ÿåˆ¶\n",
    "- è¨­è¨ˆäº†ç‰ˆæœ¬æ¯”è¼ƒå’Œæ€§èƒ½åŸºç·šç®¡ç†\n",
    "\n",
    "âœ… **A/B æ¸¬è©¦æµé‡åˆ†é…æ©Ÿåˆ¶**\n",
    "- å¯¦ç¾äº†å¤šç¨®æµé‡åˆ†é…ç­–ç•¥ï¼šç™¾åˆ†æ¯”ã€ç”¨æˆ¶å“ˆå¸Œã€åœ°ç†ä½ç½®ã€ç‰¹å¾µæ¨™èªŒã€æ™‚é–“ã€æ¼¸é€²å¼æ¨å‡º\n",
    "- å»ºç«‹äº†ä¸€è‡´æ€§æµé‡è·¯ç”±ï¼ˆåŒä¸€ç”¨æˆ¶ç¸½æ˜¯åˆ†é…åˆ°åŒä¸€ç‰ˆæœ¬ï¼‰\n",
    "- è¨­è¨ˆäº†å‹•æ…‹æµé‡èª¿æ•´æ©Ÿåˆ¶\n",
    "\n",
    "âœ… **çµ±è¨ˆé¡¯è‘—æ€§æ¸¬è©¦æ¡†æ¶**\n",
    "- å¯¦ç¾äº†é›™æ¨£æœ¬ t æª¢å®šã€æ•ˆæ‡‰å¤§å°è¨ˆç®—ï¼ˆCohen's dï¼‰\n",
    "- å»ºç«‹äº†ç½®ä¿¡å€é–“ã€çµ±è¨ˆåŠŸæ•ˆåˆ†æ\n",
    "- è¨­è¨ˆäº†æ—©æœŸåœæ­¢æ©Ÿåˆ¶å’Œæ¨£æœ¬å¤§å°è¨ˆç®—\n",
    "\n",
    "âœ… **æ¼¸é€²å¼éƒ¨ç½² (Canary/Blue-Green)**\n",
    "- å¯¦ç¾äº† Canary éƒ¨ç½²çš„æµé‡é€æ­¥å¢åŠ \n",
    "- å»ºç«‹äº†åŸºæ–¼çµ±è¨ˆçµæœçš„è‡ªå‹•æ±ºç­–æ©Ÿåˆ¶\n",
    "- è¨­è¨ˆäº†å®‰å…¨çš„å›é€€ç­–ç•¥\n",
    "\n",
    "### ğŸš€ æ ¸å¿ƒæŠ€è¡“æˆæœ\n",
    "\n",
    "1. **ModelVersionControl**: ä¼æ¥­ç´šç‰ˆæœ¬ç®¡ç†ç³»çµ±\n",
    "2. **ABTestFramework**: å®Œæ•´çš„ A/B æ¸¬è©¦æ¡†æ¶\n",
    "3. **TrafficRouter**: æ™ºèƒ½æµé‡è·¯ç”±å™¨\n",
    "4. **StatisticsEngine**: çµ±è¨ˆåˆ†æå¼•æ“\n",
    "5. **æ¥­å‹™æ±ºç­–æ¡†æ¶**: åŸºæ–¼æ•¸æ“šçš„è‡ªå‹•åŒ–æ±ºç­–æ”¯æŒ\n",
    "\n",
    "### ğŸ’¼ PayPal ç´šåˆ¥çš„ä¼æ¥­ç‰¹æ€§\n",
    "\n",
    "- **é¢¨éšªæ§åˆ¶**: å¤šå±¤æ¬¡çš„å®‰å…¨æª¢æŸ¥å’Œå›é€€æ©Ÿåˆ¶\n",
    "- **åˆè¦æ€§**: å®Œæ•´çš„ç‰ˆæœ¬è¿½è¹¤å’Œå¯¦é©—è¨˜éŒ„\n",
    "- **å¯æ“´å±•æ€§**: æ”¯æ´å¤šå€‹ä¸¦è¡Œ A/B æ¸¬è©¦\n",
    "- **è‡ªå‹•åŒ–**: åŸºæ–¼çµ±è¨ˆé¡¯è‘—æ€§çš„è‡ªå‹•æ±ºç­–\n",
    "- **æ¥­å‹™å°å‘**: å°‡æŠ€è¡“æŒ‡æ¨™è½‰åŒ–ç‚ºæ¥­å‹™æ´å¯Ÿå’Œå»ºè­°\n",
    "\n",
    "### ğŸ“Š å¯¦éš›æ¥­å‹™åƒ¹å€¼\n",
    "\n",
    "é€é PayPal é¢¨æ§æ¨¡å‹æ¡ˆä¾‹ï¼Œæˆ‘å€‘å±•ç¤ºäº†ï¼š\n",
    "- **é¢¨éšªå¹³è¡¡**: åœ¨æ¬ºè©æª¢å‡ºç‡å’Œç”¨æˆ¶é«”é©—ä¹‹é–“æ‰¾åˆ°æœ€ä½³å¹³è¡¡é»\n",
    "- **ç§‘å­¸æ±ºç­–**: åŸºæ–¼çµ±è¨ˆå­¸åŸç†çš„å®¢è§€æ±ºç­–æ¡†æ¶\n",
    "- **å¿«é€Ÿè¿­ä»£**: é€šé A/B æ¸¬è©¦åŠ é€Ÿæ¨¡å‹å„ªåŒ–é€±æœŸ\n",
    "- **æå¤±æ§åˆ¶**: æ—©æœŸç™¼ç¾å•é¡Œä¸¦åŠæ™‚å›é€€ï¼Œé™ä½æ¥­å‹™é¢¨éšª\n",
    "\n",
    "### ğŸ“ ä¸‹ä¸€æ­¥å­¸ç¿’è·¯å¾‘\n",
    "\n",
    "æº–å‚™å¥½é€²å…¥ **Lab-2.2.3: æ¨¡å‹ç”Ÿå‘½é€±æœŸç®¡ç†**ï¼Œæˆ‘å€‘å°‡å­¸ç¿’ï¼š\n",
    "- å»ºç«‹å®Œæ•´çš„æ¨¡å‹è¨»å†Šèˆ‡è‡ªå‹•ç™¼ç¾æ©Ÿåˆ¶\n",
    "- å¯¦ç¾æ€§èƒ½ç›£æ§èˆ‡è‡ªå‹•åŒ–è©•ä¼°é«”ç³»\n",
    "- è¨­è¨ˆè‡ªå‹•æ¨¡å‹æ›´æ–°å’Œæ¼‚ç§»æª¢æ¸¬\n",
    "- æŒæ¡æ¨¡å‹é€€å½¹èˆ‡è³‡æºå›æ”¶ç­–ç•¥\n",
    "\n",
    "### ğŸ’¡ å»¶ä¼¸æ€è€ƒ\n",
    "\n",
    "1. å¦‚ä½•åœ¨å¤šå€‹æ¥­å‹™ç·šä¹‹é–“å”èª¿ A/B æ¸¬è©¦è³‡æºï¼Ÿ\n",
    "2. é¢å°å­£ç¯€æ€§æ¥­å‹™æ³¢å‹•ï¼Œå¦‚ä½•èª¿æ•´æ¸¬è©¦ç­–ç•¥ï¼Ÿ\n",
    "3. å¦‚ä½•å¹³è¡¡å¯¦é©—é€Ÿåº¦èˆ‡çµ±è¨ˆå¯é æ€§ï¼Ÿ\n",
    "4. åœ¨æ³•è¦åš´æ ¼çš„é‡‘èè¡Œæ¥­ï¼Œå¦‚ä½•ç¢ºä¿ A/B æ¸¬è©¦çš„åˆè¦æ€§ï¼Ÿ\n",
    "\n",
    "### ğŸ”— èˆ‡å‰åºå¯¦é©—çš„æ•´åˆ\n",
    "\n",
    "æœ¬å¯¦é©—å»ºç«‹åœ¨ Lab-2.2.1 çš„å¤šæ¨¡å‹ç®¡ç†åŸºç¤ä¸Šï¼Œæä¾›äº†ï¼š\n",
    "- **ç‰ˆæœ¬æ§åˆ¶**: ç‚ºå¤šæ¨¡å‹å€‰åº«æä¾›äº†ç‰ˆæœ¬ç®¡ç†èƒ½åŠ›\n",
    "- **å®‰å…¨éƒ¨ç½²**: é€šé A/B æ¸¬è©¦é™ä½æ–°ç‰ˆæœ¬éƒ¨ç½²é¢¨éšª\n",
    "- **æ•¸æ“šé©…å‹•**: åŸºæ–¼å¯¦éš›æ¥­å‹™æ•¸æ“šå„ªåŒ–æ¨¡å‹é¸æ“‡\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®Œæˆä¼æ¥­ç´š A/B æ¸¬è©¦èˆ‡ç‰ˆæœ¬æ§åˆ¶ï¼æ‚¨å·²ç¶“æŒæ¡äº† PayPal ç´šåˆ¥çš„æ¨¡å‹å¯¦é©—å’Œç‰ˆæœ¬ç®¡ç†æŠ€è¡“ï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}