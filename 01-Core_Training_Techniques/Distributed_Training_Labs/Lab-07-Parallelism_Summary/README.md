# Lab 7: 分散式訓練并行策略大一統

## 概述

本章節旨在對分散式深度學習中的各種主流并行策略進行一次全面的總結與梳理，形成一個統一的框架。我們將回顧**數據平行**、**模型平行（張量平行、流水線平行）**，並引入**專家平行 (Mixture of Experts, MoE)**，最终探討如何將它們組合以訓練萬億級別的超大型模型。

![并行策略全景圖](https://pic1.zhimg.com/v2-cc5997636e2f693b4823293e87d0c3f5_1440w.jpg)

---

## 1. 並行策略的回顧與分類

在分散式訓練中，所有并行策略的根本目標都是將計算和存儲任務分配到多個處理單元（GPU），但它們的切分維度不同。

| 並行策略 | 切分對象 | 主要目標 | 優點 | 缺點 |
|:---|:---|:---|:---|:---|
| **數據平行** | **數據 (Batch)** | 加速訓練 | 實現簡單、通用性強 | 無法解決模型過大問題 |
| **張量平行** | **模型權重 (層內)** | 解決模型過大 | 通信效率高、氣泡少 | 實現複雜、通信密集 |
| **流水線平行** | **模型層 (層間)** | 解決模型過-大 | 概念直觀、通信量較少 | 流水線氣泡、實現複雜 |
| **專家平行 (MoE)**| **模型權重 (專家)** | 擴展模型規模、降低計算量 | 訓練/推理成本低 | 實現複雜、負載均衡難 |

---

## 2. 數據平行 (Data Parallelism)

- **核心思想**：每個 GPU 都擁有完整的模型副本，但只處理一部分訓練數據。
- **關鍵步驟**：
    1.  數據分發。
    2.  本地計算梯度。
    3.  **全局梯度同步 (All-Reduce)**。
    4.  本地權重更新。
- **優勢**：最常用、最通用的加速方法，易於實現。
- **限制**：要求單個 GPU 能容納完整模型。

## 3. 模型平行 (Model Parallelism)

### 3.1 流水線平行 (Pipeline Parallelism)
- **核心思想**：將模型的不同**層**順序放置在不同 GPU 上。
- **挑戰**：會產生「流水線氣泡」，導致 GPU 空閑。
- **優化**：通過將批次數據切分為**微批次 (Micro-batches)** 來填充氣泡，提高 GPU 利用率。

### 3.2 張量平行 (Tensor Parallelism)
- **核心思想**：將單個 Transformer 層內部的**權重矩陣**切分到不同 GPU 上。
- **優勢**：相比流水線平行，GPU 空閑時間更少，通信效率更高（尤其在使用 NVLink 的單機多卡環境中）。
- **限制**：通信量巨大，對節點內部的互聯帶寬要求極高。

---

## 4. 專家平行 (Mixture of Experts, MoE)

### 4.1 核心思想

MoE 是一種更激進的模型擴展方式，其核心思想是：**在模型中創建多個「專家」子網絡（通常是 FFN 層），對於每個輸入 token，通過一個可學習的門控網絡 (Gating Network) 只選擇性地激活少數幾個專家**。

![MoE 架構示意圖](https://pic4.zhimg.com/v2-9d35a3f3b97b0a3c2025d57b32d2e11d_1440w.jpg)

### 4.2 優勢與挑戰

- **優勢**：
    - **極大地擴展模型規模**：可以在總參數量達到萬億級別的同時，保持每個輸入的實際計算量不變（因為只激活了少數專家）。
    - **訓練/推理成本低**：計算量與專家數量無關，僅與激活的專家數量（通常是 1-2 個）有關。
- **挑戰**：
    - **負載均衡**：如何確保每個專家的計算負載大致均衡是一個難題。
    - **通信開銷**：門控網絡和專家之間的數據交換會引入額外的 `All-to-All` 通信。
    - **實現複雜**：需要高度定製化的訓練框架支持。

---

## 5. 混合平行：訓練萬億級模型

為了訓練最大規模的模型，研究人員和工程師將上述所有并行策略組合起來，形成複雜的混合并行方案。

**一個典型的萬億級模型訓練配置可能如下**：

1.  **節點內 (Intra-Node)**：
    -   **8 路張量平行**：利用單台伺服器內 8 張 GPU 之間的高速 NVLink 互聯，將模型層內權重切分。

2.  **節點間 (Inter-Node)**：
    -   **8 路流水線平行**：將 8 個節點組成一個流水線，每個節點負責模型的一部分層。
    -   **數據平行**：將多個這樣的流水線副本（例如，64 個）組成一個數據平行組，每個副本處理不同的數據。
    -   **專家平行**：在每個流水線階段的 FFN 層，將專家分布在數據平行組的不同 GPU 上。

**總并行度**：`8 (TP) x 8 (PP) x 64 (DP) = 4096` 塊 GPU。

---

## 6. 結論與展望

- **沒有銀彈**：沒有一種并行策略能解決所有問題。最佳方案總是根據模型結構、硬體條件和訓練規模進行**組合與權衡**。
- **通信是永恆的挑戰**：無論哪種策略，如何優化通信、減少開銷都是核心問題。
- **框架的重要性**：實現高效的混合并行極其複雜，依賴於成熟的開源框架，如 **Megatron-LM**, **DeepSpeed**, **Colossal-AI** 等。
- **未來趨勢**：
    - **自動化并行**：研究如何讓框架自動為給定模型和硬體找到最優的并行策略。
    - **更高效的通信算法**：持續優化集體通信操作。
    - **軟硬體協同設計**：設計更適合分散式訓練的硬體架構。

理解這些并行策略的組合與權衡，是掌握大規模模型訓練技術的關鍵。
