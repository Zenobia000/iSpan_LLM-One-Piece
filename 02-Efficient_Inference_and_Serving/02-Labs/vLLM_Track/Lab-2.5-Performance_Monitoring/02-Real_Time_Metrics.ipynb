{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.5-02: 實時指標收集與監控\n",
    "\n",
    "## 實驗目標\n",
    "\n",
    "本節將深入探討 vLLM 的實時性能指標收集，包括：\n",
    "- vLLM 內建指標的詳細分析\n",
    "- 高頻率實時數據流建立\n",
    "- 先進的指標聚合與計算\n",
    "- 動態監控儀表板開發\n",
    "\n",
    "## 核心監控指標體系\n",
    "\n",
    "### 1. 請求級指標 (Request-level Metrics)\n",
    "- **TTFT (Time to First Token)**: 從請求到首個 token 的時間\n",
    "- **TPOT (Time Per Output Token)**: 每個輸出 token 的平均時間\n",
    "- **Request Duration**: 完整請求的總時間\n",
    "- **Queue Time**: 請求在佇列中的等待時間\n",
    "\n",
    "### 2. 吞吐量指標 (Throughput Metrics)\n",
    "- **Requests per Second (RPS)**: 每秒處理的請求數\n",
    "- **Tokens per Second (TPS)**: 每秒生成的 token 數\n",
    "- **Concurrent Requests**: 並發請求數量\n",
    "- **Batch Size Distribution**: 批次大小分佈\n",
    "\n",
    "### 3. 資源使用指標 (Resource Utilization)\n",
    "- **GPU Memory Usage**: GPU 記憶體使用情況\n",
    "- **KV Cache Utilization**: KV 快取使用效率\n",
    "- **Model Loading Time**: 模型載入時間\n",
    "- **Attention Computation Time**: 注意力計算時間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境初始化與依賴導入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "import threading\n",
    "import logging\n",
    "import statistics\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, deque\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "# 數據處理與分析\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 視覺化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "\n",
    "# HTTP 客戶端\n",
    "import requests\n",
    "import aiohttp\n",
    "\n",
    "# Prometheus 指標\n",
    "from prometheus_client import (\n",
    "    Gauge, Counter, Histogram, Summary, \n",
    "    CollectorRegistry, start_http_server\n",
    ")\n",
    "from prometheus_client.parser import text_string_to_metric_families\n",
    "\n",
    "# 系統監控\n",
    "import psutil\n",
    "try:\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    NVIDIA_GPU_AVAILABLE = True\n",
    "except (ImportError, Exception):\n",
    "    NVIDIA_GPU_AVAILABLE = False\n",
    "\n",
    "# 設置日誌\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 啟用 Plotly 離線模式\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "print(\"✅ 實時監控環境初始化完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. vLLM Metrics 解析器與收集器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLLMMetricsParser:\n",
    "    \"\"\"vLLM Prometheus 指標解析器\"\"\"\n",
    "    \n",
    "    def __init__(self, metrics_url: str = \"http://127.0.0.1:8001/metrics\"):\n",
    "        self.metrics_url = metrics_url\n",
    "        self.last_scrape_time = None\n",
    "        self.metrics_cache = {}\n",
    "    \n",
    "    def fetch_raw_metrics(self) -> Optional[str]:\n",
    "        \"\"\"獲取原始 metrics 文本\"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.metrics_url, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                self.last_scrape_time = datetime.now()\n",
    "                return response.text\n",
    "            else:\n",
    "                logger.warning(f\"Metrics endpoint returned {response.status_code}\")\n",
    "                return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Failed to fetch metrics: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def parse_metrics(self, raw_metrics: str) -> Dict[str, Any]:\n",
    "        \"\"\"解析 Prometheus 格式的 metrics\"\"\"\n",
    "        parsed_metrics = {}\n",
    "        \n",
    "        try:\n",
    "            for family in text_string_to_metric_families(raw_metrics):\n",
    "                metric_name = family.name\n",
    "                metric_type = family.type\n",
    "                \n",
    "                if metric_type == 'counter':\n",
    "                    for sample in family.samples:\n",
    "                        parsed_metrics[sample.name] = {\n",
    "                            'value': sample.value,\n",
    "                            'labels': sample.labels,\n",
    "                            'type': 'counter'\n",
    "                        }\n",
    "                \n",
    "                elif metric_type == 'gauge':\n",
    "                    for sample in family.samples:\n",
    "                        parsed_metrics[sample.name] = {\n",
    "                            'value': sample.value,\n",
    "                            'labels': sample.labels,\n",
    "                            'type': 'gauge'\n",
    "                        }\n",
    "                \n",
    "                elif metric_type == 'histogram':\n",
    "                    histogram_data = defaultdict(dict)\n",
    "                    for sample in family.samples:\n",
    "                        key = sample.name.replace(f'{metric_name}_', '')\n",
    "                        labels_key = str(sorted(sample.labels.items()))\n",
    "                        histogram_data[labels_key][key] = sample.value\n",
    "                    \n",
    "                    parsed_metrics[metric_name] = {\n",
    "                        'type': 'histogram',\n",
    "                        'data': dict(histogram_data)\n",
    "                    }\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing metrics: {e}\")\n",
    "        \n",
    "        return parsed_metrics\n",
    "    \n",
    "    def get_specific_metrics(self, metric_patterns: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"獲取特定模式的指標\"\"\"\n",
    "        raw_metrics = self.fetch_raw_metrics()\n",
    "        if not raw_metrics:\n",
    "            return {}\n",
    "        \n",
    "        all_metrics = self.parse_metrics(raw_metrics)\n",
    "        filtered_metrics = {}\n",
    "        \n",
    "        for pattern in metric_patterns:\n",
    "            for metric_name, metric_data in all_metrics.items():\n",
    "                if pattern in metric_name:\n",
    "                    filtered_metrics[metric_name] = metric_data\n",
    "        \n",
    "        return filtered_metrics\n",
    "\n",
    "# 初始化 metrics 解析器\n",
    "metrics_parser = VLLMMetricsParser()\n",
    "print(\"✅ vLLM Metrics 解析器已初始化\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeMetricsCollector:\n",
    "    \"\"\"實時指標收集器\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_interval: float = 1.0, max_data_points: int = 1000):\n",
    "        self.collection_interval = collection_interval\n",
    "        self.max_data_points = max_data_points\n",
    "        self.running = False\n",
    "        \n",
    "        # 時間序列數據儲存\n",
    "        self.time_series_data = defaultdict(lambda: deque(maxlen=max_data_points))\n",
    "        self.timestamps = deque(maxlen=max_data_points)\n",
    "        \n",
    "        # 聚合統計\n",
    "        self.aggregated_stats = defaultdict(dict)\n",
    "        \n",
    "        # 指標定義\n",
    "        self.key_metrics = [\n",
    "            'vllm_request_success_total',\n",
    "            'vllm_request_failure_total',\n",
    "            'vllm_time_to_first_token_seconds',\n",
    "            'vllm_time_per_output_token_seconds',\n",
    "            'vllm_request_duration_seconds',\n",
    "            'vllm_num_requests_running',\n",
    "            'vllm_num_requests_waiting',\n",
    "            'vllm_gpu_cache_usage_perc'\n",
    "        ]\n",
    "        \n",
    "        # 系統指標\n",
    "        self.system_metrics = {\n",
    "            'cpu_percent': deque(maxlen=max_data_points),\n",
    "            'memory_percent': deque(maxlen=max_data_points),\n",
    "            'gpu_memory_used': deque(maxlen=max_data_points),\n",
    "            'gpu_utilization': deque(maxlen=max_data_points)\n",
    "        }\n",
    "    \n",
    "    def collect_system_metrics(self) -> Dict[str, float]:\n",
    "        \"\"\"收集系統級指標\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # CPU 和記憶體\n",
    "        metrics['cpu_percent'] = psutil.cpu_percent(interval=None)\n",
    "        metrics['memory_percent'] = psutil.virtual_memory().percent\n",
    "        \n",
    "        # GPU 指標\n",
    "        if NVIDIA_GPU_AVAILABLE:\n",
    "            try:\n",
    "                handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "                mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                util_info = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "                \n",
    "                metrics['gpu_memory_used'] = (mem_info.used / mem_info.total) * 100\n",
    "                metrics['gpu_utilization'] = util_info.gpu\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"GPU metrics collection failed: {e}\")\n",
    "                metrics['gpu_memory_used'] = 0\n",
    "                metrics['gpu_utilization'] = 0\n",
    "        else:\n",
    "            metrics['gpu_memory_used'] = 0\n",
    "            metrics['gpu_utilization'] = 0\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def collect_vllm_metrics(self) -> Dict[str, float]:\n",
    "        \"\"\"收集 vLLM 特定指標\"\"\"\n",
    "        vllm_metrics = metrics_parser.get_specific_metrics(self.key_metrics)\n",
    "        \n",
    "        # 簡化指標提取\n",
    "        simplified_metrics = {}\n",
    "        \n",
    "        for metric_name, metric_data in vllm_metrics.items():\n",
    "            if metric_data['type'] in ['counter', 'gauge']:\n",
    "                simplified_metrics[metric_name] = metric_data['value']\n",
    "            elif metric_data['type'] == 'histogram':\n",
    "                # 對於 histogram，提取關鍵統計值\n",
    "                for labels_key, hist_data in metric_data['data'].items():\n",
    "                    if 'count' in hist_data:\n",
    "                        simplified_metrics[f\"{metric_name}_count\"] = hist_data['count']\n",
    "                    if 'sum' in hist_data:\n",
    "                        simplified_metrics[f\"{metric_name}_sum\"] = hist_data['sum']\n",
    "        \n",
    "        return simplified_metrics\n",
    "    \n",
    "    def collect_single_round(self):\n",
    "        \"\"\"執行單次指標收集\"\"\"\n",
    "        timestamp = datetime.now()\n",
    "        \n",
    "        # 收集系統指標\n",
    "        system_data = self.collect_system_metrics()\n",
    "        for key, value in system_data.items():\n",
    "            self.system_metrics[key].append(value)\n",
    "        \n",
    "        # 收集 vLLM 指標\n",
    "        vllm_data = self.collect_vllm_metrics()\n",
    "        for key, value in vllm_data.items():\n",
    "            self.time_series_data[key].append(value)\n",
    "        \n",
    "        # 記錄時間戳\n",
    "        self.timestamps.append(timestamp)\n",
    "        \n",
    "        # 計算聚合統計\n",
    "        self.update_aggregated_stats()\n",
    "    \n",
    "    def update_aggregated_stats(self):\n",
    "        \"\"\"更新聚合統計數據\"\"\"\n",
    "        # 系統指標統計\n",
    "        for metric_name, values in self.system_metrics.items():\n",
    "            if len(values) > 0:\n",
    "                self.aggregated_stats[metric_name] = {\n",
    "                    'current': values[-1],\n",
    "                    'avg_5m': np.mean(list(values)[-300:]) if len(values) >= 300 else np.mean(list(values)),\n",
    "                    'max_5m': np.max(list(values)[-300:]) if len(values) >= 300 else np.max(list(values)),\n",
    "                    'min_5m': np.min(list(values)[-300:]) if len(values) >= 300 else np.min(list(values))\n",
    "                }\n",
    "        \n",
    "        # vLLM 指標統計\n",
    "        for metric_name, values in self.time_series_data.items():\n",
    "            if len(values) > 0:\n",
    "                self.aggregated_stats[metric_name] = {\n",
    "                    'current': values[-1],\n",
    "                    'avg_5m': np.mean(list(values)[-300:]) if len(values) >= 300 else np.mean(list(values)),\n",
    "                    'max_5m': np.max(list(values)[-300:]) if len(values) >= 300 else np.max(list(values)),\n",
    "                    'min_5m': np.min(list(values)[-300:]) if len(values) >= 300 else np.min(list(values))\n",
    "                }\n",
    "    \n",
    "    def start_collection(self):\n",
    "        \"\"\"開始實時收集\"\"\"\n",
    "        self.running = True\n",
    "        \n",
    "        def collection_loop():\n",
    "            while self.running:\n",
    "                try:\n",
    "                    self.collect_single_round()\n",
    "                    time.sleep(self.collection_interval)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Collection error: {e}\")\n",
    "                    time.sleep(self.collection_interval)\n",
    "        \n",
    "        # 在背景執行緒中運行\n",
    "        self.collection_thread = threading.Thread(target=collection_loop, daemon=True)\n",
    "        self.collection_thread.start()\n",
    "        \n",
    "        logger.info(f\"Started real-time metrics collection (interval: {self.collection_interval}s)\")\n",
    "    \n",
    "    def stop_collection(self):\n",
    "        \"\"\"停止實時收集\"\"\"\n",
    "        self.running = False\n",
    "        logger.info(\"Stopped real-time metrics collection\")\n",
    "    \n",
    "    def get_latest_data(self, metric_name: str, num_points: int = 60) -> tuple:\n",
    "        \"\"\"獲取最新的時間序列數據\"\"\"\n",
    "        if metric_name in self.system_metrics:\n",
    "            values = list(self.system_metrics[metric_name])[-num_points:]\n",
    "        elif metric_name in self.time_series_data:\n",
    "            values = list(self.time_series_data[metric_name])[-num_points:]\n",
    "        else:\n",
    "            return [], []\n",
    "        \n",
    "        timestamps = list(self.timestamps)[-len(values):]\n",
    "        return timestamps, values\n",
    "    \n",
    "    def get_summary_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"獲取摘要統計\"\"\"\n",
    "        return dict(self.aggregated_stats)\n",
    "\n",
    "# 初始化實時收集器\n",
    "collector = RealTimeMetricsCollector(collection_interval=2.0)\n",
    "print(\"✅ 實時指標收集器已初始化\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 動態視覺化儀表板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeDashboard:\n",
    "    \"\"\"實時監控儀表板\"\"\"\n",
    "    \n",
    "    def __init__(self, collector: RealTimeMetricsCollector):\n",
    "        self.collector = collector\n",
    "        self.fig = None\n",
    "        self.animation = None\n",
    "        \n",
    "        # 設置 matplotlib 風格\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "        \n",
    "        # 顏色配置\n",
    "        self.colors = {\n",
    "            'cpu': '#FF6B6B',\n",
    "            'memory': '#4ECDC4',\n",
    "            'gpu_memory': '#45B7D1',\n",
    "            'gpu_util': '#96CEB4',\n",
    "            'requests': '#FFEAA7',\n",
    "            'latency': '#DDA0DD'\n",
    "        }\n",
    "    \n",
    "    def create_static_dashboard(self):\n",
    "        \"\"\"創建靜態儀表板快照\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('vLLM 實時性能監控儀表板', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 系統資源監控\n",
    "        self._plot_system_metrics(axes[0, 0], 'cpu_percent', 'CPU 使用率 (%)', self.colors['cpu'])\n",
    "        self._plot_system_metrics(axes[0, 1], 'memory_percent', '記憶體使用率 (%)', self.colors['memory'])\n",
    "        self._plot_system_metrics(axes[0, 2], 'gpu_memory_used', 'GPU 記憶體使用率 (%)', self.colors['gpu_memory'])\n",
    "        \n",
    "        # vLLM 特定指標\n",
    "        self._plot_vllm_requests(axes[1, 0])\n",
    "        self._plot_vllm_latency(axes[1, 1])\n",
    "        self._plot_summary_stats(axes[1, 2])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_system_metrics(self, ax, metric_name, title, color):\n",
    "        \"\"\"繪製系統指標\"\"\"\n",
    "        timestamps, values = self.collector.get_latest_data(metric_name, 60)\n",
    "        \n",
    "        if len(values) > 0:\n",
    "            ax.plot(timestamps, values, color=color, linewidth=2)\n",
    "            ax.fill_between(timestamps, values, alpha=0.3, color=color)\n",
    "            \n",
    "            # 添加當前值標註\n",
    "            current_value = values[-1] if values else 0\n",
    "            ax.text(0.02, 0.98, f'當前: {current_value:.1f}%', \n",
    "                   transform=ax.transAxes, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        ax.set_title(title, fontweight='bold')\n",
    "        ax.set_ylabel('使用率 (%)')\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 格式化 x 軸時間顯示\n",
    "        if len(timestamps) > 0:\n",
    "            ax.set_xlim(timestamps[0], timestamps[-1])\n",
    "    \n",
    "    def _plot_vllm_requests(self, ax):\n",
    "        \"\"\"繪製 vLLM 請求指標\"\"\"\n",
    "        # 運行中的請求\n",
    "        timestamps, running = self.collector.get_latest_data('vllm_num_requests_running', 60)\n",
    "        timestamps_waiting, waiting = self.collector.get_latest_data('vllm_num_requests_waiting', 60)\n",
    "        \n",
    "        if len(running) > 0:\n",
    "            ax.plot(timestamps, running, label='運行中', color=self.colors['requests'], linewidth=2)\n",
    "        \n",
    "        if len(waiting) > 0:\n",
    "            ax.plot(timestamps_waiting, waiting, label='等待中', color='orange', linewidth=2)\n",
    "        \n",
    "        ax.set_title('vLLM 請求狀態', fontweight='bold')\n",
    "        ax.set_ylabel('請求數量')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _plot_vllm_latency(self, ax):\n",
    "        \"\"\"繪製延遲指標\"\"\"\n",
    "        # 嘗試獲取 TTFT 數據\n",
    "        timestamps, ttft_count = self.collector.get_latest_data('vllm_time_to_first_token_seconds_count', 60)\n",
    "        timestamps_sum, ttft_sum = self.collector.get_latest_data('vllm_time_to_first_token_seconds_sum', 60)\n",
    "        \n",
    "        if len(ttft_count) > 0 and len(ttft_sum) > 0:\n",
    "            # 計算平均 TTFT\n",
    "            avg_ttft = [s/c if c > 0 else 0 for s, c in zip(ttft_sum, ttft_count)]\n",
    "            ax.plot(timestamps, avg_ttft, label='TTFT 平均', color=self.colors['latency'], linewidth=2)\n",
    "        \n",
    "        ax.set_title('延遲指標', fontweight='bold')\n",
    "        ax.set_ylabel('時間 (秒)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _plot_summary_stats(self, ax):\n",
    "        \"\"\"繪製摘要統計\"\"\"\n",
    "        stats = self.collector.get_summary_stats()\n",
    "        \n",
    "        # 選擇關鍵指標顯示\n",
    "        key_stats = {\n",
    "            'CPU': stats.get('cpu_percent', {}).get('current', 0),\n",
    "            'Memory': stats.get('memory_percent', {}).get('current', 0),\n",
    "            'GPU Mem': stats.get('gpu_memory_used', {}).get('current', 0),\n",
    "            'GPU Util': stats.get('gpu_utilization', {}).get('current', 0)\n",
    "        }\n",
    "        \n",
    "        labels = list(key_stats.keys())\n",
    "        values = list(key_stats.values())\n",
    "        \n",
    "        bars = ax.bar(labels, values, \n",
    "                     color=[self.colors['cpu'], self.colors['memory'], \n",
    "                           self.colors['gpu_memory'], self.colors['gpu_util']])\n",
    "        \n",
    "        # 添加數值標籤\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{value:.1f}%', ha='center', va='bottom')\n",
    "        \n",
    "        ax.set_title('當前系統狀態', fontweight='bold')\n",
    "        ax.set_ylabel('使用率 (%)')\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def create_interactive_dashboard(self):\n",
    "        \"\"\"創建互動式 Plotly 儀表板\"\"\"\n",
    "        # 創建子圖\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=3,\n",
    "            subplot_titles=['CPU 使用率', '記憶體使用率', 'GPU 記憶體使用率',\n",
    "                          'vLLM 請求狀態', '延遲指標', '系統摘要'],\n",
    "            specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n",
    "                   [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    "        )\n",
    "        \n",
    "        # 添加 CPU 使用率\n",
    "        timestamps, cpu_values = self.collector.get_latest_data('cpu_percent', 100)\n",
    "        if len(cpu_values) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=cpu_values, \n",
    "                          mode='lines+markers', name='CPU',\n",
    "                          line=dict(color='#FF6B6B', width=2)),\n",
    "                row=1, col=1\n",
    "            )\n",
    "        \n",
    "        # 添加記憶體使用率\n",
    "        timestamps, mem_values = self.collector.get_latest_data('memory_percent', 100)\n",
    "        if len(mem_values) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=mem_values,\n",
    "                          mode='lines+markers', name='Memory',\n",
    "                          line=dict(color='#4ECDC4', width=2)),\n",
    "                row=1, col=2\n",
    "            )\n",
    "        \n",
    "        # 添加 GPU 記憶體使用率\n",
    "        timestamps, gpu_mem_values = self.collector.get_latest_data('gpu_memory_used', 100)\n",
    "        if len(gpu_mem_values) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=gpu_mem_values,\n",
    "                          mode='lines+markers', name='GPU Memory',\n",
    "                          line=dict(color='#45B7D1', width=2)),\n",
    "                row=1, col=3\n",
    "            )\n",
    "        \n",
    "        # 添加 vLLM 請求狀態\n",
    "        timestamps, running = self.collector.get_latest_data('vllm_num_requests_running', 100)\n",
    "        if len(running) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=running,\n",
    "                          mode='lines+markers', name='Running Requests',\n",
    "                          line=dict(color='#FFEAA7', width=2)),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        # 更新佈局\n",
    "        fig.update_layout(\n",
    "            title='vLLM 實時性能監控儀表板',\n",
    "            height=800,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        # 顯示圖表\n",
    "        pyo.iplot(fig)\n",
    "\n",
    "# 初始化儀表板\n",
    "dashboard = RealTimeDashboard(collector)\n",
    "print(\"✅ 實時儀表板已初始化\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 開始實時監控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開始實時指標收集\n",
    "collector.start_collection()\n",
    "\n",
    "print(\"🚀 實時監控已啟動\")\n",
    "print(\"   收集間隔: 2 秒\")\n",
    "print(\"   最大數據點: 1000\")\n",
    "print(\"   監控指標包括:\")\n",
    "print(\"   - 系統資源 (CPU, 記憶體, GPU)\")\n",
    "print(\"   - vLLM 請求指標\")\n",
    "print(\"   - 延遲和吞吐量指標\")\n",
    "print(\"\\n⏳ 等待 30 秒收集初始數據...\")\n",
    "\n",
    "# 等待收集一些初始數據\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模擬 vLLM 工作負載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLLMWorkloadSimulator:\n",
    "    \"\"\"vLLM 工作負載模擬器\"\"\"\n",
    "    \n",
    "    def __init__(self, api_base: str = \"http://127.0.0.1:8000\"):\n",
    "        self.api_base = api_base\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # 測試提示詞集合\n",
    "        self.test_prompts = [\n",
    "            \"What is the capital of France?\",\n",
    "            \"Explain quantum computing in simple terms.\",\n",
    "            \"Write a short story about a robot.\",\n",
    "            \"How do neural networks work?\",\n",
    "            \"Describe the process of photosynthesis.\",\n",
    "            \"What are the benefits of renewable energy?\",\n",
    "            \"Explain the theory of relativity.\",\n",
    "            \"Write a poem about the ocean.\"\n",
    "        ]\n",
    "    \n",
    "    def check_vllm_availability(self) -> bool:\n",
    "        \"\"\"檢查 vLLM 服務是否可用\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f\"{self.api_base}/v1/models\", timeout=5)\n",
    "            return response.status_code == 200\n",
    "        except requests.exceptions.RequestException:\n",
    "            return False\n",
    "    \n",
    "    def send_completion_request(self, prompt: str, max_tokens: int = 100) -> Dict[str, Any]:\n",
    "        \"\"\"發送完成請求\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"microsoft/DialoGPT-medium\",  # 使用配置中的模型\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.7,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = self.session.post(\n",
    "                f\"{self.api_base}/v1/completions\",\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            result = {\n",
    "                'success': response.status_code == 200,\n",
    "                'duration': duration,\n",
    "                'status_code': response.status_code,\n",
    "                'prompt_length': len(prompt),\n",
    "                'response_length': 0\n",
    "            }\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if 'choices' in data and len(data['choices']) > 0:\n",
    "                    result['response_length'] = len(data['choices'][0].get('text', ''))\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'duration': time.time() - start_time,\n",
    "                'error': str(e),\n",
    "                'prompt_length': len(prompt),\n",
    "                'response_length': 0\n",
    "            }\n",
    "    \n",
    "    async def simulate_concurrent_load(self, num_requests: int = 10, delay_range: tuple = (1, 5)):\n",
    "        \"\"\"模擬並發負載\"\"\"\n",
    "        print(f\"🔄 開始模擬 {num_requests} 個並發請求...\")\n",
    "        \n",
    "        async def single_request(request_id: int):\n",
    "            prompt = np.random.choice(self.test_prompts)\n",
    "            max_tokens = np.random.randint(50, 150)\n",
    "            \n",
    "            # 模擬請求間隔\n",
    "            await asyncio.sleep(np.random.uniform(*delay_range))\n",
    "            \n",
    "            # 同步請求 (在實際環境中應使用 aiohttp)\n",
    "            result = self.send_completion_request(prompt, max_tokens)\n",
    "            result['request_id'] = request_id\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        # 創建並發任務\n",
    "        tasks = [single_request(i) for i in range(num_requests)]\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        # 分析結果\n",
    "        successful_requests = [r for r in results if isinstance(r, dict) and r.get('success', False)]\n",
    "        failed_requests = [r for r in results if not (isinstance(r, dict) and r.get('success', False))]\n",
    "        \n",
    "        print(f\"✅ 模擬完成: {len(successful_requests)} 成功, {len(failed_requests)} 失敗\")\n",
    "        \n",
    "        if successful_requests:\n",
    "            durations = [r['duration'] for r in successful_requests]\n",
    "            print(f\"   平均延遲: {np.mean(durations):.2f}s\")\n",
    "            print(f\"   P95 延遲: {np.percentile(durations, 95):.2f}s\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def simulate_steady_load(self, duration_minutes: int = 5, requests_per_minute: int = 12):\n",
    "        \"\"\"模擬穩定負載\"\"\"\n",
    "        print(f\"🔄 開始模擬 {duration_minutes} 分鐘的穩定負載 ({requests_per_minute} 請求/分鐘)...\")\n",
    "        \n",
    "        end_time = time.time() + duration_minutes * 60\n",
    "        request_interval = 60.0 / requests_per_minute\n",
    "        request_count = 0\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        while time.time() < end_time:\n",
    "            prompt = np.random.choice(self.test_prompts)\n",
    "            max_tokens = np.random.randint(50, 150)\n",
    "            \n",
    "            result = self.send_completion_request(prompt, max_tokens)\n",
    "            result['request_id'] = request_count\n",
    "            result['timestamp'] = datetime.now()\n",
    "            \n",
    "            results.append(result)\n",
    "            request_count += 1\n",
    "            \n",
    "            if request_count % 10 == 0:\n",
    "                successful = len([r for r in results[-10:] if r.get('success', False)])\n",
    "                print(f\"   已發送 {request_count} 請求 (最近 10 個: {successful}/10 成功)\")\n",
    "            \n",
    "            # 等待下一個請求\n",
    "            time.sleep(request_interval + np.random.uniform(-0.5, 0.5))\n",
    "        \n",
    "        print(f\"✅ 穩定負載模擬完成: 總共 {request_count} 請求\")\n",
    "        return results\n",
    "\n",
    "# 初始化工作負載模擬器\n",
    "simulator = VLLMWorkloadSimulator()\n",
    "\n",
    "# 檢查 vLLM 服務可用性\n",
    "if simulator.check_vllm_availability():\n",
    "    print(\"✅ vLLM 服務已可用，可以開始負載測試\")\n",
    "    vllm_available = True\n",
    "else:\n",
    "    print(\"⚠️  vLLM 服務不可用，將跳過負載測試\")\n",
    "    print(\"   請確保 vLLM 服務正在運行: bash start_vllm_with_metrics.sh\")\n",
    "    vllm_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果 vLLM 可用，開始負載測試\n",
    "if vllm_available:\n",
    "    print(\"🚀 開始模擬工作負載...\")\n",
    "    \n",
    "    # 模擬 2 分鐘的穩定負載\n",
    "    load_results = simulator.simulate_steady_load(duration_minutes=2, requests_per_minute=6)\n",
    "    \n",
    "    print(\"\\n📊 負載測試結果分析:\")\n",
    "    successful_results = [r for r in load_results if r.get('success', False)]\n",
    "    \n",
    "    if successful_results:\n",
    "        durations = [r['duration'] for r in successful_results]\n",
    "        print(f\"   成功請求: {len(successful_results)}/{len(load_results)}\")\n",
    "        print(f\"   平均延遲: {np.mean(durations):.2f}s\")\n",
    "        print(f\"   中位數延遲: {np.median(durations):.2f}s\")\n",
    "        print(f\"   P95 延遲: {np.percentile(durations, 95):.2f}s\")\n",
    "        print(f\"   最大延遲: {np.max(durations):.2f}s\")\n",
    "else:\n",
    "    print(\"⏭️  跳過負載測試，繼續進行監控數據分析\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 實時監控儀表板展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成靜態儀表板\n",
    "print(\"📊 生成實時監控儀表板...\")\n",
    "dashboard.create_static_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示詳細的統計摘要\n",
    "def display_detailed_stats():\n",
    "    stats = collector.get_summary_stats()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📈 詳細監控統計摘要\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 系統資源統計\n",
    "    print(\"\\n🖥️  系統資源使用情況:\")\n",
    "    system_metrics = ['cpu_percent', 'memory_percent', 'gpu_memory_used', 'gpu_utilization']\n",
    "    \n",
    "    for metric in system_metrics:\n",
    "        if metric in stats:\n",
    "            data = stats[metric]\n",
    "            print(f\"   {metric:20}: 當前 {data.get('current', 0):6.1f}% | \"\n",
    "                  f\"5分鐘平均 {data.get('avg_5m', 0):6.1f}% | \"\n",
    "                  f\"最大 {data.get('max_5m', 0):6.1f}%\")\n",
    "    \n",
    "    # vLLM 指標統計\n",
    "    print(\"\\n🤖 vLLM 服務指標:\")\n",
    "    vllm_metrics = [k for k in stats.keys() if k.startswith('vllm_')]\n",
    "    \n",
    "    if vllm_metrics:\n",
    "        for metric in sorted(vllm_metrics)[:10]:  # 顯示前 10 個指標\n",
    "            data = stats[metric]\n",
    "            print(f\"   {metric:35}: {data.get('current', 0):8.2f} | \"\n",
    "                  f\"平均 {data.get('avg_5m', 0):8.2f}\")\n",
    "    else:\n",
    "        print(\"   暫無 vLLM 指標數據 (服務可能未運行)\")\n",
    "    \n",
    "    # 數據收集統計\n",
    "    print(\"\\n📊 數據收集統計:\")\n",
    "    print(f\"   收集時間點: {len(collector.timestamps)}\")\n",
    "    print(f\"   收集間隔: {collector.collection_interval} 秒\")\n",
    "    print(f\"   運行狀態: {'活躍' if collector.running else '已停止'}\")\n",
    "    \n",
    "    if len(collector.timestamps) >= 2:\n",
    "        duration = (collector.timestamps[-1] - collector.timestamps[0]).total_seconds()\n",
    "        print(f\"   監控時長: {duration:.0f} 秒 ({duration/60:.1f} 分鐘)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "display_detailed_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 進階指標分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedMetricsAnalyzer:\n",
    "    \"\"\"進階指標分析器\"\"\"\n",
    "    \n",
    "    def __init__(self, collector: RealTimeMetricsCollector):\n",
    "        self.collector = collector\n",
    "    \n",
    "    def analyze_resource_correlation(self):\n",
    "        \"\"\"分析資源使用相關性\"\"\"\n",
    "        print(\"🔍 分析系統資源使用相關性...\")\n",
    "        \n",
    "        # 獲取系統指標數據\n",
    "        _, cpu_data = self.collector.get_latest_data('cpu_percent', 1000)\n",
    "        _, memory_data = self.collector.get_latest_data('memory_percent', 1000)\n",
    "        _, gpu_memory_data = self.collector.get_latest_data('gpu_memory_used', 1000)\n",
    "        _, gpu_util_data = self.collector.get_latest_data('gpu_utilization', 1000)\n",
    "        \n",
    "        if len(cpu_data) < 10:\n",
    "            print(\"   數據點不足，無法進行相關性分析\")\n",
    "            return\n",
    "        \n",
    "        # 創建 DataFrame\n",
    "        min_len = min(len(cpu_data), len(memory_data), len(gpu_memory_data), len(gpu_util_data))\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'CPU': cpu_data[-min_len:],\n",
    "            'Memory': memory_data[-min_len:],\n",
    "            'GPU_Memory': gpu_memory_data[-min_len:],\n",
    "            'GPU_Util': gpu_util_data[-min_len:]\n",
    "        })\n",
    "        \n",
    "        # 計算相關性矩陣\n",
    "        correlation_matrix = df.corr()\n",
    "        \n",
    "        # 視覺化相關性\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # 相關性熱力圖\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                   square=True, linewidths=0.5)\n",
    "        plt.title('系統資源使用相關性')\n",
    "        \n",
    "        # 散點圖矩陣\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.scatter(df['CPU'], df['Memory'], alpha=0.6, color='blue')\n",
    "        plt.xlabel('CPU 使用率 (%)')\n",
    "        plt.ylabel('記憶體使用率 (%)')\n",
    "        plt.title('CPU vs Memory')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.scatter(df['GPU_Memory'], df['GPU_Util'], alpha=0.6, color='green')\n",
    "        plt.xlabel('GPU 記憶體使用率 (%)')\n",
    "        plt.ylabel('GPU 使用率 (%)')\n",
    "        plt.title('GPU Memory vs GPU Utilization')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 時間序列趨勢\n",
    "        plt.subplot(2, 2, 4)\n",
    "        timestamps = list(range(len(df)))\n",
    "        plt.plot(timestamps, df['CPU'], label='CPU', alpha=0.7)\n",
    "        plt.plot(timestamps, df['Memory'], label='Memory', alpha=0.7)\n",
    "        plt.plot(timestamps, df['GPU_Memory'], label='GPU Mem', alpha=0.7)\n",
    "        plt.xlabel('時間點')\n",
    "        plt.ylabel('使用率 (%)')\n",
    "        plt.title('資源使用趨勢')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return correlation_matrix\n",
    "    \n",
    "    def detect_anomalies(self, metric_name: str, threshold_std: float = 2.0):\n",
    "        \"\"\"檢測指標異常值\"\"\"\n",
    "        timestamps, values = self.collector.get_latest_data(metric_name, 1000)\n",
    "        \n",
    "        if len(values) < 20:\n",
    "            print(f\"   {metric_name}: 數據點不足，無法檢測異常\")\n",
    "            return []\n",
    "        \n",
    "        # 使用滑動平均和標準差檢測異常\n",
    "        window_size = min(20, len(values) // 4)\n",
    "        \n",
    "        anomalies = []\n",
    "        \n",
    "        for i in range(window_size, len(values)):\n",
    "            window_data = values[i-window_size:i]\n",
    "            mean_val = np.mean(window_data)\n",
    "            std_val = np.std(window_data)\n",
    "            \n",
    "            current_val = values[i]\n",
    "            \n",
    "            if abs(current_val - mean_val) > threshold_std * std_val:\n",
    "                anomalies.append({\n",
    "                    'timestamp': timestamps[i],\n",
    "                    'value': current_val,\n",
    "                    'expected_range': (mean_val - threshold_std * std_val,\n",
    "                                     mean_val + threshold_std * std_val),\n",
    "                    'deviation': abs(current_val - mean_val) / std_val if std_val > 0 else 0\n",
    "                })\n",
    "        \n",
    "        return anomalies\n",
    "    \n",
    "    def generate_performance_report(self):\n",
    "        \"\"\"生成性能報告\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📋 vLLM 性能分析報告\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 系統資源分析\n",
    "        print(\"\\n🔍 異常檢測結果:\")\n",
    "        \n",
    "        metrics_to_check = ['cpu_percent', 'memory_percent', 'gpu_memory_used', 'gpu_utilization']\n",
    "        \n",
    "        total_anomalies = 0\n",
    "        for metric in metrics_to_check:\n",
    "            anomalies = self.detect_anomalies(metric, threshold_std=2.0)\n",
    "            total_anomalies += len(anomalies)\n",
    "            \n",
    "            if anomalies:\n",
    "                print(f\"   {metric}: 發現 {len(anomalies)} 個異常點\")\n",
    "                # 顯示最嚴重的異常\n",
    "                worst_anomaly = max(anomalies, key=lambda x: x['deviation'])\n",
    "                print(f\"     最嚴重異常: {worst_anomaly['value']:.1f} (偏差 {worst_anomaly['deviation']:.1f}σ)\")\n",
    "            else:\n",
    "                print(f\"   {metric}: 無異常檢測\")\n",
    "        \n",
    "        if total_anomalies == 0:\n",
    "            print(\"   ✅ 系統運行穩定，未檢測到顯著異常\")\n",
    "        \n",
    "        # 性能摘要\n",
    "        stats = self.collector.get_summary_stats()\n",
    "        \n",
    "        print(\"\\n📊 性能摘要:\")\n",
    "        \n",
    "        # 資源使用效率評估\n",
    "        cpu_avg = stats.get('cpu_percent', {}).get('avg_5m', 0)\n",
    "        memory_avg = stats.get('memory_percent', {}).get('avg_5m', 0)\n",
    "        gpu_memory_avg = stats.get('gpu_memory_used', {}).get('avg_5m', 0)\n",
    "        \n",
    "        print(f\"   平均 CPU 使用率: {cpu_avg:.1f}%\")\n",
    "        print(f\"   平均記憶體使用率: {memory_avg:.1f}%\")\n",
    "        print(f\"   平均 GPU 記憶體使用率: {gpu_memory_avg:.1f}%\")\n",
    "        \n",
    "        # 效率評估\n",
    "        if cpu_avg < 20:\n",
    "            print(\"   💡 CPU 使用率較低，可考慮增加負載\")\n",
    "        elif cpu_avg > 80:\n",
    "            print(\"   ⚠️  CPU 使用率過高，建議優化或擴容\")\n",
    "        \n",
    "        if gpu_memory_avg < 30 and NVIDIA_GPU_AVAILABLE:\n",
    "            print(\"   💡 GPU 記憶體使用率較低，可考慮增加批次大小\")\n",
    "        elif gpu_memory_avg > 90:\n",
    "            print(\"   ⚠️  GPU 記憶體使用率過高，建議減少批次大小\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# 創建進階分析器\n",
    "analyzer = AdvancedMetricsAnalyzer(collector)\n",
    "\n",
    "# 執行分析\n",
    "print(\"🔬 執行進階指標分析...\")\n",
    "correlation_matrix = analyzer.analyze_resource_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成性能報告\n",
    "analyzer.generate_performance_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 監控數據導出與儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_monitoring_data():\n",
    "    \"\"\"導出監控數據\"\"\"\n",
    "    print(\"💾 導出監控數據...\")\n",
    "    \n",
    "    # 準備導出數據\n",
    "    export_data = {\n",
    "        'metadata': {\n",
    "            'export_time': datetime.now().isoformat(),\n",
    "            'collection_interval': collector.collection_interval,\n",
    "            'total_data_points': len(collector.timestamps),\n",
    "            'monitoring_duration_seconds': (collector.timestamps[-1] - collector.timestamps[0]).total_seconds() if len(collector.timestamps) >= 2 else 0\n",
    "        },\n",
    "        'timestamps': [ts.isoformat() for ts in collector.timestamps],\n",
    "        'system_metrics': {},\n",
    "        'vllm_metrics': {},\n",
    "        'aggregated_stats': dict(collector.aggregated_stats)\n",
    "    }\n",
    "    \n",
    "    # 導出系統指標\n",
    "    for metric_name, values in collector.system_metrics.items():\n",
    "        export_data['system_metrics'][metric_name] = list(values)\n",
    "    \n",
    "    # 導出 vLLM 指標\n",
    "    for metric_name, values in collector.time_series_data.items():\n",
    "        export_data['vllm_metrics'][metric_name] = list(values)\n",
    "    \n",
    "    # 儲存為 JSON 檔案\n",
    "    filename = f\"vllm_monitoring_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ 監控數據已導出到: {filename}\")\n",
    "    \n",
    "    # 同時導出為 CSV 格式 (便於分析)\n",
    "    if len(collector.timestamps) > 0:\n",
    "        # 創建 DataFrame\n",
    "        df_data = {'timestamp': [ts.isoformat() for ts in collector.timestamps]}\n",
    "        \n",
    "        # 添加系統指標\n",
    "        for metric_name, values in collector.system_metrics.items():\n",
    "            # 確保長度一致\n",
    "            padded_values = list(values) + [None] * (len(collector.timestamps) - len(values))\n",
    "            df_data[metric_name] = padded_values[:len(collector.timestamps)]\n",
    "        \n",
    "        # 添加部分 vLLM 指標\n",
    "        for metric_name, values in list(collector.time_series_data.items())[:10]:  # 限制數量\n",
    "            padded_values = list(values) + [None] * (len(collector.timestamps) - len(values))\n",
    "            df_data[metric_name] = padded_values[:len(collector.timestamps)]\n",
    "        \n",
    "        df = pd.DataFrame(df_data)\n",
    "        csv_filename = filename.replace('.json', '.csv')\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"✅ CSV 格式數據已導出到: {csv_filename}\")\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# 導出數據\n",
    "export_filename = export_monitoring_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 清理與停止監控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停止監控收集\n",
    "print(\"🛑 停止實時監控收集...\")\n",
    "collector.stop_collection()\n",
    "\n",
    "# 最終統計\n",
    "final_stats = collector.get_summary_stats()\n",
    "print(f\"\\n📊 最終監控統計:\")\n",
    "print(f\"   總監控時間: {len(collector.timestamps)} 個數據點\")\n",
    "print(f\"   系統指標類型: {len(collector.system_metrics)}\")\n",
    "print(f\"   vLLM 指標類型: {len(collector.time_series_data)}\")\n",
    "\n",
    "if len(collector.timestamps) >= 2:\n",
    "    duration = (collector.timestamps[-1] - collector.timestamps[0]).total_seconds()\n",
    "    print(f\"   監控持續時間: {duration:.0f} 秒 ({duration/60:.1f} 分鐘)\")\n",
    "\n",
    "print(\"\\n✅ 實時監控實驗完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實驗總結\n",
    "\n",
    "本實驗成功建立了完整的 vLLM 實時監控系統，涵蓋以下核心功能：\n",
    "\n",
    "### ✅ 完成項目\n",
    "\n",
    "1. **實時指標收集**\n",
    "   - vLLM 原生 Prometheus 指標解析\n",
    "   - 系統資源監控 (CPU, 記憶體, GPU)\n",
    "   - 高頻率數據收集 (2秒間隔)\n",
    "\n",
    "2. **動態監控視覺化**\n",
    "   - 多面板實時儀表板\n",
    "   - 系統資源使用趨勢圖\n",
    "   - vLLM 服務狀態監控\n",
    "\n",
    "3. **進階分析功能**\n",
    "   - 資源使用相關性分析\n",
    "   - 異常檢測算法\n",
    "   - 性能評估報告\n",
    "\n",
    "4. **工作負載模擬**\n",
    "   - 並發請求模擬\n",
    "   - 穩定負載測試\n",
    "   - 延遲性能分析\n",
    "\n",
    "5. **數據管理**\n",
    "   - 時間序列數據儲存\n",
    "   - JSON/CSV 格式導出\n",
    "   - 聚合統計計算\n",
    "\n",
    "### 🎯 核心成果\n",
    "\n",
    "- **實時監控架構**: 建立了可擴展的監控數據收集架構\n",
    "- **指標解析引擎**: 開發了 Prometheus 格式指標的解析器\n",
    "- **異常檢測**: 實現了基於統計的異常檢測機制\n",
    "- **性能分析**: 提供了全面的性能評估和優化建議\n",
    "\n",
    "### 📈 監控指標覆蓋\n",
    "\n",
    "- **系統層**: CPU, 記憶體, GPU 使用率\n",
    "- **應用層**: vLLM 請求狀態, 延遲指標\n",
    "- **業務層**: 吞吐量, 錯誤率, 併發數\n",
    "\n",
    "### 🔧 技術特點\n",
    "\n",
    "- **非阻塞收集**: 使用多執行緒實現背景數據收集\n",
    "- **記憶體效率**: 滑動視窗限制數據點數量\n",
    "- **容錯設計**: 網路異常和服務不可用的處理\n",
    "- **標準化輸出**: 支援多種數據格式導出\n",
    "\n",
    "### 📋 下一步\n",
    "\n",
    "繼續進行 **03-Performance_Analysis.ipynb**，學習深度性能分析和瓶頸診斷技術。\n",
    "\n",
    "---\n",
    "\n",
    "**注意事項**:\n",
    "- 生產環境建議調整收集頻率以節省資源\n",
    "- 長期監控需要配置數據保留策略\n",
    "- 異常檢測閾值需要根據實際業務調整\n",
    "- 建議結合 Grafana 實現更豐富的視覺化效果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}